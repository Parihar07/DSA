{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment_3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"l-lz7-0HC24p","colab_type":"text"},"cell_type":"markdown","source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"kXbkLeOBC24q","colab_type":"text"},"cell_type":"markdown","source":["The objective of this experiment is to understand CNN."]},{"metadata":{"id":"BJTDrSwHC24s","colab_type":"text"},"cell_type":"markdown","source":["In this experiment we will be using MNIST database. The MNIST database is a dataset of handwritten digits. It has 60,000 training samples, and 10,000 test samples. Each image is represented by 28 x 28 pixels, each containing a value 0 - 255 with its gray scale value.\n","\n","It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n","\n","It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."]},{"metadata":{"id":"DlEtqiEzC24u","colab_type":"text"},"cell_type":"markdown","source":["As we saw in the lecture, deep learning programming involves the following steps:\n","\n","1. Load the data\n","2. Specifying a Neural Network Model \n","3. Specify the Loss function and Gradient Update Algorithm\n","4. Training Loop \n","5. Compute the Accuracy on Testing dataset\n"]},{"metadata":{"id":"WYWYt6vxC24v","colab_type":"text"},"cell_type":"markdown","source":["#### Convolutional Neural Network (CNN)\n","\n","CNNs is the neural network layer used when working with image data. In this notebook, we will see how to implement CNN based neural networks.  We will be using the [pytorch](http://pytorch.org/) deep learning library. Please have a look at the pytorch website. It has more additional material, specifically:\n","- The pytorch website has a many [tutorials](http://pytorch.org/tutorials/) that you can follow additionally.\n","- There is also an [api reference](http://pytorch.org/docs/0.3.1/), for referring the definitions of functions and classes."]},{"metadata":{"id":"DwX_qLYMC24w","colab_type":"text"},"cell_type":"markdown","source":["### Keywords\n","\n","* CNN\n","* Minibatch\n","* Pooling\n","* Convolutions\n","* Filters\n","* Padding\n","* ReLU\n","* Softmax\n","* CrossEntorpyloss\n","* Adam"]},{"metadata":{"id":"s7YW-8DFC24x","colab_type":"text"},"cell_type":"markdown","source":["### Expected time to complete the experiment is : 90 min"]},{"metadata":{"id":"KURh0ytEsEsI","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"800\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/week_11/module_3_week_11_experiment_3.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zEPfO7gbDATX","colab_type":"text"},"cell_type":"markdown","source":["### Setup Steps"]},{"metadata":{"id":"vdTGBB-iDEJi","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7tlCjgEKDHVV","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"boZF0fp0Ibbf","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M3W11_SAT_EXP_3\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx pip3 install torchvision\")\n","    ipython.magic(\"sx pip install Pillow==4.0.0\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful.\")\n","      print(\"Ref Id:\", submission_id)\n","      print(\"Date of submission: \", datetime.datetime.now().date().strftime(\"%d %b %Y\"))\n","      print(\"Time of submission: \", datetime.datetime.now().time().strftime(\"%H:%M:%S\"))\n","      print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n","      print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Bikcf-BRC24z","colab_type":"text"},"cell_type":"markdown","source":["#### Importing Required Packages"]},{"metadata":{"id":"3GuIxHsqC240","colab_type":"code","colab":{}},"cell_type":"code","source":["# Importing torch library, which is a popular one for deep learning\n","import torch\n","import torch.nn as nn\n","import torch.utils as utils\n","from torch.autograd import Variable\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.utils.data as Data\n","import torch.nn.functional as F\n","\n","# OS is a standard python library, which we use for accessing the file system.\n","import os\n","\n","# Matplotllib is used for ploting graphs\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from IPython import display"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EUarXxbEC246","colab_type":"text"},"cell_type":"markdown","source":["## Step 1: Loading the data\n","We will be using the MNIST handwritten images dataset. The dataset is split in to 2 parts:\n","- train which consists of 60000 images \n","- test of 10000 images. \n","\n","These images are represeted as a 28x28 matrix."]},{"metadata":{"id":"A_kdK9FgC247","colab_type":"code","colab":{}},"cell_type":"code","source":["# Some code, to check if dataset is already downloaded.\n","DOWNLOAD_MNIST = True\n","if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n","    DOWNLOAD_MNIST = True\n","\n","# Loading the training data\n","mnist_train = torchvision.datasets.MNIST(\n","    root='./mnist/',\n","    train=True,                                     # this is training data\n","    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n","                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n","    download=DOWNLOAD_MNIST,\n",")\n","\n","# Similarly loading the testing data\n","mnist_test = torchvision.datasets.MNIST(\n","    root='./mnist/',\n","    train=False,                                     \n","    transform=torchvision.transforms.ToTensor(),    \n","    download=DOWNLOAD_MNIST,\n",")\n","\n","\n","# ploting one example\n","print(\"Shape of the training data (no of images, height, width) : \", mnist_train.train_data.size()) # (60000, 28, 28)\n","print(\"Shape of the testing data (no of images, height, width) : \", mnist_test.test_data.size())  # (10000, 28, 28)\n","print(\"\\n\")\n","print(\"###### An Example Image, Label pair ############\")\n","plt.imshow(mnist_train.train_data[0].numpy(), cmap='gray')\n","plt.title('Label : %i' % mnist_train.train_labels[0])\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z2--teHtC25E","colab_type":"text"},"cell_type":"markdown","source":["### Minibatch\n","Machine learning dataset can be really large. Hence we cannot often load the entire data in to the memory. Hence neural network training is done by loading small batches (commonly called minibatch) of data, and using it to update the learnable parameters (weights and biases) of the model."]},{"metadata":{"id":"PfXCm8nTC25F","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 1000 # The mini batch size used for doing the training\n","\n","# Data Loader for easy mini-batch loading,\n","# the image batch shape will be (batch_size, 1, 28, 28)\n","train_loader = Data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True)\n","test_loader = Data.DataLoader(dataset=mnist_test, batch_size=batch_size, shuffle=True)\n","\n","count = 0\n","for mini_batch in train_loader:\n","    images, labels = mini_batch\n","    print('Mini batch size: images -', images.size(), ' labels - ', labels.size())\n","    for j in range(batch_size):\n","        print(images[j].size(), labels[j])\n","        plt.imshow(images[j][0].numpy(), cmap='gray')\n","        plt.title('Label : %i' % labels[j])\n","        plt.show()\n","\n","# Some logic to break the loops so that we dont print the whole dataset.\n","        if j == 1:\n","            break\n","    if count == 1:\n","        break\n","        \n","    count +=1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QIgeu0AqC25L","colab_type":"text"},"cell_type":"markdown","source":["## Step 2: Defining a CNN based Neural Network\n","Now we will define a CNN based neural network, that takes input the 28x28 MNIST images and predicts a label from 0 to 9. The predictions will be of the form of a probability distribution given as an array $P$ of length 10, where each entry $P_i$  denotes the probability of the input image being the digit $i$.\n","\n","We will divide the neural network into two parts. First is the feature extractor, which given the 28x28 images, gives a feature vector. The feature extractor is a CNN based neural network. Second is a classifier, which takes the feature vector as input and produces a 10 dimensional vector called the logits. Finally the logits are converted in the prediction probabilities by applying the softmax function\n","\n","The Deep CNN we will be using is called LeNet. A pictorial representation is given bellow:\n","![alt text](http://eblearn.sourceforge.net/lib/exe/lenet5.png \"Title\")\n","\n","As you can see, the neural network has multiple operations happening one after another. Each operation has learnable parameters (weights and biases). Typically we call them the layers of a neural network. Neural networks can have many layers, and are hence called Deep Neural Networks (DNNs) or Deep CNNs. LeNet feature extractor shown above has the following layers:\n","\n","1. Convolutional layer which:\n","    1. takes an image with 1 channel (since MNIST digits are black and white; for color images, they are represented by 3 channels giving the intensities of Red, Blue and Green) : 1x28x28\n","    2. convolves with 6 filters (weights) of kernel size 5x5 and stride 1\n","    3. without padding\n","    4. so, gives a 6x24x24 tensor as output\n","2. Subsampling or MaxPooling (which reduces the height and width by half). Here we are doing 2x2-MaxPooling which takes the maximum value of every non-overlapping 2x2 window: outputs a 6x12x12 tensor\n","3. ReLU activation function applied to every entry of the tensor\n","4. Convolutional layer which:\n","    1. takes a tensor with 6 channels: 6x12x12\n","    2. convolves with 16 filters of kernel size 5x5 and stride 1\n","    3. so, gives a 16x8x8 tensor as output\n","4. MaxPooling: gives a 16x4x4 tensor as output\n","5. ReLU\n","\n","Note that output of the above neural network is a 3D tensor. This is because the input is a 3D tensor (with one dimension =1) and Convolutional and Max-Pooling layers give 3D tensors as output. Next we will reshape this 3D tensor into a long vector and pass it through the classifier network. Classifier network is typically a Multi-Layered Perceptron Network that you have seen previously.\n","\n"]},{"metadata":{"id":"4KFQv7tOC25M","colab_type":"code","colab":{}},"cell_type":"code","source":["# A CNN based Feature extractor\n","# Definining neural network in python by a class which inherits from nn.Module\n","class LeNet(nn.Module):\n","    \"\"\"LeNet feature extractor model.\"\"\"\n","\n","    def __init__(self):\n","        \"\"\"Init LeNet feature extractor model.\"\"\"\n","        super(LeNet, self).__init__()\n","\n","        # Defining the CNNfeature Extractor\n","        self.feature_extractor = nn.Sequential(\n","            # input [1 x 28 x 28]\n","            # 1st conv layer\n","            # Conv which convolves input image with 6 filters of 5x5 size, without padding\n","            nn.Conv2d(1, 6, kernel_size=5),\n","            # [6 x 24 x 24]\n","            nn.MaxPool2d(kernel_size=2), # Max pooling subsampling operation\n","            # [6 x 12 x 12]\n","            nn.ReLU(), # Non linear activation function\n","            # 2nd conv layer\n","            # input [6 x 12 x 12]\n","            # Conv which convolves input image with 16 filters of 5x5 size, without padding\n","            nn.Conv2d(6, 16, kernel_size=5),\n","            # [16 x 8 x 8]\n","            nn.MaxPool2d(kernel_size=2),\n","            # [16 x 4 x 4]\n","            nn.ReLU()\n","        )\n","        \n","        # Defining the Classifier\n","        self.classifier = nn.Sequential(\n","            # Linear layer with 120 nodes, taking a flattened [16 x 4 x 4] as input\n","            nn.Linear(16 * 4 * 4, 120),\n","            # Linear layer with 84 nodes\n","            nn.Linear(120, 84),\n","            # ReLU\n","            nn.ReLU(),\n","            # Output layer with as many nodes as number of classes\n","            nn.Linear(84, 10)\n","        )\n","        \n","    def forward(self, input):\n","        \"\"\"Define a Forward pass of the LeNet.\"\"\"\n","        out = self.feature_extractor(input) # Pass input through the feature extractor\n","        out = out.view(-1, 16 * 4 * 4) # Reshape the 2D to a vector\n","        out = self.classifier(out) # pass features through the classifier to get predictions\n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KlUPMA6NC25Q","colab_type":"text"},"cell_type":"markdown","source":["Next we will inspect our model, and see the parameters in each layer. Note that the activation and MaxPooling layers do not have any learnable parameters. Also note the sizes of parameters of each layer.\n","\n","- For convolutional layer weights, it is input channels x output_channels x window_width x window_height.\n","- For convolutional layer biases, it is output_channels.\n","- For linear layer weights, it is input_size x output_size\n","- For linear layer biases, it is output_size\n","\n","**Exercise 1**: Change the kernel sizes and channels in the LeNet model definition and see how the number of parameter change here."]},{"metadata":{"id":"4uPkNRmsC25R","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create an instance of the model\n","lenet = LeNet()\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","lenet = lenet.to(device)\n","\n","# Print out the size of parameters of each layer\n","for name, param in lenet.state_dict().items():\n","    print(name, '\\n', param.size(), '\\n')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pox6ItueC25X","colab_type":"text"},"cell_type":"markdown","source":["### Do a Forward Pass (an example), and compute accuracy\n","\n","The code below loops over the test data, does forward pass and compute the accuracy on the testing data. The weights and biases of the network are randomly initialized by default. Hence the prediction accuracy currently is very close to a random guess of the labels which is 1/10 = 10%.\n","\n","The step is done as the last step in typical deep learning program. It is given here just for illustrating Forward pass."]},{"metadata":{"id":"y7mMsccnC25Z","colab_type":"code","colab":{}},"cell_type":"code","source":["correct = 0.0\n","total = 0.0\n","for mini_batch in train_loader:\n","    images, labels = mini_batch\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    \n","    # Do the Forward pass\n","    result = lenet(images)\n","    \n","    # Covert the predictions to probabilities, by applying the softmax function\n","    result = F.softmax(result)\n"," \n","    # Find the prediction with the largest probability\n","    _,pred = torch.max(result.data,1)\n","    #print(pred)\n","    total += labels.size(0)\n","    #print(labels)\n","    # correct is incremented by the numer of predictions which are correct (equal to the ground truth labels)\n","    correct += (pred == labels).sum().item()\n","    #print((pred == labels).sum())\n","print(\"Accuracy of Test Data: {0:.2f}%\".format(100 * correct/total))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R8ZaomZlC25e","colab_type":"text"},"cell_type":"markdown","source":["## Step 3: Loss Function  and Gradient Update Algorithm\n","\n","The **loss function** is a way of measuring the difference between the current prediction of the network and the correct prediction. As we saw in the lecture, the gradient descent algorithm is essentially adjusting the learnable parameters (weights and biases) of the network so as to decrease the loss. Here we will be using the **cross entropy loss**, which is commonly used for classification task (predicting a class from 0 to 9).\n","\n","The **learning rate** is a small fraction which is used to multiply the gradients of the loss function with respect to the weights. The idea behind doing this is that, we do not want to make drastic changes the weights of the neural network in each step, but rather a gradual one. \n","\n","**Exercise 2:** Try with different values of the learning rate and see how it affects the training. You should observe that if learning rate is very small, the model hardly learns (that is produces less accuracy). \n","\n","Finding the optimal learning rate is often a trail and error method. However some gradient update algorithms can automatically find the right learning rate. \n","\n","Finally we also need to specify the gradient update algorithm. "]},{"metadata":{"id":"iQRWcL7fC25f","colab_type":"code","colab":{}},"cell_type":"code","source":["loss_func = nn.CrossEntropyLoss()\n","\n","# Set the learning rate\n","learning_rate = 0.001\n","\n","optimizer = torch.optim.Adam(lenet.parameters(), lr=learning_rate)\n","# optimizer = torch.optim.SGD(lenet.parameters(), lr=learning_rate, momentum=0.0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V5vKPAKCC25k","colab_type":"text"},"cell_type":"markdown","source":["## Step 4: Training Loop\n","Now that have loaded the data, defined the neural network, specified the loss function and optimizer algorithm, we can do the training. The training is done by loading a part of the training data, called minibatch. The size of the minibatch is specified by the batch_size.  We will load one minibatch at a time and do forward as well as backward pass on the model. We will keep doing thing by looping over the entire dataset.\n","\n","As we progress in the loop, we also plot the loss function to see if it is indeed decreasing. Ploting also helps in observing when the model has stoped learning. We will say that the model has stopped learning when the plotted loss curve becomes horizontal.\n","\n","**Exersise 3:** Try increasing the epochs and see if it improves the accuracy. You can keep increasing the epochs untill the tail of the loss curve becomes horizontal. Observe that further increase in epochs does not increase accuracy.\n","\n","**Exercise 4:** Try decreasing the learning rate and increasing the epochs. Try with differet values and achieve >95% accuracy.\n","\n","**Exercise 5:** Try  increasing the intermediate channels in the LeNet definition and adjust the learning rate, epochs to achieve >98% accuracy.\n","\n","\n","**Exercise 6:** Set the use_gpu flag to False in the beggining code and observe the slower running time.\n","\n","**Exercise 7:** Try computing the accuracy on the training data also (similar to how it was computed for testing data, seen previously."]},{"metadata":{"id":"ouOCz2SXC25l","colab_type":"code","colab":{}},"cell_type":"code","source":["# The number of times we should iterate over the training data. 1 epoch = 1 pass over the training data\n","epoch = 8\n","\n","# Train Model with train data\n","\n","loss_history = []\n","\n","for i in range(epoch):\n","    print('####### Epoch ', i)\n","    for j,[image,label] in enumerate(train_loader):\n","        # You can try with and without using GPUs, by setting this variable before the loop\n","       # if use_gpu == \"cuda\":\n","        image = image.to(device)\n","        label = label.to(device)\n","            \n","        #image = image\n","        #label = label\n","        \n","        \n","        optimizer.zero_grad() # zero out the gradients from the preivous step \n","        predictions = lenet.forward(image) # Do forward pass on the current mini batch\n","        loss = loss_func(predictions, label) # Compute loss on the current mini batch\n","        loss.backward() # Do backward pass. That is compute all the gradients for the current minibatch\n","        optimizer.step() # Update the parameters using the gradients with the learning rate\n","        \n","        if j % 100 == 0:\n","            loss_history.append(loss.item())\n","                    \n","        # display.clear_output(wait=True)\n","plt.plot(loss_history)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j2fo6SPxC25r","colab_type":"text"},"cell_type":"markdown","source":["## Step 5: Compute the Accuracy of the Model on the Test data\n","Finally we need to check how well the model is doing on the testing data. This step is also done by loading the data one minibatch at a time and computing the accuracy, which is finally averaged."]},{"metadata":{"id":"CKk8LeBdC25t","colab_type":"code","colab":{}},"cell_type":"code","source":["correct = 0.0\n","total = 0.0\n","for mini_batch in test_loader:\n","    images, labels = mini_batch\n","    \n","    # You can try with and without using GPUs, by setting this variable before the loop\n","    #if use_gpu == \"cuda\":\n","    images = images.to(device)\n","    labels = labels.to(device)\n","        \n","    #images = images\n","    \n","    # Doing the Forward pass\n","    result = lenet(images)\n","    \n","    # Coverting the predictions to probabilities, by applying the softmax function\n","    result = F.softmax(result)\n"," \n","    # Finding the prediction with the largest probability\n","    _,pred = torch.max(result.data,1)\n","    \n","    total += labels.size(0)\n","    # correct is incremented by the numer of prediction which are correct (equal to the ground truth labels)\n","    correct += (pred == labels).sum().item()\n","    \n","print(\"Accuracy of Test Data: {0:.2f}%\".format(correct/total *100))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CNkrKEJ6Dpqj","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"metadata":{"id":"U9qdvFgdC253","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"q2sl-opiD21j","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hf_4nElyD5Xd","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C_CaxhdpD6-B","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DVjTRJ12Isen","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}