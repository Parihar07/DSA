{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment_1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"2gD6DFr189TS","colab_type":"text"},"cell_type":"markdown","source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"ZB02l4Uq89TU","colab_type":"text"},"cell_type":"markdown","source":["In this experiment we will see the Auto Encoder neural network."]},{"metadata":{"id":"8WcX9NWy89TV","colab_type":"text"},"cell_type":"markdown","source":["In this experiment we will be using MNIST database. The MNIST database is a dataset of handwritten digits. It has 60,000 training samples, and 10,000 test samples. Each image is represented by 28 x 28 pixels, each containing a value 0 - 255 with its gray scale value.\n","\n","It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n","\n","It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."]},{"metadata":{"id":"ePRlli9a89TX","colab_type":"text"},"cell_type":"markdown","source":["**Auto Encoders** are a specific type of feedforward neural networks where the input is the same as the output. They compress the input into a lower-dimensional code and then reconstruct the output from this representation."]},{"metadata":{"id":"_bjWAXXT89TY","colab_type":"text"},"cell_type":"markdown","source":["### Keywords\n","\n","* Autoencoders\n","* Dimensionality reduction\n","* Reconstruction\n","* PCA\n","* MSEloss"]},{"metadata":{"id":"iCejIcaF89TZ","colab_type":"text"},"cell_type":"markdown","source":["### Expected time to complete the experiment is : 60min"]},{"metadata":{"id":"YeIm08eGre4V","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"800\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/week_11/module_3_week_11_experiment_1.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ARcaLObv9Ex6","colab_type":"text"},"cell_type":"markdown","source":["### Setup Steps"]},{"metadata":{"id":"i2IvN3K_9HzW","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"juSZUGSi9Kpt","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7ZG7J1FbGVdm","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M3W11_SAT_EXP_1\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","   ipython.magic(\"sx pip3 install torch\")\n","   ipython.magic(\"sx pip3 install torchvision\")\n","   ipython.magic(\"sx pip install Pillow==4.0.0\")\n","   print (\"Setup completed successfully\")\n","   return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful.\")\n","      print(\"Ref Id:\", submission_id)\n","      print(\"Date of submission: \", datetime.datetime.now().date().strftime(\"%d %b %Y\"))\n","      print(\"Time of submission: \", datetime.datetime.now().time().strftime(\"%H:%M:%S\"))\n","      print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n","      print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OfleGJ0189Ta","colab_type":"text"},"cell_type":"markdown","source":["#### Loading the required packages"]},{"metadata":{"id":"_f-PPleO89Tc","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.utils.data as Data\n","import torchvision.datasets as dsets\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7_gcTQxT89Th","colab_type":"text"},"cell_type":"markdown","source":["#### Defining the parameters"]},{"metadata":{"id":"KPcD-sfa89Ti","colab_type":"code","colab":{}},"cell_type":"code","source":["EPOCH = 10\n","batch_size = 64\n","LR = 0.005      \n","DOWNLOAD_MNIST = False\n","### Number of images we want to test on\n","N_TEST_IMG = 10"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tLIJVmFa89Tm","colab_type":"text"},"cell_type":"markdown","source":["#### Loading MNIST dataset from torchvision datasets"]},{"metadata":{"id":"BL2xr9pu89Tn","colab_type":"code","colab":{}},"cell_type":"code","source":["#Loading the train set file\n","train_data = dsets.MNIST(root='../data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  \n","                            download=True)\n","#Loading the test set file\n","test_data = dsets.MNIST(root='../data', \n","                           train=False, \n","                           transform=transforms.ToTensor())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yYwrpEAj89Tq","colab_type":"text"},"cell_type":"markdown","source":["#### Visulaizing one of the training data"]},{"metadata":{"id":"J2IQxwsp89Ts","colab_type":"code","colab":{}},"cell_type":"code","source":["print(train_data.train_data.size())     # (60000, 28, 28)\n","print(train_data.train_labels.size())   # (60000)\n","plt.imshow(train_data.train_data[2].numpy(), cmap='gray')\n","plt.title('%i' % train_data.train_labels[2])\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9LSB3YEb89Tz","colab_type":"code","colab":{}},"cell_type":"code","source":["#loading the train dataset\n","train_loader = torch.utils.data.DataLoader(dataset=train_data, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","# loading the test dataset\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_data, \n","                                          batch_size=batch_size, \n","                                          shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Wvd8Xs5a89T3","colab_type":"text"},"cell_type":"markdown","source":["#### Now let us construct the autoencoder neural network"]},{"metadata":{"id":"RyoJFOTZ89T5","colab_type":"code","colab":{}},"cell_type":"code","source":["class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","\n","        self.encoder = nn.Sequential(\n","            # activation functions\n","            nn.Linear(28*28, 128),\n","            nn.Tanh(),\n","            nn.Linear(128, 64),\n","            nn.Tanh(),\n","            nn.Linear(64, 12),\n","            nn.Tanh(),\n","            nn.Linear(12, 3),   # compress to 3 features which can be visualized in plt\n","        )\n","        self.decoder = nn.Sequential(\n","            #activation functions\n","            nn.Linear(3, 12),\n","            nn.Tanh(),\n","            nn.Linear(12, 64),\n","            nn.Tanh(),\n","            nn.Linear(64, 128),\n","            nn.Tanh(),\n","            nn.Linear(128, 28*28),\n","            nn.Sigmoid(),       # compress to a range (0, 1)\n","        )\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return encoded, decoded"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5-txDYHX89T8","colab_type":"text"},"cell_type":"markdown","source":["#### Now let us plot the original image and decoded image. First plot is original image and second plot is decoded image. We will also calculate the training loss for every epoch in steps. "]},{"metadata":{"id":"W-WQQi-i89T9","colab_type":"code","colab":{}},"cell_type":"code","source":["autoencoder = AutoEncoder()\n","print(autoencoder)\n","\n","# Initialization of Optimizer\n","optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n","## Initialization of Mean Square Error\n","loss_func = nn.MSELoss()\n","\n","# original data (first row) for viewing\n","view_data = train_data.train_data[:N_TEST_IMG].view(-1, 28*28).type(torch.FloatTensor)/255.\n","for epoch in range(EPOCH):\n","    for step, (x, y) in enumerate(train_loader):\n","        b_x = x.view(-1, 28*28)   # batch x, shape (batch, 28*28)\n","        b_y = x.view(-1, 28*28)   # batch y, shape (batch, 28*28)\n","        b_label = y               # batch label\n","\n","        encoded, decoded = autoencoder(b_x)\n","        loss = loss_func(decoded, b_y)      # mean square error\n","        optimizer.zero_grad()               # clear gradients for this training step\n","        loss.backward()                     # backpropagation, compute gradients\n","        optimizer.step()                    # apply gradients\n","\n","        if step % 500 == 0 and epoch in [0, 5, EPOCH-1]:\n","            print('Epoch: ', epoch, '| train loss: %.4f' % loss.item())\n","            # plotting decoded image (second row)\n","            encoded_data, decoded_data = autoencoder(view_data)\n","            # initialize figure\n","            f, a = plt.subplots(2, N_TEST_IMG, figsize=(5, 2))\n","            #Plotting orginal images\n","            for i in range(N_TEST_IMG):\n","                a[0][i].imshow(np.reshape(view_data.data.numpy()[i], (28, 28)), cmap='gray'); a[0][i].set_xticks(()); a[0][i].set_yticks(())\n","            # Plotting the decoded images\n","            for i in range(N_TEST_IMG):\n","                a[1][i].clear()\n","                a[1][i].imshow(np.reshape(decoded_data.data.numpy()[i], (28, 28)), cmap='gray')\n","                a[1][i].set_xticks(()); a[1][i].set_yticks(())\n","            plt.show(); "],"execution_count":0,"outputs":[]},{"metadata":{"id":"9-258Eb089UD","colab_type":"text"},"cell_type":"markdown","source":["Applying Autoencoders on the test data and finding the loss on the test dataset"]},{"metadata":{"id":"VoNJcP4m89UE","colab_type":"code","colab":{}},"cell_type":"code","source":["# Initialization of Optimizer\n","optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n","## Initialization of Mean Square Error\n","loss_func = nn.MSELoss()\n","\n","# original data (first row) for viewing\n","view_data = test_data.test_data[:N_TEST_IMG].view(-1, 28*28).type(torch.FloatTensor)/255.\n","\n","for b_x in range(EPOCH):\n","    for step, (x, y) in enumerate(test_loader):\n","        b_x = x.view(-1, 28*28)   # batch x, shape (batch, 28*28)\n","        b_y = x.view(-1, 28*28)   # batch y, shape (batch, 28*28)\n","        b_label = y               # batch label\n","\n","        encoded, decoded = autoencoder(b_x)\n","        loss = loss_func(decoded, b_y)\n","print(loss)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BvpvxuPG89UJ","colab_type":"text"},"cell_type":"markdown","source":["In previous experiments we have used PCA technique for dimensionality reduction which is restricted to linear map while auto encoders can have nonlinear enoder/decoders."]},{"metadata":{"id":"UGDHQ1qC89UK","colab_type":"text"},"cell_type":"markdown","source":["Applying PCA Reconstruction on the test data and calculating the loss.we can see that the autoencoders are more compact than PCA."]},{"metadata":{"id":"sP2Krot089UM","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.decomposition import PCA\n","import numpy as np\n","# Reconstruct original data\n","# Perform PCA for three components\n","pca = PCA(3)\n","loss = 0\n","for step, (x, y) in enumerate(test_loader):\n","        b_x = (x.view(-1, 28*28))   # batch x, shape (batch, 28*28)\n","        b_y = (x.view(-1, 28*28))\n","        b_x = np.array(b_x)\n","        b_y = np.array(b_y)\n","        data_reduced = pca.fit_transform(b_x)\n","        data_reconstructed = pca.inverse_transform(data_reduced)\n","        #loss += ((abs(data_reconstructed) - (b_x)) ** 2)\n","        loss += ((b_x - data_reconstructed) ** 2).mean()\n","print(loss)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cSl8m99c89UP","colab_type":"text"},"cell_type":"markdown","source":["From above we can observe that pca loss is greater thab autoencoder loss attributed to the non-linearty reduction."]},{"metadata":{"id":"EaISHzUj9lw_","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"metadata":{"id":"4kvN2gw79o-W","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SewDOKnq9rif","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7dNF6dLA9uEj","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Dp8oacWI9v9-","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rZAjoXFfHDm0","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}