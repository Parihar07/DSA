{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment_5.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"kMJOHiQHqvxF","colab_type":"text"},"cell_type":"markdown","source":["\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"rUtUVvVVqvxI","colab_type":"text"},"cell_type":"markdown","source":["The objective of this experiment is to understand how to train a multi-layer perceptron model to classify MNIST digits using PyTorch and to run on GPU."]},{"metadata":{"id":"_1iUac38qvxJ","colab_type":"text"},"cell_type":"markdown","source":["In this experiment we will be using MNIST database. The MNIST database is a dataset of handwritten digits. It has 60,000 training samples, and 10,000 test samples. Each image is represented by 28 x 28 pixels, each containing a value 0 - 255 with its gray scale value.\n","\n","It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n","\n","It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."]},{"metadata":{"id":"gAYwFVw_qvxK","colab_type":"text"},"cell_type":"markdown","source":["We will be using the same code as in notebook-1 , but we will run the code on a GPU instance.\n","\n","To do this, we need to convert all variables and the network into 'CUDA variables'.\n","\n","    1. Initialize with CUDA\n","    2. Load MNIST dataset, and visualize\n","    3. Define the Neural Network and optimizer\n","    4. Train the model"]},{"metadata":{"id":"1nQ5s9HnCFvX","colab_type":"code","cellView":"both","colab":{}},"cell_type":"code","source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/module_2_week_7_experment_5.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dUBatPVgq49B","colab_type":"text"},"cell_type":"markdown","source":["### Setup Steps"]},{"metadata":{"id":"8Y-EoQsnq7qg","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P19A06E_test\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eSzH_RtirDee","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"981234567\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ptO1SL76rFTy","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M2W7_SAT_EXP_5\" #name of the notebook\n","\n","def setup():\n","    ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx pip3 install torchvision\")\n","    ipython.magic(\"sx pip3 install seaborn\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful. Ref:\", submission_id)\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6PyxQ88tqvxM","colab_type":"code","colab":{}},"cell_type":"code","source":["## Importing required packages\n","%matplotlib inline\n","\n","### Importing torch packages\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","\n","## Importing python packages\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vbm-8HxIqvxR","colab_type":"text"},"cell_type":"markdown","source":["#### 1. Initializing CUDA"]},{"metadata":{"id":"mgFbyHXCqvxT","colab_type":"text"},"cell_type":"markdown","source":["CUDA is used as an interface between our code and the GPU.\n","\n","Normally, we run the code in the CPU. To run it in the GPU, we need CUDA. Check if CUDA is available:"]},{"metadata":{"id":"YHj_ZREiqvxU","colab_type":"code","colab":{}},"cell_type":"code","source":["### To test whether GPU instance is present in the system of not.\n","use_cuda = torch.cuda.is_available()\n","print('Using PyTorch version:', torch.__version__, 'CUDA:', use_cuda)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m_WeWksDqvxb","colab_type":"code","colab":{}},"cell_type":"code","source":["device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","device"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4zq7Ujumqvxg","colab_type":"text"},"cell_type":"markdown","source":["If it's False, then we run the program on CPU. If it's True, then we run the program on GPU.\n","\n","Let us initialize some GPU-related variables:"]},{"metadata":{"id":"UtgeAAdZqvxh","colab_type":"code","colab":{}},"cell_type":"code","source":["### Initializing batch size\n","batch_size = 32"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nG_Q01fTqvxl","colab_type":"text"},"cell_type":"markdown","source":["#### 2. Load MNIST data\n","\n","Now, we'll load the MNIST data. For the first time, we may have to download the data, which can take a while."]},{"metadata":{"id":"hUjEukqOqvxm","colab_type":"code","colab":{}},"cell_type":"code","source":["## Loading the train set file\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                   transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.1307,), (0.3081,))\n","                   ])),\n","    batch_size=batch_size, shuffle=True, \n","    #**kwargs\n","    )\n","\n","## Loading the test set file\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.1307,), (0.3081,))\n","                   ])),\n","    batch_size=batch_size, shuffle=True, \n","    #**kwargs\n","    )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FWYm5tj4qvxs","colab_type":"text"},"cell_type":"markdown","source":["The train and test data are provided via data loaders that provide iterators over the datasets.\n","\n","The first element of training data (X_train) is a 4th-order tensor of size (batch_size, 1, 28, 28), i.e. it consists of a batch of images of size 1x28x28 pixels. y_train is a vector containing the correct classes (\"0\", \"1\", ..., \"9\") for each training digit."]},{"metadata":{"id":"5As4BhINqvxt","colab_type":"code","colab":{}},"cell_type":"code","source":["for (X_train, y_train) in train_loader:\n","    print('X_train:', X_train.size(), 'type:', X_train.type())\n","    print('y_train:', y_train.size(), 'type:', y_train.type())\n","    break"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g00u_5njqvx0","colab_type":"text"},"cell_type":"markdown","source":["#### Plotting the  first 10 training digits"]},{"metadata":{"id":"lp2FH1Lqqvx2","colab_type":"code","colab":{}},"cell_type":"code","source":["pltsize=1\n","plt.figure(figsize=(15*pltsize, pltsize))\n","\n","for i in range(10):\n","    plt.subplot(1,10,i+1)\n","    plt.axis('off')\n","    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray\")\n","    plt.title('Class: '+str(y_train[i]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u664CO5Zqvx7","colab_type":"text"},"cell_type":"markdown","source":["#### 3. Define the neural network and optimizer\n","\n","Let's define the network as a Python class.\n","\n","As we know from the previous experiment, we have to write the **\\__init__()** and **forward()** methods, and PyTorch will automatically generate a **backward()** method for computing the gradients for the backward pass."]},{"metadata":{"id":"l0uDIWHDqvx8","colab_type":"code","colab":{}},"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(28*28, 50)\n","        self.fc1_drop = nn.Dropout(0.2)\n","        self.fc2 = nn.Linear(50, 50)\n","        self.fc2_drop = nn.Dropout(0.2)\n","        self.fc3 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28*28)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc1_drop(x)\n","        x = F.relu(self.fc2(x))\n","        x = self.fc2_drop(x)\n","        return F.log_softmax(self.fc3(x), dim=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nw3kD1Kjqvx_","colab_type":"text"},"cell_type":"markdown","source":["Let us declare an object of class Net, and make it a CUDA model if CUDA is available:"]},{"metadata":{"id":"VSNz4pSqqvyA","colab_type":"code","colab":{}},"cell_type":"code","source":["device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)\n","model = Net()\n","model = model.to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S_X99nfHqvyG","colab_type":"code","colab":{}},"cell_type":"code","source":["print(model)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tEOmTzYgqvyO","colab_type":"text"},"cell_type":"markdown","source":["Finally, we define an optimizer to update the model parameters based on the computed gradients. We select stochastic gradient descent (with momentum) as the optimization algorithm, and set learning rate to 0.01. Note that there are several different options for the optimizer in PyTorch that we could use instead of SGD.\n","\n","Let us define the Optimizer as SGD:"]},{"metadata":{"id":"rPBff47_qvyR","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F75Z3ABdqvyY","colab_type":"text"},"cell_type":"markdown","source":["#### 4. Train the model\n","Let's now define functions to train() and test() the model."]},{"metadata":{"id":"kq2sRlC3qvya","colab_type":"code","colab":{}},"cell_type":"code","source":["def train(epoch, log_interval=100):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","       \n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R8R0CL5Gqvye","colab_type":"text"},"cell_type":"markdown","source":["Now we are ready to train our model using the train() function. An epoch means one pass through the whole training data. After each epoch, we evaluate the model using test():"]},{"metadata":{"id":"P1Z8BhQyqvyg","colab_type":"code","colab":{}},"cell_type":"code","source":["def test(loss_vector, accuracy_vector):\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        #data, target = Variable(data, volatile=True), Variable(target)\n","        output = model(data)\n","        test_loss += F.nll_loss(output, target).item()\n","        pred = output.data.max(1)[1] # get the index of the max log-probability\n","        correct += pred.eq(target.data).to(device).sum()\n","\n","    test_loss /= len(test_loader)\n","    loss_vector.append(test_loss)\n","\n","    accuracy = 100. * correct / len(test_loader.dataset)\n","    accuracy_vector.append(accuracy)\n","    \n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset), accuracy))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"68ZN1zX6qvyl","colab_type":"text"},"cell_type":"markdown","source":["Let us compute the time it takes to run this, so as to compare the GPU's performance time with that of CPU."]},{"metadata":{"id":"9_o4ECJ6qvyl","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","epochs = 10\n","\n","lossv, accv = [], []\n","for epoch in range(1, epochs + 1):\n","    train(epoch)\n","    test(lossv, accv)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X6iurGRoqvyr","colab_type":"text"},"cell_type":"markdown","source":["Thus, GPU is much faster!\n","\n","Let's now visualize how the training progressed.\n","\n","Loss is a function of the difference of the network output and the target values. We are minimizing the loss function during training so it should decrease over time."]},{"metadata":{"id":"htZANhIUqvys","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.figure(figsize=(8,5))\n","plt.plot(np.arange(1,epochs+1), lossv)\n","plt.title('test loss')\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"error\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6ARvnE-Vqvyz","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 1: \n","\n","Plot the graph for test accuracy"]},{"metadata":{"id":"322DUtWfqvy0","colab_type":"code","colab":{}},"cell_type":"code","source":["# Your Code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g-yKB6a9qvy6","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 2:\n"," \n","Change the number of epoch to 5. Calculate the accuracy for both training and testing data."]},{"metadata":{"id":"tHBlwxymqvy8","colab_type":"code","colab":{}},"cell_type":"code","source":["# Your Code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4FS0nbiXrSs4","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"metadata":{"id":"nwYg7zierVd9","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Too Simple, I am wasting time\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-Mc7kjRerXVy","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"test\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JTUJn9amrZCd","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T5aSIZpErbTZ","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IlaxYXH_iLVU","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}