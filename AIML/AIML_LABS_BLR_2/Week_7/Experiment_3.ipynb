{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment_3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"4fpVc1Qdu-Uq","colab_type":"text"},"cell_type":"markdown","source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"dczp1mHxu-Us","colab_type":"text"},"cell_type":"markdown","source":["The objective of this experiment is to perform face recognition using SVM Classifier."]},{"metadata":{"id":"ngXJVj3Eu-Uu","colab_type":"text"},"cell_type":"markdown","source":["In this experiment we will use the Labeled Faces in the Wild dataset, which consists of several thousand collated photos of various public figures.\n","\n","This dataset is a collection of JPEG pictures of famous people collected over the internet, all details are available on the official website:\n","\n","http://vis-www.cs.umass.edu/lfw/\n","\n","Each picture is centered on a single face. Each pixel of each channel (color in RGB) is encoded by a float in range 0.0 - 1.0.\n","\n","The task is called Face Recognition (or Identification): given the picture of a face, find the name of the person given a training set (gallery).\n","\n","The original images are 250 x 250 pixels, but the default slice and resize arguments reduce them to 62 x 47."]},{"metadata":{"id":"niGijx7mB2IS","colab_type":"code","outputId":"90306f20-4009-413b-88bc-e5491faef748","executionInfo":{"status":"ok","timestamp":1544762658996,"user_tz":-330,"elapsed":1147,"user":{"displayName":"AIML Support","photoUrl":"","userId":"10944637975474083227"}},"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":260}},"cell_type":"code","source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/module_2_week_7_experment_3.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/module_2_week_7_experment_3.mp4\" type=\"video/mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"J50du7dPvEAn","colab_type":"text"},"cell_type":"markdown","source":["### Setup Steps"]},{"metadata":{"id":"Ue7egh_QvF2_","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P19A06E_test\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LV-RhG_3vI5T","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"981234567\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PQt744m8vKiY","colab_type":"code","cellView":"form","outputId":"332fd214-a3ca-4dc8-f87c-8829a691fdaa","executionInfo":{"status":"ok","timestamp":1544942626011,"user_tz":-330,"elapsed":1497,"user":{"displayName":"Raghava kumar","photoUrl":"","userId":"12233731786455370504"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M2W7_SAT_EXP_3\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","   \n","   print (\"Setup completed successfully\")\n","   return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful. Ref:\", submission_id)\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"metadata":{"id":"EbslM_liu-Uw","colab_type":"text"},"cell_type":"markdown","source":["### Importing the required packages"]},{"metadata":{"id":"LELdxmTXu-Ux","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.datasets import fetch_lfw_people\n","from sklearn.svm import SVC\n","from sklearn.decomposition import PCA\n","from sklearn.pipeline import make_pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","import seaborn as sns; sns.set()\n","\n","import warnings\n","warnings.simplefilter(\"ignore\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KQVakGy5u-U6","colab_type":"text"},"cell_type":"markdown","source":["##### Loading the dataset from sklearn datasets package"]},{"metadata":{"id":"I54otvVpu-U8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"72017c70-a892-4b6e-fe2c-aaf7416e11bf","executionInfo":{"status":"ok","timestamp":1544942679363,"user_tz":-330,"elapsed":49588,"user":{"displayName":"Raghava kumar","photoUrl":"","userId":"12233731786455370504"}}},"cell_type":"code","source":["faces = fetch_lfw_people(min_faces_per_person=60)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading LFW metadata: https://ndownloader.figshare.com/files/5976012\n","Downloading LFW metadata: https://ndownloader.figshare.com/files/5976009\n","Downloading LFW metadata: https://ndownloader.figshare.com/files/5976006\n","Downloading LFW data (~200MB): https://ndownloader.figshare.com/files/5976015\n"],"name":"stderr"}]},{"metadata":{"id":"sXgdNxglu-VB","colab_type":"code","colab":{}},"cell_type":"code","source":["print(faces.target_names)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2mGgg2NIu-VH","colab_type":"code","colab":{}},"cell_type":"code","source":["print(faces.images.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dJme-tkHu-VM","colab_type":"text"},"cell_type":"markdown","source":["To get sense of the data, Let us visualize the faces"]},{"metadata":{"id":"exS2X5Oou-VN","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","fig, ax = plt.subplots(3, 5)\n","for i, axi in enumerate(ax.flat):\n","    axi.imshow(faces.images[i], cmap='bone')\n","    axi.set(xticks=[], yticks=[],\n","            xlabel=faces.target_names[faces.target[i]])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qtV2dvi5u-VT","colab_type":"text"},"cell_type":"markdown","source":["Each image contains [62×47] or nearly 3,000 pixels. We could proceed by simply using each pixel value as a feature, but often it is more effective to use some sort of preprocessor to extract more meaningful features; here we will use a principal component analysis to extract 150 fundamental components to feed into our support vector machine classifier. We can do this most straightforwardly by packaging the preprocessor and the classifier into a single pipeline:"]},{"metadata":{"id":"w7eea2_hu-VU","colab_type":"code","colab":{}},"cell_type":"code","source":["pca = PCA(n_components=150, whiten=True, random_state=42)\n","svc = SVC(kernel='rbf', class_weight='balanced')\n","model = make_pipeline(pca, svc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HiE2ZI-8u-VY","colab_type":"text"},"cell_type":"markdown","source":["For testing our classifier output, we will split the data into a training and testing set:"]},{"metadata":{"id":"UUBB11zDu-VZ","colab_type":"code","colab":{}},"cell_type":"code","source":["Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target,\n","                                                random_state=42)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jH1nwRcfu-Ve","colab_type":"text"},"cell_type":"markdown","source":["Finally, we can use a grid search cross-validation to explore combinations of parameters. Here we will adjust C (which controls the margin hardness) and gamma (which controls the size of the radial basis function kernel), and determine the best model:"]},{"metadata":{"id":"ICQ49mEXu-Vf","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","param_grid = {'svc__C': [1, 5, 10, 50],\n","              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n","grid = GridSearchCV(model, param_grid)\n","\n","%time grid.fit(Xtrain, ytrain)\n","print(grid.best_params_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d53OmgcMu-Vl","colab_type":"text"},"cell_type":"markdown","source":["The optimal values fall toward the middle of our grid; if they fell at the edges, we would want to expand the grid to make sure we have found the true optimum. "]},{"metadata":{"id":"rxMKr5QLu-Vm","colab_type":"text"},"cell_type":"markdown","source":["Now with this cross-validated model, we can predict the labels for the test data, which the model has not yet seen:"]},{"metadata":{"id":"xZ4XreUeu-Vo","colab_type":"code","colab":{}},"cell_type":"code","source":["model = grid.best_estimator_\n","yfit = model.predict(Xtest)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VJ0WkHsmu-Vs","colab_type":"text"},"cell_type":"markdown","source":["Let's take a look at a few of the test images along with their predicted values:"]},{"metadata":{"id":"PBskyaEQu-Vt","colab_type":"code","colab":{}},"cell_type":"code","source":["fig, ax = plt.subplots(4, 6)\n","for i, axi in enumerate(ax.flat):\n","    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n","    axi.set(xticks=[], yticks=[])\n","    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n","                   color='black' if yfit[i] == ytest[i] else 'red')\n","fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IMz7csuUu-Vz","colab_type":"text"},"cell_type":"markdown","source":["Out of this small sample, our optimal estimator mislabeled only a single face (Bush’s face in the bottom row was mislabeled as Blair). We can get a better sense of our estimator's performance using the classification report, which lists recovery statistics label by label:"]},{"metadata":{"id":"sV9rW5o4u-V0","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","print(classification_report(ytest, yfit,\n","                            target_names=faces.target_names))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZYBEB5PCu-V8","colab_type":"text"},"cell_type":"markdown","source":["We might also display the confusion matrix between these classes:"]},{"metadata":{"id":"eDpXQf_Yu-V-","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","mat = confusion_matrix(ytest, yfit)\n","sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n","            xticklabels=faces.target_names,\n","            yticklabels=faces.target_names)\n","plt.xlabel('true label')\n","plt.ylabel('predicted label');"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-1Akml4Tu-WF","colab_type":"text"},"cell_type":"markdown","source":["For a real-world facial recognition task, in which the photos do not come pre-cropped into nice grids, the only difference in the facial classification scheme is the feature selection: you would need to use a more sophisticated algorithm to find the faces, and extract features that are independent of the pixellation."]},{"metadata":{"id":"noKU-O22u-WG","colab_type":"text"},"cell_type":"markdown","source":["#### Acknowledgement :  Python Data Science Handbook by Jake VanderPlas"]},{"metadata":{"id":"_yvmH3hhvU6N","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"metadata":{"id":"lVpT2nHiu-WH","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Too Simple, I am wasting time\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XeCEFupQvc6d","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"test\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9QtIBxepve8F","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JC50ZEgGvhR5","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[]}]}