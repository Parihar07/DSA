{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment_4.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"KQQf59gQpxYb","colab_type":"text"},"cell_type":"markdown","source":["\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"ned5bzeZpxYd","colab_type":"text"},"cell_type":"markdown","source":["The objective of this experiment is to understand how to implement MLP using PyTorch. "]},{"metadata":{"id":"U3uGm_53pxYf","colab_type":"text"},"cell_type":"markdown","source":["In this experiment we will be using MNIST database. The MNIST database is a dataset of handwritten digits. It has 60,000 training samples, and 10,000 test samples. Each image is represented by 28 x 28 pixels, each containing a value 0 - 255 with its gray scale value.\n","\n","It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n","\n","It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."]},{"metadata":{"id":"Tcrhtt_PpxYg","colab_type":"text"},"cell_type":"markdown","source":["#### PyTorch\n","\n","Itâ€™s a Python based scientific computing package targeted at two sets of audiences:\n","\n","1. A replacement for NumPy to use the power of GPUs\n","\n","2. a deep learning research platform that provides maximum flexibility and speed\n","\n","For more information refer the following url :\n","\n","http://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html"]},{"metadata":{"id":"bk232hH4pxYh","colab_type":"text"},"cell_type":"markdown","source":["In this experiment will be implementing MLP using Pytorch. We are going to do this step-by-step:\n","\n","    1. Load MNIST dataset, and visualize\n","    2. Define the Neural Network\n","    3. Define loss and optimizer\n","    4. Train the model\n","    5. Test the model"]},{"metadata":{"id":"-CoAuA-QB_3u","colab_type":"code","outputId":"5038906b-01b9-433a-cd8e-d29928621446","executionInfo":{"status":"ok","timestamp":1544900196437,"user_tz":-330,"elapsed":1196,"user":{"displayName":"Raghava kumar","photoUrl":"","userId":"12233731786455370504"}},"cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":261}},"cell_type":"code","source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"520\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/module_2_week_7_experment_4.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/module_2_week_7_experment_4.mp4\" type=\"video/mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"Z3Z65Oopp1iK","colab_type":"text"},"cell_type":"markdown","source":["#### Setup Steps"]},{"metadata":{"id":"UCXQZqPsp4K9","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P19A06E_test\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_FW8YgBep6WW","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"981234567\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RfeVTnF2p8Wg","colab_type":"code","cellView":"form","outputId":"a8309026-d4b6-44d9-ef2c-7ebeee3f9062","executionInfo":{"status":"ok","timestamp":1544943127995,"user_tz":-330,"elapsed":120644,"user":{"displayName":"Raghava kumar","photoUrl":"","userId":"12233731786455370504"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M2W7_SAT_EXP_4\" #name of the notebook\n","\n","def setup():\n","    ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx pip3 install torchvision\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful. Ref:\", submission_id)\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"metadata":{"id":"3N5PAB6KpxYl","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1Hp_SebBpxYp","colab_type":"code","colab":{}},"cell_type":"code","source":["torch.__version__"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Lzp2eOKZpxYy","colab_type":"text"},"cell_type":"markdown","source":["#### Importing Required Packages"]},{"metadata":{"id":"ceL7S_99pxYy","colab_type":"code","colab":{}},"cell_type":"code","source":["# Hyper Parameters \n","input_size = 784\n","hidden_size = 500\n","num_classes = 10\n","num_epochs = 10\n","batch_size = 10\n","learning_rate = 0.001"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3yD9SnrZpxY2","colab_type":"text"},"cell_type":"markdown","source":["#### 1. Loading MNIST dataset"]},{"metadata":{"id":"KbN2vNhppxY4","colab_type":"text"},"cell_type":"markdown","source":["Now, we'll load the MNIST data. First time we may have to download the data, which can take a while."]},{"metadata":{"id":"VSguZdsrpxY6","colab_type":"text"},"cell_type":"markdown","source":["requires_grad=True"]},{"metadata":{"id":"u5YFliFupxY7","colab_type":"code","outputId":"31ba73d5-8c09-4091-d7fa-a585cfc5dbf0","executionInfo":{"status":"ok","timestamp":1544943130611,"user_tz":-330,"elapsed":105910,"user":{"displayName":"Raghava kumar","photoUrl":"","userId":"12233731786455370504"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"cell_type":"code","source":["#Loading the train set file\n","train_dataset = dsets.MNIST(root='../data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  \n","                            download=True)\n","#Loading the test set file\n","test_dataset = dsets.MNIST(root='../data', \n","                           train=False, \n","                           transform=transforms.ToTensor())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"metadata":{"id":"v69lvSHjpxZB","colab_type":"text"},"cell_type":"markdown","source":["Loading the dataset using \"Dataloader\" - this dataloader will return batches of data."]},{"metadata":{"id":"_2aBHJ7BpxZC","colab_type":"code","colab":{}},"cell_type":"code","source":["#loading the train dataset\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","# loading the test dataset\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dAZcPlxipxZH","colab_type":"text"},"cell_type":"markdown","source":["The train and test data are provided via data loaders that provide iterators over the datasets. Loading X and Y train values from the loader."]},{"metadata":{"id":"lHvKfOvJpxZI","colab_type":"code","outputId":"055446bb-2bb6-4de3-d289-a7a44ed41f97","executionInfo":{"status":"ok","timestamp":1544943131366,"user_tz":-330,"elapsed":92948,"user":{"displayName":"Raghava kumar","photoUrl":"","userId":"12233731786455370504"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["for (X_train, y_train) in train_loader:\n","    print('X_train:', X_train.size(), 'type:', X_train.type())\n","    print('y_train:', y_train.size(), 'type:', y_train.type())\n","    break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["X_train: torch.Size([10, 1, 28, 28]) type: torch.FloatTensor\n","y_train: torch.Size([10]) type: torch.LongTensor\n"],"name":"stdout"}]},{"metadata":{"id":"t-n4UN9apxZO","colab_type":"text"},"cell_type":"markdown","source":["#### Plotting first 10 training digits"]},{"metadata":{"id":"sd2w6x2dpxZP","colab_type":"code","outputId":"3bacfc9e-70d8-4292-887c-69c2f1951e43","executionInfo":{"status":"ok","timestamp":1544943131759,"user_tz":-330,"elapsed":77188,"user":{"displayName":"Raghava kumar","photoUrl":"","userId":"12233731786455370504"}},"colab":{"base_uri":"https://localhost:8080/","height":117}},"cell_type":"code","source":["pltsize=1\n","plt.figure(figsize=(15*pltsize, pltsize))\n","\n","for i in range(10):\n","    plt.subplot(1,10,i+1)\n","    plt.axis('off')\n","    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray\")\n","    plt.title('Class: '+str(y_train[i]))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA2QAAABkCAYAAADpAPNVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiImGiBpmIiIiIiEiY/B81aTXFoXZuKgAAAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7ff2c2f9b780>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"N3mYtDEZpxZU","colab_type":"text"},"cell_type":"markdown","source":["#### 2. Defining the Neural Network"]},{"metadata":{"id":"nYmCvakapxZV","colab_type":"text"},"cell_type":"markdown","source":["Let's define the network as a Python class. This Python class inherits functions from _nn.module_.\n","\n","There are three convenient functions that are defined in this class:\n","\n","- ### **\\__init__()**:\n","In this function, we shall declare all the layers of our neural network, including the number of neurons, non-linear activations, etc.\n","\n","- ### **forward()**:\n","This is the function that is used to compute forward pass of the network. Here, we shall connect the different layers we had defined in \\__init__, according to the network architecture we want to make. In this case, $x -> fc1 -> relu -> fc2 -> out$.\n","\n","\"forward\" can be called by calling the object of this class directly. For example:\n","\n","```\n","net = Network()\n","out = net(x)\n","```\n","\n","- ### **backward()**:\n","This function is used to compute gradients across the entire network, and is called from the loss function at the end of the network.\n","\n","```\n","loss.backward()\n","```\n","\n","We have to write the **__init__()** and **forward()** methods, and PyTorch will automatically generate a **backward()** method for computing the gradients for the backward pass."]},{"metadata":{"id":"WyB_ckmBpxZV","colab_type":"code","colab":{}},"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size) \n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, num_classes)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        out = self.softmax(out)\n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s7hz1ktNpxZa","colab_type":"text"},"cell_type":"markdown","source":["#### Creating a neural network object"]},{"metadata":{"id":"aKQaIwlCpxZb","colab_type":"code","colab":{}},"cell_type":"code","source":["net = Net(input_size, hidden_size, num_classes)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BKFKVmdvpxZe","colab_type":"text"},"cell_type":"markdown","source":["#### 3. Loss and Optimizer"]},{"metadata":{"id":"rv7aDzN_pxZf","colab_type":"text"},"cell_type":"markdown","source":["We shall use the Cross Entropy Loss function as the loss."]},{"metadata":{"id":"Gu3RTZfNpxZg","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jJzOVspCpxZl","colab_type":"text"},"cell_type":"markdown","source":["We shall use SGD as the optimizer."]},{"metadata":{"id":"4LoQq7P-pxZm","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"OAByClI6pxZq","colab_type":"text"},"cell_type":"markdown","source":["#### 4. Train the Model"]},{"metadata":{"id":"_ASfc1I9pxZr","colab_type":"code","outputId":"b612f791-ebdf-4aa2-fced-011c483465a0","executionInfo":{"status":"ok","timestamp":1544943280562,"user_tz":-330,"elapsed":214514,"user":{"displayName":"Raghava kumar","photoUrl":"","userId":"12233731786455370504"}},"colab":{"base_uri":"https://localhost:8080/","height":1037}},"cell_type":"code","source":["# In each epoch\n","for epoch in range(num_epochs):\n","    \n","    # For each batch of images in train set\n","    for i, (images, labels) in enumerate(train_loader):\n","        \n","        # Convert torch tensor to Variable\n","        images = images.view(-1, 28*28)\n","        labels = labels\n","        \n","        # Initialize gradients to 0\n","        optimizer.zero_grad()\n","        \n","        # Forward pass (this calls the \"forward\" function within Net)\n","        outputs = net(images)\n","        \n","        # Find the loss\n","        loss = criterion(outputs, labels)\n","        \n","        # Find the gradients of all weights using the loss\n","        loss.backward()\n","        \n","        # Update the weights using the optimizer\n","        # For e.g.: w = w - (delta_w)*lr\n","        optimizer.step()\n","        \n","        if (i+1) % 1000 == 0:\n","            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n","                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch [1/10], Step [1000/6000], Loss: 2.3059\n","Epoch [1/10], Step [2000/6000], Loss: 2.2992\n","Epoch [1/10], Step [3000/6000], Loss: 2.2960\n","Epoch [1/10], Step [4000/6000], Loss: 2.2998\n","Epoch [1/10], Step [5000/6000], Loss: 2.2951\n","Epoch [1/10], Step [6000/6000], Loss: 2.2831\n","Epoch [2/10], Step [1000/6000], Loss: 2.2915\n","Epoch [2/10], Step [2000/6000], Loss: 2.2838\n","Epoch [2/10], Step [3000/6000], Loss: 2.2462\n","Epoch [2/10], Step [4000/6000], Loss: 2.2449\n","Epoch [2/10], Step [5000/6000], Loss: 2.2853\n","Epoch [2/10], Step [6000/6000], Loss: 2.2142\n","Epoch [3/10], Step [1000/6000], Loss: 2.2690\n","Epoch [3/10], Step [2000/6000], Loss: 2.2167\n","Epoch [3/10], Step [3000/6000], Loss: 2.1765\n","Epoch [3/10], Step [4000/6000], Loss: 2.1726\n","Epoch [3/10], Step [5000/6000], Loss: 2.0921\n","Epoch [3/10], Step [6000/6000], Loss: 2.0827\n","Epoch [4/10], Step [1000/6000], Loss: 2.0760\n","Epoch [4/10], Step [2000/6000], Loss: 2.0991\n","Epoch [4/10], Step [3000/6000], Loss: 2.1547\n","Epoch [4/10], Step [4000/6000], Loss: 2.0181\n","Epoch [4/10], Step [5000/6000], Loss: 1.8882\n","Epoch [4/10], Step [6000/6000], Loss: 1.9754\n","Epoch [5/10], Step [1000/6000], Loss: 1.9048\n","Epoch [5/10], Step [2000/6000], Loss: 1.9435\n","Epoch [5/10], Step [3000/6000], Loss: 1.7976\n","Epoch [5/10], Step [4000/6000], Loss: 2.0630\n","Epoch [5/10], Step [5000/6000], Loss: 1.9190\n","Epoch [5/10], Step [6000/6000], Loss: 1.8695\n","Epoch [6/10], Step [1000/6000], Loss: 1.9020\n","Epoch [6/10], Step [2000/6000], Loss: 1.9523\n","Epoch [6/10], Step [3000/6000], Loss: 1.7560\n","Epoch [6/10], Step [4000/6000], Loss: 1.9417\n","Epoch [6/10], Step [5000/6000], Loss: 1.7802\n","Epoch [6/10], Step [6000/6000], Loss: 1.9481\n","Epoch [7/10], Step [1000/6000], Loss: 1.8818\n","Epoch [7/10], Step [2000/6000], Loss: 1.7560\n","Epoch [7/10], Step [3000/6000], Loss: 1.8482\n","Epoch [7/10], Step [4000/6000], Loss: 1.6836\n","Epoch [7/10], Step [5000/6000], Loss: 1.7721\n","Epoch [7/10], Step [6000/6000], Loss: 1.8690\n","Epoch [8/10], Step [1000/6000], Loss: 1.7374\n","Epoch [8/10], Step [2000/6000], Loss: 1.7781\n","Epoch [8/10], Step [3000/6000], Loss: 1.7414\n","Epoch [8/10], Step [4000/6000], Loss: 1.7792\n","Epoch [8/10], Step [5000/6000], Loss: 1.6925\n","Epoch [8/10], Step [6000/6000], Loss: 1.7584\n","Epoch [9/10], Step [1000/6000], Loss: 1.7594\n","Epoch [9/10], Step [2000/6000], Loss: 1.7483\n","Epoch [9/10], Step [3000/6000], Loss: 1.7688\n","Epoch [9/10], Step [4000/6000], Loss: 1.7308\n","Epoch [9/10], Step [5000/6000], Loss: 1.7612\n","Epoch [9/10], Step [6000/6000], Loss: 1.8921\n","Epoch [10/10], Step [1000/6000], Loss: 1.5870\n","Epoch [10/10], Step [2000/6000], Loss: 1.6363\n","Epoch [10/10], Step [3000/6000], Loss: 1.6340\n","Epoch [10/10], Step [4000/6000], Loss: 1.5456\n","Epoch [10/10], Step [5000/6000], Loss: 1.8685\n","Epoch [10/10], Step [6000/6000], Loss: 1.7125\n"],"name":"stdout"}]},{"metadata":{"id":"hXJz8iRwpxZw","colab_type":"text"},"cell_type":"markdown","source":["#### 5. Test the Model"]},{"metadata":{"id":"2psIB85qpxZy","colab_type":"code","outputId":"8068d091-5b7e-4a21-dab6-66c0d6d44c9a","executionInfo":{"status":"ok","timestamp":1544943281899,"user_tz":-330,"elapsed":213451,"user":{"displayName":"Raghava kumar","photoUrl":"","userId":"12233731786455370504"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["correct = 0\n","total = 0\n","# For each batch of images in test set\n","for images, labels in test_loader:\n","    \n","    # Get the images\n","    images = images.view(-1, 28*28)\n","    \n","    # Find the output by doing a forward pass through the network\n","    outputs = net(images)\n","    \n","    # Find the class of each sample by taking a max across the probabilities of each class\n","    _, predicted = torch.max(outputs.data, 1)\n","    \n","    # Increment 'total', and 'correct' according to whether the prediction was correct or not\n","    total += labels.size(0)\n","    correct += (predicted.cpu() == labels).sum()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 82 %\n"],"name":"stdout"}]},{"metadata":{"id":"ErznFh2CpxZ7","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 1:\n","\n","Play with number of epochs, batch_size, hidden layer size, non-linearity, etc."]},{"metadata":{"id":"VLH_ulfJqdhl","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:"]},{"metadata":{"id":"oBxVxwCLpxZ7","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good and Challenging me\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QHXw9ZiCqh-0","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"test\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SfKyaKmYqjf7","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L-VGSFDXqlX-","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[]}]}