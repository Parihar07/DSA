{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"YI5Musv4oHt6","colab_type":"text"},"cell_type":"markdown","source":["\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"el2BC3yaoHt8","colab_type":"text"},"cell_type":"markdown","source":["\n","#### To be done in the Lab"]},{"metadata":{"id":"rEV6MkIuoHt9","colab_type":"text"},"cell_type":"markdown","source":["The objective of this experiment is to study the effect of different features on Multi-class classification."]},{"metadata":{"id":"D-DLyJpOoHt-","colab_type":"text"},"cell_type":"markdown","source":["In this experiment, we will use the CIFAR-10 dataset consists of 60,000 32x32 colour images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images."]},{"metadata":{"id":"6ZI_P8FLoHt_","colab_type":"text"},"cell_type":"markdown","source":["They are in a particular python-specific format called pickle. You need not worry about the format's internals, as the site has given the code needed to read such files. The code is given in the first code block below.\n","\n","**The code returns the contents of each data file as a dictionary**."]},{"metadata":{"id":"OqmRfC1KoHuB","colab_type":"text"},"cell_type":"markdown","source":["There are 8 files in the cifar-10 directory.\n","\n","    1. batches.meta\n","\n","    2. data_batch_1\n","\n","    3. data_batch_2\t\n","\n","    4. data_batch_3\n","\n","    5. data_batch_4\t\n","\n","    6. data_batch_5\n","\n","    7. readme.html\n","\n","    8. test_batch\n","\n","We will take a peek at these files."]},{"metadata":{"id":"Abx4j1LUoHuC","colab_type":"text"},"cell_type":"markdown","source":["### DataSource\n","\n","https://www.cs.toronto.edu/~kriz/cifar.html"]},{"metadata":{"id":"t3AQ95KyoXJo","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P19A06E_test\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OGZKSZZcodXQ","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"981234567\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kjBAmhhgoexs","colab_type":"code","cellView":"form","outputId":"b51792ec-035f-47cf-e461-865835dec355","executionInfo":{"status":"ok","timestamp":1542892734479,"user_tz":-330,"elapsed":50612,"user":{"displayName":"Arun Kumar S","photoUrl":"","userId":"14042875339399760993"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M1W4_SAT_EXP_2\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week3/Exp3/AIML_DS_CIFAR-10_STD.zip\")\n","    ipython.magic(\"sx unzip AIML_DS_CIFAR-10_STD.zip\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful. Ref:\", submission_id)\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"metadata":{"id":"q4srzRipoHuH","colab_type":"code","colab":{}},"cell_type":"code","source":["# Importing required packages\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import scipy.io as sio\n","import itertools\n","import operator\n","import random\n","import collections\n","from scipy import stats\n","from sklearn.metrics import accuracy_score"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qJPFyUlhoHuM","colab_type":"code","colab":{}},"cell_type":"code","source":["# Special function to read special files\n","def unpickle(file):\n","    import pickle\n","    with open(file, 'rb') as fo:\n","        dict = pickle.load(fo, encoding='latin1')\n","    return dict"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DtshQ8SpoHuQ","colab_type":"text"},"cell_type":"markdown","source":["**data**  - a 10,000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n","\n","**labels** -  a list of 10,000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data."]},{"metadata":{"id":"fmf5RhH1oHuR","colab_type":"text"},"cell_type":"markdown","source":["### Visualizing the images in CIFAR-10 Dataset\n","1. Here get_data unpickles the CIFAR Dataset and stores the data as 10000*3072 dimension in array X and labels as 10000*1 dimension in array Y. \n","2. Visualize function shows the image corresponding to id number."]},{"metadata":{"id":"s5uJPnJpoHuS","colab_type":"code","colab":{}},"cell_type":"code","source":["# Function to load the data\n","def get_data(file):\n","    dict = unpickle(file)\n","    X = np.asarray(dict['data']).astype(\"uint8\")\n","    Y = np.asarray(dict['labels'])\n","    names = np.asarray(dict['filenames'])\n","    list_class=(unpickle(\"AIML_DS_CIFAR-10_STD/batches.meta\")['label_names'])\n","    return X,Y,names,list_class\n","                     \n","# Function to visualize the data\n","\n","def visualize_image(X, Y, names, image_id):\n","    rgb = X[image_id,:]\n","    img = rgb.reshape(3, 32, 32).transpose([1, 2, 0])\n","    print(img.shape)\n","    plt.imshow(img)\n","    plt.title(names[image_id])\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wO2iJs4UoHuW","colab_type":"code","outputId":"e7c239f6-2129-49dc-96c5-178e3604ba03","executionInfo":{"status":"ok","timestamp":1542892792209,"user_tz":-330,"elapsed":1261,"user":{"displayName":"Arun Kumar S","photoUrl":"","userId":"14042875339399760993"}},"colab":{"base_uri":"https://localhost:8080/","height":396}},"cell_type":"code","source":["# Read image\n","X, Y, names, classes = get_data(\"AIML_DS_CIFAR-10_STD/data_batch_3\")\n","# Visualize the 10th image\n","pick = 14\n","print(\"Class =\",classes[Y[pick]])\n","visualize_image(X, Y, names, pick)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Class = airplane\n","(32, 32, 3)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUsAAAFZCAYAAAARqQ0OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEmCyJCISYLIkIhJgsiQiEmCyJCIS+H+LlgwiElrd3gAAAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7f7159797080>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"38iB2wZLoHud","colab_type":"text"},"cell_type":"markdown","source":["We shall run a linear classifier. You can look at the code that calculates weights for the optimal line in \"perceptron_sgd\"."]},{"metadata":{"id":"E3FxWmFxoHue","colab_type":"text"},"cell_type":"markdown","source":["The perceptron is an algorithm for supervised learning of binary classifiers. It is an artificial neuron conceived as a model of biological neurons, which are the elementary units in an artificial neural network. An artificial neuron is a linear combination of certain (one or more) inputs and a corresponding weight vector."]},{"metadata":{"id":"1vIRAsfaoHuf","colab_type":"code","colab":{}},"cell_type":"code","source":["## Linear classifier code -\n","# code to estimate optimal linear boundary,\n","# classify train data by estimating the optimal linear boundary,\n","# predict labels based on linear boundary,\n","# and compute the accuracy of the classification\n","\n","# code to estimate optimal linear boundary (can ignore for now),\n","def perceptron_sgd(X, Y):\n","    w = np.zeros(len(X[0]))\n","    eta = 0.01 # learning rate\n","    epochs = 100\n","    for t in range(epochs):\n","        if (t+1) % 50 == 0:\n","            print(\"Running Epoch #\", t+1)\n","            # print(\"acc:\", compute_accuracy(predict(X[:, :-1], w), Y))\n","        for i, x in enumerate(X):\n","            if (np.dot(X[i], w) * Y[i]) <= 0:\n","                w = w + eta * X[i] * Y[i]\n","        eta *= 0.75\n","    return w\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lr7GRM4WoHuk","colab_type":"code","colab":{}},"cell_type":"code","source":["# classify train data by estimating the optimal linear boundary,\n","def classify(train_feat, train_labels):\n","    ## mapping first label to -1 and second to +1\n","    labels = np.sort(np.unique(train_labels))\n","    lmap = {labels[0] : -1, labels[1] : 1}\n","    l = [lmap[i] for i in train_labels]     \n","    ## appending 1 to train features\n","    add_one2train = np.ones((len(train_feat), 1))\n","    append_train_features = np.hstack((np.asarray(train_feat), add_one2train))\n","    w = perceptron_sgd(append_train_features, l)\n","    return w\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tHulTtONoHup","colab_type":"code","colab":{}},"cell_type":"code","source":["# predict labels based on linear boundary,\n","def predict(features, w):\n","    ##appending 1 to test features\n","    add_one = np.ones((len(features),1))\n","    append_features = np.hstack((np.asarray(features), add_one))\n","    pred = np.dot(append_features, w)\n","    return pred"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6CqlTOsIoHuu","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# compute the accuracy of the classification\n","def compute_accuracy(pred, test_labels):\n","    # To make it general, let us find the unique set of labels in test_labels\n","    # (could be \"apples\" and \"oranges\", or \"1\" and \"2\"),\n","    labels = np.sort(np.unique(test_labels))\n","    # and then assign -1 and 1 to these unique labels\n","    lmap = {labels[0] : -1, labels[1] : 1}\n","    # Let's now convert the labels to -1 and 1\n","    l = [lmap[i] for i in test_labels]\n","    # Let us find the accuracy\n","    p = []\n","    for i in range(len(pred)):\n","        p.append(1 if pred[i] >= 0 else -1)\n","    acc = np.mean(np.asarray(p) == np.asarray(l))\n","    return acc"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r3bKwwJaoHu-","colab_type":"text"},"cell_type":"markdown","source":["### Feature type 1: Raw Intensity values of RGB \n","Use Intensity values of RGB as intensity features. For this use the raw intensity features extracted above."]},{"metadata":{"id":"_PR632LkoHvA","colab_type":"code","colab":{}},"cell_type":"code","source":["## Unpickling the data and labels from CIFAR-10 Dataset,\n","## and Preparing the raw features for training and test data.\n","\n","X_train = []\n","Y_train = []\n","# Read all training features and labels\n","for j in \"12345\": \n","    batch_file = 'AIML_DS_CIFAR-10_STD/data_batch_'+ j\n","    x_train, y_train, names_train, classes_train = get_data(batch_file)\n","    X_train.extend(x_train)\n","    Y_train.extend(y_train)\n","\n","X_train = np.asarray(X_train)\n","Y_train = np.asarray(Y_train)\n","\n","# Read all test features and labels\n","X_test, Y_test, names_test, classes_test = get_data(\"AIML_DS_CIFAR-10_STD/test_batch\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c4v5ldX4oHvd","colab_type":"text"},"cell_type":"markdown","source":["### Feature type 2: Hand crafted features\n","For this we extracted 9 dimension feature for each image. Feature consist of min,max and mean intensity values for RGB channel."]},{"metadata":{"id":"3d-Z6iudoHvf","colab_type":"code","colab":{}},"cell_type":"code","source":["## Hand crafted features. For this we extracted 9 dimension feature for each image.\n","## Feature consist of min, max and mean intensity values for RGB channel.\n","\n","# Extract min, max and mean of R, G, and B in each image\n","# in train\n","def extract_RGB_min_max_mean(X):\n","    R, G, B = 1024, 2048, 3072\n","    R_min = np.reshape(np.min(X[:, :R], axis=1), (len(X), 1))\n","    R_max = np.reshape(np.max(X[:, :R], axis=1), (len(X), 1))\n","    R_mean = np.reshape(np.mean(X[:, :R], axis=1), (len(X), 1))\n","    G_min = np.reshape(np.min(X[:, R:G], axis=1), (len(X), 1))\n","    G_max = np.reshape(np.max(X[:, R:G], axis=1), (len(X), 1))\n","    G_mean = np.reshape(np.mean(X[:, R:G], axis=1), (len(X), 1))\n","    B_min = np.reshape(np.min(X[:, G:B], axis=1), (len(X), 1))\n","    B_max = np.reshape(np.max(X[:, G:B], axis=1), (len(X), 1))\n","    B_mean = np.reshape(np.mean(X[:, G:B], axis=1), (len(X), 1))\n","    return np.hstack((R_min, R_max, R_mean, G_min, G_max, G_mean, B_min, B_max, B_mean))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rZew0AtXoHvq","colab_type":"text"},"cell_type":"markdown","source":["### Feature-type3: PCA Features\n","Use PCA to reduce features high dimensionality features into low dimansionality features"]},{"metadata":{"id":"XCsUQCE1oHvr","colab_type":"code","colab":{}},"cell_type":"code","source":["## apply pca\n","from sklearn.decomposition import PCA\n","\n","def extract_eigenvectors(k, X_train):\n","    pca = PCA(n_components=k)\n","    pca.fit(X_train)\n","    eigen_vectors = pca.components_\n","    return eigen_vectors, pca\n","\n","def make_pca_features(eigen_vectors, X):\n","    return np.transpose(np.dot(eigen_vectors, np.transpose(X)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UnI1U2FWoHv9","colab_type":"text"},"cell_type":"markdown","source":["### Feature type-4: Deep Features"]},{"metadata":{"id":"I3cJnYQ-oHv-","colab_type":"code","colab":{}},"cell_type":"code","source":["### Loading the features\n","features = sio.loadmat('AIML_DS_CIFAR-10_STD/cifar10_deep_features.mat')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YBJGwEzqoHwB","colab_type":"code","outputId":"c9c85cf4-1d67-4b55-9137-5513a9a2f5c7","executionInfo":{"status":"ok","timestamp":1542351984345,"user_tz":-330,"elapsed":581,"user":{"displayName":"AIML Support","photoUrl":"","userId":"10944637975474083227"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# Extracting the deep features into training and testing\n","deep_features_train = features['x_train']\n","deep_labels_train = np.squeeze(np.transpose(features['y_train']))\n","deep_features_test = features['x_test']\n","deep_labels_test = np.squeeze(np.transpose(features['y_test']))\n","print(deep_features_train.shape, deep_labels_train.shape, deep_features_test.shape, deep_labels_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(50000, 512) (50000,) (10000, 512) (10000,)\n"],"name":"stdout"}]},{"metadata":{"id":"XouqAcQRoHwN","colab_type":"text"},"cell_type":"markdown","source":[" let us move onto multi-class classification. We shall do this by training a binary classifier for every pair of classes, and take a majority vote on the classes obtained.\n","\n","Let us first summarize all the features we have:"]},{"metadata":{"id":"QimBQXXGoHwP","colab_type":"code","outputId":"50192c6f-d76a-4f4b-d87a-67812058cac4","executionInfo":{"status":"ok","timestamp":1542351987642,"user_tz":-330,"elapsed":1055,"user":{"displayName":"AIML Support","photoUrl":"","userId":"10944637975474083227"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# Raw features\n","print(X_train.shape, X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(50000, 3072) (10000, 3072)\n"],"name":"stdout"}]},{"metadata":{"id":"aehDzknEoHwT","colab_type":"code","colab":{}},"cell_type":"code","source":["# Extract hand features for full training and test sets\n","head_features_train = extract_RGB_min_max_mean(X_train)\n","head_features_test = extract_RGB_min_max_mean(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jqTeadpOoHwW","colab_type":"code","outputId":"d51fba4d-1530-4ece-cc2c-0c85f84214a5","executionInfo":{"status":"ok","timestamp":1542351989628,"user_tz":-330,"elapsed":572,"user":{"displayName":"AIML Support","photoUrl":"","userId":"10944637975474083227"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["print(head_features_train.shape, head_features_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(50000, 9) (10000, 9)\n"],"name":"stdout"}]},{"metadata":{"id":"5qvNusELoHwa","colab_type":"code","colab":{}},"cell_type":"code","source":["# Extract pca features for full training and test sets\n","# Make pca features, with k=100\n","k = 200\n","eigen_vectors, pca_object = extract_eigenvectors(k, X_train)\n","pca_features_train = make_pca_features(eigen_vectors, X_train)\n","pca_features_test = make_pca_features(eigen_vectors, X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E04KwawvoHwe","colab_type":"text"},"cell_type":"markdown","source":["### Summarizing the extracted features:\n","\n","1. Raw Features: `(X_train, Y_train, X_test, Y_test)`\n","2. Hand made features: `(hand_features_train, Y_train, hand_features_test, Y_test)`\n","3. PCA Features: `(pca_features_train, Y_train, pca_features_test, Y_test)`\n","4. Deep Features (VGG): `(deep_features_train, deep_labels_train, deep_features_test, deep_labels_test)`\n","                  \n","So we can choose any one of these 4 types of features, and train multiclass classifiers.\n","\n","## Find accuracies with multi-class classification:\n","\n","The code for multiclass classification is provided below, and the classifier can be called using `multiclass_classification(train_features, train_labels, test_features, test_labels)`."]},{"metadata":{"id":"wfH3BVyroHwe","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","def extract_two_classes(data, x,y):\n","    xtrain = []\n","    ytrain = []\n","    merged = []\n","    merged.extend(data[x])\n","    merged.extend(data[y])\n","    random.shuffle(merged)\n","    xtrain = list(zip(*merged))[0]\n","    ytrain = list(zip(*merged))[1]\n","    return xtrain, ytrain\n","  \n","def oneVsone(data, num_classes, test_sample):\n","    weight = []\n","    prediction = []\n","    for i, j in list(itertools.combinations(range(num_classes), 2)):\n","        print(\"Training for classes\", i, j)\n","        xtrain, ytrain = extract_two_classes(data, i,j)\n","        w = classify(xtrain, ytrain)\n","        weight.append((w,(i,j)))\n","        pred = []\n","        preds = predict(test_sample, w)\n","        for p in predict(test_sample, w):\n","            if p > 0:\n","                pred.append(j)\n","            else:\n","                pred.append(i)\n","        prediction.append(pred)\n","        res = stats.mode(np.asarray(prediction))[0]\n","    return np.squeeze(res)\n","\n","# classify train data by estimating the optimal linear boundary,\n","def classify(train_feat, train_labels):\n","    ## mapping first label to -1 and second to +1\n","    labels = np.sort(np.unique(train_labels))\n","    lmap = {labels[0] : -1, labels[1] : 1}\n","    l = [lmap[i] for i in train_labels]     \n","    ## appending 1 to train features\n","    add_one2train = np.ones((len(train_feat), 1))\n","    append_train_features = np.hstack((np.asarray(train_feat), add_one2train))\n","    w = perceptron_sgd(append_train_features, l)\n","    return w\n","  \n","  \n","def multiclass_classification(X_train, Y_train, X_test, Y_test):\n","\n","    ## Train features and labels you want to use\n","    xtrain = X_train\n","    ytrain = Y_train\n","    ## Test features and labels you want to check on\n","    xtest = X_test\n","    ytest = Y_test\n","\n","    l = zip(xtrain,  ytrain)\n","    #L.sort(key=lambda x: x[1])\n","    L = sorted(l, key=lambda x: x[1])\n","\n","    it = itertools.groupby(L, operator.itemgetter(1))\n","    All_classes = []\n","\n","    for key, subiter in it:\n","#         print ('Class:', key)\n","        data = []\n","        for item in subiter:\n","            data.append(item)\n","        All_classes.append(data)\n","\n","    pred = oneVsone(All_classes, len(np.unique(Y_train)), xtest)\n","    print(accuracy_score(ytest, pred))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O-QZrTU2oHwh","colab_type":"text"},"cell_type":"markdown","source":["Replace `train_features`, `train_labels`, `test_features` and `test_labels` with the variables of your choice from the 4 above (raw, hand-crafted, pca, deep), and compare the accuracies."]},{"metadata":{"id":"RYZZnneFoHwi","colab_type":"code","colab":{}},"cell_type":"code","source":["# FEATURES & LABELS\n","train_features = ??\n","train_labels = ??\n","test_features = ??\n","test_labels = ??"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l09yJS1noHwl","colab_type":"code","colab":{}},"cell_type":"code","source":["multiclass_classification(train_features, train_labels, test_features, test_labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BKOXa_pXoHwn","colab_type":"text"},"cell_type":"markdown","source":["## In case we want to use sklearn's library for *faster* multi-class linear classification:"]},{"metadata":{"id":"Ojdz9l1EoHwo","colab_type":"code","colab":{}},"cell_type":"code","source":["actual_labels = np.array([(i, j) for i in range(10) for j in range(i+1, 10)]).T\n","\n","print(actual_labels)\n","\n","def extract_2classes_with_binary_labels(i, j, X, Y):\n","    # Select class #0\n","    X_0 = X[Y == i]\n","    Y_0 = np.zeros((len(X_0)))\n","    # Select class #1\n","    X_1 = X[Y == j]\n","    Y_1 = np.ones((len(X_1)))\n","    # Join the two classes to make the set\n","    X_2classes = np.vstack((X_0, X_1))\n","    Y_2classes = np.append(Y_0, Y_1)\n","    return X_2classes, Y_2classes\n","\n","# one-vs-one classifier\n","from sklearn import linear_model\n","def one_vs_one_classifier(train_features, train_labels):\n","    clf = linear_model.SGDClassifier(random_state=1)\n","    clf.fit(train_features, train_labels)\n","    return clf\n","\n","\n","def multiclass_classify_using_sklearn(X_train, Y_train, X_test, Y_test):\n","    \n","    classifiers = []\n","    \n","    # For each pair of classes:\n","    for i in range(0, 9):\n","        for j in range(i+1, 10):\n","            print(\"Training pair of classes:\", i, j)\n","            \n","            # Extract the train features and labels of the two classes\n","            train_features, train_labels = extract_2classes_with_binary_labels(i, j, X_train, Y_train)\n","            \n","            # Let us make each one-vs-one classifier\n","            # Train the classifier on these features and labels\n","            clf = one_vs_one_classifier(train_features, train_labels)\n","            classifiers.append(clf)\n","    \n","    # Find each classifier's prediction\n","    predicted_classes_from_all_classifiers = np.zeros((len(X_test), len(classifiers)), dtype=int)\n","    for c, clf in enumerate(classifiers):\n","        preds = np.asarray(clf.predict(X_test), dtype=int)\n","        predicted_classes_from_all_classifiers[:, c] = actual_labels[preds, c]\n","\n","    # Take majority vote for each sample\n","    predicted_classes = []\n","    for p in predicted_classes_from_all_classifiers:\n","        predicted_classes.append(np.argmax(np.bincount(p)))\n","    \n","    # Find accuracy\n","    test_accuracy = np.mean(predicted_classes == Y_test)\n","    print(\"Test accuracy: \", test_accuracy)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WY38AWSNoHwr","colab_type":"code","colab":{}},"cell_type":"code","source":["# FEATURES & LABELS\n","train_features = ??\n","train_labels = ??\n","test_features = ??\n","test_labels = ??"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mx3xvOUVoHwt","colab_type":"code","colab":{}},"cell_type":"code","source":["multiclass_classify_using_sklearn(train_features, train_labels, test_features, test_labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qxtMi4choHwz","colab_type":"text"},"cell_type":"markdown","source":["### Summary"]},{"metadata":{"id":"-VAczjVaoHw0","colab_type":"text"},"cell_type":"markdown","source":["1. We have seen how to extract the features from images using different techniques namely Raw intensity using RGB, hand-crafted features, PCA and Deep features.\n","2. We have learnt how to perform Binary-Class Classification and Multi-Class Classification. "]},{"metadata":{"id":"Ha4LnOtAoHw1","colab_type":"text"},"cell_type":"markdown","source":["#### For more information"]},{"metadata":{"id":"bGRlJ6kGoHw1","colab_type":"text"},"cell_type":"markdown","source":["https://medium.com/100-days-of-algorithms/day-92-pca-bdb66840a8fb"]},{"metadata":{"id":"vwEn-cW1oHw2","colab_type":"text"},"cell_type":"markdown","source":["https://towardsdatascience.com/what-the-hell-is-perceptron-626217814f53"]},{"metadata":{"id":"dpAoX2nds8yX","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"metadata":{"id":"MMi236E1oHw3","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good, But Not Challenging for me\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UDK7URYKtCwS","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"Test\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"myTLlKeGtGPz","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UTQ-GwXLtJVn","colab_type":"code","cellView":"form","outputId":"df9645e5-9ffd-44a6-d933-2d54e1aa35fa","executionInfo":{"status":"ok","timestamp":1542352088954,"user_tz":-330,"elapsed":1444,"user":{"displayName":"AIML Support","photoUrl":"","userId":"10944637975474083227"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Your submission is successful. Ref: 2805\n"],"name":"stdout"}]},{"metadata":{"id":"41VhqR9eWSjl","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}