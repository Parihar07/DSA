{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP_Classifier_CrossEntropy.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"WYDPGccf_JXv","colab_type":"text"},"cell_type":"markdown","source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"M3KlC2Y6_P1E","colab_type":"text"},"cell_type":"markdown","source":["\n","####Classification using MLP with Cross Entropy Loss"]},{"metadata":{"id":"d2gjZ5oU_hrk","colab_type":"text"},"cell_type":"markdown","source":["The objective of this case study is to understand classification i.e., if the price of the house is low (0) or high (1) using Multilayer perceptron with Cross Entropy Loss.  The package used here is [PyTorch](https://pytorch.org/). "]},{"metadata":{"id":"5h93h9DvYEhx","colab_type":"text"},"cell_type":"markdown","source":["#### Setup Steps"]},{"metadata":{"id":"f2e4LMfgYwPy","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P18_test\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"osqR_TXZYwZw","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"912345678\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-TctuuBZYwjx","colab_type":"code","cellView":"form","outputId":"754ce63d-0014-47d1-d34f-e80534deee55","executionInfo":{"status":"ok","timestamp":1543297404423,"user_tz":-330,"elapsed":96670,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M2W6_SUN_CS_1\" #name of the notebook\n","\n","def setup():\n","    #ipython.magic(\"sx wget https://www.dropbox.com/s/vu7xkf6j3v9p5np/AIML_DS_REGR01_SIMPLEPENDULUMOSCILLATIONDATA.txt.zip?dl=1\")\n","   # ipython.magic(\"sx unzip AIML_DS_REGR01_SIMPLEPENDULUMOSCILLATIONDATA.txt.zip?dl=1\")\n","    ipython.magic(\"sx pip install torch\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(\"Please enter valid Id\")\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful. Ref:\", submission_id)\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"metadata":{"id":"6u0c6-VXdWjO","colab_type":"text"},"cell_type":"markdown","source":["## Importing required packages for the experiment"]},{"metadata":{"colab_type":"code","id":"T2vxSk8VpJ0L","colab":{}},"cell_type":"code","source":["# Importing required Packages\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import  torch\n","from torch import nn\n","from sklearn.preprocessing import StandardScaler"],"execution_count":0,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:34:08.691158Z","start_time":"2018-11-23T07:34:08.685467Z"},"colab_type":"code","id":"KhJrSQ0wmQDN","colab":{}},"cell_type":"code","source":["#The attributes of related House price are stored in \"X\" as features. \n","X = np.array([[3, 2000, 90], [2, 800, 143], [2, 850, 167], [1, 550, 267], [4, 2000, 396]])\n","#The House price whether it is low (0) or high (1) are stored in \"y\" as labels.\n","y = np.array([1, 0, 0, 0 , 1])\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"rUBlUjsLpxQC","outputId":"3b9926a3-39e4-49c9-f998-bf9069a47b3a","executionInfo":{"status":"ok","timestamp":1543297426643,"user_tz":-330,"elapsed":646,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"cell_type":"code","source":["#Standard scaling the features \"X\"\n","ss = StandardScaler()\n","ss.fit(X)\n","X = ss.transform(X)\n","X"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n","  warnings.warn(msg, DataConversionWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["array([[ 0.58834841,  1.20863526, -1.13296108],\n","       [-0.39223227, -0.6997362 , -0.64318182],\n","       [-0.39223227, -0.62022073, -0.42139498],\n","       [-1.37281295, -1.09731359,  0.50271682],\n","       [ 1.56892908,  1.20863526,  1.69482106]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:32:33.885729Z","start_time":"2018-11-23T07:32:33.875066Z"},"colab_type":"code","id":"4NTCCccwmQEp","colab":{}},"cell_type":"code","source":["#Defining the model for Linear Classification with MLP using PyTorch's nn.Module\n","\n","class LinearClassificationModel(nn.Module):\n","\n","    def __init__(self, input_dim, output_dim):\n","\n","        super(LinearClassificationModel, self).__init__() \n","        # Calling Super Class's constructor\n","        self.linear1 = nn.Linear(input_dim, 4)\n","        self.linear2 = nn.Linear(4, output_dim)\n","        self.activation= nn.Sigmoid()\n","        # nn.Linear is defined in nn.Module\n","\n","    def forward(self, x):\n","        # Here the forward pass is simply a linear function\n","        #print(x.size())\n","        out = self.linear1(x)\n","        out = self.linear2(out)\n","        out = self.activation(out)\n","        return out\n","\n","input_dim = 3\n","output_dim = 2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KihaU4ewDM92","colab_type":"text"},"cell_type":"markdown","source":["From the above defined model, we 3 neurons in the input layer, 4 neurons in the hidden layer and 2 neurons in the output layer.\n","\n","![alt text](https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/MLP_classification.png)"]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:33:14.943117Z","start_time":"2018-11-23T07:33:14.931903Z"},"colab_type":"code","id":"wQa8qRHemQEv","colab":{}},"cell_type":"code","source":["model = LinearClassificationModel(input_dim,output_dim) #The LinearClassificationModel() is saved in model\n","criterion = nn.CrossEntropyLoss() #The criterion or the loss used is CrossEntropyLoss\n","l_rate = 0.01  #Learning Rate\n","optimiser = torch.optim.SGD(model.parameters(), lr = l_rate) #Stochastic Gradient Descent\n","\n","epochs = 5000  #number of epochs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"POVRQsj8DmQw","colab_type":"text"},"cell_type":"markdown","source":["Here, we are using Cross Entropy Loss for two classes and Stochastic Gradient Descent on the entire batch.\n","\n","\n","This criterion combines :func:`nn.LogSoftmax` and :func:`nn.NLLLoss` in one single class.\n","\n","The loss can be described as:\n","\n","$loss(x,class) = -log(\\frac{exp(x[class])}{\\sum_{j}exp(x[j])}) \n","                        = -x[class] + log(\\sum_{j}exp(x[j]))$\n"," \n","The losses are averaged across observations for the batch.\n","\n","For more details, can follow this [link](https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html). "]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:37:06.946827Z","start_time":"2018-11-23T07:37:06.921324Z"},"colab_type":"code","id":"Tm7a9HyXmQE1","outputId":"d787c258-a7b8-4ae1-90c6-ed9f25cf5723","scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":870417}},"cell_type":"code","source":["#Storing the losses in a list for the prescribed epochs \n","losses = []\n","for epoch in range(epochs):\n","#increase the number of epochs by 1 every time\n","    epoch +=1\n","  #inputs and labels are stored in a particular format as per the model\n","    inputs = torch.from_numpy(X.astype(np.float32))\n","    labels = torch.from_numpy(y.astype(np.float32))\n","    labels = labels.type(torch.long)  \n","    #clear grads as discussed in prev post\n","    optimiser.zero_grad()\n","    #forward to get predicted values\n","    outputs = model.forward(inputs)\n","    print('outputs: ', outputs)\n","    print('labels: ', labels)\n","    print('outputs size: ', outputs.size())\n","    print('labels size: ', labels.size())\n","    loss = criterion(outputs,labels)\n","    print('loss:', loss)\n","    loss.backward()# back props\n","    optimiser.step()# update the parameters\n","    print('epoch {}, loss {}'.format(epoch,loss.item()))\n","    losses.append(loss.item())\n","    if (epoch-1)%50 == 0:\n","        for i in model.parameters():\n","            print(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["outputs:  tensor([[0.5274, 0.4117],\n","        [0.5892, 0.4660],\n","        [0.5947, 0.4669],\n","        [0.6547, 0.4835],\n","        [0.5726, 0.4687]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6750, grad_fn=<NllLossBackward>)\n","epoch 1, loss 0.6750216484069824\n","Parameter containing:\n","tensor([[ 0.0118, -0.2458,  0.2447],\n","        [-0.3649,  0.1132,  0.0272],\n","        [-0.4374, -0.1074, -0.0330],\n","        [-0.3468, -0.3102, -0.0038]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4427, -0.4320,  0.0317,  0.0821], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.4857,  0.2353,  0.4079, -0.3391],\n","        [ 0.3085, -0.2979,  0.1233,  0.0118]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2591, -0.4338], requires_grad=True)\n","outputs:  tensor([[0.5271, 0.4119],\n","        [0.5895, 0.4657],\n","        [0.5950, 0.4667],\n","        [0.6553, 0.4831],\n","        [0.5720, 0.4690]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6747, grad_fn=<NllLossBackward>)\n","epoch 2, loss 0.6746863126754761\n","outputs:  tensor([[0.5268, 0.4120],\n","        [0.5899, 0.4655],\n","        [0.5953, 0.4665],\n","        [0.6559, 0.4826],\n","        [0.5714, 0.4693]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6744, grad_fn=<NllLossBackward>)\n","epoch 3, loss 0.6743512749671936\n","outputs:  tensor([[0.5265, 0.4122],\n","        [0.5902, 0.4653],\n","        [0.5956, 0.4663],\n","        [0.6564, 0.4822],\n","        [0.5708, 0.4696]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6740, grad_fn=<NllLossBackward>)\n","epoch 4, loss 0.6740164160728455\n","outputs:  tensor([[0.5262, 0.4123],\n","        [0.5905, 0.4651],\n","        [0.5959, 0.4661],\n","        [0.6570, 0.4818],\n","        [0.5702, 0.4699]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6737, grad_fn=<NllLossBackward>)\n","epoch 5, loss 0.6736818552017212\n","outputs:  tensor([[0.5259, 0.4125],\n","        [0.5908, 0.4649],\n","        [0.5962, 0.4659],\n","        [0.6576, 0.4813],\n","        [0.5696, 0.4702]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6733, grad_fn=<NllLossBackward>)\n","epoch 6, loss 0.6733473539352417\n","outputs:  tensor([[0.5256, 0.4126],\n","        [0.5912, 0.4647],\n","        [0.5965, 0.4657],\n","        [0.6582, 0.4809],\n","        [0.5691, 0.4705]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6730, grad_fn=<NllLossBackward>)\n","epoch 7, loss 0.6730132102966309\n","outputs:  tensor([[0.5253, 0.4128],\n","        [0.5915, 0.4644],\n","        [0.5968, 0.4655],\n","        [0.6588, 0.4805],\n","        [0.5685, 0.4708]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6727, grad_fn=<NllLossBackward>)\n","epoch 8, loss 0.6726792454719543\n","outputs:  tensor([[0.5250, 0.4129],\n","        [0.5918, 0.4642],\n","        [0.5971, 0.4653],\n","        [0.6594, 0.4800],\n","        [0.5679, 0.4711]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6723, grad_fn=<NllLossBackward>)\n","epoch 9, loss 0.6723455190658569\n","outputs:  tensor([[0.5247, 0.4131],\n","        [0.5921, 0.4640],\n","        [0.5974, 0.4651],\n","        [0.6599, 0.4796],\n","        [0.5673, 0.4714]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6720, grad_fn=<NllLossBackward>)\n","epoch 10, loss 0.6720119118690491\n","outputs:  tensor([[0.5244, 0.4132],\n","        [0.5925, 0.4638],\n","        [0.5977, 0.4648],\n","        [0.6605, 0.4792],\n","        [0.5667, 0.4717]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6717, grad_fn=<NllLossBackward>)\n","epoch 11, loss 0.6716784834861755\n","outputs:  tensor([[0.5241, 0.4134],\n","        [0.5928, 0.4636],\n","        [0.5980, 0.4646],\n","        [0.6611, 0.4788],\n","        [0.5661, 0.4720]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6713, grad_fn=<NllLossBackward>)\n","epoch 12, loss 0.6713453531265259\n","outputs:  tensor([[0.5237, 0.4135],\n","        [0.5931, 0.4634],\n","        [0.5983, 0.4644],\n","        [0.6617, 0.4783],\n","        [0.5655, 0.4723]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6710, grad_fn=<NllLossBackward>)\n","epoch 13, loss 0.671012282371521\n","outputs:  tensor([[0.5234, 0.4137],\n","        [0.5934, 0.4631],\n","        [0.5986, 0.4642],\n","        [0.6623, 0.4779],\n","        [0.5649, 0.4726]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6707, grad_fn=<NllLossBackward>)\n","epoch 14, loss 0.6706794500350952\n","outputs:  tensor([[0.5231, 0.4138],\n","        [0.5938, 0.4629],\n","        [0.5989, 0.4640],\n","        [0.6629, 0.4775],\n","        [0.5642, 0.4729]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6703, grad_fn=<NllLossBackward>)\n","epoch 15, loss 0.670346736907959\n","outputs:  tensor([[0.5228, 0.4140],\n","        [0.5941, 0.4627],\n","        [0.5992, 0.4638],\n","        [0.6634, 0.4770],\n","        [0.5636, 0.4732]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6700, grad_fn=<NllLossBackward>)\n","epoch 16, loss 0.6700142025947571\n","outputs:  tensor([[0.5225, 0.4141],\n","        [0.5944, 0.4625],\n","        [0.5995, 0.4636],\n","        [0.6640, 0.4766],\n","        [0.5630, 0.4735]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6697, grad_fn=<NllLossBackward>)\n","epoch 17, loss 0.6696819067001343\n","outputs:  tensor([[0.5222, 0.4143],\n","        [0.5947, 0.4623],\n","        [0.5998, 0.4634],\n","        [0.6646, 0.4762],\n","        [0.5624, 0.4738]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6693, grad_fn=<NllLossBackward>)\n","epoch 18, loss 0.6693496108055115\n","outputs:  tensor([[0.5219, 0.4145],\n","        [0.5950, 0.4621],\n","        [0.6001, 0.4632],\n","        [0.6652, 0.4757],\n","        [0.5618, 0.4741]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6690, grad_fn=<NllLossBackward>)\n","epoch 19, loss 0.6690176129341125\n","outputs:  tensor([[0.5216, 0.4146],\n","        [0.5954, 0.4619],\n","        [0.6004, 0.4630],\n","        [0.6657, 0.4753],\n","        [0.5612, 0.4744]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6687, grad_fn=<NllLossBackward>)\n","epoch 20, loss 0.6686856150627136\n","outputs:  tensor([[0.5213, 0.4148],\n","        [0.5957, 0.4616],\n","        [0.6007, 0.4628],\n","        [0.6663, 0.4749],\n","        [0.5606, 0.4747]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6684, grad_fn=<NllLossBackward>)\n","epoch 21, loss 0.6683538556098938\n","outputs:  tensor([[0.5210, 0.4149],\n","        [0.5960, 0.4614],\n","        [0.6010, 0.4626],\n","        [0.6669, 0.4744],\n","        [0.5600, 0.4750]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6680, grad_fn=<NllLossBackward>)\n","epoch 22, loss 0.6680221557617188\n","outputs:  tensor([[0.5206, 0.4151],\n","        [0.5963, 0.4612],\n","        [0.6013, 0.4623],\n","        [0.6675, 0.4740],\n","        [0.5594, 0.4753]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6677, grad_fn=<NllLossBackward>)\n","epoch 23, loss 0.6676905751228333\n","outputs:  tensor([[0.5203, 0.4152],\n","        [0.5967, 0.4610],\n","        [0.6016, 0.4621],\n","        [0.6680, 0.4736],\n","        [0.5588, 0.4756]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6674, grad_fn=<NllLossBackward>)\n","epoch 24, loss 0.6673590540885925\n","outputs:  tensor([[0.5200, 0.4154],\n","        [0.5970, 0.4608],\n","        [0.6019, 0.4619],\n","        [0.6686, 0.4732],\n","        [0.5582, 0.4759]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6670, grad_fn=<NllLossBackward>)\n","epoch 25, loss 0.6670278310775757\n","outputs:  tensor([[0.5197, 0.4155],\n","        [0.5973, 0.4606],\n","        [0.6022, 0.4617],\n","        [0.6692, 0.4727],\n","        [0.5576, 0.4762]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6667, grad_fn=<NllLossBackward>)\n","epoch 26, loss 0.6666966080665588\n","outputs:  tensor([[0.5194, 0.4157],\n","        [0.5976, 0.4604],\n","        [0.6025, 0.4615],\n","        [0.6698, 0.4723],\n","        [0.5570, 0.4765]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6664, grad_fn=<NllLossBackward>)\n","epoch 27, loss 0.6663654446601868\n","outputs:  tensor([[0.5191, 0.4158],\n","        [0.5979, 0.4601],\n","        [0.6028, 0.4613],\n","        [0.6703, 0.4719],\n","        [0.5563, 0.4768]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6660, grad_fn=<NllLossBackward>)\n","epoch 28, loss 0.6660344004631042\n","outputs:  tensor([[0.5188, 0.4160],\n","        [0.5982, 0.4599],\n","        [0.6031, 0.4611],\n","        [0.6709, 0.4714],\n","        [0.5557, 0.4771]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6657, grad_fn=<NllLossBackward>)\n","epoch 29, loss 0.6657034754753113\n","outputs:  tensor([[0.5185, 0.4162],\n","        [0.5986, 0.4597],\n","        [0.6034, 0.4609],\n","        [0.6715, 0.4710],\n","        [0.5551, 0.4774]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6654, grad_fn=<NllLossBackward>)\n","epoch 30, loss 0.6653725504875183\n","outputs:  tensor([[0.5181, 0.4163],\n","        [0.5989, 0.4595],\n","        [0.6037, 0.4607],\n","        [0.6720, 0.4706],\n","        [0.5545, 0.4777]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6650, grad_fn=<NllLossBackward>)\n","epoch 31, loss 0.6650418043136597\n","outputs:  tensor([[0.5178, 0.4165],\n","        [0.5992, 0.4593],\n","        [0.6040, 0.4605],\n","        [0.6726, 0.4701],\n","        [0.5539, 0.4780]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6647, grad_fn=<NllLossBackward>)\n","epoch 32, loss 0.6647111177444458\n","outputs:  tensor([[0.5175, 0.4166],\n","        [0.5995, 0.4591],\n","        [0.6043, 0.4603],\n","        [0.6732, 0.4697],\n","        [0.5533, 0.4783]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6644, grad_fn=<NllLossBackward>)\n","epoch 33, loss 0.6643804311752319\n","outputs:  tensor([[0.5172, 0.4168],\n","        [0.5998, 0.4589],\n","        [0.6046, 0.4601],\n","        [0.6738, 0.4693],\n","        [0.5526, 0.4786]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6640, grad_fn=<NllLossBackward>)\n","epoch 34, loss 0.6640498042106628\n","outputs:  tensor([[0.5169, 0.4169],\n","        [0.6002, 0.4587],\n","        [0.6049, 0.4599],\n","        [0.6743, 0.4689],\n","        [0.5520, 0.4789]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6637, grad_fn=<NllLossBackward>)\n","epoch 35, loss 0.6637192964553833\n","outputs:  tensor([[0.5166, 0.4171],\n","        [0.6005, 0.4585],\n","        [0.6052, 0.4597],\n","        [0.6749, 0.4684],\n","        [0.5514, 0.4792]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6634, grad_fn=<NllLossBackward>)\n","epoch 36, loss 0.6633888483047485\n","outputs:  tensor([[0.5162, 0.4173],\n","        [0.6008, 0.4582],\n","        [0.6055, 0.4595],\n","        [0.6755, 0.4680],\n","        [0.5508, 0.4795]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6631, grad_fn=<NllLossBackward>)\n","epoch 37, loss 0.6630584001541138\n","outputs:  tensor([[0.5159, 0.4174],\n","        [0.6011, 0.4580],\n","        [0.6058, 0.4593],\n","        [0.6760, 0.4676],\n","        [0.5502, 0.4798]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6627, grad_fn=<NllLossBackward>)\n","epoch 38, loss 0.6627280116081238\n","outputs:  tensor([[0.5156, 0.4176],\n","        [0.6014, 0.4578],\n","        [0.6061, 0.4591],\n","        [0.6766, 0.4671],\n","        [0.5495, 0.4801]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6624, grad_fn=<NllLossBackward>)\n","epoch 39, loss 0.6623976230621338\n","outputs:  tensor([[0.5153, 0.4177],\n","        [0.6017, 0.4576],\n","        [0.6064, 0.4589],\n","        [0.6772, 0.4667],\n","        [0.5489, 0.4804]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6621, grad_fn=<NllLossBackward>)\n","epoch 40, loss 0.6620672941207886\n","outputs:  tensor([[0.5150, 0.4179],\n","        [0.6021, 0.4574],\n","        [0.6067, 0.4587],\n","        [0.6777, 0.4663],\n","        [0.5483, 0.4807]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6617, grad_fn=<NllLossBackward>)\n","epoch 41, loss 0.6617370247840881\n","outputs:  tensor([[0.5146, 0.4180],\n","        [0.6024, 0.4572],\n","        [0.6070, 0.4584],\n","        [0.6783, 0.4659],\n","        [0.5477, 0.4810]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6614, grad_fn=<NllLossBackward>)\n","epoch 42, loss 0.6614067554473877\n","outputs:  tensor([[0.5143, 0.4182],\n","        [0.6027, 0.4570],\n","        [0.6073, 0.4582],\n","        [0.6789, 0.4654],\n","        [0.5470, 0.4813]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6611, grad_fn=<NllLossBackward>)\n","epoch 43, loss 0.6610764861106873\n","outputs:  tensor([[0.5140, 0.4184],\n","        [0.6030, 0.4568],\n","        [0.6076, 0.4580],\n","        [0.6794, 0.4650],\n","        [0.5464, 0.4816]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6607, grad_fn=<NllLossBackward>)\n","epoch 44, loss 0.6607462167739868\n","outputs:  tensor([[0.5137, 0.4185],\n","        [0.6033, 0.4566],\n","        [0.6079, 0.4578],\n","        [0.6800, 0.4646],\n","        [0.5458, 0.4819]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6604, grad_fn=<NllLossBackward>)\n","epoch 45, loss 0.6604159474372864\n","outputs:  tensor([[0.5134, 0.4187],\n","        [0.6036, 0.4564],\n","        [0.6081, 0.4576],\n","        [0.6805, 0.4641],\n","        [0.5451, 0.4822]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6601, grad_fn=<NllLossBackward>)\n","epoch 46, loss 0.6600856781005859\n","outputs:  tensor([[0.5130, 0.4188],\n","        [0.6040, 0.4561],\n","        [0.6084, 0.4574],\n","        [0.6811, 0.4637],\n","        [0.5445, 0.4825]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6598, grad_fn=<NllLossBackward>)\n","epoch 47, loss 0.6597554683685303\n","outputs:  tensor([[0.5127, 0.4190],\n","        [0.6043, 0.4559],\n","        [0.6087, 0.4572],\n","        [0.6817, 0.4633],\n","        [0.5439, 0.4828]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6594, grad_fn=<NllLossBackward>)\n","epoch 48, loss 0.6594251394271851\n","outputs:  tensor([[0.5124, 0.4192],\n","        [0.6046, 0.4557],\n","        [0.6090, 0.4570],\n","        [0.6822, 0.4629],\n","        [0.5432, 0.4832]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6591, grad_fn=<NllLossBackward>)\n","epoch 49, loss 0.6590949296951294\n","outputs:  tensor([[0.5121, 0.4193],\n","        [0.6049, 0.4555],\n","        [0.6093, 0.4568],\n","        [0.6828, 0.4624],\n","        [0.5426, 0.4835]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6588, grad_fn=<NllLossBackward>)\n","epoch 50, loss 0.6587646007537842\n","outputs:  tensor([[0.5118, 0.4195],\n","        [0.6052, 0.4553],\n","        [0.6096, 0.4566],\n","        [0.6834, 0.4620],\n","        [0.5420, 0.4838]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6584, grad_fn=<NllLossBackward>)\n","epoch 51, loss 0.658434271812439\n","Parameter containing:\n","tensor([[ 0.0028, -0.2562,  0.2422],\n","        [-0.3928,  0.0817,  0.0197],\n","        [-0.4530, -0.1252, -0.0373],\n","        [-0.3309, -0.2921,  0.0005]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4432, -0.4279,  0.0334,  0.0801], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.4991,  0.2457,  0.4376, -0.3044],\n","        [ 0.2938, -0.3079,  0.0925, -0.0243]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2655, -0.4425], requires_grad=True)\n","outputs:  tensor([[0.5114, 0.4196],\n","        [0.6055, 0.4551],\n","        [0.6099, 0.4564],\n","        [0.6839, 0.4616],\n","        [0.5413, 0.4841]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6581, grad_fn=<NllLossBackward>)\n","epoch 52, loss 0.658103883266449\n","outputs:  tensor([[0.5111, 0.4198],\n","        [0.6058, 0.4549],\n","        [0.6102, 0.4562],\n","        [0.6845, 0.4611],\n","        [0.5407, 0.4844]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6578, grad_fn=<NllLossBackward>)\n","epoch 53, loss 0.657773494720459\n","outputs:  tensor([[0.5108, 0.4200],\n","        [0.6062, 0.4547],\n","        [0.6105, 0.4560],\n","        [0.6850, 0.4607],\n","        [0.5401, 0.4847]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6574, grad_fn=<NllLossBackward>)\n","epoch 54, loss 0.6574430465698242\n","outputs:  tensor([[0.5105, 0.4201],\n","        [0.6065, 0.4545],\n","        [0.6108, 0.4558],\n","        [0.6856, 0.4603],\n","        [0.5394, 0.4850]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6571, grad_fn=<NllLossBackward>)\n","epoch 55, loss 0.6571126580238342\n","outputs:  tensor([[0.5101, 0.4203],\n","        [0.6068, 0.4543],\n","        [0.6111, 0.4556],\n","        [0.6862, 0.4599],\n","        [0.5388, 0.4853]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6568, grad_fn=<NllLossBackward>)\n","epoch 56, loss 0.6567821502685547\n","outputs:  tensor([[0.5098, 0.4205],\n","        [0.6071, 0.4540],\n","        [0.6114, 0.4554],\n","        [0.6867, 0.4594],\n","        [0.5381, 0.4856]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6565, grad_fn=<NllLossBackward>)\n","epoch 57, loss 0.6564515829086304\n","outputs:  tensor([[0.5095, 0.4206],\n","        [0.6074, 0.4538],\n","        [0.6117, 0.4552],\n","        [0.6873, 0.4590],\n","        [0.5375, 0.4859]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6561, grad_fn=<NllLossBackward>)\n","epoch 58, loss 0.6561208963394165\n","outputs:  tensor([[0.5091, 0.4208],\n","        [0.6077, 0.4536],\n","        [0.6120, 0.4550],\n","        [0.6878, 0.4586],\n","        [0.5369, 0.4863]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6558, grad_fn=<NllLossBackward>)\n","epoch 59, loss 0.6557902097702026\n","outputs:  tensor([[0.5088, 0.4209],\n","        [0.6080, 0.4534],\n","        [0.6122, 0.4548],\n","        [0.6884, 0.4581],\n","        [0.5362, 0.4866]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6555, grad_fn=<NllLossBackward>)\n","epoch 60, loss 0.6554595232009888\n","outputs:  tensor([[0.5085, 0.4211],\n","        [0.6084, 0.4532],\n","        [0.6125, 0.4546],\n","        [0.6890, 0.4577],\n","        [0.5356, 0.4869]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6551, grad_fn=<NllLossBackward>)\n","epoch 61, loss 0.6551286578178406\n","outputs:  tensor([[0.5082, 0.4213],\n","        [0.6087, 0.4530],\n","        [0.6128, 0.4544],\n","        [0.6895, 0.4573],\n","        [0.5349, 0.4872]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6548, grad_fn=<NllLossBackward>)\n","epoch 62, loss 0.6547977328300476\n","outputs:  tensor([[0.5078, 0.4214],\n","        [0.6090, 0.4528],\n","        [0.6131, 0.4542],\n","        [0.6901, 0.4569],\n","        [0.5343, 0.4875]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6545, grad_fn=<NllLossBackward>)\n","epoch 63, loss 0.6544669270515442\n","outputs:  tensor([[0.5075, 0.4216],\n","        [0.6093, 0.4526],\n","        [0.6134, 0.4540],\n","        [0.6906, 0.4564],\n","        [0.5336, 0.4878]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6541, grad_fn=<NllLossBackward>)\n","epoch 64, loss 0.6541357040405273\n","outputs:  tensor([[0.5072, 0.4218],\n","        [0.6096, 0.4524],\n","        [0.6137, 0.4538],\n","        [0.6912, 0.4560],\n","        [0.5330, 0.4882]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6538, grad_fn=<NllLossBackward>)\n","epoch 65, loss 0.6538046598434448\n","outputs:  tensor([[0.5068, 0.4219],\n","        [0.6099, 0.4522],\n","        [0.6140, 0.4536],\n","        [0.6917, 0.4556],\n","        [0.5323, 0.4885]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6535, grad_fn=<NllLossBackward>)\n","epoch 66, loss 0.653473436832428\n","outputs:  tensor([[0.5065, 0.4221],\n","        [0.6102, 0.4520],\n","        [0.6143, 0.4534],\n","        [0.6923, 0.4551],\n","        [0.5317, 0.4888]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6531, grad_fn=<NllLossBackward>)\n","epoch 67, loss 0.6531421542167664\n","outputs:  tensor([[0.5062, 0.4223],\n","        [0.6105, 0.4518],\n","        [0.6146, 0.4532],\n","        [0.6928, 0.4547],\n","        [0.5310, 0.4891]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6528, grad_fn=<NllLossBackward>)\n","epoch 68, loss 0.6528106927871704\n","outputs:  tensor([[0.5058, 0.4224],\n","        [0.6109, 0.4515],\n","        [0.6149, 0.4530],\n","        [0.6934, 0.4543],\n","        [0.5304, 0.4894]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6525, grad_fn=<NllLossBackward>)\n","epoch 69, loss 0.6524791717529297\n","outputs:  tensor([[0.5055, 0.4226],\n","        [0.6112, 0.4513],\n","        [0.6152, 0.4528],\n","        [0.6940, 0.4538],\n","        [0.5297, 0.4897]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6521, grad_fn=<NllLossBackward>)\n","epoch 70, loss 0.6521474719047546\n","outputs:  tensor([[0.5052, 0.4228],\n","        [0.6115, 0.4511],\n","        [0.6154, 0.4526],\n","        [0.6945, 0.4534],\n","        [0.5291, 0.4901]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6518, grad_fn=<NllLossBackward>)\n","epoch 71, loss 0.6518157720565796\n","outputs:  tensor([[0.5048, 0.4229],\n","        [0.6118, 0.4509],\n","        [0.6157, 0.4524],\n","        [0.6951, 0.4530],\n","        [0.5284, 0.4904]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6515, grad_fn=<NllLossBackward>)\n","epoch 72, loss 0.6514838933944702\n","outputs:  tensor([[0.5045, 0.4231],\n","        [0.6121, 0.4507],\n","        [0.6160, 0.4522],\n","        [0.6956, 0.4525],\n","        [0.5277, 0.4907]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6512, grad_fn=<NllLossBackward>)\n","epoch 73, loss 0.6511518955230713\n","outputs:  tensor([[0.5042, 0.4233],\n","        [0.6124, 0.4505],\n","        [0.6163, 0.4520],\n","        [0.6962, 0.4521],\n","        [0.5271, 0.4910]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6508, grad_fn=<NllLossBackward>)\n","epoch 74, loss 0.6508197784423828\n","outputs:  tensor([[0.5038, 0.4234],\n","        [0.6127, 0.4503],\n","        [0.6166, 0.4518],\n","        [0.6967, 0.4517],\n","        [0.5264, 0.4914]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6505, grad_fn=<NllLossBackward>)\n","epoch 75, loss 0.6504875421524048\n","outputs:  tensor([[0.5035, 0.4236],\n","        [0.6130, 0.4501],\n","        [0.6169, 0.4516],\n","        [0.6973, 0.4512],\n","        [0.5258, 0.4917]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6502, grad_fn=<NllLossBackward>)\n","epoch 76, loss 0.6501551270484924\n","outputs:  tensor([[0.5031, 0.4238],\n","        [0.6134, 0.4499],\n","        [0.6172, 0.4514],\n","        [0.6978, 0.4508],\n","        [0.5251, 0.4920]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6498, grad_fn=<NllLossBackward>)\n","epoch 77, loss 0.6498225927352905\n","outputs:  tensor([[0.5028, 0.4240],\n","        [0.6137, 0.4497],\n","        [0.6175, 0.4512],\n","        [0.6984, 0.4504],\n","        [0.5244, 0.4923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6495, grad_fn=<NllLossBackward>)\n","epoch 78, loss 0.6494899988174438\n","outputs:  tensor([[0.5025, 0.4241],\n","        [0.6140, 0.4495],\n","        [0.6178, 0.4510],\n","        [0.6989, 0.4499],\n","        [0.5238, 0.4927]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6492, grad_fn=<NllLossBackward>)\n","epoch 79, loss 0.6491571664810181\n","outputs:  tensor([[0.5021, 0.4243],\n","        [0.6143, 0.4493],\n","        [0.6181, 0.4508],\n","        [0.6995, 0.4495],\n","        [0.5231, 0.4930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6488, grad_fn=<NllLossBackward>)\n","epoch 80, loss 0.648824155330658\n","outputs:  tensor([[0.5018, 0.4245],\n","        [0.6146, 0.4490],\n","        [0.6183, 0.4506],\n","        [0.7000, 0.4491],\n","        [0.5224, 0.4933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6485, grad_fn=<NllLossBackward>)\n","epoch 81, loss 0.6484910845756531\n","outputs:  tensor([[0.5015, 0.4246],\n","        [0.6149, 0.4488],\n","        [0.6186, 0.4504],\n","        [0.7006, 0.4486],\n","        [0.5218, 0.4936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6482, grad_fn=<NllLossBackward>)\n","epoch 82, loss 0.6481578946113586\n","outputs:  tensor([[0.5011, 0.4248],\n","        [0.6152, 0.4486],\n","        [0.6189, 0.4501],\n","        [0.7011, 0.4482],\n","        [0.5211, 0.4940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6478, grad_fn=<NllLossBackward>)\n","epoch 83, loss 0.6478244066238403\n","outputs:  tensor([[0.5008, 0.4250],\n","        [0.6155, 0.4484],\n","        [0.6192, 0.4499],\n","        [0.7017, 0.4478],\n","        [0.5204, 0.4943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6475, grad_fn=<NllLossBackward>)\n","epoch 84, loss 0.6474908590316772\n","outputs:  tensor([[0.5004, 0.4252],\n","        [0.6158, 0.4482],\n","        [0.6195, 0.4497],\n","        [0.7022, 0.4473],\n","        [0.5198, 0.4946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6472, grad_fn=<NllLossBackward>)\n","epoch 85, loss 0.6471570730209351\n","outputs:  tensor([[0.5001, 0.4253],\n","        [0.6162, 0.4480],\n","        [0.6198, 0.4495],\n","        [0.7028, 0.4469],\n","        [0.5191, 0.4950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6468, grad_fn=<NllLossBackward>)\n","epoch 86, loss 0.6468232274055481\n","outputs:  tensor([[0.4997, 0.4255],\n","        [0.6165, 0.4478],\n","        [0.6201, 0.4493],\n","        [0.7033, 0.4465],\n","        [0.5184, 0.4953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6465, grad_fn=<NllLossBackward>)\n","epoch 87, loss 0.6464890837669373\n","outputs:  tensor([[0.4994, 0.4257],\n","        [0.6168, 0.4476],\n","        [0.6204, 0.4491],\n","        [0.7039, 0.4460],\n","        [0.5177, 0.4956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6462, grad_fn=<NllLossBackward>)\n","epoch 88, loss 0.6461547613143921\n","outputs:  tensor([[0.4991, 0.4259],\n","        [0.6171, 0.4474],\n","        [0.6207, 0.4489],\n","        [0.7044, 0.4456],\n","        [0.5171, 0.4959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6458, grad_fn=<NllLossBackward>)\n","epoch 89, loss 0.6458203196525574\n","outputs:  tensor([[0.4987, 0.4260],\n","        [0.6174, 0.4472],\n","        [0.6209, 0.4487],\n","        [0.7050, 0.4452],\n","        [0.5164, 0.4963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6455, grad_fn=<NllLossBackward>)\n","epoch 90, loss 0.6454856991767883\n","outputs:  tensor([[0.4984, 0.4262],\n","        [0.6177, 0.4470],\n","        [0.6212, 0.4485],\n","        [0.7055, 0.4447],\n","        [0.5157, 0.4966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6452, grad_fn=<NllLossBackward>)\n","epoch 91, loss 0.6451508402824402\n","outputs:  tensor([[0.4980, 0.4264],\n","        [0.6180, 0.4467],\n","        [0.6215, 0.4483],\n","        [0.7061, 0.4443],\n","        [0.5150, 0.4970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6448, grad_fn=<NllLossBackward>)\n","epoch 92, loss 0.6448158025741577\n","outputs:  tensor([[0.4977, 0.4266],\n","        [0.6183, 0.4465],\n","        [0.6218, 0.4481],\n","        [0.7066, 0.4438],\n","        [0.5143, 0.4973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6445, grad_fn=<NllLossBackward>)\n","epoch 93, loss 0.6444805860519409\n","outputs:  tensor([[0.4973, 0.4268],\n","        [0.6186, 0.4463],\n","        [0.6221, 0.4479],\n","        [0.7072, 0.4434],\n","        [0.5137, 0.4976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6441, grad_fn=<NllLossBackward>)\n","epoch 94, loss 0.6441451907157898\n","outputs:  tensor([[0.4970, 0.4269],\n","        [0.6190, 0.4461],\n","        [0.6224, 0.4477],\n","        [0.7077, 0.4430],\n","        [0.5130, 0.4980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6438, grad_fn=<NllLossBackward>)\n","epoch 95, loss 0.6438095569610596\n","outputs:  tensor([[0.4966, 0.4271],\n","        [0.6193, 0.4459],\n","        [0.6227, 0.4475],\n","        [0.7083, 0.4425],\n","        [0.5123, 0.4983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6435, grad_fn=<NllLossBackward>)\n","epoch 96, loss 0.643473744392395\n","outputs:  tensor([[0.4963, 0.4273],\n","        [0.6196, 0.4457],\n","        [0.6230, 0.4473],\n","        [0.7088, 0.4421],\n","        [0.5116, 0.4986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6431, grad_fn=<NllLossBackward>)\n","epoch 97, loss 0.6431376338005066\n","outputs:  tensor([[0.4959, 0.4275],\n","        [0.6199, 0.4455],\n","        [0.6233, 0.4471],\n","        [0.7094, 0.4417],\n","        [0.5109, 0.4990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6428, grad_fn=<NllLossBackward>)\n","epoch 98, loss 0.6428014039993286\n","outputs:  tensor([[0.4956, 0.4276],\n","        [0.6202, 0.4453],\n","        [0.6235, 0.4469],\n","        [0.7099, 0.4412],\n","        [0.5102, 0.4993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6425, grad_fn=<NllLossBackward>)\n","epoch 99, loss 0.6424649357795715\n","outputs:  tensor([[0.4952, 0.4278],\n","        [0.6205, 0.4451],\n","        [0.6238, 0.4467],\n","        [0.7104, 0.4408],\n","        [0.5095, 0.4997]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6421, grad_fn=<NllLossBackward>)\n","epoch 100, loss 0.6421281695365906\n","outputs:  tensor([[0.4949, 0.4280],\n","        [0.6208, 0.4449],\n","        [0.6241, 0.4465],\n","        [0.7110, 0.4403],\n","        [0.5088, 0.5000]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6418, grad_fn=<NllLossBackward>)\n","epoch 101, loss 0.6417912840843201\n","Parameter containing:\n","tensor([[-0.0072, -0.2678,  0.2392],\n","        [-0.4212,  0.0496,  0.0119],\n","        [-0.4711, -0.1459, -0.0424],\n","        [-0.3190, -0.2785,  0.0039]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4435, -0.4240,  0.0352,  0.0789], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.5128,  0.2593,  0.4683, -0.2723],\n","        [ 0.2783, -0.3212,  0.0602, -0.0580]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2708, -0.4507], requires_grad=True)\n","outputs:  tensor([[0.4945, 0.4282],\n","        [0.6211, 0.4446],\n","        [0.6244, 0.4463],\n","        [0.7115, 0.4399],\n","        [0.5081, 0.5004]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6415, grad_fn=<NllLossBackward>)\n","epoch 102, loss 0.6414541602134705\n","outputs:  tensor([[0.4942, 0.4284],\n","        [0.6214, 0.4444],\n","        [0.6247, 0.4461],\n","        [0.7121, 0.4394],\n","        [0.5075, 0.5007]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6411, grad_fn=<NllLossBackward>)\n","epoch 103, loss 0.6411167979240417\n","outputs:  tensor([[0.4938, 0.4286],\n","        [0.6218, 0.4442],\n","        [0.6250, 0.4459],\n","        [0.7126, 0.4390],\n","        [0.5068, 0.5010]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6408, grad_fn=<NllLossBackward>)\n","epoch 104, loss 0.6407791376113892\n","outputs:  tensor([[0.4935, 0.4287],\n","        [0.6221, 0.4440],\n","        [0.6253, 0.4457],\n","        [0.7132, 0.4386],\n","        [0.5061, 0.5014]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6404, grad_fn=<NllLossBackward>)\n","epoch 105, loss 0.6404412984848022\n","outputs:  tensor([[0.4931, 0.4289],\n","        [0.6224, 0.4438],\n","        [0.6256, 0.4455],\n","        [0.7137, 0.4381],\n","        [0.5054, 0.5017]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6401, grad_fn=<NllLossBackward>)\n","epoch 106, loss 0.6401032209396362\n","outputs:  tensor([[0.4927, 0.4291],\n","        [0.6227, 0.4436],\n","        [0.6259, 0.4453],\n","        [0.7143, 0.4377],\n","        [0.5047, 0.5021]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6398, grad_fn=<NllLossBackward>)\n","epoch 107, loss 0.6397649049758911\n","outputs:  tensor([[0.4924, 0.4293],\n","        [0.6230, 0.4434],\n","        [0.6261, 0.4451],\n","        [0.7148, 0.4372],\n","        [0.5040, 0.5024]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6394, grad_fn=<NllLossBackward>)\n","epoch 108, loss 0.6394263505935669\n","outputs:  tensor([[0.4920, 0.4295],\n","        [0.6233, 0.4432],\n","        [0.6264, 0.4449],\n","        [0.7154, 0.4368],\n","        [0.5033, 0.5028]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6391, grad_fn=<NllLossBackward>)\n","epoch 109, loss 0.6390875577926636\n","outputs:  tensor([[0.4917, 0.4297],\n","        [0.6236, 0.4430],\n","        [0.6267, 0.4447],\n","        [0.7159, 0.4363],\n","        [0.5026, 0.5031]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6387, grad_fn=<NllLossBackward>)\n","epoch 110, loss 0.6387484669685364\n","outputs:  tensor([[0.4913, 0.4298],\n","        [0.6239, 0.4427],\n","        [0.6270, 0.4445],\n","        [0.7164, 0.4359],\n","        [0.5019, 0.5035]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6384, grad_fn=<NllLossBackward>)\n","epoch 111, loss 0.6384091377258301\n","outputs:  tensor([[0.4910, 0.4300],\n","        [0.6243, 0.4425],\n","        [0.6273, 0.4443],\n","        [0.7170, 0.4355],\n","        [0.5012, 0.5038]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6381, grad_fn=<NllLossBackward>)\n","epoch 112, loss 0.6380695104598999\n","outputs:  tensor([[0.4906, 0.4302],\n","        [0.6246, 0.4423],\n","        [0.6276, 0.4441],\n","        [0.7175, 0.4350],\n","        [0.5004, 0.5042]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6377, grad_fn=<NllLossBackward>)\n","epoch 113, loss 0.6377296447753906\n","outputs:  tensor([[0.4902, 0.4304],\n","        [0.6249, 0.4421],\n","        [0.6279, 0.4438],\n","        [0.7181, 0.4346],\n","        [0.4997, 0.5046]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6374, grad_fn=<NllLossBackward>)\n","epoch 114, loss 0.6373895406723022\n","outputs:  tensor([[0.4899, 0.4306],\n","        [0.6252, 0.4419],\n","        [0.6282, 0.4436],\n","        [0.7186, 0.4341],\n","        [0.4990, 0.5049]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6370, grad_fn=<NllLossBackward>)\n","epoch 115, loss 0.6370492577552795\n","outputs:  tensor([[0.4895, 0.4308],\n","        [0.6255, 0.4417],\n","        [0.6285, 0.4434],\n","        [0.7192, 0.4337],\n","        [0.4983, 0.5053]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6367, grad_fn=<NllLossBackward>)\n","epoch 116, loss 0.6367084980010986\n","outputs:  tensor([[0.4891, 0.4310],\n","        [0.6258, 0.4415],\n","        [0.6287, 0.4432],\n","        [0.7197, 0.4332],\n","        [0.4976, 0.5056]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6364, grad_fn=<NllLossBackward>)\n","epoch 117, loss 0.636367678642273\n","outputs:  tensor([[0.4888, 0.4312],\n","        [0.6261, 0.4413],\n","        [0.6290, 0.4430],\n","        [0.7202, 0.4328],\n","        [0.4969, 0.5060]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6360, grad_fn=<NllLossBackward>)\n","epoch 118, loss 0.6360265016555786\n","outputs:  tensor([[0.4884, 0.4314],\n","        [0.6264, 0.4410],\n","        [0.6293, 0.4428],\n","        [0.7208, 0.4323],\n","        [0.4962, 0.5063]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6357, grad_fn=<NllLossBackward>)\n","epoch 119, loss 0.6356850862503052\n","outputs:  tensor([[0.4881, 0.4316],\n","        [0.6267, 0.4408],\n","        [0.6296, 0.4426],\n","        [0.7213, 0.4319],\n","        [0.4955, 0.5067]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6353, grad_fn=<NllLossBackward>)\n","epoch 120, loss 0.6353432536125183\n","outputs:  tensor([[0.4877, 0.4317],\n","        [0.6271, 0.4406],\n","        [0.6299, 0.4424],\n","        [0.7219, 0.4314],\n","        [0.4948, 0.5071]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6350, grad_fn=<NllLossBackward>)\n","epoch 121, loss 0.6350012421607971\n","outputs:  tensor([[0.4873, 0.4319],\n","        [0.6274, 0.4404],\n","        [0.6302, 0.4422],\n","        [0.7224, 0.4310],\n","        [0.4940, 0.5074]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6347, grad_fn=<NllLossBackward>)\n","epoch 122, loss 0.6346589922904968\n","outputs:  tensor([[0.4870, 0.4321],\n","        [0.6277, 0.4402],\n","        [0.6305, 0.4420],\n","        [0.7230, 0.4305],\n","        [0.4933, 0.5078]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6343, grad_fn=<NllLossBackward>)\n","epoch 123, loss 0.6343163251876831\n","outputs:  tensor([[0.4866, 0.4323],\n","        [0.6280, 0.4400],\n","        [0.6308, 0.4418],\n","        [0.7235, 0.4301],\n","        [0.4926, 0.5082]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6340, grad_fn=<NllLossBackward>)\n","epoch 124, loss 0.6339734792709351\n","outputs:  tensor([[0.4862, 0.4325],\n","        [0.6283, 0.4398],\n","        [0.6311, 0.4416],\n","        [0.7240, 0.4296],\n","        [0.4919, 0.5085]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6336, grad_fn=<NllLossBackward>)\n","epoch 125, loss 0.6336303353309631\n","outputs:  tensor([[0.4859, 0.4327],\n","        [0.6286, 0.4395],\n","        [0.6314, 0.4414],\n","        [0.7246, 0.4292],\n","        [0.4911, 0.5089]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6333, grad_fn=<NllLossBackward>)\n","epoch 126, loss 0.6332868337631226\n","outputs:  tensor([[0.4855, 0.4329],\n","        [0.6289, 0.4393],\n","        [0.6316, 0.4412],\n","        [0.7251, 0.4287],\n","        [0.4904, 0.5093]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6329, grad_fn=<NllLossBackward>)\n","epoch 127, loss 0.6329430937767029\n","outputs:  tensor([[0.4851, 0.4331],\n","        [0.6293, 0.4391],\n","        [0.6319, 0.4410],\n","        [0.7257, 0.4283],\n","        [0.4897, 0.5096]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6326, grad_fn=<NllLossBackward>)\n","epoch 128, loss 0.6325989961624146\n","outputs:  tensor([[0.4847, 0.4333],\n","        [0.6296, 0.4389],\n","        [0.6322, 0.4408],\n","        [0.7262, 0.4278],\n","        [0.4890, 0.5100]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6323, grad_fn=<NllLossBackward>)\n","epoch 129, loss 0.6322546601295471\n","outputs:  tensor([[0.4844, 0.4335],\n","        [0.6299, 0.4387],\n","        [0.6325, 0.4405],\n","        [0.7267, 0.4274],\n","        [0.4882, 0.5104]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6319, grad_fn=<NllLossBackward>)\n","epoch 130, loss 0.631909966468811\n","outputs:  tensor([[0.4840, 0.4337],\n","        [0.6302, 0.4385],\n","        [0.6328, 0.4403],\n","        [0.7273, 0.4269],\n","        [0.4875, 0.5107]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6316, grad_fn=<NllLossBackward>)\n","epoch 131, loss 0.6315650939941406\n","outputs:  tensor([[0.4836, 0.4339],\n","        [0.6305, 0.4383],\n","        [0.6331, 0.4401],\n","        [0.7278, 0.4265],\n","        [0.4868, 0.5111]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6312, grad_fn=<NllLossBackward>)\n","epoch 132, loss 0.631219744682312\n","outputs:  tensor([[0.4833, 0.4341],\n","        [0.6308, 0.4380],\n","        [0.6334, 0.4399],\n","        [0.7284, 0.4260],\n","        [0.4861, 0.5115]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6309, grad_fn=<NllLossBackward>)\n","epoch 133, loss 0.6308742165565491\n","outputs:  tensor([[0.4829, 0.4343],\n","        [0.6311, 0.4378],\n","        [0.6337, 0.4397],\n","        [0.7289, 0.4255],\n","        [0.4853, 0.5119]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6305, grad_fn=<NllLossBackward>)\n","epoch 134, loss 0.6305282711982727\n","outputs:  tensor([[0.4825, 0.4345],\n","        [0.6314, 0.4376],\n","        [0.6340, 0.4395],\n","        [0.7294, 0.4251],\n","        [0.4846, 0.5123]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6302, grad_fn=<NllLossBackward>)\n","epoch 135, loss 0.630182147026062\n","outputs:  tensor([[0.4821, 0.4347],\n","        [0.6318, 0.4374],\n","        [0.6343, 0.4393],\n","        [0.7300, 0.4246],\n","        [0.4838, 0.5126]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6298, grad_fn=<NllLossBackward>)\n","epoch 136, loss 0.6298356056213379\n","outputs:  tensor([[0.4818, 0.4349],\n","        [0.6321, 0.4372],\n","        [0.6345, 0.4391],\n","        [0.7305, 0.4242],\n","        [0.4831, 0.5130]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6295, grad_fn=<NllLossBackward>)\n","epoch 137, loss 0.6294887065887451\n","outputs:  tensor([[0.4814, 0.4351],\n","        [0.6324, 0.4370],\n","        [0.6348, 0.4389],\n","        [0.7311, 0.4237],\n","        [0.4824, 0.5134]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6291, grad_fn=<NllLossBackward>)\n","epoch 138, loss 0.6291415691375732\n","outputs:  tensor([[0.4810, 0.4353],\n","        [0.6327, 0.4367],\n","        [0.6351, 0.4387],\n","        [0.7316, 0.4233],\n","        [0.4816, 0.5138]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6288, grad_fn=<NllLossBackward>)\n","epoch 139, loss 0.6287940740585327\n","outputs:  tensor([[0.4806, 0.4355],\n","        [0.6330, 0.4365],\n","        [0.6354, 0.4385],\n","        [0.7321, 0.4228],\n","        [0.4809, 0.5142]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6284, grad_fn=<NllLossBackward>)\n","epoch 140, loss 0.6284462213516235\n","outputs:  tensor([[0.4802, 0.4357],\n","        [0.6333, 0.4363],\n","        [0.6357, 0.4382],\n","        [0.7327, 0.4223],\n","        [0.4801, 0.5145]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6281, grad_fn=<NllLossBackward>)\n","epoch 141, loss 0.6280980706214905\n","outputs:  tensor([[0.4799, 0.4359],\n","        [0.6336, 0.4361],\n","        [0.6360, 0.4380],\n","        [0.7332, 0.4219],\n","        [0.4794, 0.5149]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6277, grad_fn=<NllLossBackward>)\n","epoch 142, loss 0.6277496218681335\n","outputs:  tensor([[0.4795, 0.4361],\n","        [0.6340, 0.4359],\n","        [0.6363, 0.4378],\n","        [0.7338, 0.4214],\n","        [0.4787, 0.5153]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6274, grad_fn=<NllLossBackward>)\n","epoch 143, loss 0.6274008750915527\n","outputs:  tensor([[0.4791, 0.4363],\n","        [0.6343, 0.4356],\n","        [0.6366, 0.4376],\n","        [0.7343, 0.4209],\n","        [0.4779, 0.5157]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6271, grad_fn=<NllLossBackward>)\n","epoch 144, loss 0.6270517110824585\n","outputs:  tensor([[0.4787, 0.4365],\n","        [0.6346, 0.4354],\n","        [0.6369, 0.4374],\n","        [0.7348, 0.4205],\n","        [0.4772, 0.5161]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6267, grad_fn=<NllLossBackward>)\n","epoch 145, loss 0.6267022490501404\n","outputs:  tensor([[0.4783, 0.4367],\n","        [0.6349, 0.4352],\n","        [0.6372, 0.4372],\n","        [0.7354, 0.4200],\n","        [0.4764, 0.5165]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6264, grad_fn=<NllLossBackward>)\n","epoch 146, loss 0.6263524889945984\n","outputs:  tensor([[0.4780, 0.4370],\n","        [0.6352, 0.4350],\n","        [0.6375, 0.4370],\n","        [0.7359, 0.4196],\n","        [0.4757, 0.5169]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6260, grad_fn=<NllLossBackward>)\n","epoch 147, loss 0.6260023713111877\n","outputs:  tensor([[0.4776, 0.4372],\n","        [0.6355, 0.4348],\n","        [0.6377, 0.4368],\n","        [0.7364, 0.4191],\n","        [0.4749, 0.5173]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6257, grad_fn=<NllLossBackward>)\n","epoch 148, loss 0.6256519556045532\n","outputs:  tensor([[0.4772, 0.4374],\n","        [0.6359, 0.4346],\n","        [0.6380, 0.4366],\n","        [0.7370, 0.4186],\n","        [0.4742, 0.5177]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6253, grad_fn=<NllLossBackward>)\n","epoch 149, loss 0.6253010630607605\n","outputs:  tensor([[0.4768, 0.4376],\n","        [0.6362, 0.4343],\n","        [0.6383, 0.4363],\n","        [0.7375, 0.4182],\n","        [0.4734, 0.5181]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6249, grad_fn=<NllLossBackward>)\n","epoch 150, loss 0.6249499320983887\n","outputs:  tensor([[0.4764, 0.4378],\n","        [0.6365, 0.4341],\n","        [0.6386, 0.4361],\n","        [0.7381, 0.4177],\n","        [0.4727, 0.5185]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6246, grad_fn=<NllLossBackward>)\n","epoch 151, loss 0.6245984435081482\n","Parameter containing:\n","tensor([[-0.0180, -0.2804,  0.2359],\n","        [-0.4501,  0.0167,  0.0039],\n","        [-0.4916, -0.1694, -0.0483],\n","        [-0.3106, -0.2688,  0.0064]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4437, -0.4203,  0.0370,  0.0784], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.5268,  0.2760,  0.5001, -0.2426],\n","        [ 0.2620, -0.3376,  0.0265, -0.0897]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2752, -0.4584], requires_grad=True)\n","outputs:  tensor([[0.4760, 0.4380],\n","        [0.6368, 0.4339],\n","        [0.6389, 0.4359],\n","        [0.7386, 0.4172],\n","        [0.4719, 0.5188]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6242, grad_fn=<NllLossBackward>)\n","epoch 152, loss 0.6242465972900391\n","outputs:  tensor([[0.4756, 0.4382],\n","        [0.6371, 0.4337],\n","        [0.6392, 0.4357],\n","        [0.7391, 0.4168],\n","        [0.4711, 0.5192]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6239, grad_fn=<NllLossBackward>)\n","epoch 153, loss 0.6238943934440613\n","outputs:  tensor([[0.4753, 0.4384],\n","        [0.6374, 0.4334],\n","        [0.6395, 0.4355],\n","        [0.7397, 0.4163],\n","        [0.4704, 0.5196]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6235, grad_fn=<NllLossBackward>)\n","epoch 154, loss 0.6235419511795044\n","outputs:  tensor([[0.4749, 0.4386],\n","        [0.6377, 0.4332],\n","        [0.6398, 0.4353],\n","        [0.7402, 0.4158],\n","        [0.4696, 0.5200]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6232, grad_fn=<NllLossBackward>)\n","epoch 155, loss 0.6231890916824341\n","outputs:  tensor([[0.4745, 0.4389],\n","        [0.6381, 0.4330],\n","        [0.6401, 0.4351],\n","        [0.7407, 0.4154],\n","        [0.4689, 0.5205]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6228, grad_fn=<NllLossBackward>)\n","epoch 156, loss 0.6228358149528503\n","outputs:  tensor([[0.4741, 0.4391],\n","        [0.6384, 0.4328],\n","        [0.6404, 0.4349],\n","        [0.7413, 0.4149],\n","        [0.4681, 0.5209]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6225, grad_fn=<NllLossBackward>)\n","epoch 157, loss 0.622482180595398\n","outputs:  tensor([[0.4737, 0.4393],\n","        [0.6387, 0.4326],\n","        [0.6407, 0.4346],\n","        [0.7418, 0.4144],\n","        [0.4673, 0.5213]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6221, grad_fn=<NllLossBackward>)\n","epoch 158, loss 0.6221283674240112\n","outputs:  tensor([[0.4733, 0.4395],\n","        [0.6390, 0.4323],\n","        [0.6410, 0.4344],\n","        [0.7423, 0.4139],\n","        [0.4666, 0.5217]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6218, grad_fn=<NllLossBackward>)\n","epoch 159, loss 0.6217740178108215\n","outputs:  tensor([[0.4729, 0.4397],\n","        [0.6393, 0.4321],\n","        [0.6413, 0.4342],\n","        [0.7429, 0.4135],\n","        [0.4658, 0.5221]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6214, grad_fn=<NllLossBackward>)\n","epoch 160, loss 0.621419370174408\n","outputs:  tensor([[0.4725, 0.4399],\n","        [0.6397, 0.4319],\n","        [0.6416, 0.4340],\n","        [0.7434, 0.4130],\n","        [0.4650, 0.5225]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6211, grad_fn=<NllLossBackward>)\n","epoch 161, loss 0.6210644245147705\n","outputs:  tensor([[0.4721, 0.4402],\n","        [0.6400, 0.4317],\n","        [0.6418, 0.4338],\n","        [0.7440, 0.4125],\n","        [0.4643, 0.5229]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6207, grad_fn=<NllLossBackward>)\n","epoch 162, loss 0.6207090616226196\n","outputs:  tensor([[0.4717, 0.4404],\n","        [0.6403, 0.4314],\n","        [0.6421, 0.4336],\n","        [0.7445, 0.4121],\n","        [0.4635, 0.5233]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6204, grad_fn=<NllLossBackward>)\n","epoch 163, loss 0.6203533411026001\n","outputs:  tensor([[0.4713, 0.4406],\n","        [0.6406, 0.4312],\n","        [0.6424, 0.4333],\n","        [0.7450, 0.4116],\n","        [0.4627, 0.5237]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6200, grad_fn=<NllLossBackward>)\n","epoch 164, loss 0.6199972629547119\n","outputs:  tensor([[0.4709, 0.4408],\n","        [0.6409, 0.4310],\n","        [0.6427, 0.4331],\n","        [0.7456, 0.4111],\n","        [0.4619, 0.5241]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6196, grad_fn=<NllLossBackward>)\n","epoch 165, loss 0.6196408271789551\n","outputs:  tensor([[0.4705, 0.4410],\n","        [0.6412, 0.4308],\n","        [0.6430, 0.4329],\n","        [0.7461, 0.4106],\n","        [0.4612, 0.5246]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6193, grad_fn=<NllLossBackward>)\n","epoch 166, loss 0.6192840337753296\n","outputs:  tensor([[0.4701, 0.4413],\n","        [0.6416, 0.4305],\n","        [0.6433, 0.4327],\n","        [0.7466, 0.4101],\n","        [0.4604, 0.5250]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6189, grad_fn=<NllLossBackward>)\n","epoch 167, loss 0.6189268827438354\n","outputs:  tensor([[0.4698, 0.4415],\n","        [0.6419, 0.4303],\n","        [0.6436, 0.4325],\n","        [0.7472, 0.4097],\n","        [0.4596, 0.5254]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6186, grad_fn=<NllLossBackward>)\n","epoch 168, loss 0.6185693740844727\n","outputs:  tensor([[0.4694, 0.4417],\n","        [0.6422, 0.4301],\n","        [0.6439, 0.4323],\n","        [0.7477, 0.4092],\n","        [0.4588, 0.5258]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6182, grad_fn=<NllLossBackward>)\n","epoch 169, loss 0.6182115077972412\n","outputs:  tensor([[0.4690, 0.4419],\n","        [0.6425, 0.4299],\n","        [0.6442, 0.4320],\n","        [0.7482, 0.4087],\n","        [0.4581, 0.5262]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6179, grad_fn=<NllLossBackward>)\n","epoch 170, loss 0.6178532838821411\n","outputs:  tensor([[0.4686, 0.4422],\n","        [0.6428, 0.4296],\n","        [0.6445, 0.4318],\n","        [0.7488, 0.4082],\n","        [0.4573, 0.5266]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6175, grad_fn=<NllLossBackward>)\n","epoch 171, loss 0.6174945831298828\n","outputs:  tensor([[0.4682, 0.4424],\n","        [0.6432, 0.4294],\n","        [0.6448, 0.4316],\n","        [0.7493, 0.4078],\n","        [0.4565, 0.5271]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6171, grad_fn=<NllLossBackward>)\n","epoch 172, loss 0.6171356439590454\n","outputs:  tensor([[0.4677, 0.4426],\n","        [0.6435, 0.4292],\n","        [0.6451, 0.4314],\n","        [0.7498, 0.4073],\n","        [0.4557, 0.5275]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6168, grad_fn=<NllLossBackward>)\n","epoch 173, loss 0.6167763471603394\n","outputs:  tensor([[0.4673, 0.4428],\n","        [0.6438, 0.4289],\n","        [0.6454, 0.4312],\n","        [0.7504, 0.4068],\n","        [0.4549, 0.5279]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6164, grad_fn=<NllLossBackward>)\n","epoch 174, loss 0.6164165735244751\n","outputs:  tensor([[0.4669, 0.4431],\n","        [0.6441, 0.4287],\n","        [0.6457, 0.4310],\n","        [0.7509, 0.4063],\n","        [0.4541, 0.5284]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6161, grad_fn=<NllLossBackward>)\n","epoch 175, loss 0.616056501865387\n","outputs:  tensor([[0.4665, 0.4433],\n","        [0.6444, 0.4285],\n","        [0.6460, 0.4307],\n","        [0.7514, 0.4058],\n","        [0.4534, 0.5288]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6157, grad_fn=<NllLossBackward>)\n","epoch 176, loss 0.6156960129737854\n","outputs:  tensor([[0.4661, 0.4435],\n","        [0.6448, 0.4283],\n","        [0.6463, 0.4305],\n","        [0.7520, 0.4053],\n","        [0.4526, 0.5292]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6153, grad_fn=<NllLossBackward>)\n","epoch 177, loss 0.61533522605896\n","outputs:  tensor([[0.4657, 0.4438],\n","        [0.6451, 0.4280],\n","        [0.6466, 0.4303],\n","        [0.7525, 0.4049],\n","        [0.4518, 0.5296]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6150, grad_fn=<NllLossBackward>)\n","epoch 178, loss 0.6149740815162659\n","outputs:  tensor([[0.4653, 0.4440],\n","        [0.6454, 0.4278],\n","        [0.6469, 0.4301],\n","        [0.7530, 0.4044],\n","        [0.4510, 0.5301]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6146, grad_fn=<NllLossBackward>)\n","epoch 179, loss 0.6146124601364136\n","outputs:  tensor([[0.4649, 0.4442],\n","        [0.6457, 0.4276],\n","        [0.6472, 0.4299],\n","        [0.7536, 0.4039],\n","        [0.4502, 0.5305]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6143, grad_fn=<NllLossBackward>)\n","epoch 180, loss 0.6142505407333374\n","outputs:  tensor([[0.4645, 0.4445],\n","        [0.6460, 0.4273],\n","        [0.6475, 0.4296],\n","        [0.7541, 0.4034],\n","        [0.4494, 0.5309]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6139, grad_fn=<NllLossBackward>)\n","epoch 181, loss 0.6138882637023926\n","outputs:  tensor([[0.4641, 0.4447],\n","        [0.6464, 0.4271],\n","        [0.6477, 0.4294],\n","        [0.7546, 0.4029],\n","        [0.4486, 0.5314]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6135, grad_fn=<NllLossBackward>)\n","epoch 182, loss 0.6135255098342896\n","outputs:  tensor([[0.4637, 0.4449],\n","        [0.6467, 0.4269],\n","        [0.6480, 0.4292],\n","        [0.7552, 0.4024],\n","        [0.4478, 0.5318]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6132, grad_fn=<NllLossBackward>)\n","epoch 183, loss 0.6131623983383179\n","outputs:  tensor([[0.4633, 0.4452],\n","        [0.6470, 0.4266],\n","        [0.6483, 0.4290],\n","        [0.7557, 0.4019],\n","        [0.4470, 0.5323]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6128, grad_fn=<NllLossBackward>)\n","epoch 184, loss 0.6127990484237671\n","outputs:  tensor([[0.4629, 0.4454],\n","        [0.6473, 0.4264],\n","        [0.6486, 0.4287],\n","        [0.7562, 0.4014],\n","        [0.4462, 0.5327]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6124, grad_fn=<NllLossBackward>)\n","epoch 185, loss 0.6124352216720581\n","outputs:  tensor([[0.4625, 0.4456],\n","        [0.6477, 0.4262],\n","        [0.6489, 0.4285],\n","        [0.7568, 0.4010],\n","        [0.4454, 0.5332]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6121, grad_fn=<NllLossBackward>)\n","epoch 186, loss 0.6120710968971252\n","outputs:  tensor([[0.4620, 0.4459],\n","        [0.6480, 0.4259],\n","        [0.6492, 0.4283],\n","        [0.7573, 0.4005],\n","        [0.4446, 0.5336]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6117, grad_fn=<NllLossBackward>)\n","epoch 187, loss 0.6117064356803894\n","outputs:  tensor([[0.4616, 0.4461],\n","        [0.6483, 0.4257],\n","        [0.6495, 0.4281],\n","        [0.7578, 0.4000],\n","        [0.4438, 0.5340]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6113, grad_fn=<NllLossBackward>)\n","epoch 188, loss 0.6113415956497192\n","outputs:  tensor([[0.4612, 0.4463],\n","        [0.6486, 0.4255],\n","        [0.6498, 0.4278],\n","        [0.7584, 0.3995],\n","        [0.4430, 0.5345]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6110, grad_fn=<NllLossBackward>)\n","epoch 189, loss 0.6109762191772461\n","outputs:  tensor([[0.4608, 0.4466],\n","        [0.6489, 0.4252],\n","        [0.6501, 0.4276],\n","        [0.7589, 0.3990],\n","        [0.4422, 0.5349]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6106, grad_fn=<NllLossBackward>)\n","epoch 190, loss 0.6106106042861938\n","outputs:  tensor([[0.4604, 0.4468],\n","        [0.6493, 0.4250],\n","        [0.6504, 0.4274],\n","        [0.7594, 0.3985],\n","        [0.4414, 0.5354]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6102, grad_fn=<NllLossBackward>)\n","epoch 191, loss 0.6102445721626282\n","outputs:  tensor([[0.4600, 0.4471],\n","        [0.6496, 0.4248],\n","        [0.6507, 0.4272],\n","        [0.7600, 0.3980],\n","        [0.4406, 0.5358]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6099, grad_fn=<NllLossBackward>)\n","epoch 192, loss 0.6098781824111938\n","outputs:  tensor([[0.4596, 0.4473],\n","        [0.6499, 0.4245],\n","        [0.6510, 0.4269],\n","        [0.7605, 0.3975],\n","        [0.4398, 0.5363]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6095, grad_fn=<NllLossBackward>)\n","epoch 193, loss 0.6095113754272461\n","outputs:  tensor([[0.4591, 0.4475],\n","        [0.6502, 0.4243],\n","        [0.6513, 0.4267],\n","        [0.7610, 0.3970],\n","        [0.4390, 0.5367]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6091, grad_fn=<NllLossBackward>)\n","epoch 194, loss 0.6091440916061401\n","outputs:  tensor([[0.4587, 0.4478],\n","        [0.6506, 0.4241],\n","        [0.6516, 0.4265],\n","        [0.7616, 0.3965],\n","        [0.4382, 0.5372]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6088, grad_fn=<NllLossBackward>)\n","epoch 195, loss 0.6087766885757446\n","outputs:  tensor([[0.4583, 0.4480],\n","        [0.6509, 0.4238],\n","        [0.6519, 0.4263],\n","        [0.7621, 0.3960],\n","        [0.4374, 0.5377]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6084, grad_fn=<NllLossBackward>)\n","epoch 196, loss 0.6084086894989014\n","outputs:  tensor([[0.4579, 0.4483],\n","        [0.6512, 0.4236],\n","        [0.6522, 0.4260],\n","        [0.7626, 0.3955],\n","        [0.4366, 0.5381]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6080, grad_fn=<NllLossBackward>)\n","epoch 197, loss 0.6080403923988342\n","outputs:  tensor([[0.4575, 0.4485],\n","        [0.6515, 0.4234],\n","        [0.6525, 0.4258],\n","        [0.7631, 0.3950],\n","        [0.4357, 0.5386]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6077, grad_fn=<NllLossBackward>)\n","epoch 198, loss 0.6076717376708984\n","outputs:  tensor([[0.4571, 0.4488],\n","        [0.6519, 0.4231],\n","        [0.6528, 0.4256],\n","        [0.7637, 0.3945],\n","        [0.4349, 0.5390]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6073, grad_fn=<NllLossBackward>)\n","epoch 199, loss 0.6073026657104492\n","outputs:  tensor([[0.4566, 0.4490],\n","        [0.6522, 0.4229],\n","        [0.6531, 0.4254],\n","        [0.7642, 0.3940],\n","        [0.4341, 0.5395]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6069, grad_fn=<NllLossBackward>)\n","epoch 200, loss 0.6069332361221313\n","outputs:  tensor([[0.4562, 0.4493],\n","        [0.6525, 0.4226],\n","        [0.6534, 0.4251],\n","        [0.7647, 0.3935],\n","        [0.4333, 0.5400]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6066, grad_fn=<NllLossBackward>)\n","epoch 201, loss 0.6065634489059448\n","Parameter containing:\n","tensor([[-0.0296, -0.2940,  0.2322],\n","        [-0.4797, -0.0170, -0.0042],\n","        [-0.5142, -0.1955, -0.0548],\n","        [-0.3054, -0.2627,  0.0080]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4438, -0.4167,  0.0388,  0.0783], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.5413,  0.2952,  0.5327, -0.2150],\n","        [ 0.2448, -0.3570, -0.0088, -0.1197]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2789, -0.4658], requires_grad=True)\n","outputs:  tensor([[0.4558, 0.4495],\n","        [0.6528, 0.4224],\n","        [0.6537, 0.4249],\n","        [0.7653, 0.3930],\n","        [0.4325, 0.5404]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6062, grad_fn=<NllLossBackward>)\n","epoch 202, loss 0.6061933636665344\n","outputs:  tensor([[0.4554, 0.4498],\n","        [0.6532, 0.4222],\n","        [0.6540, 0.4247],\n","        [0.7658, 0.3925],\n","        [0.4317, 0.5409]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6058, grad_fn=<NllLossBackward>)\n","epoch 203, loss 0.605822741985321\n","outputs:  tensor([[0.4549, 0.4500],\n","        [0.6535, 0.4219],\n","        [0.6543, 0.4244],\n","        [0.7663, 0.3920],\n","        [0.4308, 0.5414]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6055, grad_fn=<NllLossBackward>)\n","epoch 204, loss 0.6054518222808838\n","outputs:  tensor([[0.4545, 0.4503],\n","        [0.6538, 0.4217],\n","        [0.6546, 0.4242],\n","        [0.7669, 0.3915],\n","        [0.4300, 0.5418]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6051, grad_fn=<NllLossBackward>)\n","epoch 205, loss 0.6050805449485779\n","outputs:  tensor([[0.4541, 0.4505],\n","        [0.6541, 0.4214],\n","        [0.6549, 0.4240],\n","        [0.7674, 0.3910],\n","        [0.4292, 0.5423]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6047, grad_fn=<NllLossBackward>)\n","epoch 206, loss 0.6047088503837585\n","outputs:  tensor([[0.4537, 0.4508],\n","        [0.6545, 0.4212],\n","        [0.6552, 0.4238],\n","        [0.7679, 0.3905],\n","        [0.4284, 0.5428]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6043, grad_fn=<NllLossBackward>)\n","epoch 207, loss 0.6043368577957153\n","outputs:  tensor([[0.4532, 0.4510],\n","        [0.6548, 0.4210],\n","        [0.6555, 0.4235],\n","        [0.7684, 0.3900],\n","        [0.4276, 0.5433]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6040, grad_fn=<NllLossBackward>)\n","epoch 208, loss 0.6039645075798035\n","outputs:  tensor([[0.4528, 0.4513],\n","        [0.6551, 0.4207],\n","        [0.6558, 0.4233],\n","        [0.7690, 0.3895],\n","        [0.4267, 0.5437]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6036, grad_fn=<NllLossBackward>)\n","epoch 209, loss 0.6035917401313782\n","outputs:  tensor([[0.4524, 0.4516],\n","        [0.6555, 0.4205],\n","        [0.6561, 0.4231],\n","        [0.7695, 0.3890],\n","        [0.4259, 0.5442]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6032, grad_fn=<NllLossBackward>)\n","epoch 210, loss 0.603218674659729\n","outputs:  tensor([[0.4519, 0.4518],\n","        [0.6558, 0.4202],\n","        [0.6564, 0.4228],\n","        [0.7700, 0.3884],\n","        [0.4251, 0.5447]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6028, grad_fn=<NllLossBackward>)\n","epoch 211, loss 0.6028450727462769\n","outputs:  tensor([[0.4515, 0.4521],\n","        [0.6561, 0.4200],\n","        [0.6567, 0.4226],\n","        [0.7706, 0.3879],\n","        [0.4242, 0.5452]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6025, grad_fn=<NllLossBackward>)\n","epoch 212, loss 0.6024712324142456\n","outputs:  tensor([[0.4511, 0.4523],\n","        [0.6564, 0.4197],\n","        [0.6570, 0.4224],\n","        [0.7711, 0.3874],\n","        [0.4234, 0.5457]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6021, grad_fn=<NllLossBackward>)\n","epoch 213, loss 0.6020969152450562\n","outputs:  tensor([[0.4507, 0.4526],\n","        [0.6568, 0.4195],\n","        [0.6573, 0.4221],\n","        [0.7716, 0.3869],\n","        [0.4226, 0.5462]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6017, grad_fn=<NllLossBackward>)\n","epoch 214, loss 0.6017223596572876\n","outputs:  tensor([[0.4502, 0.4528],\n","        [0.6571, 0.4193],\n","        [0.6576, 0.4219],\n","        [0.7721, 0.3864],\n","        [0.4218, 0.5466]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6013, grad_fn=<NllLossBackward>)\n","epoch 215, loss 0.6013473868370056\n","outputs:  tensor([[0.4498, 0.4531],\n","        [0.6574, 0.4190],\n","        [0.6580, 0.4217],\n","        [0.7727, 0.3859],\n","        [0.4209, 0.5471]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6010, grad_fn=<NllLossBackward>)\n","epoch 216, loss 0.600972056388855\n","outputs:  tensor([[0.4494, 0.4534],\n","        [0.6578, 0.4188],\n","        [0.6583, 0.4214],\n","        [0.7732, 0.3854],\n","        [0.4201, 0.5476]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6006, grad_fn=<NllLossBackward>)\n","epoch 217, loss 0.6005963087081909\n","outputs:  tensor([[0.4489, 0.4536],\n","        [0.6581, 0.4185],\n","        [0.6586, 0.4212],\n","        [0.7737, 0.3849],\n","        [0.4193, 0.5481]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.6002, grad_fn=<NllLossBackward>)\n","epoch 218, loss 0.6002203226089478\n","outputs:  tensor([[0.4485, 0.4539],\n","        [0.6584, 0.4183],\n","        [0.6589, 0.4210],\n","        [0.7742, 0.3843],\n","        [0.4184, 0.5486]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5998, grad_fn=<NllLossBackward>)\n","epoch 219, loss 0.5998439788818359\n","outputs:  tensor([[0.4481, 0.4542],\n","        [0.6587, 0.4180],\n","        [0.6592, 0.4207],\n","        [0.7748, 0.3838],\n","        [0.4176, 0.5491]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5995, grad_fn=<NllLossBackward>)\n","epoch 220, loss 0.5994670987129211\n","outputs:  tensor([[0.4476, 0.4544],\n","        [0.6591, 0.4178],\n","        [0.6595, 0.4205],\n","        [0.7753, 0.3833],\n","        [0.4168, 0.5496]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5991, grad_fn=<NllLossBackward>)\n","epoch 221, loss 0.5990899801254272\n","outputs:  tensor([[0.4472, 0.4547],\n","        [0.6594, 0.4175],\n","        [0.6598, 0.4202],\n","        [0.7758, 0.3828],\n","        [0.4159, 0.5501]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5987, grad_fn=<NllLossBackward>)\n","epoch 222, loss 0.5987124443054199\n","outputs:  tensor([[0.4467, 0.4550],\n","        [0.6597, 0.4173],\n","        [0.6601, 0.4200],\n","        [0.7763, 0.3823],\n","        [0.4151, 0.5506]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5983, grad_fn=<NllLossBackward>)\n","epoch 223, loss 0.5983346104621887\n","outputs:  tensor([[0.4463, 0.4552],\n","        [0.6601, 0.4170],\n","        [0.6604, 0.4198],\n","        [0.7769, 0.3817],\n","        [0.4142, 0.5511]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5980, grad_fn=<NllLossBackward>)\n","epoch 224, loss 0.5979563593864441\n","outputs:  tensor([[0.4459, 0.4555],\n","        [0.6604, 0.4168],\n","        [0.6607, 0.4195],\n","        [0.7774, 0.3812],\n","        [0.4134, 0.5516]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5976, grad_fn=<NllLossBackward>)\n","epoch 225, loss 0.5975778698921204\n","outputs:  tensor([[0.4454, 0.4558],\n","        [0.6607, 0.4165],\n","        [0.6610, 0.4193],\n","        [0.7779, 0.3807],\n","        [0.4126, 0.5521]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5972, grad_fn=<NllLossBackward>)\n","epoch 226, loss 0.5971988439559937\n","outputs:  tensor([[0.4450, 0.4560],\n","        [0.6611, 0.4163],\n","        [0.6613, 0.4191],\n","        [0.7784, 0.3802],\n","        [0.4117, 0.5526]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5968, grad_fn=<NllLossBackward>)\n","epoch 227, loss 0.5968196988105774\n","outputs:  tensor([[0.4445, 0.4563],\n","        [0.6614, 0.4160],\n","        [0.6616, 0.4188],\n","        [0.7790, 0.3797],\n","        [0.4109, 0.5531]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5964, grad_fn=<NllLossBackward>)\n","epoch 228, loss 0.5964400172233582\n","outputs:  tensor([[0.4441, 0.4566],\n","        [0.6617, 0.4158],\n","        [0.6619, 0.4186],\n","        [0.7795, 0.3791],\n","        [0.4100, 0.5536]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5961, grad_fn=<NllLossBackward>)\n","epoch 229, loss 0.596060037612915\n","outputs:  tensor([[0.4437, 0.4569],\n","        [0.6621, 0.4155],\n","        [0.6622, 0.4183],\n","        [0.7800, 0.3786],\n","        [0.4092, 0.5541]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5957, grad_fn=<NllLossBackward>)\n","epoch 230, loss 0.5956797003746033\n","outputs:  tensor([[0.4432, 0.4571],\n","        [0.6624, 0.4153],\n","        [0.6625, 0.4181],\n","        [0.7805, 0.3781],\n","        [0.4083, 0.5546]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5953, grad_fn=<NllLossBackward>)\n","epoch 231, loss 0.5952990651130676\n","outputs:  tensor([[0.4428, 0.4574],\n","        [0.6627, 0.4150],\n","        [0.6628, 0.4179],\n","        [0.7811, 0.3776],\n","        [0.4075, 0.5551]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5949, grad_fn=<NllLossBackward>)\n","epoch 232, loss 0.5949180126190186\n","outputs:  tensor([[0.4423, 0.4577],\n","        [0.6631, 0.4148],\n","        [0.6631, 0.4176],\n","        [0.7816, 0.3770],\n","        [0.4066, 0.5557]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5945, grad_fn=<NllLossBackward>)\n","epoch 233, loss 0.5945366621017456\n","outputs:  tensor([[0.4419, 0.4580],\n","        [0.6634, 0.4145],\n","        [0.6634, 0.4174],\n","        [0.7821, 0.3765],\n","        [0.4058, 0.5562]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5942, grad_fn=<NllLossBackward>)\n","epoch 234, loss 0.594154953956604\n","outputs:  tensor([[0.4414, 0.4582],\n","        [0.6637, 0.4143],\n","        [0.6638, 0.4171],\n","        [0.7826, 0.3760],\n","        [0.4049, 0.5567]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5938, grad_fn=<NllLossBackward>)\n","epoch 235, loss 0.5937728881835938\n","outputs:  tensor([[0.4410, 0.4585],\n","        [0.6641, 0.4140],\n","        [0.6641, 0.4169],\n","        [0.7832, 0.3754],\n","        [0.4041, 0.5572]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5934, grad_fn=<NllLossBackward>)\n","epoch 236, loss 0.5933904647827148\n","outputs:  tensor([[0.4405, 0.4588],\n","        [0.6644, 0.4137],\n","        [0.6644, 0.4166],\n","        [0.7837, 0.3749],\n","        [0.4032, 0.5577]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5930, grad_fn=<NllLossBackward>)\n","epoch 237, loss 0.5930078029632568\n","outputs:  tensor([[0.4401, 0.4591],\n","        [0.6647, 0.4135],\n","        [0.6647, 0.4164],\n","        [0.7842, 0.3744],\n","        [0.4024, 0.5582]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5926, grad_fn=<NllLossBackward>)\n","epoch 238, loss 0.5926246643066406\n","outputs:  tensor([[0.4396, 0.4594],\n","        [0.6651, 0.4132],\n","        [0.6650, 0.4162],\n","        [0.7847, 0.3738],\n","        [0.4015, 0.5588]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5922, grad_fn=<NllLossBackward>)\n","epoch 239, loss 0.5922413468360901\n","outputs:  tensor([[0.4392, 0.4596],\n","        [0.6654, 0.4130],\n","        [0.6653, 0.4159],\n","        [0.7852, 0.3733],\n","        [0.4007, 0.5593]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5919, grad_fn=<NllLossBackward>)\n","epoch 240, loss 0.5918575525283813\n","outputs:  tensor([[0.4387, 0.4599],\n","        [0.6657, 0.4127],\n","        [0.6656, 0.4157],\n","        [0.7858, 0.3728],\n","        [0.3998, 0.5598]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5915, grad_fn=<NllLossBackward>)\n","epoch 241, loss 0.5914734601974487\n","outputs:  tensor([[0.4383, 0.4602],\n","        [0.6661, 0.4125],\n","        [0.6659, 0.4154],\n","        [0.7863, 0.3722],\n","        [0.3990, 0.5603]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5911, grad_fn=<NllLossBackward>)\n","epoch 242, loss 0.591089129447937\n","outputs:  tensor([[0.4378, 0.4605],\n","        [0.6664, 0.4122],\n","        [0.6662, 0.4152],\n","        [0.7868, 0.3717],\n","        [0.3981, 0.5609]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5907, grad_fn=<NllLossBackward>)\n","epoch 243, loss 0.5907043218612671\n","outputs:  tensor([[0.4374, 0.4608],\n","        [0.6667, 0.4119],\n","        [0.6665, 0.4149],\n","        [0.7873, 0.3712],\n","        [0.3973, 0.5614]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5903, grad_fn=<NllLossBackward>)\n","epoch 244, loss 0.5903192758560181\n","outputs:  tensor([[0.4369, 0.4611],\n","        [0.6671, 0.4117],\n","        [0.6668, 0.4147],\n","        [0.7878, 0.3706],\n","        [0.3964, 0.5619]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5899, grad_fn=<NllLossBackward>)\n","epoch 245, loss 0.5899339318275452\n","outputs:  tensor([[0.4365, 0.4614],\n","        [0.6674, 0.4114],\n","        [0.6672, 0.4144],\n","        [0.7884, 0.3701],\n","        [0.3955, 0.5625]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5895, grad_fn=<NllLossBackward>)\n","epoch 246, loss 0.5895482301712036\n","outputs:  tensor([[0.4360, 0.4617],\n","        [0.6678, 0.4112],\n","        [0.6675, 0.4142],\n","        [0.7889, 0.3696],\n","        [0.3947, 0.5630]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5892, grad_fn=<NllLossBackward>)\n","epoch 247, loss 0.5891622304916382\n","outputs:  tensor([[0.4356, 0.4619],\n","        [0.6681, 0.4109],\n","        [0.6678, 0.4139],\n","        [0.7894, 0.3690],\n","        [0.3938, 0.5636]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5888, grad_fn=<NllLossBackward>)\n","epoch 248, loss 0.5887759327888489\n","outputs:  tensor([[0.4351, 0.4622],\n","        [0.6684, 0.4106],\n","        [0.6681, 0.4137],\n","        [0.7899, 0.3685],\n","        [0.3930, 0.5641]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5884, grad_fn=<NllLossBackward>)\n","epoch 249, loss 0.5883892178535461\n","outputs:  tensor([[0.4347, 0.4625],\n","        [0.6688, 0.4104],\n","        [0.6684, 0.4134],\n","        [0.7904, 0.3679],\n","        [0.3921, 0.5646]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5880, grad_fn=<NllLossBackward>)\n","epoch 250, loss 0.5880022644996643\n","outputs:  tensor([[0.4342, 0.4628],\n","        [0.6691, 0.4101],\n","        [0.6687, 0.4132],\n","        [0.7910, 0.3674],\n","        [0.3912, 0.5652]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5876, grad_fn=<NllLossBackward>)\n","epoch 251, loss 0.5876150131225586\n","Parameter containing:\n","tensor([[-0.0417, -0.3083,  0.2284],\n","        [-0.5097, -0.0516, -0.0124],\n","        [-0.5386, -0.2238, -0.0618],\n","        [-0.3031, -0.2599,  0.0089]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4438, -0.4131,  0.0407,  0.0786], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.5561,  0.3165,  0.5660, -0.1892],\n","        [ 0.2267, -0.3791, -0.0455, -0.1482]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2820, -0.4728], requires_grad=True)\n","outputs:  tensor([[0.4338, 0.4631],\n","        [0.6694, 0.4099],\n","        [0.6690, 0.4129],\n","        [0.7915, 0.3669],\n","        [0.3904, 0.5657]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5872, grad_fn=<NllLossBackward>)\n","epoch 252, loss 0.5872274041175842\n","outputs:  tensor([[0.4333, 0.4634],\n","        [0.6698, 0.4096],\n","        [0.6693, 0.4127],\n","        [0.7920, 0.3663],\n","        [0.3895, 0.5663]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5868, grad_fn=<NllLossBackward>)\n","epoch 253, loss 0.586839497089386\n","outputs:  tensor([[0.4328, 0.4637],\n","        [0.6701, 0.4093],\n","        [0.6696, 0.4124],\n","        [0.7925, 0.3658],\n","        [0.3886, 0.5668]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5865, grad_fn=<NllLossBackward>)\n","epoch 254, loss 0.5864512920379639\n","outputs:  tensor([[0.4324, 0.4640],\n","        [0.6705, 0.4091],\n","        [0.6700, 0.4122],\n","        [0.7930, 0.3652],\n","        [0.3878, 0.5674]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5861, grad_fn=<NllLossBackward>)\n","epoch 255, loss 0.5860627293586731\n","outputs:  tensor([[0.4319, 0.4643],\n","        [0.6708, 0.4088],\n","        [0.6703, 0.4119],\n","        [0.7935, 0.3647],\n","        [0.3869, 0.5679]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5857, grad_fn=<NllLossBackward>)\n","epoch 256, loss 0.5856739282608032\n","outputs:  tensor([[0.4315, 0.4646],\n","        [0.6711, 0.4085],\n","        [0.6706, 0.4117],\n","        [0.7941, 0.3641],\n","        [0.3860, 0.5685]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5853, grad_fn=<NllLossBackward>)\n","epoch 257, loss 0.5852848291397095\n","outputs:  tensor([[0.4310, 0.4649],\n","        [0.6715, 0.4083],\n","        [0.6709, 0.4114],\n","        [0.7946, 0.3636],\n","        [0.3852, 0.5690]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5849, grad_fn=<NllLossBackward>)\n","epoch 258, loss 0.5848954916000366\n","outputs:  tensor([[0.4305, 0.4652],\n","        [0.6718, 0.4080],\n","        [0.6712, 0.4112],\n","        [0.7951, 0.3630],\n","        [0.3843, 0.5696]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5845, grad_fn=<NllLossBackward>)\n","epoch 259, loss 0.5845056772232056\n","outputs:  tensor([[0.4301, 0.4655],\n","        [0.6722, 0.4077],\n","        [0.6715, 0.4109],\n","        [0.7956, 0.3625],\n","        [0.3834, 0.5701]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5841, grad_fn=<NllLossBackward>)\n","epoch 260, loss 0.5841156840324402\n","outputs:  tensor([[0.4296, 0.4658],\n","        [0.6725, 0.4075],\n","        [0.6718, 0.4107],\n","        [0.7961, 0.3619],\n","        [0.3826, 0.5707]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5837, grad_fn=<NllLossBackward>)\n","epoch 261, loss 0.5837254524230957\n","outputs:  tensor([[0.4292, 0.4661],\n","        [0.6728, 0.4072],\n","        [0.6721, 0.4104],\n","        [0.7966, 0.3614],\n","        [0.3817, 0.5712]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5833, grad_fn=<NllLossBackward>)\n","epoch 262, loss 0.5833348035812378\n","outputs:  tensor([[0.4287, 0.4664],\n","        [0.6732, 0.4069],\n","        [0.6725, 0.4102],\n","        [0.7971, 0.3608],\n","        [0.3808, 0.5718]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5829, grad_fn=<NllLossBackward>)\n","epoch 263, loss 0.5829439163208008\n","outputs:  tensor([[0.4282, 0.4667],\n","        [0.6735, 0.4067],\n","        [0.6728, 0.4099],\n","        [0.7977, 0.3603],\n","        [0.3800, 0.5724]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5826, grad_fn=<NllLossBackward>)\n","epoch 264, loss 0.5825528502464294\n","outputs:  tensor([[0.4278, 0.4670],\n","        [0.6739, 0.4064],\n","        [0.6731, 0.4097],\n","        [0.7982, 0.3597],\n","        [0.3791, 0.5729]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5822, grad_fn=<NllLossBackward>)\n","epoch 265, loss 0.5821614265441895\n","outputs:  tensor([[0.4273, 0.4673],\n","        [0.6742, 0.4061],\n","        [0.6734, 0.4094],\n","        [0.7987, 0.3592],\n","        [0.3782, 0.5735]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5818, grad_fn=<NllLossBackward>)\n","epoch 266, loss 0.5817697644233704\n","outputs:  tensor([[0.4268, 0.4676],\n","        [0.6745, 0.4059],\n","        [0.6737, 0.4091],\n","        [0.7992, 0.3586],\n","        [0.3774, 0.5741]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5814, grad_fn=<NllLossBackward>)\n","epoch 267, loss 0.5813777446746826\n","outputs:  tensor([[0.4264, 0.4679],\n","        [0.6749, 0.4056],\n","        [0.6740, 0.4089],\n","        [0.7997, 0.3581],\n","        [0.3765, 0.5746]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5810, grad_fn=<NllLossBackward>)\n","epoch 268, loss 0.5809854865074158\n","outputs:  tensor([[0.4259, 0.4683],\n","        [0.6752, 0.4053],\n","        [0.6743, 0.4086],\n","        [0.8002, 0.3575],\n","        [0.3756, 0.5752]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5806, grad_fn=<NllLossBackward>)\n","epoch 269, loss 0.5805929899215698\n","outputs:  tensor([[0.4254, 0.4686],\n","        [0.6756, 0.4050],\n","        [0.6747, 0.4084],\n","        [0.8007, 0.3570],\n","        [0.3747, 0.5758]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5802, grad_fn=<NllLossBackward>)\n","epoch 270, loss 0.5802001953125\n","outputs:  tensor([[0.4250, 0.4689],\n","        [0.6759, 0.4048],\n","        [0.6750, 0.4081],\n","        [0.8012, 0.3564],\n","        [0.3739, 0.5763]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5798, grad_fn=<NllLossBackward>)\n","epoch 271, loss 0.5798071622848511\n","outputs:  tensor([[0.4245, 0.4692],\n","        [0.6763, 0.4045],\n","        [0.6753, 0.4078],\n","        [0.8018, 0.3558],\n","        [0.3730, 0.5769]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5794, grad_fn=<NllLossBackward>)\n","epoch 272, loss 0.5794138312339783\n","outputs:  tensor([[0.4240, 0.4695],\n","        [0.6766, 0.4042],\n","        [0.6756, 0.4076],\n","        [0.8023, 0.3553],\n","        [0.3721, 0.5775]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5790, grad_fn=<NllLossBackward>)\n","epoch 273, loss 0.5790202021598816\n","outputs:  tensor([[0.4235, 0.4698],\n","        [0.6769, 0.4039],\n","        [0.6759, 0.4073],\n","        [0.8028, 0.3547],\n","        [0.3712, 0.5781]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5786, grad_fn=<NllLossBackward>)\n","epoch 274, loss 0.5786264538764954\n","outputs:  tensor([[0.4231, 0.4701],\n","        [0.6773, 0.4037],\n","        [0.6762, 0.4071],\n","        [0.8033, 0.3542],\n","        [0.3704, 0.5787]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5782, grad_fn=<NllLossBackward>)\n","epoch 275, loss 0.5782323479652405\n","outputs:  tensor([[0.4226, 0.4704],\n","        [0.6776, 0.4034],\n","        [0.6766, 0.4068],\n","        [0.8038, 0.3536],\n","        [0.3695, 0.5792]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5778, grad_fn=<NllLossBackward>)\n","epoch 276, loss 0.5778380632400513\n","outputs:  tensor([[0.4221, 0.4708],\n","        [0.6780, 0.4031],\n","        [0.6769, 0.4065],\n","        [0.8043, 0.3530],\n","        [0.3686, 0.5798]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5774, grad_fn=<NllLossBackward>)\n","epoch 277, loss 0.5774434804916382\n","outputs:  tensor([[0.4217, 0.4711],\n","        [0.6783, 0.4028],\n","        [0.6772, 0.4063],\n","        [0.8048, 0.3525],\n","        [0.3677, 0.5804]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5770, grad_fn=<NllLossBackward>)\n","epoch 278, loss 0.577048659324646\n","outputs:  tensor([[0.4212, 0.4714],\n","        [0.6787, 0.4026],\n","        [0.6775, 0.4060],\n","        [0.8053, 0.3519],\n","        [0.3669, 0.5810]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5767, grad_fn=<NllLossBackward>)\n","epoch 279, loss 0.5766535997390747\n","outputs:  tensor([[0.4207, 0.4717],\n","        [0.6790, 0.4023],\n","        [0.6778, 0.4058],\n","        [0.8058, 0.3513],\n","        [0.3660, 0.5816]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5763, grad_fn=<NllLossBackward>)\n","epoch 280, loss 0.5762583017349243\n","outputs:  tensor([[0.4202, 0.4720],\n","        [0.6794, 0.4020],\n","        [0.6781, 0.4055],\n","        [0.8063, 0.3508],\n","        [0.3651, 0.5822]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5759, grad_fn=<NllLossBackward>)\n","epoch 281, loss 0.5758627653121948\n","outputs:  tensor([[0.4198, 0.4724],\n","        [0.6797, 0.4017],\n","        [0.6785, 0.4052],\n","        [0.8068, 0.3502],\n","        [0.3642, 0.5828]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5755, grad_fn=<NllLossBackward>)\n","epoch 282, loss 0.5754669904708862\n","outputs:  tensor([[0.4193, 0.4727],\n","        [0.6800, 0.4015],\n","        [0.6788, 0.4050],\n","        [0.8073, 0.3496],\n","        [0.3634, 0.5833]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5751, grad_fn=<NllLossBackward>)\n","epoch 283, loss 0.5750709176063538\n","outputs:  tensor([[0.4188, 0.4730],\n","        [0.6804, 0.4012],\n","        [0.6791, 0.4047],\n","        [0.8079, 0.3491],\n","        [0.3625, 0.5839]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5747, grad_fn=<NllLossBackward>)\n","epoch 284, loss 0.5746747255325317\n","outputs:  tensor([[0.4183, 0.4733],\n","        [0.6807, 0.4009],\n","        [0.6794, 0.4044],\n","        [0.8084, 0.3485],\n","        [0.3616, 0.5845]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5743, grad_fn=<NllLossBackward>)\n","epoch 285, loss 0.5742782354354858\n","outputs:  tensor([[0.4179, 0.4737],\n","        [0.6811, 0.4006],\n","        [0.6797, 0.4042],\n","        [0.8089, 0.3479],\n","        [0.3607, 0.5851]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5739, grad_fn=<NllLossBackward>)\n","epoch 286, loss 0.5738815069198608\n","outputs:  tensor([[0.4174, 0.4740],\n","        [0.6814, 0.4003],\n","        [0.6801, 0.4039],\n","        [0.8094, 0.3474],\n","        [0.3598, 0.5857]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5735, grad_fn=<NllLossBackward>)\n","epoch 287, loss 0.5734847187995911\n","outputs:  tensor([[0.4169, 0.4743],\n","        [0.6818, 0.4000],\n","        [0.6804, 0.4036],\n","        [0.8099, 0.3468],\n","        [0.3590, 0.5863]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5731, grad_fn=<NllLossBackward>)\n","epoch 288, loss 0.5730875730514526\n","outputs:  tensor([[0.4164, 0.4747],\n","        [0.6821, 0.3998],\n","        [0.6807, 0.4034],\n","        [0.8104, 0.3462],\n","        [0.3581, 0.5869]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5727, grad_fn=<NllLossBackward>)\n","epoch 289, loss 0.5726902484893799\n","outputs:  tensor([[0.4159, 0.4750],\n","        [0.6825, 0.3995],\n","        [0.6810, 0.4031],\n","        [0.8109, 0.3457],\n","        [0.3572, 0.5875]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5723, grad_fn=<NllLossBackward>)\n","epoch 290, loss 0.5722927451133728\n","outputs:  tensor([[0.4155, 0.4753],\n","        [0.6828, 0.3992],\n","        [0.6813, 0.4028],\n","        [0.8114, 0.3451],\n","        [0.3563, 0.5881]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5719, grad_fn=<NllLossBackward>)\n","epoch 291, loss 0.5718949437141418\n","outputs:  tensor([[0.4150, 0.4756],\n","        [0.6832, 0.3989],\n","        [0.6816, 0.4026],\n","        [0.8119, 0.3445],\n","        [0.3554, 0.5887]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5715, grad_fn=<NllLossBackward>)\n","epoch 292, loss 0.5714970827102661\n","outputs:  tensor([[0.4145, 0.4760],\n","        [0.6835, 0.3986],\n","        [0.6820, 0.4023],\n","        [0.8124, 0.3439],\n","        [0.3546, 0.5893]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5711, grad_fn=<NllLossBackward>)\n","epoch 293, loss 0.5710989236831665\n","outputs:  tensor([[0.4140, 0.4763],\n","        [0.6839, 0.3983],\n","        [0.6823, 0.4020],\n","        [0.8129, 0.3434],\n","        [0.3537, 0.5900]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5707, grad_fn=<NllLossBackward>)\n","epoch 294, loss 0.5707006454467773\n","outputs:  tensor([[0.4135, 0.4766],\n","        [0.6842, 0.3981],\n","        [0.6826, 0.4018],\n","        [0.8134, 0.3428],\n","        [0.3528, 0.5906]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5703, grad_fn=<NllLossBackward>)\n","epoch 295, loss 0.5703021287918091\n","outputs:  tensor([[0.4131, 0.4770],\n","        [0.6846, 0.3978],\n","        [0.6829, 0.4015],\n","        [0.8139, 0.3422],\n","        [0.3519, 0.5912]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5699, grad_fn=<NllLossBackward>)\n","epoch 296, loss 0.5699033737182617\n","outputs:  tensor([[0.4126, 0.4773],\n","        [0.6849, 0.3975],\n","        [0.6833, 0.4012],\n","        [0.8144, 0.3416],\n","        [0.3510, 0.5918]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5695, grad_fn=<NllLossBackward>)\n","epoch 297, loss 0.5695044994354248\n","outputs:  tensor([[0.4121, 0.4777],\n","        [0.6853, 0.3972],\n","        [0.6836, 0.4009],\n","        [0.8149, 0.3411],\n","        [0.3502, 0.5924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5691, grad_fn=<NllLossBackward>)\n","epoch 298, loss 0.569105327129364\n","outputs:  tensor([[0.4116, 0.4780],\n","        [0.6856, 0.3969],\n","        [0.6839, 0.4007],\n","        [0.8154, 0.3405],\n","        [0.3493, 0.5930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5687, grad_fn=<NllLossBackward>)\n","epoch 299, loss 0.5687061548233032\n","outputs:  tensor([[0.4111, 0.4783],\n","        [0.6859, 0.3966],\n","        [0.6842, 0.4004],\n","        [0.8159, 0.3399],\n","        [0.3484, 0.5936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5683, grad_fn=<NllLossBackward>)\n","epoch 300, loss 0.5683066844940186\n","outputs:  tensor([[0.4106, 0.4787],\n","        [0.6863, 0.3963],\n","        [0.6845, 0.4001],\n","        [0.8164, 0.3393],\n","        [0.3475, 0.5942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5679, grad_fn=<NllLossBackward>)\n","epoch 301, loss 0.5679070949554443\n","Parameter containing:\n","tensor([[-0.0541, -0.3232,  0.2246],\n","        [-0.5400, -0.0868, -0.0204],\n","        [-0.5643, -0.2540, -0.0690],\n","        [-0.3034, -0.2600,  0.0090]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4439, -0.4096,  0.0427,  0.0792], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.5712,  0.3393,  0.5994, -0.1652],\n","        [ 0.2080, -0.4035, -0.0833, -0.1755]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2847, -0.4795], requires_grad=True)\n","outputs:  tensor([[0.4101, 0.4790],\n","        [0.6866, 0.3960],\n","        [0.6849, 0.3998],\n","        [0.8169, 0.3387],\n","        [0.3466, 0.5949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5675, grad_fn=<NllLossBackward>)\n","epoch 302, loss 0.567507266998291\n","outputs:  tensor([[0.4097, 0.4794],\n","        [0.6870, 0.3958],\n","        [0.6852, 0.3996],\n","        [0.8174, 0.3382],\n","        [0.3458, 0.5955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5671, grad_fn=<NllLossBackward>)\n","epoch 303, loss 0.5671073794364929\n","outputs:  tensor([[0.4092, 0.4797],\n","        [0.6873, 0.3955],\n","        [0.6855, 0.3993],\n","        [0.8179, 0.3376],\n","        [0.3449, 0.5961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5667, grad_fn=<NllLossBackward>)\n","epoch 304, loss 0.5667073130607605\n","outputs:  tensor([[0.4087, 0.4800],\n","        [0.6877, 0.3952],\n","        [0.6858, 0.3990],\n","        [0.8184, 0.3370],\n","        [0.3440, 0.5967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5663, grad_fn=<NllLossBackward>)\n","epoch 305, loss 0.566307008266449\n","outputs:  tensor([[0.4082, 0.4804],\n","        [0.6880, 0.3949],\n","        [0.6861, 0.3987],\n","        [0.8189, 0.3364],\n","        [0.3431, 0.5974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5659, grad_fn=<NllLossBackward>)\n","epoch 306, loss 0.5659065842628479\n","outputs:  tensor([[0.4077, 0.4807],\n","        [0.6884, 0.3946],\n","        [0.6865, 0.3985],\n","        [0.8194, 0.3358],\n","        [0.3422, 0.5980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5655, grad_fn=<NllLossBackward>)\n","epoch 307, loss 0.5655060410499573\n","outputs:  tensor([[0.4072, 0.4811],\n","        [0.6887, 0.3943],\n","        [0.6868, 0.3982],\n","        [0.8199, 0.3353],\n","        [0.3414, 0.5986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5651, grad_fn=<NllLossBackward>)\n","epoch 308, loss 0.5651053190231323\n","outputs:  tensor([[0.4067, 0.4814],\n","        [0.6891, 0.3940],\n","        [0.6871, 0.3979],\n","        [0.8204, 0.3347],\n","        [0.3405, 0.5992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5647, grad_fn=<NllLossBackward>)\n","epoch 309, loss 0.564704418182373\n","outputs:  tensor([[0.4062, 0.4818],\n","        [0.6895, 0.3937],\n","        [0.6874, 0.3976],\n","        [0.8209, 0.3341],\n","        [0.3396, 0.5999]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5643, grad_fn=<NllLossBackward>)\n","epoch 310, loss 0.5643035173416138\n","outputs:  tensor([[0.4058, 0.4821],\n","        [0.6898, 0.3934],\n","        [0.6878, 0.3974],\n","        [0.8213, 0.3335],\n","        [0.3387, 0.6005]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5639, grad_fn=<NllLossBackward>)\n","epoch 311, loss 0.5639023780822754\n","outputs:  tensor([[0.4053, 0.4825],\n","        [0.6902, 0.3931],\n","        [0.6881, 0.3971],\n","        [0.8218, 0.3329],\n","        [0.3378, 0.6011]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5635, grad_fn=<NllLossBackward>)\n","epoch 312, loss 0.5635010600090027\n","outputs:  tensor([[0.4048, 0.4828],\n","        [0.6905, 0.3928],\n","        [0.6884, 0.3968],\n","        [0.8223, 0.3323],\n","        [0.3370, 0.6018]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5631, grad_fn=<NllLossBackward>)\n","epoch 313, loss 0.5630996823310852\n","outputs:  tensor([[0.4043, 0.4832],\n","        [0.6909, 0.3925],\n","        [0.6887, 0.3965],\n","        [0.8228, 0.3317],\n","        [0.3361, 0.6024]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5627, grad_fn=<NllLossBackward>)\n","epoch 314, loss 0.5626981854438782\n","outputs:  tensor([[0.4038, 0.4835],\n","        [0.6912, 0.3922],\n","        [0.6891, 0.3962],\n","        [0.8233, 0.3311],\n","        [0.3352, 0.6031]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5623, grad_fn=<NllLossBackward>)\n","epoch 315, loss 0.5622965693473816\n","outputs:  tensor([[0.4033, 0.4839],\n","        [0.6916, 0.3919],\n","        [0.6894, 0.3960],\n","        [0.8238, 0.3306],\n","        [0.3343, 0.6037]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5619, grad_fn=<NllLossBackward>)\n","epoch 316, loss 0.5618947744369507\n","outputs:  tensor([[0.4028, 0.4842],\n","        [0.6919, 0.3916],\n","        [0.6897, 0.3957],\n","        [0.8243, 0.3300],\n","        [0.3334, 0.6043]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5615, grad_fn=<NllLossBackward>)\n","epoch 317, loss 0.561492919921875\n","outputs:  tensor([[0.4023, 0.4846],\n","        [0.6923, 0.3913],\n","        [0.6900, 0.3954],\n","        [0.8248, 0.3294],\n","        [0.3326, 0.6050]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5611, grad_fn=<NllLossBackward>)\n","epoch 318, loss 0.5610909461975098\n","outputs:  tensor([[0.4018, 0.4850],\n","        [0.6926, 0.3910],\n","        [0.6904, 0.3951],\n","        [0.8253, 0.3288],\n","        [0.3317, 0.6056]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5607, grad_fn=<NllLossBackward>)\n","epoch 319, loss 0.5606887936592102\n","outputs:  tensor([[0.4013, 0.4853],\n","        [0.6930, 0.3907],\n","        [0.6907, 0.3948],\n","        [0.8258, 0.3282],\n","        [0.3308, 0.6063]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5603, grad_fn=<NllLossBackward>)\n","epoch 320, loss 0.5602866411209106\n","outputs:  tensor([[0.4008, 0.4857],\n","        [0.6933, 0.3904],\n","        [0.6910, 0.3946],\n","        [0.8262, 0.3276],\n","        [0.3299, 0.6069]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5599, grad_fn=<NllLossBackward>)\n","epoch 321, loss 0.5598844289779663\n","outputs:  tensor([[0.4003, 0.4860],\n","        [0.6937, 0.3901],\n","        [0.6913, 0.3943],\n","        [0.8267, 0.3270],\n","        [0.3290, 0.6076]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5595, grad_fn=<NllLossBackward>)\n","epoch 322, loss 0.5594819784164429\n","outputs:  tensor([[0.3998, 0.4864],\n","        [0.6940, 0.3898],\n","        [0.6917, 0.3940],\n","        [0.8272, 0.3264],\n","        [0.3282, 0.6082]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5591, grad_fn=<NllLossBackward>)\n","epoch 323, loss 0.5590795278549194\n","outputs:  tensor([[0.3994, 0.4868],\n","        [0.6944, 0.3895],\n","        [0.6920, 0.3937],\n","        [0.8277, 0.3258],\n","        [0.3273, 0.6089]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5587, grad_fn=<NllLossBackward>)\n","epoch 324, loss 0.5586768984794617\n","outputs:  tensor([[0.3989, 0.4871],\n","        [0.6947, 0.3892],\n","        [0.6923, 0.3934],\n","        [0.8282, 0.3252],\n","        [0.3264, 0.6095]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5583, grad_fn=<NllLossBackward>)\n","epoch 325, loss 0.5582742691040039\n","outputs:  tensor([[0.3984, 0.4875],\n","        [0.6951, 0.3889],\n","        [0.6926, 0.3931],\n","        [0.8287, 0.3246],\n","        [0.3255, 0.6102]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5579, grad_fn=<NllLossBackward>)\n","epoch 326, loss 0.5578715205192566\n","outputs:  tensor([[0.3979, 0.4879],\n","        [0.6954, 0.3886],\n","        [0.6930, 0.3928],\n","        [0.8292, 0.3240],\n","        [0.3246, 0.6108]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5575, grad_fn=<NllLossBackward>)\n","epoch 327, loss 0.5574687719345093\n","outputs:  tensor([[0.3974, 0.4882],\n","        [0.6958, 0.3883],\n","        [0.6933, 0.3926],\n","        [0.8296, 0.3234],\n","        [0.3238, 0.6115]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5571, grad_fn=<NllLossBackward>)\n","epoch 328, loss 0.5570658445358276\n","outputs:  tensor([[0.3969, 0.4886],\n","        [0.6962, 0.3880],\n","        [0.6936, 0.3923],\n","        [0.8301, 0.3228],\n","        [0.3229, 0.6121]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5567, grad_fn=<NllLossBackward>)\n","epoch 329, loss 0.556662917137146\n","outputs:  tensor([[0.3964, 0.4890],\n","        [0.6965, 0.3877],\n","        [0.6939, 0.3920],\n","        [0.8306, 0.3223],\n","        [0.3220, 0.6128]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5563, grad_fn=<NllLossBackward>)\n","epoch 330, loss 0.5562599301338196\n","outputs:  tensor([[0.3959, 0.4893],\n","        [0.6969, 0.3874],\n","        [0.6943, 0.3917],\n","        [0.8311, 0.3217],\n","        [0.3211, 0.6134]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5559, grad_fn=<NllLossBackward>)\n","epoch 331, loss 0.5558568239212036\n","outputs:  tensor([[0.3954, 0.4897],\n","        [0.6972, 0.3871],\n","        [0.6946, 0.3914],\n","        [0.8316, 0.3211],\n","        [0.3203, 0.6141]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5555, grad_fn=<NllLossBackward>)\n","epoch 332, loss 0.5554537773132324\n","outputs:  tensor([[0.3949, 0.4901],\n","        [0.6976, 0.3868],\n","        [0.6949, 0.3911],\n","        [0.8320, 0.3205],\n","        [0.3194, 0.6148]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5551, grad_fn=<NllLossBackward>)\n","epoch 333, loss 0.5550505518913269\n","outputs:  tensor([[0.3944, 0.4904],\n","        [0.6979, 0.3865],\n","        [0.6953, 0.3908],\n","        [0.8325, 0.3199],\n","        [0.3185, 0.6154]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5546, grad_fn=<NllLossBackward>)\n","epoch 334, loss 0.5546473264694214\n","outputs:  tensor([[0.3939, 0.4908],\n","        [0.6983, 0.3862],\n","        [0.6956, 0.3905],\n","        [0.8330, 0.3193],\n","        [0.3176, 0.6161]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5542, grad_fn=<NllLossBackward>)\n","epoch 335, loss 0.5542441606521606\n","outputs:  tensor([[0.3934, 0.4912],\n","        [0.6986, 0.3859],\n","        [0.6959, 0.3903],\n","        [0.8335, 0.3187],\n","        [0.3168, 0.6168]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5538, grad_fn=<NllLossBackward>)\n","epoch 336, loss 0.5538407564163208\n","outputs:  tensor([[0.3929, 0.4916],\n","        [0.6990, 0.3856],\n","        [0.6962, 0.3900],\n","        [0.8340, 0.3181],\n","        [0.3159, 0.6174]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5534, grad_fn=<NllLossBackward>)\n","epoch 337, loss 0.5534374117851257\n","outputs:  tensor([[0.3924, 0.4919],\n","        [0.6993, 0.3853],\n","        [0.6966, 0.3897],\n","        [0.8344, 0.3175],\n","        [0.3150, 0.6181]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5530, grad_fn=<NllLossBackward>)\n","epoch 338, loss 0.5530341267585754\n","outputs:  tensor([[0.3919, 0.4923],\n","        [0.6997, 0.3850],\n","        [0.6969, 0.3894],\n","        [0.8349, 0.3169],\n","        [0.3141, 0.6188]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5526, grad_fn=<NllLossBackward>)\n","epoch 339, loss 0.552630603313446\n","outputs:  tensor([[0.3914, 0.4927],\n","        [0.7001, 0.3846],\n","        [0.6972, 0.3891],\n","        [0.8354, 0.3162],\n","        [0.3133, 0.6194]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5522, grad_fn=<NllLossBackward>)\n","epoch 340, loss 0.5522271394729614\n","outputs:  tensor([[0.3909, 0.4931],\n","        [0.7004, 0.3843],\n","        [0.6975, 0.3888],\n","        [0.8359, 0.3156],\n","        [0.3124, 0.6201]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5518, grad_fn=<NllLossBackward>)\n","epoch 341, loss 0.5518237352371216\n","outputs:  tensor([[0.3904, 0.4935],\n","        [0.7008, 0.3840],\n","        [0.6979, 0.3885],\n","        [0.8363, 0.3150],\n","        [0.3115, 0.6208]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5514, grad_fn=<NllLossBackward>)\n","epoch 342, loss 0.5514202117919922\n","outputs:  tensor([[0.3899, 0.4938],\n","        [0.7011, 0.3837],\n","        [0.6982, 0.3882],\n","        [0.8368, 0.3144],\n","        [0.3107, 0.6215]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5510, grad_fn=<NllLossBackward>)\n","epoch 343, loss 0.5510168075561523\n","outputs:  tensor([[0.3894, 0.4942],\n","        [0.7015, 0.3834],\n","        [0.6985, 0.3879],\n","        [0.8373, 0.3138],\n","        [0.3098, 0.6221]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5506, grad_fn=<NllLossBackward>)\n","epoch 344, loss 0.550613284111023\n","outputs:  tensor([[0.3889, 0.4946],\n","        [0.7018, 0.3831],\n","        [0.6989, 0.3876],\n","        [0.8378, 0.3132],\n","        [0.3089, 0.6228]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5502, grad_fn=<NllLossBackward>)\n","epoch 345, loss 0.5502098202705383\n","outputs:  tensor([[0.3884, 0.4950],\n","        [0.7022, 0.3828],\n","        [0.6992, 0.3873],\n","        [0.8382, 0.3126],\n","        [0.3081, 0.6235]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5498, grad_fn=<NllLossBackward>)\n","epoch 346, loss 0.5498062968254089\n","outputs:  tensor([[0.3879, 0.4954],\n","        [0.7026, 0.3825],\n","        [0.6995, 0.3870],\n","        [0.8387, 0.3120],\n","        [0.3072, 0.6242]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5494, grad_fn=<NllLossBackward>)\n","epoch 347, loss 0.5494028329849243\n","outputs:  tensor([[0.3874, 0.4957],\n","        [0.7029, 0.3822],\n","        [0.6999, 0.3867],\n","        [0.8392, 0.3114],\n","        [0.3063, 0.6248]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5490, grad_fn=<NllLossBackward>)\n","epoch 348, loss 0.5489993095397949\n","outputs:  tensor([[0.3869, 0.4961],\n","        [0.7033, 0.3818],\n","        [0.7002, 0.3864],\n","        [0.8396, 0.3108],\n","        [0.3055, 0.6255]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5486, grad_fn=<NllLossBackward>)\n","epoch 349, loss 0.5485958456993103\n","outputs:  tensor([[0.3864, 0.4965],\n","        [0.7036, 0.3815],\n","        [0.7005, 0.3861],\n","        [0.8401, 0.3102],\n","        [0.3046, 0.6262]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5482, grad_fn=<NllLossBackward>)\n","epoch 350, loss 0.5481923818588257\n","outputs:  tensor([[0.3859, 0.4969],\n","        [0.7040, 0.3812],\n","        [0.7008, 0.3858],\n","        [0.8406, 0.3096],\n","        [0.3037, 0.6269]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5478, grad_fn=<NllLossBackward>)\n","epoch 351, loss 0.5477889776229858\n","Parameter containing:\n","tensor([[-0.0665, -0.3383,  0.2209],\n","        [-0.5701, -0.1223, -0.0282],\n","        [-0.5907, -0.2854, -0.0762],\n","        [-0.3058, -0.2627,  0.0086]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4441, -0.4061,  0.0449,  0.0800], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.5865,  0.3628,  0.6325, -0.1430],\n","        [ 0.1887, -0.4297, -0.1220, -0.2016]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2872, -0.4859], requires_grad=True)\n","outputs:  tensor([[0.3854, 0.4973],\n","        [0.7043, 0.3809],\n","        [0.7012, 0.3855],\n","        [0.8411, 0.3090],\n","        [0.3029, 0.6276]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5474, grad_fn=<NllLossBackward>)\n","epoch 352, loss 0.5473855137825012\n","outputs:  tensor([[0.3848, 0.4977],\n","        [0.7047, 0.3806],\n","        [0.7015, 0.3852],\n","        [0.8415, 0.3084],\n","        [0.3020, 0.6282]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5470, grad_fn=<NllLossBackward>)\n","epoch 353, loss 0.5469821691513062\n","outputs:  tensor([[0.3843, 0.4981],\n","        [0.7051, 0.3803],\n","        [0.7018, 0.3850],\n","        [0.8420, 0.3078],\n","        [0.3011, 0.6289]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5466, grad_fn=<NllLossBackward>)\n","epoch 354, loss 0.5465788245201111\n","outputs:  tensor([[0.3838, 0.4985],\n","        [0.7054, 0.3799],\n","        [0.7022, 0.3847],\n","        [0.8425, 0.3072],\n","        [0.3003, 0.6296]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5462, grad_fn=<NllLossBackward>)\n","epoch 355, loss 0.546175479888916\n","outputs:  tensor([[0.3833, 0.4989],\n","        [0.7058, 0.3796],\n","        [0.7025, 0.3844],\n","        [0.8429, 0.3065],\n","        [0.2994, 0.6303]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5458, grad_fn=<NllLossBackward>)\n","epoch 356, loss 0.5457721948623657\n","outputs:  tensor([[0.3828, 0.4993],\n","        [0.7061, 0.3793],\n","        [0.7028, 0.3841],\n","        [0.8434, 0.3059],\n","        [0.2985, 0.6310]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5454, grad_fn=<NllLossBackward>)\n","epoch 357, loss 0.545369029045105\n","outputs:  tensor([[0.3823, 0.4996],\n","        [0.7065, 0.3790],\n","        [0.7032, 0.3838],\n","        [0.8438, 0.3053],\n","        [0.2977, 0.6317]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5450, grad_fn=<NllLossBackward>)\n","epoch 358, loss 0.5449657440185547\n","outputs:  tensor([[0.3818, 0.5000],\n","        [0.7068, 0.3787],\n","        [0.7035, 0.3835],\n","        [0.8443, 0.3047],\n","        [0.2968, 0.6324]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5446, grad_fn=<NllLossBackward>)\n","epoch 359, loss 0.5445626378059387\n","outputs:  tensor([[0.3813, 0.5004],\n","        [0.7072, 0.3783],\n","        [0.7038, 0.3832],\n","        [0.8448, 0.3041],\n","        [0.2960, 0.6331]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5442, grad_fn=<NllLossBackward>)\n","epoch 360, loss 0.5441595315933228\n","outputs:  tensor([[0.3808, 0.5008],\n","        [0.7076, 0.3780],\n","        [0.7041, 0.3828],\n","        [0.8452, 0.3035],\n","        [0.2951, 0.6338]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5438, grad_fn=<NllLossBackward>)\n","epoch 361, loss 0.5437566041946411\n","outputs:  tensor([[0.3803, 0.5012],\n","        [0.7079, 0.3777],\n","        [0.7045, 0.3825],\n","        [0.8457, 0.3029],\n","        [0.2942, 0.6345]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5434, grad_fn=<NllLossBackward>)\n","epoch 362, loss 0.5433536171913147\n","outputs:  tensor([[0.3798, 0.5016],\n","        [0.7083, 0.3774],\n","        [0.7048, 0.3822],\n","        [0.8462, 0.3023],\n","        [0.2934, 0.6352]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5430, grad_fn=<NllLossBackward>)\n","epoch 363, loss 0.5429507493972778\n","outputs:  tensor([[0.3793, 0.5020],\n","        [0.7086, 0.3771],\n","        [0.7051, 0.3819],\n","        [0.8466, 0.3017],\n","        [0.2925, 0.6359]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5425, grad_fn=<NllLossBackward>)\n","epoch 364, loss 0.5425480008125305\n","outputs:  tensor([[0.3788, 0.5024],\n","        [0.7090, 0.3767],\n","        [0.7055, 0.3816],\n","        [0.8471, 0.3010],\n","        [0.2917, 0.6365]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5421, grad_fn=<NllLossBackward>)\n","epoch 365, loss 0.5421452522277832\n","outputs:  tensor([[0.3783, 0.5028],\n","        [0.7093, 0.3764],\n","        [0.7058, 0.3813],\n","        [0.8475, 0.3004],\n","        [0.2908, 0.6372]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5417, grad_fn=<NllLossBackward>)\n","epoch 366, loss 0.5417426228523254\n","outputs:  tensor([[0.3778, 0.5032],\n","        [0.7097, 0.3761],\n","        [0.7061, 0.3810],\n","        [0.8480, 0.2998],\n","        [0.2900, 0.6379]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5413, grad_fn=<NllLossBackward>)\n","epoch 367, loss 0.5413400530815125\n","outputs:  tensor([[0.3773, 0.5036],\n","        [0.7101, 0.3758],\n","        [0.7065, 0.3807],\n","        [0.8484, 0.2992],\n","        [0.2891, 0.6386]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5409, grad_fn=<NllLossBackward>)\n","epoch 368, loss 0.5409375429153442\n","outputs:  tensor([[0.3767, 0.5040],\n","        [0.7104, 0.3754],\n","        [0.7068, 0.3804],\n","        [0.8489, 0.2986],\n","        [0.2883, 0.6393]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5405, grad_fn=<NllLossBackward>)\n","epoch 369, loss 0.5405352115631104\n","outputs:  tensor([[0.3762, 0.5044],\n","        [0.7108, 0.3751],\n","        [0.7071, 0.3801],\n","        [0.8494, 0.2980],\n","        [0.2874, 0.6400]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5401, grad_fn=<NllLossBackward>)\n","epoch 370, loss 0.5401328802108765\n","outputs:  tensor([[0.3757, 0.5048],\n","        [0.7111, 0.3748],\n","        [0.7075, 0.3798],\n","        [0.8498, 0.2974],\n","        [0.2866, 0.6408]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5397, grad_fn=<NllLossBackward>)\n","epoch 371, loss 0.5397306680679321\n","outputs:  tensor([[0.3752, 0.5053],\n","        [0.7115, 0.3745],\n","        [0.7078, 0.3795],\n","        [0.8503, 0.2967],\n","        [0.2857, 0.6415]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5393, grad_fn=<NllLossBackward>)\n","epoch 372, loss 0.5393286943435669\n","outputs:  tensor([[0.3747, 0.5057],\n","        [0.7119, 0.3741],\n","        [0.7081, 0.3792],\n","        [0.8507, 0.2961],\n","        [0.2849, 0.6422]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5389, grad_fn=<NllLossBackward>)\n","epoch 373, loss 0.5389267206192017\n","outputs:  tensor([[0.3742, 0.5061],\n","        [0.7122, 0.3738],\n","        [0.7085, 0.3789],\n","        [0.8512, 0.2955],\n","        [0.2840, 0.6429]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5385, grad_fn=<NllLossBackward>)\n","epoch 374, loss 0.5385249257087708\n","outputs:  tensor([[0.3737, 0.5065],\n","        [0.7126, 0.3735],\n","        [0.7088, 0.3786],\n","        [0.8516, 0.2949],\n","        [0.2832, 0.6436]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5381, grad_fn=<NllLossBackward>)\n","epoch 375, loss 0.5381231307983398\n","outputs:  tensor([[0.3732, 0.5069],\n","        [0.7129, 0.3732],\n","        [0.7091, 0.3783],\n","        [0.8521, 0.2943],\n","        [0.2823, 0.6443]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5377, grad_fn=<NllLossBackward>)\n","epoch 376, loss 0.537721574306488\n","outputs:  tensor([[0.3727, 0.5073],\n","        [0.7133, 0.3728],\n","        [0.7094, 0.3780],\n","        [0.8525, 0.2937],\n","        [0.2815, 0.6450]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5373, grad_fn=<NllLossBackward>)\n","epoch 377, loss 0.537320077419281\n","outputs:  tensor([[0.3722, 0.5077],\n","        [0.7137, 0.3725],\n","        [0.7098, 0.3777],\n","        [0.8530, 0.2931],\n","        [0.2806, 0.6457]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5369, grad_fn=<NllLossBackward>)\n","epoch 378, loss 0.5369186997413635\n","outputs:  tensor([[0.3717, 0.5081],\n","        [0.7140, 0.3722],\n","        [0.7101, 0.3773],\n","        [0.8534, 0.2924],\n","        [0.2798, 0.6464]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5365, grad_fn=<NllLossBackward>)\n","epoch 379, loss 0.5365175008773804\n","outputs:  tensor([[0.3711, 0.5085],\n","        [0.7144, 0.3718],\n","        [0.7104, 0.3770],\n","        [0.8539, 0.2918],\n","        [0.2790, 0.6471]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5361, grad_fn=<NllLossBackward>)\n","epoch 380, loss 0.5361164212226868\n","outputs:  tensor([[0.3706, 0.5089],\n","        [0.7147, 0.3715],\n","        [0.7108, 0.3767],\n","        [0.8543, 0.2912],\n","        [0.2781, 0.6478]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5357, grad_fn=<NllLossBackward>)\n","epoch 381, loss 0.5357155799865723\n","outputs:  tensor([[0.3701, 0.5094],\n","        [0.7151, 0.3712],\n","        [0.7111, 0.3764],\n","        [0.8547, 0.2906],\n","        [0.2773, 0.6485]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5353, grad_fn=<NllLossBackward>)\n","epoch 382, loss 0.5353147387504578\n","outputs:  tensor([[0.3696, 0.5098],\n","        [0.7155, 0.3709],\n","        [0.7114, 0.3761],\n","        [0.8552, 0.2900],\n","        [0.2764, 0.6492]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5349, grad_fn=<NllLossBackward>)\n","epoch 383, loss 0.5349141359329224\n","outputs:  tensor([[0.3691, 0.5102],\n","        [0.7158, 0.3705],\n","        [0.7118, 0.3758],\n","        [0.8556, 0.2893],\n","        [0.2756, 0.6500]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5345, grad_fn=<NllLossBackward>)\n","epoch 384, loss 0.5345136523246765\n","outputs:  tensor([[0.3686, 0.5106],\n","        [0.7162, 0.3702],\n","        [0.7121, 0.3755],\n","        [0.8561, 0.2887],\n","        [0.2748, 0.6507]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5341, grad_fn=<NllLossBackward>)\n","epoch 385, loss 0.534113347530365\n","outputs:  tensor([[0.3681, 0.5110],\n","        [0.7165, 0.3699],\n","        [0.7124, 0.3752],\n","        [0.8565, 0.2881],\n","        [0.2739, 0.6514]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5337, grad_fn=<NllLossBackward>)\n","epoch 386, loss 0.5337132215499878\n","outputs:  tensor([[0.3676, 0.5114],\n","        [0.7169, 0.3695],\n","        [0.7128, 0.3749],\n","        [0.8570, 0.2875],\n","        [0.2731, 0.6521]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5333, grad_fn=<NllLossBackward>)\n","epoch 387, loss 0.5333132743835449\n","outputs:  tensor([[0.3671, 0.5119],\n","        [0.7173, 0.3692],\n","        [0.7131, 0.3745],\n","        [0.8574, 0.2869],\n","        [0.2723, 0.6528]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5329, grad_fn=<NllLossBackward>)\n","epoch 388, loss 0.5329135060310364\n","outputs:  tensor([[0.3666, 0.5123],\n","        [0.7176, 0.3689],\n","        [0.7134, 0.3742],\n","        [0.8578, 0.2863],\n","        [0.2714, 0.6535]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5325, grad_fn=<NllLossBackward>)\n","epoch 389, loss 0.5325137376785278\n","outputs:  tensor([[0.3660, 0.5127],\n","        [0.7180, 0.3685],\n","        [0.7138, 0.3739],\n","        [0.8583, 0.2856],\n","        [0.2706, 0.6543]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5321, grad_fn=<NllLossBackward>)\n","epoch 390, loss 0.5321143269538879\n","outputs:  tensor([[0.3655, 0.5131],\n","        [0.7183, 0.3682],\n","        [0.7141, 0.3736],\n","        [0.8587, 0.2850],\n","        [0.2698, 0.6550]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5317, grad_fn=<NllLossBackward>)\n","epoch 391, loss 0.5317150950431824\n","outputs:  tensor([[0.3650, 0.5136],\n","        [0.7187, 0.3679],\n","        [0.7144, 0.3733],\n","        [0.8592, 0.2844],\n","        [0.2689, 0.6557]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5313, grad_fn=<NllLossBackward>)\n","epoch 392, loss 0.5313159823417664\n","outputs:  tensor([[0.3645, 0.5140],\n","        [0.7190, 0.3675],\n","        [0.7148, 0.3730],\n","        [0.8596, 0.2838],\n","        [0.2681, 0.6564]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5309, grad_fn=<NllLossBackward>)\n","epoch 393, loss 0.5309170484542847\n","outputs:  tensor([[0.3640, 0.5144],\n","        [0.7194, 0.3672],\n","        [0.7151, 0.3726],\n","        [0.8600, 0.2832],\n","        [0.2673, 0.6571]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5305, grad_fn=<NllLossBackward>)\n","epoch 394, loss 0.5305184125900269\n","outputs:  tensor([[0.3635, 0.5148],\n","        [0.7198, 0.3668],\n","        [0.7154, 0.3723],\n","        [0.8605, 0.2825],\n","        [0.2665, 0.6579]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5301, grad_fn=<NllLossBackward>)\n","epoch 395, loss 0.5301198959350586\n","outputs:  tensor([[0.3630, 0.5153],\n","        [0.7201, 0.3665],\n","        [0.7158, 0.3720],\n","        [0.8609, 0.2819],\n","        [0.2656, 0.6586]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5297, grad_fn=<NllLossBackward>)\n","epoch 396, loss 0.5297216176986694\n","outputs:  tensor([[0.3625, 0.5157],\n","        [0.7205, 0.3662],\n","        [0.7161, 0.3717],\n","        [0.8613, 0.2813],\n","        [0.2648, 0.6593]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5293, grad_fn=<NllLossBackward>)\n","epoch 397, loss 0.5293235182762146\n","outputs:  tensor([[0.3620, 0.5161],\n","        [0.7208, 0.3658],\n","        [0.7164, 0.3714],\n","        [0.8618, 0.2807],\n","        [0.2640, 0.6600]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5289, grad_fn=<NllLossBackward>)\n","epoch 398, loss 0.5289256572723389\n","outputs:  tensor([[0.3614, 0.5165],\n","        [0.7212, 0.3655],\n","        [0.7168, 0.3711],\n","        [0.8622, 0.2801],\n","        [0.2632, 0.6607]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5285, grad_fn=<NllLossBackward>)\n","epoch 399, loss 0.5285279154777527\n","outputs:  tensor([[0.3609, 0.5170],\n","        [0.7216, 0.3652],\n","        [0.7171, 0.3707],\n","        [0.8626, 0.2794],\n","        [0.2624, 0.6615]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5281, grad_fn=<NllLossBackward>)\n","epoch 400, loss 0.5281305909156799\n","outputs:  tensor([[0.3604, 0.5174],\n","        [0.7219, 0.3648],\n","        [0.7174, 0.3704],\n","        [0.8631, 0.2788],\n","        [0.2616, 0.6622]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5277, grad_fn=<NllLossBackward>)\n","epoch 401, loss 0.527733325958252\n","Parameter containing:\n","tensor([[-0.0786, -0.3534,  0.2175],\n","        [-0.5998, -0.1578, -0.0355],\n","        [-0.6173, -0.3176, -0.0830],\n","        [-0.3099, -0.2674,  0.0077]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4445, -0.4025,  0.0474,  0.0810], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.6018,  0.3866,  0.6648, -0.1224],\n","        [ 0.1691, -0.4572, -0.1610, -0.2266]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2897, -0.4919], requires_grad=True)\n","outputs:  tensor([[0.3599, 0.5178],\n","        [0.7223, 0.3645],\n","        [0.7178, 0.3701],\n","        [0.8635, 0.2782],\n","        [0.2607, 0.6629]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5273, grad_fn=<NllLossBackward>)\n","epoch 402, loss 0.5273364186286926\n","outputs:  tensor([[0.3594, 0.5183],\n","        [0.7226, 0.3641],\n","        [0.7181, 0.3698],\n","        [0.8639, 0.2776],\n","        [0.2599, 0.6636]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5269, grad_fn=<NllLossBackward>)\n","epoch 403, loss 0.5269395709037781\n","outputs:  tensor([[0.3589, 0.5187],\n","        [0.7230, 0.3638],\n","        [0.7184, 0.3695],\n","        [0.8643, 0.2770],\n","        [0.2591, 0.6644]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5265, grad_fn=<NllLossBackward>)\n","epoch 404, loss 0.5265430808067322\n","outputs:  tensor([[0.3584, 0.5191],\n","        [0.7234, 0.3635],\n","        [0.7188, 0.3691],\n","        [0.8648, 0.2763],\n","        [0.2583, 0.6651]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5261, grad_fn=<NllLossBackward>)\n","epoch 405, loss 0.5261468291282654\n","outputs:  tensor([[0.3579, 0.5196],\n","        [0.7237, 0.3631],\n","        [0.7191, 0.3688],\n","        [0.8652, 0.2757],\n","        [0.2575, 0.6658]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5258, grad_fn=<NllLossBackward>)\n","epoch 406, loss 0.5257507562637329\n","outputs:  tensor([[0.3573, 0.5200],\n","        [0.7241, 0.3628],\n","        [0.7194, 0.3685],\n","        [0.8656, 0.2751],\n","        [0.2567, 0.6666]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5254, grad_fn=<NllLossBackward>)\n","epoch 407, loss 0.5253550410270691\n","outputs:  tensor([[0.3568, 0.5204],\n","        [0.7244, 0.3624],\n","        [0.7198, 0.3682],\n","        [0.8660, 0.2745],\n","        [0.2559, 0.6673]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5250, grad_fn=<NllLossBackward>)\n","epoch 408, loss 0.5249594449996948\n","outputs:  tensor([[0.3563, 0.5209],\n","        [0.7248, 0.3621],\n","        [0.7201, 0.3679],\n","        [0.8665, 0.2739],\n","        [0.2551, 0.6680]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5246, grad_fn=<NllLossBackward>)\n","epoch 409, loss 0.5245642066001892\n","outputs:  tensor([[0.3558, 0.5213],\n","        [0.7252, 0.3618],\n","        [0.7204, 0.3675],\n","        [0.8669, 0.2732],\n","        [0.2543, 0.6687]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5242, grad_fn=<NllLossBackward>)\n","epoch 410, loss 0.5241691470146179\n","outputs:  tensor([[0.3553, 0.5217],\n","        [0.7255, 0.3614],\n","        [0.7208, 0.3672],\n","        [0.8673, 0.2726],\n","        [0.2535, 0.6695]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5238, grad_fn=<NllLossBackward>)\n","epoch 411, loss 0.5237743258476257\n","outputs:  tensor([[0.3548, 0.5222],\n","        [0.7259, 0.3611],\n","        [0.7211, 0.3669],\n","        [0.8677, 0.2720],\n","        [0.2527, 0.6702]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5234, grad_fn=<NllLossBackward>)\n","epoch 412, loss 0.523379921913147\n","outputs:  tensor([[0.3543, 0.5226],\n","        [0.7262, 0.3607],\n","        [0.7214, 0.3666],\n","        [0.8681, 0.2714],\n","        [0.2518, 0.6709]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5230, grad_fn=<NllLossBackward>)\n","epoch 413, loss 0.522985577583313\n","outputs:  tensor([[0.3538, 0.5231],\n","        [0.7266, 0.3604],\n","        [0.7218, 0.3663],\n","        [0.8686, 0.2708],\n","        [0.2510, 0.6717]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5226, grad_fn=<NllLossBackward>)\n","epoch 414, loss 0.5225917100906372\n","outputs:  tensor([[0.3533, 0.5235],\n","        [0.7270, 0.3600],\n","        [0.7221, 0.3659],\n","        [0.8690, 0.2701],\n","        [0.2503, 0.6724]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5222, grad_fn=<NllLossBackward>)\n","epoch 415, loss 0.522197961807251\n","outputs:  tensor([[0.3527, 0.5239],\n","        [0.7273, 0.3597],\n","        [0.7224, 0.3656],\n","        [0.8694, 0.2695],\n","        [0.2495, 0.6731]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5218, grad_fn=<NllLossBackward>)\n","epoch 416, loss 0.5218045115470886\n","outputs:  tensor([[0.3522, 0.5244],\n","        [0.7277, 0.3593],\n","        [0.7228, 0.3653],\n","        [0.8698, 0.2689],\n","        [0.2487, 0.6739]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5214, grad_fn=<NllLossBackward>)\n","epoch 417, loss 0.5214114785194397\n","outputs:  tensor([[0.3517, 0.5248],\n","        [0.7280, 0.3590],\n","        [0.7231, 0.3650],\n","        [0.8702, 0.2683],\n","        [0.2479, 0.6746]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5210, grad_fn=<NllLossBackward>)\n","epoch 418, loss 0.5210186243057251\n","outputs:  tensor([[0.3512, 0.5253],\n","        [0.7284, 0.3587],\n","        [0.7234, 0.3646],\n","        [0.8706, 0.2677],\n","        [0.2471, 0.6753]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5206, grad_fn=<NllLossBackward>)\n","epoch 419, loss 0.5206260681152344\n","outputs:  tensor([[0.3507, 0.5257],\n","        [0.7288, 0.3583],\n","        [0.7238, 0.3643],\n","        [0.8710, 0.2670],\n","        [0.2463, 0.6761]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5202, grad_fn=<NllLossBackward>)\n","epoch 420, loss 0.5202338099479675\n","outputs:  tensor([[0.3502, 0.5262],\n","        [0.7291, 0.3580],\n","        [0.7241, 0.3640],\n","        [0.8715, 0.2664],\n","        [0.2455, 0.6768]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5198, grad_fn=<NllLossBackward>)\n","epoch 421, loss 0.5198420286178589\n","outputs:  tensor([[0.3497, 0.5266],\n","        [0.7295, 0.3576],\n","        [0.7244, 0.3637],\n","        [0.8719, 0.2658],\n","        [0.2447, 0.6775]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5195, grad_fn=<NllLossBackward>)\n","epoch 422, loss 0.5194503664970398\n","outputs:  tensor([[0.3492, 0.5271],\n","        [0.7298, 0.3573],\n","        [0.7248, 0.3633],\n","        [0.8723, 0.2652],\n","        [0.2439, 0.6783]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5191, grad_fn=<NllLossBackward>)\n","epoch 423, loss 0.5190590023994446\n","outputs:  tensor([[0.3487, 0.5275],\n","        [0.7302, 0.3569],\n","        [0.7251, 0.3630],\n","        [0.8727, 0.2646],\n","        [0.2431, 0.6790]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5187, grad_fn=<NllLossBackward>)\n","epoch 424, loss 0.5186679363250732\n","outputs:  tensor([[0.3481, 0.5280],\n","        [0.7305, 0.3566],\n","        [0.7254, 0.3627],\n","        [0.8731, 0.2639],\n","        [0.2423, 0.6797]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5183, grad_fn=<NllLossBackward>)\n","epoch 425, loss 0.5182772874832153\n","outputs:  tensor([[0.3476, 0.5284],\n","        [0.7309, 0.3562],\n","        [0.7258, 0.3623],\n","        [0.8735, 0.2633],\n","        [0.2416, 0.6805]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5179, grad_fn=<NllLossBackward>)\n","epoch 426, loss 0.5178868770599365\n","outputs:  tensor([[0.3471, 0.5289],\n","        [0.7313, 0.3559],\n","        [0.7261, 0.3620],\n","        [0.8739, 0.2627],\n","        [0.2408, 0.6812]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5175, grad_fn=<NllLossBackward>)\n","epoch 427, loss 0.5174968242645264\n","outputs:  tensor([[0.3466, 0.5293],\n","        [0.7316, 0.3555],\n","        [0.7264, 0.3617],\n","        [0.8743, 0.2621],\n","        [0.2400, 0.6819]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5171, grad_fn=<NllLossBackward>)\n","epoch 428, loss 0.5171070694923401\n","outputs:  tensor([[0.3461, 0.5298],\n","        [0.7320, 0.3552],\n","        [0.7268, 0.3614],\n","        [0.8747, 0.2615],\n","        [0.2392, 0.6827]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5167, grad_fn=<NllLossBackward>)\n","epoch 429, loss 0.5167176127433777\n","outputs:  tensor([[0.3456, 0.5302],\n","        [0.7323, 0.3548],\n","        [0.7271, 0.3610],\n","        [0.8751, 0.2608],\n","        [0.2385, 0.6834]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5163, grad_fn=<NllLossBackward>)\n","epoch 430, loss 0.5163285136222839\n","outputs:  tensor([[0.3451, 0.5307],\n","        [0.7327, 0.3545],\n","        [0.7274, 0.3607],\n","        [0.8755, 0.2602],\n","        [0.2377, 0.6841]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5159, grad_fn=<NllLossBackward>)\n","epoch 431, loss 0.5159398317337036\n","outputs:  tensor([[0.3446, 0.5311],\n","        [0.7331, 0.3541],\n","        [0.7278, 0.3604],\n","        [0.8759, 0.2596],\n","        [0.2369, 0.6849]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5156, grad_fn=<NllLossBackward>)\n","epoch 432, loss 0.5155513882637024\n","outputs:  tensor([[0.3441, 0.5316],\n","        [0.7334, 0.3538],\n","        [0.7281, 0.3600],\n","        [0.8763, 0.2590],\n","        [0.2361, 0.6856]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5152, grad_fn=<NllLossBackward>)\n","epoch 433, loss 0.5151633024215698\n","outputs:  tensor([[0.3436, 0.5320],\n","        [0.7338, 0.3534],\n","        [0.7284, 0.3597],\n","        [0.8767, 0.2584],\n","        [0.2354, 0.6863]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5148, grad_fn=<NllLossBackward>)\n","epoch 434, loss 0.5147756338119507\n","outputs:  tensor([[0.3430, 0.5325],\n","        [0.7341, 0.3531],\n","        [0.7288, 0.3594],\n","        [0.8771, 0.2577],\n","        [0.2346, 0.6871]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5144, grad_fn=<NllLossBackward>)\n","epoch 435, loss 0.5143882036209106\n","outputs:  tensor([[0.3425, 0.5329],\n","        [0.7345, 0.3527],\n","        [0.7291, 0.3591],\n","        [0.8775, 0.2571],\n","        [0.2338, 0.6878]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5140, grad_fn=<NllLossBackward>)\n","epoch 436, loss 0.5140012502670288\n","outputs:  tensor([[0.3420, 0.5334],\n","        [0.7348, 0.3524],\n","        [0.7294, 0.3587],\n","        [0.8779, 0.2565],\n","        [0.2331, 0.6885]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5136, grad_fn=<NllLossBackward>)\n","epoch 437, loss 0.5136145353317261\n","outputs:  tensor([[0.3415, 0.5338],\n","        [0.7352, 0.3520],\n","        [0.7298, 0.3584],\n","        [0.8783, 0.2559],\n","        [0.2323, 0.6893]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5132, grad_fn=<NllLossBackward>)\n","epoch 438, loss 0.5132282972335815\n","outputs:  tensor([[0.3410, 0.5343],\n","        [0.7356, 0.3517],\n","        [0.7301, 0.3581],\n","        [0.8787, 0.2553],\n","        [0.2315, 0.6900]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5128, grad_fn=<NllLossBackward>)\n","epoch 439, loss 0.5128422975540161\n","outputs:  tensor([[0.3405, 0.5348],\n","        [0.7359, 0.3513],\n","        [0.7304, 0.3577],\n","        [0.8791, 0.2547],\n","        [0.2308, 0.6908]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5125, grad_fn=<NllLossBackward>)\n","epoch 440, loss 0.5124566555023193\n","outputs:  tensor([[0.3400, 0.5352],\n","        [0.7363, 0.3510],\n","        [0.7307, 0.3574],\n","        [0.8795, 0.2540],\n","        [0.2300, 0.6915]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5121, grad_fn=<NllLossBackward>)\n","epoch 441, loss 0.5120714902877808\n","outputs:  tensor([[0.3395, 0.5357],\n","        [0.7366, 0.3506],\n","        [0.7311, 0.3571],\n","        [0.8799, 0.2534],\n","        [0.2293, 0.6922]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5117, grad_fn=<NllLossBackward>)\n","epoch 442, loss 0.5116866827011108\n","outputs:  tensor([[0.3390, 0.5361],\n","        [0.7370, 0.3502],\n","        [0.7314, 0.3567],\n","        [0.8803, 0.2528],\n","        [0.2285, 0.6930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5113, grad_fn=<NllLossBackward>)\n","epoch 443, loss 0.5113021731376648\n","outputs:  tensor([[0.3385, 0.5366],\n","        [0.7373, 0.3499],\n","        [0.7317, 0.3564],\n","        [0.8807, 0.2522],\n","        [0.2278, 0.6937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5109, grad_fn=<NllLossBackward>)\n","epoch 444, loss 0.510918140411377\n","outputs:  tensor([[0.3380, 0.5371],\n","        [0.7377, 0.3495],\n","        [0.7321, 0.3561],\n","        [0.8811, 0.2516],\n","        [0.2270, 0.6944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5105, grad_fn=<NllLossBackward>)\n","epoch 445, loss 0.5105344653129578\n","outputs:  tensor([[0.3375, 0.5375],\n","        [0.7380, 0.3492],\n","        [0.7324, 0.3557],\n","        [0.8815, 0.2510],\n","        [0.2263, 0.6952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5102, grad_fn=<NllLossBackward>)\n","epoch 446, loss 0.5101511478424072\n","outputs:  tensor([[0.3369, 0.5380],\n","        [0.7384, 0.3488],\n","        [0.7327, 0.3554],\n","        [0.8818, 0.2503],\n","        [0.2255, 0.6959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5098, grad_fn=<NllLossBackward>)\n","epoch 447, loss 0.5097681879997253\n","outputs:  tensor([[0.3364, 0.5385],\n","        [0.7388, 0.3485],\n","        [0.7331, 0.3551],\n","        [0.8822, 0.2497],\n","        [0.2248, 0.6967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5094, grad_fn=<NllLossBackward>)\n","epoch 448, loss 0.5093857049942017\n","outputs:  tensor([[0.3359, 0.5389],\n","        [0.7391, 0.3481],\n","        [0.7334, 0.3547],\n","        [0.8826, 0.2491],\n","        [0.2240, 0.6974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5090, grad_fn=<NllLossBackward>)\n","epoch 449, loss 0.5090035200119019\n","outputs:  tensor([[0.3354, 0.5394],\n","        [0.7395, 0.3478],\n","        [0.7337, 0.3544],\n","        [0.8830, 0.2485],\n","        [0.2233, 0.6981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5086, grad_fn=<NllLossBackward>)\n","epoch 450, loss 0.5086218118667603\n","outputs:  tensor([[0.3349, 0.5398],\n","        [0.7398, 0.3474],\n","        [0.7341, 0.3541],\n","        [0.8834, 0.2479],\n","        [0.2225, 0.6989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5082, grad_fn=<NllLossBackward>)\n","epoch 451, loss 0.5082405209541321\n","Parameter containing:\n","tensor([[-0.0904, -0.3683,  0.2145],\n","        [-0.6287, -0.1928, -0.0422],\n","        [-0.6436, -0.3500, -0.0893],\n","        [-0.3154, -0.2737,  0.0066]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4452, -0.3988,  0.0502,  0.0821], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.6168,  0.4099,  0.6958, -0.1034],\n","        [ 0.1494, -0.4854, -0.1997, -0.2503]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2923, -0.4977], requires_grad=True)\n","outputs:  tensor([[0.3344, 0.5403],\n","        [0.7402, 0.3470],\n","        [0.7344, 0.3537],\n","        [0.8838, 0.2473],\n","        [0.2218, 0.6996]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5079, grad_fn=<NllLossBackward>)\n","epoch 452, loss 0.5078595280647278\n","outputs:  tensor([[0.3339, 0.5408],\n","        [0.7405, 0.3467],\n","        [0.7347, 0.3534],\n","        [0.8841, 0.2467],\n","        [0.2210, 0.7003]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5075, grad_fn=<NllLossBackward>)\n","epoch 453, loss 0.5074790716171265\n","outputs:  tensor([[0.3334, 0.5412],\n","        [0.7409, 0.3463],\n","        [0.7351, 0.3530],\n","        [0.8845, 0.2461],\n","        [0.2203, 0.7011]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5071, grad_fn=<NllLossBackward>)\n","epoch 454, loss 0.5070988535881042\n","outputs:  tensor([[0.3329, 0.5417],\n","        [0.7412, 0.3460],\n","        [0.7354, 0.3527],\n","        [0.8849, 0.2454],\n","        [0.2196, 0.7018]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5067, grad_fn=<NllLossBackward>)\n","epoch 455, loss 0.5067192316055298\n","outputs:  tensor([[0.3324, 0.5422],\n","        [0.7416, 0.3456],\n","        [0.7357, 0.3524],\n","        [0.8853, 0.2448],\n","        [0.2188, 0.7025]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5063, grad_fn=<NllLossBackward>)\n","epoch 456, loss 0.5063399076461792\n","outputs:  tensor([[0.3319, 0.5426],\n","        [0.7420, 0.3453],\n","        [0.7360, 0.3520],\n","        [0.8857, 0.2442],\n","        [0.2181, 0.7033]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5060, grad_fn=<NllLossBackward>)\n","epoch 457, loss 0.5059610605239868\n","outputs:  tensor([[0.3314, 0.5431],\n","        [0.7423, 0.3449],\n","        [0.7364, 0.3517],\n","        [0.8860, 0.2436],\n","        [0.2174, 0.7040]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5056, grad_fn=<NllLossBackward>)\n","epoch 458, loss 0.5055826902389526\n","outputs:  tensor([[0.3309, 0.5436],\n","        [0.7427, 0.3445],\n","        [0.7367, 0.3514],\n","        [0.8864, 0.2430],\n","        [0.2167, 0.7048]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5052, grad_fn=<NllLossBackward>)\n","epoch 459, loss 0.5052046775817871\n","outputs:  tensor([[0.3304, 0.5441],\n","        [0.7430, 0.3442],\n","        [0.7370, 0.3510],\n","        [0.8868, 0.2424],\n","        [0.2159, 0.7055]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5048, grad_fn=<NllLossBackward>)\n","epoch 460, loss 0.5048270225524902\n","outputs:  tensor([[0.3299, 0.5445],\n","        [0.7434, 0.3438],\n","        [0.7374, 0.3507],\n","        [0.8872, 0.2418],\n","        [0.2152, 0.7062]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5044, grad_fn=<NllLossBackward>)\n","epoch 461, loss 0.5044498443603516\n","outputs:  tensor([[0.3294, 0.5450],\n","        [0.7437, 0.3435],\n","        [0.7377, 0.3504],\n","        [0.8875, 0.2412],\n","        [0.2145, 0.7070]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5041, grad_fn=<NllLossBackward>)\n","epoch 462, loss 0.5040732026100159\n","outputs:  tensor([[0.3288, 0.5455],\n","        [0.7441, 0.3431],\n","        [0.7380, 0.3500],\n","        [0.8879, 0.2406],\n","        [0.2138, 0.7077]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5037, grad_fn=<NllLossBackward>)\n","epoch 463, loss 0.503696858882904\n","outputs:  tensor([[0.3283, 0.5459],\n","        [0.7444, 0.3427],\n","        [0.7384, 0.3497],\n","        [0.8883, 0.2399],\n","        [0.2130, 0.7084]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5033, grad_fn=<NllLossBackward>)\n","epoch 464, loss 0.5033210515975952\n","outputs:  tensor([[0.3278, 0.5464],\n","        [0.7448, 0.3424],\n","        [0.7387, 0.3493],\n","        [0.8887, 0.2393],\n","        [0.2123, 0.7092]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5029, grad_fn=<NllLossBackward>)\n","epoch 465, loss 0.502945601940155\n","outputs:  tensor([[0.3273, 0.5469],\n","        [0.7451, 0.3420],\n","        [0.7390, 0.3490],\n","        [0.8890, 0.2387],\n","        [0.2116, 0.7099]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5026, grad_fn=<NllLossBackward>)\n","epoch 466, loss 0.5025706887245178\n","outputs:  tensor([[0.3268, 0.5474],\n","        [0.7455, 0.3417],\n","        [0.7393, 0.3487],\n","        [0.8894, 0.2381],\n","        [0.2109, 0.7106]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5022, grad_fn=<NllLossBackward>)\n","epoch 467, loss 0.502196192741394\n","outputs:  tensor([[0.3263, 0.5478],\n","        [0.7458, 0.3413],\n","        [0.7397, 0.3483],\n","        [0.8898, 0.2375],\n","        [0.2102, 0.7114]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5018, grad_fn=<NllLossBackward>)\n","epoch 468, loss 0.5018221735954285\n","outputs:  tensor([[0.3258, 0.5483],\n","        [0.7462, 0.3409],\n","        [0.7400, 0.3480],\n","        [0.8901, 0.2369],\n","        [0.2095, 0.7121]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5014, grad_fn=<NllLossBackward>)\n","epoch 469, loss 0.5014485120773315\n","outputs:  tensor([[0.3253, 0.5488],\n","        [0.7466, 0.3406],\n","        [0.7403, 0.3476],\n","        [0.8905, 0.2363],\n","        [0.2088, 0.7128]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5011, grad_fn=<NllLossBackward>)\n","epoch 470, loss 0.5010753870010376\n","outputs:  tensor([[0.3248, 0.5493],\n","        [0.7469, 0.3402],\n","        [0.7407, 0.3473],\n","        [0.8909, 0.2357],\n","        [0.2081, 0.7136]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5007, grad_fn=<NllLossBackward>)\n","epoch 471, loss 0.5007027387619019\n","outputs:  tensor([[0.3243, 0.5497],\n","        [0.7473, 0.3399],\n","        [0.7410, 0.3470],\n","        [0.8912, 0.2351],\n","        [0.2073, 0.7143]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5003, grad_fn=<NllLossBackward>)\n","epoch 472, loss 0.5003305077552795\n","outputs:  tensor([[0.3238, 0.5502],\n","        [0.7476, 0.3395],\n","        [0.7413, 0.3466],\n","        [0.8916, 0.2345],\n","        [0.2066, 0.7150]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.5000, grad_fn=<NllLossBackward>)\n","epoch 473, loss 0.49995875358581543\n","outputs:  tensor([[0.3233, 0.5507],\n","        [0.7480, 0.3391],\n","        [0.7416, 0.3463],\n","        [0.8919, 0.2339],\n","        [0.2059, 0.7158]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4996, grad_fn=<NllLossBackward>)\n","epoch 474, loss 0.4995875358581543\n","outputs:  tensor([[0.3228, 0.5512],\n","        [0.7483, 0.3388],\n","        [0.7420, 0.3459],\n","        [0.8923, 0.2333],\n","        [0.2052, 0.7165]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4992, grad_fn=<NllLossBackward>)\n","epoch 475, loss 0.4992167353630066\n","outputs:  tensor([[0.3223, 0.5517],\n","        [0.7487, 0.3384],\n","        [0.7423, 0.3456],\n","        [0.8927, 0.2327],\n","        [0.2045, 0.7172]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4988, grad_fn=<NllLossBackward>)\n","epoch 476, loss 0.4988463521003723\n","outputs:  tensor([[0.3218, 0.5521],\n","        [0.7490, 0.3380],\n","        [0.7426, 0.3453],\n","        [0.8930, 0.2321],\n","        [0.2038, 0.7180]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4985, grad_fn=<NllLossBackward>)\n","epoch 477, loss 0.498476505279541\n","outputs:  tensor([[0.3213, 0.5526],\n","        [0.7494, 0.3377],\n","        [0.7430, 0.3449],\n","        [0.8934, 0.2315],\n","        [0.2032, 0.7187]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4981, grad_fn=<NllLossBackward>)\n","epoch 478, loss 0.49810704588890076\n","outputs:  tensor([[0.3208, 0.5531],\n","        [0.7497, 0.3373],\n","        [0.7433, 0.3446],\n","        [0.8937, 0.2309],\n","        [0.2025, 0.7194]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4977, grad_fn=<NllLossBackward>)\n","epoch 479, loss 0.49773818254470825\n","outputs:  tensor([[0.3203, 0.5536],\n","        [0.7501, 0.3370],\n","        [0.7436, 0.3442],\n","        [0.8941, 0.2303],\n","        [0.2018, 0.7202]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4974, grad_fn=<NllLossBackward>)\n","epoch 480, loss 0.49736976623535156\n","outputs:  tensor([[0.3198, 0.5541],\n","        [0.7504, 0.3366],\n","        [0.7439, 0.3439],\n","        [0.8945, 0.2297],\n","        [0.2011, 0.7209]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4970, grad_fn=<NllLossBackward>)\n","epoch 481, loss 0.4970018267631531\n","outputs:  tensor([[0.3193, 0.5545],\n","        [0.7508, 0.3362],\n","        [0.7443, 0.3435],\n","        [0.8948, 0.2291],\n","        [0.2004, 0.7216]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4966, grad_fn=<NllLossBackward>)\n","epoch 482, loss 0.4966343343257904\n","outputs:  tensor([[0.3188, 0.5550],\n","        [0.7511, 0.3359],\n","        [0.7446, 0.3432],\n","        [0.8952, 0.2285],\n","        [0.1997, 0.7223]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4963, grad_fn=<NllLossBackward>)\n","epoch 483, loss 0.4962674081325531\n","outputs:  tensor([[0.3183, 0.5555],\n","        [0.7515, 0.3355],\n","        [0.7449, 0.3429],\n","        [0.8955, 0.2279],\n","        [0.1990, 0.7231]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4959, grad_fn=<NllLossBackward>)\n","epoch 484, loss 0.4959009289741516\n","outputs:  tensor([[0.3178, 0.5560],\n","        [0.7518, 0.3351],\n","        [0.7453, 0.3425],\n","        [0.8959, 0.2273],\n","        [0.1983, 0.7238]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4955, grad_fn=<NllLossBackward>)\n","epoch 485, loss 0.4955349564552307\n","outputs:  tensor([[0.3173, 0.5565],\n","        [0.7522, 0.3348],\n","        [0.7456, 0.3422],\n","        [0.8962, 0.2267],\n","        [0.1977, 0.7245]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4952, grad_fn=<NllLossBackward>)\n","epoch 486, loss 0.4951695501804352\n","outputs:  tensor([[0.3168, 0.5569],\n","        [0.7525, 0.3344],\n","        [0.7459, 0.3418],\n","        [0.8966, 0.2261],\n","        [0.1970, 0.7252]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4948, grad_fn=<NllLossBackward>)\n","epoch 487, loss 0.4948044717311859\n","outputs:  tensor([[0.3163, 0.5574],\n","        [0.7529, 0.3340],\n","        [0.7462, 0.3415],\n","        [0.8969, 0.2255],\n","        [0.1963, 0.7260]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4944, grad_fn=<NllLossBackward>)\n","epoch 488, loss 0.49444007873535156\n","outputs:  tensor([[0.3158, 0.5579],\n","        [0.7532, 0.3337],\n","        [0.7466, 0.3411],\n","        [0.8973, 0.2249],\n","        [0.1956, 0.7267]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4941, grad_fn=<NllLossBackward>)\n","epoch 489, loss 0.49407610297203064\n","outputs:  tensor([[0.3153, 0.5584],\n","        [0.7536, 0.3333],\n","        [0.7469, 0.3408],\n","        [0.8976, 0.2243],\n","        [0.1950, 0.7274]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4937, grad_fn=<NllLossBackward>)\n","epoch 490, loss 0.49371272325515747\n","outputs:  tensor([[0.3149, 0.5589],\n","        [0.7539, 0.3329],\n","        [0.7472, 0.3405],\n","        [0.8980, 0.2237],\n","        [0.1943, 0.7281]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4933, grad_fn=<NllLossBackward>)\n","epoch 491, loss 0.4933496415615082\n","outputs:  tensor([[0.3144, 0.5594],\n","        [0.7543, 0.3326],\n","        [0.7475, 0.3401],\n","        [0.8983, 0.2231],\n","        [0.1936, 0.7289]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4930, grad_fn=<NllLossBackward>)\n","epoch 492, loss 0.4929872453212738\n","outputs:  tensor([[0.3139, 0.5599],\n","        [0.7546, 0.3322],\n","        [0.7479, 0.3398],\n","        [0.8986, 0.2225],\n","        [0.1930, 0.7296]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4926, grad_fn=<NllLossBackward>)\n","epoch 493, loss 0.49262532591819763\n","outputs:  tensor([[0.3134, 0.5603],\n","        [0.7549, 0.3318],\n","        [0.7482, 0.3394],\n","        [0.8990, 0.2219],\n","        [0.1923, 0.7303]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4923, grad_fn=<NllLossBackward>)\n","epoch 494, loss 0.4922639727592468\n","outputs:  tensor([[0.3129, 0.5608],\n","        [0.7553, 0.3315],\n","        [0.7485, 0.3391],\n","        [0.8993, 0.2213],\n","        [0.1916, 0.7310]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4919, grad_fn=<NllLossBackward>)\n","epoch 495, loss 0.49190300703048706\n","outputs:  tensor([[0.3124, 0.5613],\n","        [0.7556, 0.3311],\n","        [0.7488, 0.3387],\n","        [0.8997, 0.2207],\n","        [0.1910, 0.7318]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4915, grad_fn=<NllLossBackward>)\n","epoch 496, loss 0.49154266715049744\n","outputs:  tensor([[0.3119, 0.5618],\n","        [0.7560, 0.3307],\n","        [0.7492, 0.3384],\n","        [0.9000, 0.2201],\n","        [0.1903, 0.7325]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4912, grad_fn=<NllLossBackward>)\n","epoch 497, loss 0.491182804107666\n","outputs:  tensor([[0.3114, 0.5623],\n","        [0.7563, 0.3304],\n","        [0.7495, 0.3380],\n","        [0.9003, 0.2195],\n","        [0.1897, 0.7332]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4908, grad_fn=<NllLossBackward>)\n","epoch 498, loss 0.49082350730895996\n","outputs:  tensor([[0.3109, 0.5628],\n","        [0.7567, 0.3300],\n","        [0.7498, 0.3377],\n","        [0.9007, 0.2189],\n","        [0.1890, 0.7339]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4905, grad_fn=<NllLossBackward>)\n","epoch 499, loss 0.4904646873474121\n","outputs:  tensor([[0.3104, 0.5633],\n","        [0.7570, 0.3296],\n","        [0.7501, 0.3374],\n","        [0.9010, 0.2184],\n","        [0.1883, 0.7346]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4901, grad_fn=<NllLossBackward>)\n","epoch 500, loss 0.49010640382766724\n","outputs:  tensor([[0.3099, 0.5638],\n","        [0.7574, 0.3293],\n","        [0.7505, 0.3370],\n","        [0.9013, 0.2178],\n","        [0.1877, 0.7354]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4897, grad_fn=<NllLossBackward>)\n","epoch 501, loss 0.4897487759590149\n","Parameter containing:\n","tensor([[-0.1017, -0.3830,  0.2119],\n","        [-0.6563, -0.2269, -0.0481],\n","        [-0.6692, -0.3821, -0.0949],\n","        [-0.3218, -0.2813,  0.0053]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4461, -0.3949,  0.0533,  0.0833], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.6315,  0.4324,  0.7253, -0.0860],\n","        [ 0.1298, -0.5138, -0.2378, -0.2729]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2949, -0.5032], requires_grad=True)\n","outputs:  tensor([[0.3094, 0.5643],\n","        [0.7577, 0.3289],\n","        [0.7508, 0.3367],\n","        [0.9017, 0.2172],\n","        [0.1870, 0.7361]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4894, grad_fn=<NllLossBackward>)\n","epoch 502, loss 0.4893915057182312\n","outputs:  tensor([[0.3089, 0.5647],\n","        [0.7581, 0.3285],\n","        [0.7511, 0.3363],\n","        [0.9020, 0.2166],\n","        [0.1864, 0.7368]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4890, grad_fn=<NllLossBackward>)\n","epoch 503, loss 0.48903483152389526\n","outputs:  tensor([[0.3084, 0.5652],\n","        [0.7584, 0.3282],\n","        [0.7514, 0.3360],\n","        [0.9024, 0.2160],\n","        [0.1857, 0.7375]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4887, grad_fn=<NllLossBackward>)\n","epoch 504, loss 0.4886786937713623\n","outputs:  tensor([[0.3080, 0.5657],\n","        [0.7588, 0.3278],\n","        [0.7517, 0.3356],\n","        [0.9027, 0.2154],\n","        [0.1851, 0.7382]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4883, grad_fn=<NllLossBackward>)\n","epoch 505, loss 0.4883231222629547\n","outputs:  tensor([[0.3075, 0.5662],\n","        [0.7591, 0.3274],\n","        [0.7521, 0.3353],\n","        [0.9030, 0.2148],\n","        [0.1845, 0.7389]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4880, grad_fn=<NllLossBackward>)\n","epoch 506, loss 0.4879680573940277\n","outputs:  tensor([[0.3070, 0.5667],\n","        [0.7594, 0.3271],\n","        [0.7524, 0.3349],\n","        [0.9033, 0.2142],\n","        [0.1838, 0.7397]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4876, grad_fn=<NllLossBackward>)\n","epoch 507, loss 0.48761358857154846\n","outputs:  tensor([[0.3065, 0.5672],\n","        [0.7598, 0.3267],\n","        [0.7527, 0.3346],\n","        [0.9037, 0.2137],\n","        [0.1832, 0.7404]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4873, grad_fn=<NllLossBackward>)\n","epoch 508, loss 0.48725956678390503\n","outputs:  tensor([[0.3060, 0.5677],\n","        [0.7601, 0.3263],\n","        [0.7530, 0.3342],\n","        [0.9040, 0.2131],\n","        [0.1825, 0.7411]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4869, grad_fn=<NllLossBackward>)\n","epoch 509, loss 0.4869062006473541\n","outputs:  tensor([[0.3055, 0.5682],\n","        [0.7605, 0.3260],\n","        [0.7534, 0.3339],\n","        [0.9043, 0.2125],\n","        [0.1819, 0.7418]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4866, grad_fn=<NllLossBackward>)\n","epoch 510, loss 0.4865533411502838\n","outputs:  tensor([[0.3050, 0.5687],\n","        [0.7608, 0.3256],\n","        [0.7537, 0.3335],\n","        [0.9047, 0.2119],\n","        [0.1813, 0.7425]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4862, grad_fn=<NllLossBackward>)\n","epoch 511, loss 0.4862009882926941\n","outputs:  tensor([[0.3045, 0.5692],\n","        [0.7612, 0.3252],\n","        [0.7540, 0.3332],\n","        [0.9050, 0.2113],\n","        [0.1806, 0.7432]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4858, grad_fn=<NllLossBackward>)\n","epoch 512, loss 0.48584920167922974\n","outputs:  tensor([[0.3040, 0.5697],\n","        [0.7615, 0.3249],\n","        [0.7543, 0.3329],\n","        [0.9053, 0.2108],\n","        [0.1800, 0.7439]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4855, grad_fn=<NllLossBackward>)\n","epoch 513, loss 0.48549801111221313\n","outputs:  tensor([[0.3036, 0.5702],\n","        [0.7618, 0.3245],\n","        [0.7546, 0.3325],\n","        [0.9056, 0.2102],\n","        [0.1794, 0.7446]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4851, grad_fn=<NllLossBackward>)\n","epoch 514, loss 0.4851473867893219\n","outputs:  tensor([[0.3031, 0.5706],\n","        [0.7622, 0.3241],\n","        [0.7550, 0.3322],\n","        [0.9059, 0.2096],\n","        [0.1788, 0.7453]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4848, grad_fn=<NllLossBackward>)\n","epoch 515, loss 0.48479723930358887\n","outputs:  tensor([[0.3026, 0.5711],\n","        [0.7625, 0.3238],\n","        [0.7553, 0.3318],\n","        [0.9063, 0.2090],\n","        [0.1781, 0.7461]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4844, grad_fn=<NllLossBackward>)\n","epoch 516, loss 0.484447717666626\n","outputs:  tensor([[0.3021, 0.5716],\n","        [0.7629, 0.3234],\n","        [0.7556, 0.3315],\n","        [0.9066, 0.2084],\n","        [0.1775, 0.7468]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4841, grad_fn=<NllLossBackward>)\n","epoch 517, loss 0.48409873247146606\n","outputs:  tensor([[0.3016, 0.5721],\n","        [0.7632, 0.3230],\n","        [0.7559, 0.3311],\n","        [0.9069, 0.2079],\n","        [0.1769, 0.7475]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4838, grad_fn=<NllLossBackward>)\n","epoch 518, loss 0.4837503433227539\n","outputs:  tensor([[0.3011, 0.5726],\n","        [0.7635, 0.3227],\n","        [0.7562, 0.3308],\n","        [0.9072, 0.2073],\n","        [0.1763, 0.7482]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4834, grad_fn=<NllLossBackward>)\n","epoch 519, loss 0.4834025502204895\n","outputs:  tensor([[0.3007, 0.5731],\n","        [0.7639, 0.3223],\n","        [0.7566, 0.3304],\n","        [0.9075, 0.2067],\n","        [0.1757, 0.7489]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4831, grad_fn=<NllLossBackward>)\n","epoch 520, loss 0.48305511474609375\n","outputs:  tensor([[0.3002, 0.5736],\n","        [0.7642, 0.3219],\n","        [0.7569, 0.3301],\n","        [0.9079, 0.2061],\n","        [0.1750, 0.7496]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4827, grad_fn=<NllLossBackward>)\n","epoch 521, loss 0.4827084541320801\n","outputs:  tensor([[0.2997, 0.5741],\n","        [0.7646, 0.3215],\n","        [0.7572, 0.3297],\n","        [0.9082, 0.2056],\n","        [0.1744, 0.7503]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4824, grad_fn=<NllLossBackward>)\n","epoch 522, loss 0.4823622703552246\n","outputs:  tensor([[0.2992, 0.5746],\n","        [0.7649, 0.3212],\n","        [0.7575, 0.3294],\n","        [0.9085, 0.2050],\n","        [0.1738, 0.7510]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4820, grad_fn=<NllLossBackward>)\n","epoch 523, loss 0.4820167124271393\n","outputs:  tensor([[0.2987, 0.5751],\n","        [0.7652, 0.3208],\n","        [0.7578, 0.3290],\n","        [0.9088, 0.2044],\n","        [0.1732, 0.7517]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4817, grad_fn=<NllLossBackward>)\n","epoch 524, loss 0.48167166113853455\n","outputs:  tensor([[0.2982, 0.5756],\n","        [0.7656, 0.3204],\n","        [0.7582, 0.3287],\n","        [0.9091, 0.2039],\n","        [0.1726, 0.7524]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4813, grad_fn=<NllLossBackward>)\n","epoch 525, loss 0.48132723569869995\n","outputs:  tensor([[0.2978, 0.5761],\n","        [0.7659, 0.3201],\n","        [0.7585, 0.3283],\n","        [0.9094, 0.2033],\n","        [0.1720, 0.7531]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4810, grad_fn=<NllLossBackward>)\n","epoch 526, loss 0.48098334670066833\n","outputs:  tensor([[0.2973, 0.5766],\n","        [0.7663, 0.3197],\n","        [0.7588, 0.3280],\n","        [0.9097, 0.2027],\n","        [0.1714, 0.7538]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4806, grad_fn=<NllLossBackward>)\n","epoch 527, loss 0.48064008355140686\n","outputs:  tensor([[0.2968, 0.5771],\n","        [0.7666, 0.3193],\n","        [0.7591, 0.3276],\n","        [0.9100, 0.2021],\n","        [0.1708, 0.7545]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4803, grad_fn=<NllLossBackward>)\n","epoch 528, loss 0.48029738664627075\n","outputs:  tensor([[0.2963, 0.5776],\n","        [0.7669, 0.3190],\n","        [0.7594, 0.3273],\n","        [0.9103, 0.2016],\n","        [0.1702, 0.7552]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4800, grad_fn=<NllLossBackward>)\n","epoch 529, loss 0.47995519638061523\n","outputs:  tensor([[0.2958, 0.5781],\n","        [0.7673, 0.3186],\n","        [0.7597, 0.3269],\n","        [0.9107, 0.2010],\n","        [0.1696, 0.7559]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4796, grad_fn=<NllLossBackward>)\n","epoch 530, loss 0.47961369156837463\n","outputs:  tensor([[0.2954, 0.5786],\n","        [0.7676, 0.3182],\n","        [0.7601, 0.3266],\n","        [0.9110, 0.2004],\n","        [0.1690, 0.7566]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4793, grad_fn=<NllLossBackward>)\n","epoch 531, loss 0.47927266359329224\n","outputs:  tensor([[0.2949, 0.5791],\n","        [0.7679, 0.3179],\n","        [0.7604, 0.3262],\n","        [0.9113, 0.1999],\n","        [0.1684, 0.7573]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4789, grad_fn=<NllLossBackward>)\n","epoch 532, loss 0.47893232107162476\n","outputs:  tensor([[0.2944, 0.5796],\n","        [0.7683, 0.3175],\n","        [0.7607, 0.3259],\n","        [0.9116, 0.1993],\n","        [0.1678, 0.7579]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4786, grad_fn=<NllLossBackward>)\n","epoch 533, loss 0.47859248518943787\n","outputs:  tensor([[0.2939, 0.5801],\n","        [0.7686, 0.3171],\n","        [0.7610, 0.3255],\n","        [0.9119, 0.1988],\n","        [0.1672, 0.7586]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4783, grad_fn=<NllLossBackward>)\n","epoch 534, loss 0.4782532751560211\n","outputs:  tensor([[0.2935, 0.5806],\n","        [0.7690, 0.3167],\n","        [0.7613, 0.3252],\n","        [0.9122, 0.1982],\n","        [0.1666, 0.7593]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4779, grad_fn=<NllLossBackward>)\n","epoch 535, loss 0.4779146611690521\n","outputs:  tensor([[0.2930, 0.5811],\n","        [0.7693, 0.3164],\n","        [0.7616, 0.3249],\n","        [0.9125, 0.1976],\n","        [0.1661, 0.7600]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4776, grad_fn=<NllLossBackward>)\n","epoch 536, loss 0.4775766432285309\n","outputs:  tensor([[0.2925, 0.5816],\n","        [0.7696, 0.3160],\n","        [0.7620, 0.3245],\n","        [0.9128, 0.1971],\n","        [0.1655, 0.7607]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4772, grad_fn=<NllLossBackward>)\n","epoch 537, loss 0.47723913192749023\n","outputs:  tensor([[0.2920, 0.5821],\n","        [0.7700, 0.3156],\n","        [0.7623, 0.3242],\n","        [0.9131, 0.1965],\n","        [0.1649, 0.7614]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4769, grad_fn=<NllLossBackward>)\n","epoch 538, loss 0.4769023060798645\n","outputs:  tensor([[0.2916, 0.5826],\n","        [0.7703, 0.3153],\n","        [0.7626, 0.3238],\n","        [0.9134, 0.1960],\n","        [0.1643, 0.7621]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4766, grad_fn=<NllLossBackward>)\n","epoch 539, loss 0.47656598687171936\n","outputs:  tensor([[0.2911, 0.5831],\n","        [0.7706, 0.3149],\n","        [0.7629, 0.3235],\n","        [0.9137, 0.1954],\n","        [0.1637, 0.7628]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4762, grad_fn=<NllLossBackward>)\n","epoch 540, loss 0.47623029351234436\n","outputs:  tensor([[0.2906, 0.5836],\n","        [0.7710, 0.3145],\n","        [0.7632, 0.3231],\n","        [0.9140, 0.1948],\n","        [0.1632, 0.7635]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4759, grad_fn=<NllLossBackward>)\n","epoch 541, loss 0.4758952260017395\n","outputs:  tensor([[0.2901, 0.5841],\n","        [0.7713, 0.3142],\n","        [0.7635, 0.3228],\n","        [0.9143, 0.1943],\n","        [0.1626, 0.7641]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4756, grad_fn=<NllLossBackward>)\n","epoch 542, loss 0.4755607545375824\n","outputs:  tensor([[0.2897, 0.5846],\n","        [0.7716, 0.3138],\n","        [0.7638, 0.3224],\n","        [0.9146, 0.1937],\n","        [0.1620, 0.7648]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4752, grad_fn=<NllLossBackward>)\n","epoch 543, loss 0.47522681951522827\n","outputs:  tensor([[0.2892, 0.5851],\n","        [0.7720, 0.3134],\n","        [0.7642, 0.3221],\n","        [0.9149, 0.1932],\n","        [0.1614, 0.7655]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4749, grad_fn=<NllLossBackward>)\n","epoch 544, loss 0.4748935103416443\n","outputs:  tensor([[0.2887, 0.5856],\n","        [0.7723, 0.3130],\n","        [0.7645, 0.3217],\n","        [0.9152, 0.1926],\n","        [0.1609, 0.7662]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4746, grad_fn=<NllLossBackward>)\n","epoch 545, loss 0.4745608866214752\n","outputs:  tensor([[0.2883, 0.5861],\n","        [0.7726, 0.3127],\n","        [0.7648, 0.3214],\n","        [0.9154, 0.1921],\n","        [0.1603, 0.7669]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4742, grad_fn=<NllLossBackward>)\n","epoch 546, loss 0.4742286801338196\n","outputs:  tensor([[0.2878, 0.5866],\n","        [0.7730, 0.3123],\n","        [0.7651, 0.3210],\n","        [0.9157, 0.1915],\n","        [0.1597, 0.7675]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4739, grad_fn=<NllLossBackward>)\n","epoch 547, loss 0.47389721870422363\n","outputs:  tensor([[0.2873, 0.5871],\n","        [0.7733, 0.3119],\n","        [0.7654, 0.3207],\n","        [0.9160, 0.1910],\n","        [0.1592, 0.7682]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4736, grad_fn=<NllLossBackward>)\n","epoch 548, loss 0.47356635332107544\n","outputs:  tensor([[0.2868, 0.5876],\n","        [0.7736, 0.3116],\n","        [0.7657, 0.3203],\n","        [0.9163, 0.1904],\n","        [0.1586, 0.7689]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4732, grad_fn=<NllLossBackward>)\n","epoch 549, loss 0.47323599457740784\n","outputs:  tensor([[0.2864, 0.5881],\n","        [0.7739, 0.3112],\n","        [0.7660, 0.3200],\n","        [0.9166, 0.1899],\n","        [0.1581, 0.7696]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4729, grad_fn=<NllLossBackward>)\n","epoch 550, loss 0.47290629148483276\n","outputs:  tensor([[0.2859, 0.5886],\n","        [0.7743, 0.3108],\n","        [0.7663, 0.3196],\n","        [0.9169, 0.1893],\n","        [0.1575, 0.7702]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4726, grad_fn=<NllLossBackward>)\n","epoch 551, loss 0.4725772440433502\n","Parameter containing:\n","tensor([[-0.1124, -0.3972,  0.2096],\n","        [-0.6825, -0.2600, -0.0532],\n","        [-0.6938, -0.4136, -0.0998],\n","        [-0.3287, -0.2898,  0.0040]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4472, -0.3908,  0.0567,  0.0846], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.6457,  0.4538,  0.7529, -0.0700],\n","        [ 0.1105, -0.5418, -0.2747, -0.2941]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2978, -0.5086], requires_grad=True)\n","outputs:  tensor([[0.2854, 0.5891],\n","        [0.7746, 0.3105],\n","        [0.7667, 0.3193],\n","        [0.9172, 0.1888],\n","        [0.1569, 0.7709]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4722, grad_fn=<NllLossBackward>)\n","epoch 552, loss 0.47224873304367065\n","outputs:  tensor([[0.2850, 0.5896],\n","        [0.7749, 0.3101],\n","        [0.7670, 0.3189],\n","        [0.9175, 0.1882],\n","        [0.1564, 0.7716]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4719, grad_fn=<NllLossBackward>)\n","epoch 553, loss 0.4719208776950836\n","outputs:  tensor([[0.2845, 0.5901],\n","        [0.7753, 0.3097],\n","        [0.7673, 0.3186],\n","        [0.9178, 0.1877],\n","        [0.1558, 0.7723]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4716, grad_fn=<NllLossBackward>)\n","epoch 554, loss 0.47159361839294434\n","outputs:  tensor([[0.2840, 0.5906],\n","        [0.7756, 0.3093],\n","        [0.7676, 0.3182],\n","        [0.9180, 0.1871],\n","        [0.1553, 0.7729]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4713, grad_fn=<NllLossBackward>)\n","epoch 555, loss 0.47126689553260803\n","outputs:  tensor([[0.2836, 0.5911],\n","        [0.7759, 0.3090],\n","        [0.7679, 0.3179],\n","        [0.9183, 0.1866],\n","        [0.1547, 0.7736]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4709, grad_fn=<NllLossBackward>)\n","epoch 556, loss 0.47094088792800903\n","outputs:  tensor([[0.2831, 0.5916],\n","        [0.7763, 0.3086],\n","        [0.7682, 0.3175],\n","        [0.9186, 0.1861],\n","        [0.1542, 0.7743]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4706, grad_fn=<NllLossBackward>)\n","epoch 557, loss 0.4706154465675354\n","outputs:  tensor([[0.2826, 0.5921],\n","        [0.7766, 0.3082],\n","        [0.7685, 0.3172],\n","        [0.9189, 0.1855],\n","        [0.1536, 0.7749]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4703, grad_fn=<NllLossBackward>)\n","epoch 558, loss 0.4702906012535095\n","outputs:  tensor([[0.2822, 0.5926],\n","        [0.7769, 0.3079],\n","        [0.7688, 0.3168],\n","        [0.9192, 0.1850],\n","        [0.1531, 0.7756]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4700, grad_fn=<NllLossBackward>)\n","epoch 559, loss 0.46996641159057617\n","outputs:  tensor([[0.2817, 0.5931],\n","        [0.7772, 0.3075],\n","        [0.7691, 0.3165],\n","        [0.9194, 0.1844],\n","        [0.1526, 0.7763]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4696, grad_fn=<NllLossBackward>)\n","epoch 560, loss 0.4696427881717682\n","outputs:  tensor([[0.2813, 0.5936],\n","        [0.7776, 0.3071],\n","        [0.7694, 0.3161],\n","        [0.9197, 0.1839],\n","        [0.1520, 0.7769]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4693, grad_fn=<NllLossBackward>)\n","epoch 561, loss 0.46931976079940796\n","outputs:  tensor([[0.2808, 0.5941],\n","        [0.7779, 0.3068],\n","        [0.7698, 0.3158],\n","        [0.9200, 0.1834],\n","        [0.1515, 0.7776]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4690, grad_fn=<NllLossBackward>)\n","epoch 562, loss 0.46899738907814026\n","outputs:  tensor([[0.2803, 0.5946],\n","        [0.7782, 0.3064],\n","        [0.7701, 0.3154],\n","        [0.9203, 0.1828],\n","        [0.1509, 0.7782]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4687, grad_fn=<NllLossBackward>)\n","epoch 563, loss 0.4686756134033203\n","outputs:  tensor([[0.2799, 0.5951],\n","        [0.7785, 0.3060],\n","        [0.7704, 0.3151],\n","        [0.9205, 0.1823],\n","        [0.1504, 0.7789]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4684, grad_fn=<NllLossBackward>)\n","epoch 564, loss 0.4683545231819153\n","outputs:  tensor([[0.2794, 0.5956],\n","        [0.7789, 0.3056],\n","        [0.7707, 0.3147],\n","        [0.9208, 0.1818],\n","        [0.1499, 0.7796]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4680, grad_fn=<NllLossBackward>)\n","epoch 565, loss 0.46803387999534607\n","outputs:  tensor([[0.2790, 0.5961],\n","        [0.7792, 0.3053],\n","        [0.7710, 0.3144],\n","        [0.9211, 0.1812],\n","        [0.1494, 0.7802]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4677, grad_fn=<NllLossBackward>)\n","epoch 566, loss 0.46771401166915894\n","outputs:  tensor([[0.2785, 0.5966],\n","        [0.7795, 0.3049],\n","        [0.7713, 0.3140],\n","        [0.9214, 0.1807],\n","        [0.1488, 0.7809]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4674, grad_fn=<NllLossBackward>)\n","epoch 567, loss 0.4673946797847748\n","outputs:  tensor([[0.2780, 0.5971],\n","        [0.7798, 0.3045],\n","        [0.7716, 0.3137],\n","        [0.9216, 0.1802],\n","        [0.1483, 0.7815]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4671, grad_fn=<NllLossBackward>)\n","epoch 568, loss 0.46707600355148315\n","outputs:  tensor([[0.2776, 0.5976],\n","        [0.7802, 0.3042],\n","        [0.7719, 0.3133],\n","        [0.9219, 0.1796],\n","        [0.1478, 0.7822]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4668, grad_fn=<NllLossBackward>)\n","epoch 569, loss 0.4667579233646393\n","outputs:  tensor([[0.2771, 0.5981],\n","        [0.7805, 0.3038],\n","        [0.7722, 0.3130],\n","        [0.9222, 0.1791],\n","        [0.1473, 0.7828]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4664, grad_fn=<NllLossBackward>)\n","epoch 570, loss 0.46644049882888794\n","outputs:  tensor([[0.2767, 0.5986],\n","        [0.7808, 0.3034],\n","        [0.7725, 0.3126],\n","        [0.9225, 0.1786],\n","        [0.1467, 0.7835]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4661, grad_fn=<NllLossBackward>)\n","epoch 571, loss 0.4661235809326172\n","outputs:  tensor([[0.2762, 0.5991],\n","        [0.7811, 0.3031],\n","        [0.7728, 0.3123],\n","        [0.9227, 0.1780],\n","        [0.1462, 0.7841]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4658, grad_fn=<NllLossBackward>)\n","epoch 572, loss 0.46580737829208374\n","outputs:  tensor([[0.2757, 0.5996],\n","        [0.7815, 0.3027],\n","        [0.7731, 0.3119],\n","        [0.9230, 0.1775],\n","        [0.1457, 0.7848]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4655, grad_fn=<NllLossBackward>)\n","epoch 573, loss 0.46549177169799805\n","outputs:  tensor([[0.2753, 0.6001],\n","        [0.7818, 0.3023],\n","        [0.7734, 0.3116],\n","        [0.9233, 0.1770],\n","        [0.1452, 0.7854]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4652, grad_fn=<NllLossBackward>)\n","epoch 574, loss 0.46517688035964966\n","outputs:  tensor([[0.2748, 0.6006],\n","        [0.7821, 0.3020],\n","        [0.7737, 0.3112],\n","        [0.9235, 0.1765],\n","        [0.1447, 0.7861]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4649, grad_fn=<NllLossBackward>)\n","epoch 575, loss 0.4648624360561371\n","outputs:  tensor([[0.2744, 0.6011],\n","        [0.7824, 0.3016],\n","        [0.7740, 0.3109],\n","        [0.9238, 0.1759],\n","        [0.1442, 0.7867]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4645, grad_fn=<NllLossBackward>)\n","epoch 576, loss 0.4645487666130066\n","outputs:  tensor([[0.2739, 0.6016],\n","        [0.7827, 0.3012],\n","        [0.7743, 0.3105],\n","        [0.9240, 0.1754],\n","        [0.1436, 0.7873]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4642, grad_fn=<NllLossBackward>)\n","epoch 577, loss 0.4642356336116791\n","outputs:  tensor([[0.2735, 0.6022],\n","        [0.7831, 0.3009],\n","        [0.7746, 0.3102],\n","        [0.9243, 0.1749],\n","        [0.1431, 0.7880]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4639, grad_fn=<NllLossBackward>)\n","epoch 578, loss 0.4639231562614441\n","outputs:  tensor([[0.2730, 0.6027],\n","        [0.7834, 0.3005],\n","        [0.7749, 0.3099],\n","        [0.9246, 0.1744],\n","        [0.1426, 0.7886]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4636, grad_fn=<NllLossBackward>)\n","epoch 579, loss 0.46361130475997925\n","outputs:  tensor([[0.2726, 0.6032],\n","        [0.7837, 0.3001],\n","        [0.7753, 0.3095],\n","        [0.9248, 0.1739],\n","        [0.1421, 0.7893]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4633, grad_fn=<NllLossBackward>)\n","epoch 580, loss 0.46330007910728455\n","outputs:  tensor([[0.2721, 0.6037],\n","        [0.7840, 0.2997],\n","        [0.7756, 0.3092],\n","        [0.9251, 0.1733],\n","        [0.1416, 0.7899]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4630, grad_fn=<NllLossBackward>)\n","epoch 581, loss 0.4629895091056824\n","outputs:  tensor([[0.2717, 0.6042],\n","        [0.7843, 0.2994],\n","        [0.7759, 0.3088],\n","        [0.9254, 0.1728],\n","        [0.1411, 0.7905]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4627, grad_fn=<NllLossBackward>)\n","epoch 582, loss 0.46267953515052795\n","outputs:  tensor([[0.2712, 0.6047],\n","        [0.7847, 0.2990],\n","        [0.7762, 0.3085],\n","        [0.9256, 0.1723],\n","        [0.1406, 0.7912]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4624, grad_fn=<NllLossBackward>)\n","epoch 583, loss 0.4623700976371765\n","outputs:  tensor([[0.2708, 0.6052],\n","        [0.7850, 0.2986],\n","        [0.7765, 0.3081],\n","        [0.9259, 0.1718],\n","        [0.1401, 0.7918]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4621, grad_fn=<NllLossBackward>)\n","epoch 584, loss 0.46206134557724\n","outputs:  tensor([[0.2703, 0.6057],\n","        [0.7853, 0.2983],\n","        [0.7768, 0.3078],\n","        [0.9261, 0.1713],\n","        [0.1396, 0.7924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4618, grad_fn=<NllLossBackward>)\n","epoch 585, loss 0.4617532789707184\n","outputs:  tensor([[0.2699, 0.6062],\n","        [0.7856, 0.2979],\n","        [0.7771, 0.3074],\n","        [0.9264, 0.1708],\n","        [0.1391, 0.7931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4614, grad_fn=<NllLossBackward>)\n","epoch 586, loss 0.46144574880599976\n","outputs:  tensor([[0.2694, 0.6067],\n","        [0.7859, 0.2975],\n","        [0.7774, 0.3071],\n","        [0.9266, 0.1703],\n","        [0.1386, 0.7937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4611, grad_fn=<NllLossBackward>)\n","epoch 587, loss 0.46113890409469604\n","outputs:  tensor([[0.2690, 0.6072],\n","        [0.7862, 0.2972],\n","        [0.7777, 0.3067],\n","        [0.9269, 0.1698],\n","        [0.1381, 0.7943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4608, grad_fn=<NllLossBackward>)\n","epoch 588, loss 0.4608326852321625\n","outputs:  tensor([[0.2685, 0.6077],\n","        [0.7866, 0.2968],\n","        [0.7780, 0.3064],\n","        [0.9271, 0.1692],\n","        [0.1377, 0.7950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4605, grad_fn=<NllLossBackward>)\n","epoch 589, loss 0.46052709221839905\n","outputs:  tensor([[0.2681, 0.6082],\n","        [0.7869, 0.2964],\n","        [0.7783, 0.3060],\n","        [0.9274, 0.1687],\n","        [0.1372, 0.7956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4602, grad_fn=<NllLossBackward>)\n","epoch 590, loss 0.460222065448761\n","outputs:  tensor([[0.2676, 0.6087],\n","        [0.7872, 0.2961],\n","        [0.7786, 0.3057],\n","        [0.9277, 0.1682],\n","        [0.1367, 0.7962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4599, grad_fn=<NllLossBackward>)\n","epoch 591, loss 0.45991769433021545\n","outputs:  tensor([[0.2672, 0.6092],\n","        [0.7875, 0.2957],\n","        [0.7789, 0.3053],\n","        [0.9279, 0.1677],\n","        [0.1362, 0.7968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4596, grad_fn=<NllLossBackward>)\n","epoch 592, loss 0.45961397886276245\n","outputs:  tensor([[0.2668, 0.6097],\n","        [0.7878, 0.2953],\n","        [0.7792, 0.3050],\n","        [0.9282, 0.1672],\n","        [0.1357, 0.7975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4593, grad_fn=<NllLossBackward>)\n","epoch 593, loss 0.4593108296394348\n","outputs:  tensor([[0.2663, 0.6102],\n","        [0.7881, 0.2950],\n","        [0.7795, 0.3046],\n","        [0.9284, 0.1667],\n","        [0.1352, 0.7981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4590, grad_fn=<NllLossBackward>)\n","epoch 594, loss 0.4590083956718445\n","outputs:  tensor([[0.2659, 0.6107],\n","        [0.7885, 0.2946],\n","        [0.7798, 0.3043],\n","        [0.9286, 0.1662],\n","        [0.1348, 0.7987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4587, grad_fn=<NllLossBackward>)\n","epoch 595, loss 0.4587065577507019\n","outputs:  tensor([[0.2654, 0.6112],\n","        [0.7888, 0.2942],\n","        [0.7801, 0.3039],\n","        [0.9289, 0.1657],\n","        [0.1343, 0.7993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4584, grad_fn=<NllLossBackward>)\n","epoch 596, loss 0.45840540528297424\n","outputs:  tensor([[0.2650, 0.6117],\n","        [0.7891, 0.2939],\n","        [0.7804, 0.3036],\n","        [0.9291, 0.1652],\n","        [0.1338, 0.7999]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4581, grad_fn=<NllLossBackward>)\n","epoch 597, loss 0.4581047594547272\n","outputs:  tensor([[0.2646, 0.6122],\n","        [0.7894, 0.2935],\n","        [0.7806, 0.3033],\n","        [0.9294, 0.1647],\n","        [0.1333, 0.8005]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4578, grad_fn=<NllLossBackward>)\n","epoch 598, loss 0.45780473947525024\n","outputs:  tensor([[0.2641, 0.6127],\n","        [0.7897, 0.2931],\n","        [0.7809, 0.3029],\n","        [0.9296, 0.1642],\n","        [0.1329, 0.8012]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4575, grad_fn=<NllLossBackward>)\n","epoch 599, loss 0.45750540494918823\n","outputs:  tensor([[0.2637, 0.6132],\n","        [0.7900, 0.2928],\n","        [0.7812, 0.3026],\n","        [0.9299, 0.1637],\n","        [0.1324, 0.8018]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4572, grad_fn=<NllLossBackward>)\n","epoch 600, loss 0.45720672607421875\n","outputs:  tensor([[0.2632, 0.6137],\n","        [0.7903, 0.2924],\n","        [0.7815, 0.3022],\n","        [0.9301, 0.1632],\n","        [0.1319, 0.8024]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4569, grad_fn=<NllLossBackward>)\n","epoch 601, loss 0.45690861344337463\n","Parameter containing:\n","tensor([[-0.1226, -0.4109,  0.2077],\n","        [-0.7072, -0.2916, -0.0575],\n","        [-0.7171, -0.4440, -0.1040],\n","        [-0.3359, -0.2988,  0.0028]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4486, -0.3866,  0.0605,  0.0859], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.6592,  0.4740,  0.7788, -0.0554],\n","        [ 0.0918, -0.5689, -0.3100, -0.3140]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3007, -0.5137], requires_grad=True)\n","outputs:  tensor([[0.2628, 0.6142],\n","        [0.7906, 0.2920],\n","        [0.7818, 0.3019],\n","        [0.9304, 0.1627],\n","        [0.1315, 0.8030]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4566, grad_fn=<NllLossBackward>)\n","epoch 602, loss 0.4566112160682678\n","outputs:  tensor([[0.2624, 0.6147],\n","        [0.7909, 0.2917],\n","        [0.7821, 0.3015],\n","        [0.9306, 0.1622],\n","        [0.1310, 0.8036]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4563, grad_fn=<NllLossBackward>)\n","epoch 603, loss 0.4563143849372864\n","outputs:  tensor([[0.2619, 0.6152],\n","        [0.7913, 0.2913],\n","        [0.7824, 0.3012],\n","        [0.9308, 0.1617],\n","        [0.1305, 0.8042]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4560, grad_fn=<NllLossBackward>)\n","epoch 604, loss 0.45601820945739746\n","outputs:  tensor([[0.2615, 0.6157],\n","        [0.7916, 0.2909],\n","        [0.7827, 0.3008],\n","        [0.9311, 0.1612],\n","        [0.1301, 0.8048]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4557, grad_fn=<NllLossBackward>)\n","epoch 605, loss 0.4557225704193115\n","outputs:  tensor([[0.2610, 0.6162],\n","        [0.7919, 0.2906],\n","        [0.7830, 0.3005],\n","        [0.9313, 0.1608],\n","        [0.1296, 0.8054]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4554, grad_fn=<NllLossBackward>)\n","epoch 606, loss 0.45542773604393005\n","outputs:  tensor([[0.2606, 0.6167],\n","        [0.7922, 0.2902],\n","        [0.7833, 0.3001],\n","        [0.9316, 0.1603],\n","        [0.1291, 0.8060]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4551, grad_fn=<NllLossBackward>)\n","epoch 607, loss 0.4551333785057068\n","outputs:  tensor([[0.2602, 0.6172],\n","        [0.7925, 0.2899],\n","        [0.7836, 0.2998],\n","        [0.9318, 0.1598],\n","        [0.1287, 0.8066]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4548, grad_fn=<NllLossBackward>)\n","epoch 608, loss 0.45483970642089844\n","outputs:  tensor([[0.2597, 0.6177],\n","        [0.7928, 0.2895],\n","        [0.7839, 0.2994],\n","        [0.9320, 0.1593],\n","        [0.1282, 0.8072]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4545, grad_fn=<NllLossBackward>)\n","epoch 609, loss 0.45454660058021545\n","outputs:  tensor([[0.2593, 0.6182],\n","        [0.7931, 0.2891],\n","        [0.7842, 0.2991],\n","        [0.9323, 0.1588],\n","        [0.1278, 0.8078]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4543, grad_fn=<NllLossBackward>)\n","epoch 610, loss 0.4542542099952698\n","outputs:  tensor([[0.2589, 0.6187],\n","        [0.7934, 0.2888],\n","        [0.7845, 0.2988],\n","        [0.9325, 0.1583],\n","        [0.1273, 0.8084]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4540, grad_fn=<NllLossBackward>)\n","epoch 611, loss 0.45396238565444946\n","outputs:  tensor([[0.2584, 0.6192],\n","        [0.7937, 0.2884],\n","        [0.7848, 0.2984],\n","        [0.9327, 0.1578],\n","        [0.1269, 0.8090]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4537, grad_fn=<NllLossBackward>)\n","epoch 612, loss 0.4536711573600769\n","outputs:  tensor([[0.2580, 0.6197],\n","        [0.7940, 0.2880],\n","        [0.7851, 0.2981],\n","        [0.9330, 0.1574],\n","        [0.1264, 0.8096]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4534, grad_fn=<NllLossBackward>)\n","epoch 613, loss 0.45338067412376404\n","outputs:  tensor([[0.2576, 0.6202],\n","        [0.7943, 0.2877],\n","        [0.7854, 0.2977],\n","        [0.9332, 0.1569],\n","        [0.1260, 0.8102]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4531, grad_fn=<NllLossBackward>)\n","epoch 614, loss 0.45309072732925415\n","outputs:  tensor([[0.2572, 0.6207],\n","        [0.7946, 0.2873],\n","        [0.7856, 0.2974],\n","        [0.9334, 0.1564],\n","        [0.1255, 0.8108]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4528, grad_fn=<NllLossBackward>)\n","epoch 615, loss 0.4528014063835144\n","outputs:  tensor([[0.2567, 0.6212],\n","        [0.7949, 0.2869],\n","        [0.7859, 0.2970],\n","        [0.9337, 0.1559],\n","        [0.1251, 0.8114]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4525, grad_fn=<NllLossBackward>)\n","epoch 616, loss 0.45251280069351196\n","outputs:  tensor([[0.2563, 0.6217],\n","        [0.7953, 0.2866],\n","        [0.7862, 0.2967],\n","        [0.9339, 0.1554],\n","        [0.1247, 0.8120]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4522, grad_fn=<NllLossBackward>)\n","epoch 617, loss 0.4522247314453125\n","outputs:  tensor([[0.2559, 0.6222],\n","        [0.7956, 0.2862],\n","        [0.7865, 0.2963],\n","        [0.9341, 0.1550],\n","        [0.1242, 0.8126]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4519, grad_fn=<NllLossBackward>)\n","epoch 618, loss 0.45193734765052795\n","outputs:  tensor([[0.2554, 0.6227],\n","        [0.7959, 0.2859],\n","        [0.7868, 0.2960],\n","        [0.9344, 0.1545],\n","        [0.1238, 0.8132]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4517, grad_fn=<NllLossBackward>)\n","epoch 619, loss 0.45165055990219116\n","outputs:  tensor([[0.2550, 0.6232],\n","        [0.7962, 0.2855],\n","        [0.7871, 0.2957],\n","        [0.9346, 0.1540],\n","        [0.1233, 0.8137]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4514, grad_fn=<NllLossBackward>)\n","epoch 620, loss 0.4513644278049469\n","outputs:  tensor([[0.2546, 0.6237],\n","        [0.7965, 0.2851],\n","        [0.7874, 0.2953],\n","        [0.9348, 0.1535],\n","        [0.1229, 0.8143]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4511, grad_fn=<NllLossBackward>)\n","epoch 621, loss 0.4510788917541504\n","outputs:  tensor([[0.2542, 0.6242],\n","        [0.7968, 0.2848],\n","        [0.7877, 0.2950],\n","        [0.9350, 0.1531],\n","        [0.1225, 0.8149]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4508, grad_fn=<NllLossBackward>)\n","epoch 622, loss 0.450793981552124\n","outputs:  tensor([[0.2537, 0.6247],\n","        [0.7971, 0.2844],\n","        [0.7880, 0.2946],\n","        [0.9353, 0.1526],\n","        [0.1220, 0.8155]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4505, grad_fn=<NllLossBackward>)\n","epoch 623, loss 0.4505097270011902\n","outputs:  tensor([[0.2533, 0.6252],\n","        [0.7974, 0.2840],\n","        [0.7882, 0.2943],\n","        [0.9355, 0.1521],\n","        [0.1216, 0.8161]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4502, grad_fn=<NllLossBackward>)\n","epoch 624, loss 0.4502260088920593\n","outputs:  tensor([[0.2529, 0.6257],\n","        [0.7977, 0.2837],\n","        [0.7885, 0.2939],\n","        [0.9357, 0.1517],\n","        [0.1212, 0.8166]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4499, grad_fn=<NllLossBackward>)\n","epoch 625, loss 0.4499429762363434\n","outputs:  tensor([[0.2525, 0.6262],\n","        [0.7980, 0.2833],\n","        [0.7888, 0.2936],\n","        [0.9359, 0.1512],\n","        [0.1208, 0.8172]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4497, grad_fn=<NllLossBackward>)\n","epoch 626, loss 0.44966062903404236\n","outputs:  tensor([[0.2521, 0.6267],\n","        [0.7983, 0.2830],\n","        [0.7891, 0.2933],\n","        [0.9361, 0.1507],\n","        [0.1203, 0.8178]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4494, grad_fn=<NllLossBackward>)\n","epoch 627, loss 0.4493788182735443\n","outputs:  tensor([[0.2516, 0.6272],\n","        [0.7986, 0.2826],\n","        [0.7894, 0.2929],\n","        [0.9364, 0.1503],\n","        [0.1199, 0.8184]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4491, grad_fn=<NllLossBackward>)\n","epoch 628, loss 0.4490976333618164\n","outputs:  tensor([[0.2512, 0.6277],\n","        [0.7989, 0.2822],\n","        [0.7897, 0.2926],\n","        [0.9366, 0.1498],\n","        [0.1195, 0.8189]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4488, grad_fn=<NllLossBackward>)\n","epoch 629, loss 0.4488171637058258\n","outputs:  tensor([[0.2508, 0.6282],\n","        [0.7992, 0.2819],\n","        [0.7900, 0.2922],\n","        [0.9368, 0.1493],\n","        [0.1191, 0.8195]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4485, grad_fn=<NllLossBackward>)\n","epoch 630, loss 0.4485372006893158\n","outputs:  tensor([[0.2504, 0.6287],\n","        [0.7995, 0.2815],\n","        [0.7903, 0.2919],\n","        [0.9370, 0.1489],\n","        [0.1186, 0.8201]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4483, grad_fn=<NllLossBackward>)\n","epoch 631, loss 0.4482579827308655\n","outputs:  tensor([[0.2500, 0.6292],\n","        [0.7998, 0.2812],\n","        [0.7905, 0.2915],\n","        [0.9372, 0.1484],\n","        [0.1182, 0.8206]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4480, grad_fn=<NllLossBackward>)\n","epoch 632, loss 0.44797927141189575\n","outputs:  tensor([[0.2495, 0.6297],\n","        [0.8001, 0.2808],\n","        [0.7908, 0.2912],\n","        [0.9375, 0.1479],\n","        [0.1178, 0.8212]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4477, grad_fn=<NllLossBackward>)\n","epoch 633, loss 0.4477013051509857\n","outputs:  tensor([[0.2491, 0.6302],\n","        [0.8004, 0.2804],\n","        [0.7911, 0.2909],\n","        [0.9377, 0.1475],\n","        [0.1174, 0.8218]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4474, grad_fn=<NllLossBackward>)\n","epoch 634, loss 0.44742387533187866\n","outputs:  tensor([[0.2487, 0.6307],\n","        [0.8007, 0.2801],\n","        [0.7914, 0.2905],\n","        [0.9379, 0.1470],\n","        [0.1170, 0.8223]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4471, grad_fn=<NllLossBackward>)\n","epoch 635, loss 0.44714707136154175\n","outputs:  tensor([[0.2483, 0.6312],\n","        [0.8010, 0.2797],\n","        [0.7917, 0.2902],\n","        [0.9381, 0.1466],\n","        [0.1166, 0.8229]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4469, grad_fn=<NllLossBackward>)\n","epoch 636, loss 0.446870893239975\n","outputs:  tensor([[0.2479, 0.6317],\n","        [0.8013, 0.2794],\n","        [0.7920, 0.2898],\n","        [0.9383, 0.1461],\n","        [0.1162, 0.8235]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4466, grad_fn=<NllLossBackward>)\n","epoch 637, loss 0.44659537076950073\n","outputs:  tensor([[0.2475, 0.6322],\n","        [0.8016, 0.2790],\n","        [0.7922, 0.2895],\n","        [0.9385, 0.1457],\n","        [0.1158, 0.8240]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4463, grad_fn=<NllLossBackward>)\n","epoch 638, loss 0.44632038474082947\n","outputs:  tensor([[0.2470, 0.6327],\n","        [0.8019, 0.2787],\n","        [0.7925, 0.2892],\n","        [0.9387, 0.1452],\n","        [0.1154, 0.8246]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4460, grad_fn=<NllLossBackward>)\n","epoch 639, loss 0.44604605436325073\n","outputs:  tensor([[0.2466, 0.6332],\n","        [0.8022, 0.2783],\n","        [0.7928, 0.2888],\n","        [0.9390, 0.1448],\n","        [0.1149, 0.8251]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4458, grad_fn=<NllLossBackward>)\n","epoch 640, loss 0.44577234983444214\n","outputs:  tensor([[0.2462, 0.6337],\n","        [0.8024, 0.2779],\n","        [0.7931, 0.2885],\n","        [0.9392, 0.1443],\n","        [0.1145, 0.8257]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4455, grad_fn=<NllLossBackward>)\n","epoch 641, loss 0.44549936056137085\n","outputs:  tensor([[0.2458, 0.6342],\n","        [0.8027, 0.2776],\n","        [0.7934, 0.2881],\n","        [0.9394, 0.1439],\n","        [0.1141, 0.8262]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4452, grad_fn=<NllLossBackward>)\n","epoch 642, loss 0.44522684812545776\n","outputs:  tensor([[0.2454, 0.6347],\n","        [0.8030, 0.2772],\n","        [0.7937, 0.2878],\n","        [0.9396, 0.1434],\n","        [0.1137, 0.8268]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4450, grad_fn=<NllLossBackward>)\n","epoch 643, loss 0.444955050945282\n","outputs:  tensor([[0.2450, 0.6352],\n","        [0.8033, 0.2769],\n","        [0.7939, 0.2875],\n","        [0.9398, 0.1430],\n","        [0.1133, 0.8273]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4447, grad_fn=<NllLossBackward>)\n","epoch 644, loss 0.44468384981155396\n","outputs:  tensor([[0.2446, 0.6357],\n","        [0.8036, 0.2765],\n","        [0.7942, 0.2871],\n","        [0.9400, 0.1425],\n","        [0.1129, 0.8279]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4444, grad_fn=<NllLossBackward>)\n","epoch 645, loss 0.44441327452659607\n","outputs:  tensor([[0.2442, 0.6362],\n","        [0.8039, 0.2762],\n","        [0.7945, 0.2868],\n","        [0.9402, 0.1421],\n","        [0.1126, 0.8284]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4441, grad_fn=<NllLossBackward>)\n","epoch 646, loss 0.44414329528808594\n","outputs:  tensor([[0.2437, 0.6367],\n","        [0.8042, 0.2758],\n","        [0.7948, 0.2864],\n","        [0.9404, 0.1416],\n","        [0.1122, 0.8290]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4439, grad_fn=<NllLossBackward>)\n","epoch 647, loss 0.44387388229370117\n","outputs:  tensor([[0.2433, 0.6371],\n","        [0.8045, 0.2754],\n","        [0.7951, 0.2861],\n","        [0.9406, 0.1412],\n","        [0.1118, 0.8295]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4436, grad_fn=<NllLossBackward>)\n","epoch 648, loss 0.44360512495040894\n","outputs:  tensor([[0.2429, 0.6376],\n","        [0.8048, 0.2751],\n","        [0.7953, 0.2858],\n","        [0.9408, 0.1407],\n","        [0.1114, 0.8301]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4433, grad_fn=<NllLossBackward>)\n","epoch 649, loss 0.4433370530605316\n","outputs:  tensor([[0.2425, 0.6381],\n","        [0.8051, 0.2747],\n","        [0.7956, 0.2854],\n","        [0.9410, 0.1403],\n","        [0.1110, 0.8306]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4431, grad_fn=<NllLossBackward>)\n","epoch 650, loss 0.4430694580078125\n","outputs:  tensor([[0.2421, 0.6386],\n","        [0.8054, 0.2744],\n","        [0.7959, 0.2851],\n","        [0.9412, 0.1399],\n","        [0.1106, 0.8311]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4428, grad_fn=<NllLossBackward>)\n","epoch 651, loss 0.4428026080131531\n","Parameter containing:\n","tensor([[-0.1321, -0.4240,  0.2061],\n","        [-0.7301, -0.3218, -0.0611],\n","        [-0.7390, -0.4733, -0.1075],\n","        [-0.3431, -0.3080,  0.0018]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4502, -0.3822,  0.0645,  0.0874], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.6721,  0.4928,  0.8029, -0.0421],\n","        [ 0.0738, -0.5950, -0.3436, -0.3327]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3037, -0.5187], requires_grad=True)\n","outputs:  tensor([[0.2417, 0.6391],\n","        [0.8057, 0.2740],\n","        [0.7962, 0.2848],\n","        [0.9414, 0.1394],\n","        [0.1102, 0.8317]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4425, grad_fn=<NllLossBackward>)\n","epoch 652, loss 0.44253629446029663\n","outputs:  tensor([[0.2413, 0.6396],\n","        [0.8060, 0.2737],\n","        [0.7964, 0.2844],\n","        [0.9416, 0.1390],\n","        [0.1098, 0.8322]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4423, grad_fn=<NllLossBackward>)\n","epoch 653, loss 0.4422706663608551\n","outputs:  tensor([[0.2409, 0.6401],\n","        [0.8062, 0.2733],\n","        [0.7967, 0.2841],\n","        [0.9418, 0.1386],\n","        [0.1094, 0.8327]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4420, grad_fn=<NllLossBackward>)\n","epoch 654, loss 0.44200554490089417\n","outputs:  tensor([[0.2405, 0.6406],\n","        [0.8065, 0.2730],\n","        [0.7970, 0.2837],\n","        [0.9420, 0.1381],\n","        [0.1091, 0.8333]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4417, grad_fn=<NllLossBackward>)\n","epoch 655, loss 0.44174113869667053\n","outputs:  tensor([[0.2401, 0.6411],\n","        [0.8068, 0.2726],\n","        [0.7973, 0.2834],\n","        [0.9422, 0.1377],\n","        [0.1087, 0.8338]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4415, grad_fn=<NllLossBackward>)\n","epoch 656, loss 0.44147729873657227\n","outputs:  tensor([[0.2397, 0.6416],\n","        [0.8071, 0.2722],\n","        [0.7975, 0.2831],\n","        [0.9424, 0.1373],\n","        [0.1083, 0.8343]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4412, grad_fn=<NllLossBackward>)\n","epoch 657, loss 0.441213995218277\n","outputs:  tensor([[0.2393, 0.6421],\n","        [0.8074, 0.2719],\n","        [0.7978, 0.2827],\n","        [0.9426, 0.1368],\n","        [0.1079, 0.8349]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4410, grad_fn=<NllLossBackward>)\n","epoch 658, loss 0.4409514367580414\n","outputs:  tensor([[0.2389, 0.6426],\n","        [0.8077, 0.2715],\n","        [0.7981, 0.2824],\n","        [0.9428, 0.1364],\n","        [0.1075, 0.8354]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4407, grad_fn=<NllLossBackward>)\n","epoch 659, loss 0.44068947434425354\n","outputs:  tensor([[0.2385, 0.6430],\n","        [0.8080, 0.2712],\n","        [0.7984, 0.2821],\n","        [0.9430, 0.1360],\n","        [0.1072, 0.8359]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4404, grad_fn=<NllLossBackward>)\n","epoch 660, loss 0.44042807817459106\n","outputs:  tensor([[0.2381, 0.6435],\n","        [0.8083, 0.2708],\n","        [0.7986, 0.2817],\n","        [0.9432, 0.1355],\n","        [0.1068, 0.8365]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4402, grad_fn=<NllLossBackward>)\n","epoch 661, loss 0.4401671290397644\n","outputs:  tensor([[0.2377, 0.6440],\n","        [0.8085, 0.2705],\n","        [0.7989, 0.2814],\n","        [0.9434, 0.1351],\n","        [0.1064, 0.8370]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4399, grad_fn=<NllLossBackward>)\n","epoch 662, loss 0.4399070143699646\n","outputs:  tensor([[0.2373, 0.6445],\n","        [0.8088, 0.2701],\n","        [0.7992, 0.2810],\n","        [0.9436, 0.1347],\n","        [0.1061, 0.8375]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4396, grad_fn=<NllLossBackward>)\n","epoch 663, loss 0.4396474361419678\n","outputs:  tensor([[0.2369, 0.6450],\n","        [0.8091, 0.2698],\n","        [0.7995, 0.2807],\n","        [0.9438, 0.1343],\n","        [0.1057, 0.8380]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4394, grad_fn=<NllLossBackward>)\n","epoch 664, loss 0.4393884241580963\n","outputs:  tensor([[0.2365, 0.6455],\n","        [0.8094, 0.2694],\n","        [0.7997, 0.2804],\n","        [0.9440, 0.1338],\n","        [0.1053, 0.8385]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4391, grad_fn=<NllLossBackward>)\n","epoch 665, loss 0.43913012742996216\n","outputs:  tensor([[0.2361, 0.6460],\n","        [0.8097, 0.2691],\n","        [0.8000, 0.2800],\n","        [0.9442, 0.1334],\n","        [0.1049, 0.8391]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4389, grad_fn=<NllLossBackward>)\n","epoch 666, loss 0.4388723373413086\n","outputs:  tensor([[0.2357, 0.6465],\n","        [0.8100, 0.2687],\n","        [0.8003, 0.2797],\n","        [0.9444, 0.1330],\n","        [0.1046, 0.8396]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4386, grad_fn=<NllLossBackward>)\n","epoch 667, loss 0.4386151432991028\n","outputs:  tensor([[0.2353, 0.6470],\n","        [0.8102, 0.2684],\n","        [0.8006, 0.2794],\n","        [0.9446, 0.1326],\n","        [0.1042, 0.8401]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4384, grad_fn=<NllLossBackward>)\n","epoch 668, loss 0.4383586049079895\n","outputs:  tensor([[0.2349, 0.6474],\n","        [0.8105, 0.2680],\n","        [0.8008, 0.2790],\n","        [0.9448, 0.1322],\n","        [0.1039, 0.8406]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4381, grad_fn=<NllLossBackward>)\n","epoch 669, loss 0.4381026327610016\n","outputs:  tensor([[0.2345, 0.6479],\n","        [0.8108, 0.2677],\n","        [0.8011, 0.2787],\n","        [0.9450, 0.1317],\n","        [0.1035, 0.8411]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4378, grad_fn=<NllLossBackward>)\n","epoch 670, loss 0.4378472864627838\n","outputs:  tensor([[0.2341, 0.6484],\n","        [0.8111, 0.2673],\n","        [0.8014, 0.2784],\n","        [0.9451, 0.1313],\n","        [0.1031, 0.8416]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4376, grad_fn=<NllLossBackward>)\n","epoch 671, loss 0.4375925064086914\n","outputs:  tensor([[0.2337, 0.6489],\n","        [0.8114, 0.2670],\n","        [0.8016, 0.2780],\n","        [0.9453, 0.1309],\n","        [0.1028, 0.8421]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4373, grad_fn=<NllLossBackward>)\n","epoch 672, loss 0.43733835220336914\n","outputs:  tensor([[0.2334, 0.6494],\n","        [0.8117, 0.2666],\n","        [0.8019, 0.2777],\n","        [0.9455, 0.1305],\n","        [0.1024, 0.8426]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4371, grad_fn=<NllLossBackward>)\n","epoch 673, loss 0.437084823846817\n","outputs:  tensor([[0.2330, 0.6499],\n","        [0.8119, 0.2663],\n","        [0.8022, 0.2774],\n","        [0.9457, 0.1301],\n","        [0.1021, 0.8431]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4368, grad_fn=<NllLossBackward>)\n","epoch 674, loss 0.43683186173439026\n","outputs:  tensor([[0.2326, 0.6504],\n","        [0.8122, 0.2659],\n","        [0.8025, 0.2770],\n","        [0.9459, 0.1297],\n","        [0.1017, 0.8436]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4366, grad_fn=<NllLossBackward>)\n","epoch 675, loss 0.43657946586608887\n","outputs:  tensor([[0.2322, 0.6508],\n","        [0.8125, 0.2656],\n","        [0.8027, 0.2767],\n","        [0.9461, 0.1293],\n","        [0.1014, 0.8441]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4363, grad_fn=<NllLossBackward>)\n","epoch 676, loss 0.4363277554512024\n","outputs:  tensor([[0.2318, 0.6513],\n","        [0.8128, 0.2652],\n","        [0.8030, 0.2764],\n","        [0.9463, 0.1289],\n","        [0.1010, 0.8446]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4361, grad_fn=<NllLossBackward>)\n","epoch 677, loss 0.43607664108276367\n","outputs:  tensor([[0.2314, 0.6518],\n","        [0.8131, 0.2649],\n","        [0.8033, 0.2760],\n","        [0.9464, 0.1285],\n","        [0.1007, 0.8451]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4358, grad_fn=<NllLossBackward>)\n","epoch 678, loss 0.43582606315612793\n","outputs:  tensor([[0.2310, 0.6523],\n","        [0.8133, 0.2645],\n","        [0.8035, 0.2757],\n","        [0.9466, 0.1280],\n","        [0.1003, 0.8456]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4356, grad_fn=<NllLossBackward>)\n","epoch 679, loss 0.43557605147361755\n","outputs:  tensor([[0.2306, 0.6528],\n","        [0.8136, 0.2642],\n","        [0.8038, 0.2754],\n","        [0.9468, 0.1276],\n","        [0.1000, 0.8461]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4353, grad_fn=<NllLossBackward>)\n","epoch 680, loss 0.4353266656398773\n","outputs:  tensor([[0.2303, 0.6533],\n","        [0.8139, 0.2638],\n","        [0.8041, 0.2751],\n","        [0.9470, 0.1272],\n","        [0.0996, 0.8466]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4351, grad_fn=<NllLossBackward>)\n","epoch 681, loss 0.435077965259552\n","outputs:  tensor([[0.2299, 0.6537],\n","        [0.8142, 0.2635],\n","        [0.8043, 0.2747],\n","        [0.9472, 0.1268],\n","        [0.0993, 0.8471]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4348, grad_fn=<NllLossBackward>)\n","epoch 682, loss 0.4348297119140625\n","outputs:  tensor([[0.2295, 0.6542],\n","        [0.8144, 0.2631],\n","        [0.8046, 0.2744],\n","        [0.9474, 0.1264],\n","        [0.0989, 0.8476]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4346, grad_fn=<NllLossBackward>)\n","epoch 683, loss 0.4345821440219879\n","outputs:  tensor([[0.2291, 0.6547],\n","        [0.8147, 0.2628],\n","        [0.8049, 0.2741],\n","        [0.9475, 0.1260],\n","        [0.0986, 0.8481]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4343, grad_fn=<NllLossBackward>)\n","epoch 684, loss 0.4343351423740387\n","outputs:  tensor([[0.2287, 0.6552],\n","        [0.8150, 0.2625],\n","        [0.8051, 0.2737],\n","        [0.9477, 0.1256],\n","        [0.0983, 0.8486]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4341, grad_fn=<NllLossBackward>)\n","epoch 685, loss 0.43408864736557007\n","outputs:  tensor([[0.2283, 0.6557],\n","        [0.8153, 0.2621],\n","        [0.8054, 0.2734],\n","        [0.9479, 0.1252],\n","        [0.0979, 0.8491]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4338, grad_fn=<NllLossBackward>)\n","epoch 686, loss 0.43384283781051636\n","outputs:  tensor([[0.2279, 0.6562],\n","        [0.8155, 0.2618],\n","        [0.8057, 0.2731],\n","        [0.9481, 0.1248],\n","        [0.0976, 0.8496]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4336, grad_fn=<NllLossBackward>)\n","epoch 687, loss 0.4335975646972656\n","outputs:  tensor([[0.2276, 0.6566],\n","        [0.8158, 0.2614],\n","        [0.8059, 0.2727],\n","        [0.9482, 0.1244],\n","        [0.0972, 0.8501]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4334, grad_fn=<NllLossBackward>)\n","epoch 688, loss 0.4333530366420746\n","outputs:  tensor([[0.2272, 0.6571],\n","        [0.8161, 0.2611],\n","        [0.8062, 0.2724],\n","        [0.9484, 0.1240],\n","        [0.0969, 0.8506]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4331, grad_fn=<NllLossBackward>)\n","epoch 689, loss 0.4331088960170746\n","outputs:  tensor([[0.2268, 0.6576],\n","        [0.8164, 0.2607],\n","        [0.8064, 0.2721],\n","        [0.9486, 0.1236],\n","        [0.0966, 0.8510]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4329, grad_fn=<NllLossBackward>)\n","epoch 690, loss 0.4328653812408447\n","outputs:  tensor([[0.2264, 0.6581],\n","        [0.8166, 0.2604],\n","        [0.8067, 0.2718],\n","        [0.9488, 0.1233],\n","        [0.0962, 0.8515]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4326, grad_fn=<NllLossBackward>)\n","epoch 691, loss 0.4326225221157074\n","outputs:  tensor([[0.2261, 0.6586],\n","        [0.8169, 0.2600],\n","        [0.8070, 0.2714],\n","        [0.9489, 0.1229],\n","        [0.0959, 0.8520]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4324, grad_fn=<NllLossBackward>)\n","epoch 692, loss 0.43238019943237305\n","outputs:  tensor([[0.2257, 0.6590],\n","        [0.8172, 0.2597],\n","        [0.8072, 0.2711],\n","        [0.9491, 0.1225],\n","        [0.0956, 0.8525]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4321, grad_fn=<NllLossBackward>)\n","epoch 693, loss 0.4321385324001312\n","outputs:  tensor([[0.2253, 0.6595],\n","        [0.8175, 0.2594],\n","        [0.8075, 0.2708],\n","        [0.9493, 0.1221],\n","        [0.0953, 0.8529]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4319, grad_fn=<NllLossBackward>)\n","epoch 694, loss 0.4318973422050476\n","outputs:  tensor([[0.2249, 0.6600],\n","        [0.8177, 0.2590],\n","        [0.8078, 0.2704],\n","        [0.9495, 0.1217],\n","        [0.0949, 0.8534]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4317, grad_fn=<NllLossBackward>)\n","epoch 695, loss 0.43165677785873413\n","outputs:  tensor([[0.2245, 0.6605],\n","        [0.8180, 0.2587],\n","        [0.8080, 0.2701],\n","        [0.9496, 0.1213],\n","        [0.0946, 0.8539]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4314, grad_fn=<NllLossBackward>)\n","epoch 696, loss 0.4314168095588684\n","outputs:  tensor([[0.2242, 0.6609],\n","        [0.8183, 0.2583],\n","        [0.8083, 0.2698],\n","        [0.9498, 0.1209],\n","        [0.0943, 0.8544]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4312, grad_fn=<NllLossBackward>)\n","epoch 697, loss 0.43117743730545044\n","outputs:  tensor([[0.2238, 0.6614],\n","        [0.8185, 0.2580],\n","        [0.8085, 0.2695],\n","        [0.9500, 0.1205],\n","        [0.0940, 0.8548]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4309, grad_fn=<NllLossBackward>)\n","epoch 698, loss 0.4309385418891907\n","outputs:  tensor([[0.2234, 0.6619],\n","        [0.8188, 0.2577],\n","        [0.8088, 0.2691],\n","        [0.9501, 0.1202],\n","        [0.0936, 0.8553]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4307, grad_fn=<NllLossBackward>)\n","epoch 699, loss 0.4307003617286682\n","outputs:  tensor([[0.2230, 0.6624],\n","        [0.8191, 0.2573],\n","        [0.8091, 0.2688],\n","        [0.9503, 0.1198],\n","        [0.0933, 0.8558]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4305, grad_fn=<NllLossBackward>)\n","epoch 700, loss 0.43046265840530396\n","outputs:  tensor([[0.2227, 0.6629],\n","        [0.8193, 0.2570],\n","        [0.8093, 0.2685],\n","        [0.9505, 0.1194],\n","        [0.0930, 0.8562]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4302, grad_fn=<NllLossBackward>)\n","epoch 701, loss 0.43022555112838745\n","Parameter containing:\n","tensor([[-0.1411, -0.4366,  0.2048],\n","        [-0.7515, -0.3504, -0.0641],\n","        [-0.7596, -0.5012, -0.1104],\n","        [-0.3502, -0.3172,  0.0008]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4519, -0.3778,  0.0686,  0.0889], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.6843,  0.5104,  0.8253, -0.0298],\n","        [ 0.0565, -0.6199, -0.3753, -0.3500]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3067, -0.5235], requires_grad=True)\n","outputs:  tensor([[0.2223, 0.6633],\n","        [0.8196, 0.2566],\n","        [0.8096, 0.2682],\n","        [0.9507, 0.1190],\n","        [0.0927, 0.8567]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4300, grad_fn=<NllLossBackward>)\n","epoch 702, loss 0.4299890398979187\n","outputs:  tensor([[0.2219, 0.6638],\n","        [0.8199, 0.2563],\n","        [0.8098, 0.2678],\n","        [0.9508, 0.1186],\n","        [0.0924, 0.8572]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4298, grad_fn=<NllLossBackward>)\n","epoch 703, loss 0.4297531247138977\n","outputs:  tensor([[0.2216, 0.6643],\n","        [0.8201, 0.2559],\n","        [0.8101, 0.2675],\n","        [0.9510, 0.1183],\n","        [0.0920, 0.8576]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4295, grad_fn=<NllLossBackward>)\n","epoch 704, loss 0.4295176863670349\n","outputs:  tensor([[0.2212, 0.6647],\n","        [0.8204, 0.2556],\n","        [0.8103, 0.2672],\n","        [0.9512, 0.1179],\n","        [0.0917, 0.8581]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4293, grad_fn=<NllLossBackward>)\n","epoch 705, loss 0.4292829632759094\n","outputs:  tensor([[0.2208, 0.6652],\n","        [0.8207, 0.2553],\n","        [0.8106, 0.2669],\n","        [0.9513, 0.1175],\n","        [0.0914, 0.8586]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4290, grad_fn=<NllLossBackward>)\n","epoch 706, loss 0.42904871702194214\n","outputs:  tensor([[0.2205, 0.6657],\n","        [0.8209, 0.2549],\n","        [0.8109, 0.2665],\n","        [0.9515, 0.1171],\n","        [0.0911, 0.8590]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4288, grad_fn=<NllLossBackward>)\n","epoch 707, loss 0.4288150668144226\n","outputs:  tensor([[0.2201, 0.6662],\n","        [0.8212, 0.2546],\n","        [0.8111, 0.2662],\n","        [0.9517, 0.1168],\n","        [0.0908, 0.8595]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4286, grad_fn=<NllLossBackward>)\n","epoch 708, loss 0.4285818934440613\n","outputs:  tensor([[0.2197, 0.6666],\n","        [0.8215, 0.2543],\n","        [0.8114, 0.2659],\n","        [0.9518, 0.1164],\n","        [0.0905, 0.8599]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4283, grad_fn=<NllLossBackward>)\n","epoch 709, loss 0.42834943532943726\n","outputs:  tensor([[0.2194, 0.6671],\n","        [0.8217, 0.2539],\n","        [0.8116, 0.2656],\n","        [0.9520, 0.1160],\n","        [0.0902, 0.8604]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4281, grad_fn=<NllLossBackward>)\n","epoch 710, loss 0.42811745405197144\n","outputs:  tensor([[0.2190, 0.6676],\n","        [0.8220, 0.2536],\n","        [0.8119, 0.2652],\n","        [0.9521, 0.1156],\n","        [0.0899, 0.8608]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4279, grad_fn=<NllLossBackward>)\n","epoch 711, loss 0.42788606882095337\n","outputs:  tensor([[0.2186, 0.6681],\n","        [0.8223, 0.2532],\n","        [0.8121, 0.2649],\n","        [0.9523, 0.1153],\n","        [0.0896, 0.8613]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4277, grad_fn=<NllLossBackward>)\n","epoch 712, loss 0.42765527963638306\n","outputs:  tensor([[0.2183, 0.6685],\n","        [0.8225, 0.2529],\n","        [0.8124, 0.2646],\n","        [0.9525, 0.1149],\n","        [0.0893, 0.8617]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4274, grad_fn=<NllLossBackward>)\n","epoch 713, loss 0.4274250566959381\n","outputs:  tensor([[0.2179, 0.6690],\n","        [0.8228, 0.2526],\n","        [0.8126, 0.2643],\n","        [0.9526, 0.1145],\n","        [0.0890, 0.8622]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4272, grad_fn=<NllLossBackward>)\n","epoch 714, loss 0.42719537019729614\n","outputs:  tensor([[0.2175, 0.6695],\n","        [0.8231, 0.2522],\n","        [0.8129, 0.2640],\n","        [0.9528, 0.1142],\n","        [0.0887, 0.8626]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4270, grad_fn=<NllLossBackward>)\n","epoch 715, loss 0.42696619033813477\n","outputs:  tensor([[0.2172, 0.6699],\n","        [0.8233, 0.2519],\n","        [0.8132, 0.2636],\n","        [0.9529, 0.1138],\n","        [0.0884, 0.8631]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4267, grad_fn=<NllLossBackward>)\n","epoch 716, loss 0.42673763632774353\n","outputs:  tensor([[0.2168, 0.6704],\n","        [0.8236, 0.2516],\n","        [0.8134, 0.2633],\n","        [0.9531, 0.1134],\n","        [0.0881, 0.8635]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4265, grad_fn=<NllLossBackward>)\n","epoch 717, loss 0.4265096187591553\n","outputs:  tensor([[0.2164, 0.6709],\n","        [0.8238, 0.2512],\n","        [0.8137, 0.2630],\n","        [0.9533, 0.1131],\n","        [0.0878, 0.8640]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4263, grad_fn=<NllLossBackward>)\n","epoch 718, loss 0.4262821078300476\n","outputs:  tensor([[0.2161, 0.6713],\n","        [0.8241, 0.2509],\n","        [0.8139, 0.2627],\n","        [0.9534, 0.1127],\n","        [0.0875, 0.8644]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4261, grad_fn=<NllLossBackward>)\n","epoch 719, loss 0.42605528235435486\n","outputs:  tensor([[0.2157, 0.6718],\n","        [0.8244, 0.2506],\n","        [0.8142, 0.2624],\n","        [0.9536, 0.1124],\n","        [0.0872, 0.8648]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4258, grad_fn=<NllLossBackward>)\n","epoch 720, loss 0.4258289933204651\n","outputs:  tensor([[0.2154, 0.6723],\n","        [0.8246, 0.2502],\n","        [0.8144, 0.2620],\n","        [0.9537, 0.1120],\n","        [0.0869, 0.8653]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4256, grad_fn=<NllLossBackward>)\n","epoch 721, loss 0.42560315132141113\n","outputs:  tensor([[0.2150, 0.6727],\n","        [0.8249, 0.2499],\n","        [0.8147, 0.2617],\n","        [0.9539, 0.1116],\n","        [0.0866, 0.8657]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4254, grad_fn=<NllLossBackward>)\n","epoch 722, loss 0.4253779351711273\n","outputs:  tensor([[0.2147, 0.6732],\n","        [0.8251, 0.2496],\n","        [0.8149, 0.2614],\n","        [0.9540, 0.1113],\n","        [0.0863, 0.8661]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4252, grad_fn=<NllLossBackward>)\n","epoch 723, loss 0.42515334486961365\n","outputs:  tensor([[0.2143, 0.6737],\n","        [0.8254, 0.2492],\n","        [0.8152, 0.2611],\n","        [0.9542, 0.1109],\n","        [0.0860, 0.8666]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4249, grad_fn=<NllLossBackward>)\n","epoch 724, loss 0.424929141998291\n","outputs:  tensor([[0.2139, 0.6741],\n","        [0.8257, 0.2489],\n","        [0.8154, 0.2608],\n","        [0.9544, 0.1106],\n","        [0.0857, 0.8670]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4247, grad_fn=<NllLossBackward>)\n","epoch 725, loss 0.4247055947780609\n","outputs:  tensor([[0.2136, 0.6746],\n","        [0.8259, 0.2486],\n","        [0.8157, 0.2604],\n","        [0.9545, 0.1102],\n","        [0.0854, 0.8674]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4245, grad_fn=<NllLossBackward>)\n","epoch 726, loss 0.4244825839996338\n","outputs:  tensor([[0.2132, 0.6751],\n","        [0.8262, 0.2482],\n","        [0.8159, 0.2601],\n","        [0.9547, 0.1099],\n","        [0.0851, 0.8679]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4243, grad_fn=<NllLossBackward>)\n","epoch 727, loss 0.42426013946533203\n","outputs:  tensor([[0.2129, 0.6755],\n","        [0.8264, 0.2479],\n","        [0.8162, 0.2598],\n","        [0.9548, 0.1095],\n","        [0.0848, 0.8683]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4240, grad_fn=<NllLossBackward>)\n","epoch 728, loss 0.42403826117515564\n","outputs:  tensor([[0.2125, 0.6760],\n","        [0.8267, 0.2476],\n","        [0.8164, 0.2595],\n","        [0.9550, 0.1092],\n","        [0.0845, 0.8687]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4238, grad_fn=<NllLossBackward>)\n","epoch 729, loss 0.42381685972213745\n","outputs:  tensor([[0.2122, 0.6764],\n","        [0.8269, 0.2472],\n","        [0.8167, 0.2592],\n","        [0.9551, 0.1088],\n","        [0.0843, 0.8692]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4236, grad_fn=<NllLossBackward>)\n","epoch 730, loss 0.423596054315567\n","outputs:  tensor([[0.2118, 0.6769],\n","        [0.8272, 0.2469],\n","        [0.8169, 0.2589],\n","        [0.9553, 0.1085],\n","        [0.0840, 0.8696]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4234, grad_fn=<NllLossBackward>)\n","epoch 731, loss 0.42337578535079956\n","outputs:  tensor([[0.2115, 0.6774],\n","        [0.8275, 0.2466],\n","        [0.8172, 0.2585],\n","        [0.9554, 0.1081],\n","        [0.0837, 0.8700]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4232, grad_fn=<NllLossBackward>)\n","epoch 732, loss 0.42315611243247986\n","outputs:  tensor([[0.2111, 0.6778],\n","        [0.8277, 0.2463],\n","        [0.8174, 0.2582],\n","        [0.9556, 0.1078],\n","        [0.0834, 0.8704]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4229, grad_fn=<NllLossBackward>)\n","epoch 733, loss 0.42293691635131836\n","outputs:  tensor([[0.2108, 0.6783],\n","        [0.8280, 0.2459],\n","        [0.8177, 0.2579],\n","        [0.9557, 0.1074],\n","        [0.0831, 0.8708]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4227, grad_fn=<NllLossBackward>)\n","epoch 734, loss 0.4227182865142822\n","outputs:  tensor([[0.2104, 0.6788],\n","        [0.8282, 0.2456],\n","        [0.8179, 0.2576],\n","        [0.9559, 0.1071],\n","        [0.0829, 0.8713]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4225, grad_fn=<NllLossBackward>)\n","epoch 735, loss 0.42250022292137146\n","outputs:  tensor([[0.2101, 0.6792],\n","        [0.8285, 0.2453],\n","        [0.8181, 0.2573],\n","        [0.9560, 0.1067],\n","        [0.0826, 0.8717]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4223, grad_fn=<NllLossBackward>)\n","epoch 736, loss 0.42228269577026367\n","outputs:  tensor([[0.2097, 0.6797],\n","        [0.8287, 0.2449],\n","        [0.8184, 0.2570],\n","        [0.9562, 0.1064],\n","        [0.0823, 0.8721]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4221, grad_fn=<NllLossBackward>)\n","epoch 737, loss 0.4220656454563141\n","outputs:  tensor([[0.2094, 0.6801],\n","        [0.8290, 0.2446],\n","        [0.8186, 0.2566],\n","        [0.9563, 0.1061],\n","        [0.0820, 0.8725]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4218, grad_fn=<NllLossBackward>)\n","epoch 738, loss 0.42184916138648987\n","outputs:  tensor([[0.2090, 0.6806],\n","        [0.8292, 0.2443],\n","        [0.8189, 0.2563],\n","        [0.9564, 0.1057],\n","        [0.0818, 0.8729]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4216, grad_fn=<NllLossBackward>)\n","epoch 739, loss 0.42163318395614624\n","outputs:  tensor([[0.2087, 0.6810],\n","        [0.8295, 0.2440],\n","        [0.8191, 0.2560],\n","        [0.9566, 0.1054],\n","        [0.0815, 0.8733]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4214, grad_fn=<NllLossBackward>)\n","epoch 740, loss 0.42141780257225037\n","outputs:  tensor([[0.2083, 0.6815],\n","        [0.8297, 0.2436],\n","        [0.8194, 0.2557],\n","        [0.9567, 0.1050],\n","        [0.0812, 0.8737]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4212, grad_fn=<NllLossBackward>)\n","epoch 741, loss 0.42120295763015747\n","outputs:  tensor([[0.2080, 0.6820],\n","        [0.8300, 0.2433],\n","        [0.8196, 0.2554],\n","        [0.9569, 0.1047],\n","        [0.0809, 0.8742]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4210, grad_fn=<NllLossBackward>)\n","epoch 742, loss 0.42098861932754517\n","outputs:  tensor([[0.2076, 0.6824],\n","        [0.8302, 0.2430],\n","        [0.8199, 0.2551],\n","        [0.9570, 0.1044],\n","        [0.0807, 0.8746]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4208, grad_fn=<NllLossBackward>)\n","epoch 743, loss 0.4207748472690582\n","outputs:  tensor([[0.2073, 0.6829],\n","        [0.8305, 0.2427],\n","        [0.8201, 0.2548],\n","        [0.9572, 0.1040],\n","        [0.0804, 0.8750]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4206, grad_fn=<NllLossBackward>)\n","epoch 744, loss 0.4205615520477295\n","outputs:  tensor([[0.2070, 0.6833],\n","        [0.8307, 0.2423],\n","        [0.8203, 0.2545],\n","        [0.9573, 0.1037],\n","        [0.0801, 0.8754]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4203, grad_fn=<NllLossBackward>)\n","epoch 745, loss 0.4203488230705261\n","outputs:  tensor([[0.2066, 0.6838],\n","        [0.8310, 0.2420],\n","        [0.8206, 0.2541],\n","        [0.9575, 0.1034],\n","        [0.0799, 0.8758]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4201, grad_fn=<NllLossBackward>)\n","epoch 746, loss 0.4201366901397705\n","outputs:  tensor([[0.2063, 0.6842],\n","        [0.8312, 0.2417],\n","        [0.8208, 0.2538],\n","        [0.9576, 0.1030],\n","        [0.0796, 0.8762]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4199, grad_fn=<NllLossBackward>)\n","epoch 747, loss 0.4199249744415283\n","outputs:  tensor([[0.2059, 0.6847],\n","        [0.8315, 0.2414],\n","        [0.8211, 0.2535],\n","        [0.9577, 0.1027],\n","        [0.0793, 0.8766]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4197, grad_fn=<NllLossBackward>)\n","epoch 748, loss 0.4197138249874115\n","outputs:  tensor([[0.2056, 0.6851],\n","        [0.8317, 0.2410],\n","        [0.8213, 0.2532],\n","        [0.9579, 0.1024],\n","        [0.0791, 0.8770]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4195, grad_fn=<NllLossBackward>)\n","epoch 749, loss 0.41950327157974243\n","outputs:  tensor([[0.2053, 0.6856],\n","        [0.8320, 0.2407],\n","        [0.8215, 0.2529],\n","        [0.9580, 0.1020],\n","        [0.0788, 0.8774]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4193, grad_fn=<NllLossBackward>)\n","epoch 750, loss 0.4192931652069092\n","outputs:  tensor([[0.2049, 0.6861],\n","        [0.8322, 0.2404],\n","        [0.8218, 0.2526],\n","        [0.9582, 0.1017],\n","        [0.0785, 0.8778]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4191, grad_fn=<NllLossBackward>)\n","epoch 751, loss 0.41908353567123413\n","Parameter containing:\n","tensor([[-0.1496, -0.4486,  0.2037],\n","        [-0.7712, -0.3773, -0.0664],\n","        [-0.7788, -0.5278, -0.1128],\n","        [-0.3571, -0.3264,  0.0001]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4538, -0.3734,  0.0729,  0.0905], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.6958,  0.5268,  0.8461, -0.0185],\n","        [ 0.0401, -0.6434, -0.4052, -0.3662]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3097, -0.5281], requires_grad=True)\n","outputs:  tensor([[0.2046, 0.6865],\n","        [0.8325, 0.2401],\n","        [0.8220, 0.2523],\n","        [0.9583, 0.1014],\n","        [0.0783, 0.8782]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4189, grad_fn=<NllLossBackward>)\n","epoch 752, loss 0.41887450218200684\n","outputs:  tensor([[0.2042, 0.6870],\n","        [0.8327, 0.2397],\n","        [0.8223, 0.2520],\n","        [0.9584, 0.1011],\n","        [0.0780, 0.8786]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4187, grad_fn=<NllLossBackward>)\n","epoch 753, loss 0.4186660349369049\n","outputs:  tensor([[0.2039, 0.6874],\n","        [0.8330, 0.2394],\n","        [0.8225, 0.2517],\n","        [0.9586, 0.1007],\n","        [0.0778, 0.8790]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4185, grad_fn=<NllLossBackward>)\n","epoch 754, loss 0.4184580445289612\n","outputs:  tensor([[0.2036, 0.6879],\n","        [0.8332, 0.2391],\n","        [0.8227, 0.2513],\n","        [0.9587, 0.1004],\n","        [0.0775, 0.8793]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4183, grad_fn=<NllLossBackward>)\n","epoch 755, loss 0.41825056076049805\n","outputs:  tensor([[0.2032, 0.6883],\n","        [0.8335, 0.2388],\n","        [0.8230, 0.2510],\n","        [0.9588, 0.1001],\n","        [0.0772, 0.8797]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4180, grad_fn=<NllLossBackward>)\n","epoch 756, loss 0.4180435538291931\n","outputs:  tensor([[0.2029, 0.6888],\n","        [0.8337, 0.2385],\n","        [0.8232, 0.2507],\n","        [0.9590, 0.0998],\n","        [0.0770, 0.8801]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4178, grad_fn=<NllLossBackward>)\n","epoch 757, loss 0.4178372025489807\n","outputs:  tensor([[0.2026, 0.6892],\n","        [0.8339, 0.2381],\n","        [0.8235, 0.2504],\n","        [0.9591, 0.0995],\n","        [0.0767, 0.8805]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4176, grad_fn=<NllLossBackward>)\n","epoch 758, loss 0.41763123869895935\n","outputs:  tensor([[0.2022, 0.6897],\n","        [0.8342, 0.2378],\n","        [0.8237, 0.2501],\n","        [0.9593, 0.0991],\n","        [0.0765, 0.8809]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4174, grad_fn=<NllLossBackward>)\n","epoch 759, loss 0.41742581129074097\n","outputs:  tensor([[0.2019, 0.6901],\n","        [0.8344, 0.2375],\n","        [0.8239, 0.2498],\n","        [0.9594, 0.0988],\n","        [0.0762, 0.8813]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4172, grad_fn=<NllLossBackward>)\n","epoch 760, loss 0.41722092032432556\n","outputs:  tensor([[0.2016, 0.6905],\n","        [0.8347, 0.2372],\n","        [0.8242, 0.2495],\n","        [0.9595, 0.0985],\n","        [0.0760, 0.8817]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4170, grad_fn=<NllLossBackward>)\n","epoch 761, loss 0.41701656579971313\n","outputs:  tensor([[0.2012, 0.6910],\n","        [0.8349, 0.2369],\n","        [0.8244, 0.2492],\n","        [0.9597, 0.0982],\n","        [0.0757, 0.8821]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4168, grad_fn=<NllLossBackward>)\n","epoch 762, loss 0.4168126583099365\n","outputs:  tensor([[0.2009, 0.6914],\n","        [0.8352, 0.2365],\n","        [0.8246, 0.2489],\n","        [0.9598, 0.0979],\n","        [0.0755, 0.8824]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4166, grad_fn=<NllLossBackward>)\n","epoch 763, loss 0.41660937666893005\n","outputs:  tensor([[0.2006, 0.6919],\n","        [0.8354, 0.2362],\n","        [0.8249, 0.2486],\n","        [0.9599, 0.0976],\n","        [0.0752, 0.8828]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4164, grad_fn=<NllLossBackward>)\n","epoch 764, loss 0.4164065420627594\n","outputs:  tensor([[0.2002, 0.6923],\n","        [0.8356, 0.2359],\n","        [0.8251, 0.2483],\n","        [0.9601, 0.0972],\n","        [0.0750, 0.8832]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4162, grad_fn=<NllLossBackward>)\n","epoch 765, loss 0.41620421409606934\n","outputs:  tensor([[0.1999, 0.6928],\n","        [0.8359, 0.2356],\n","        [0.8253, 0.2480],\n","        [0.9602, 0.0969],\n","        [0.0747, 0.8836]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4160, grad_fn=<NllLossBackward>)\n","epoch 766, loss 0.41600242257118225\n","outputs:  tensor([[0.1996, 0.6932],\n","        [0.8361, 0.2353],\n","        [0.8256, 0.2477],\n","        [0.9603, 0.0966],\n","        [0.0745, 0.8839]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4158, grad_fn=<NllLossBackward>)\n","epoch 767, loss 0.4158010482788086\n","outputs:  tensor([[0.1993, 0.6937],\n","        [0.8364, 0.2350],\n","        [0.8258, 0.2474],\n","        [0.9605, 0.0963],\n","        [0.0742, 0.8843]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4156, grad_fn=<NllLossBackward>)\n","epoch 768, loss 0.4156002402305603\n","outputs:  tensor([[0.1989, 0.6941],\n","        [0.8366, 0.2346],\n","        [0.8260, 0.2471],\n","        [0.9606, 0.0960],\n","        [0.0740, 0.8847]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4154, grad_fn=<NllLossBackward>)\n","epoch 769, loss 0.415399968624115\n","outputs:  tensor([[0.1986, 0.6945],\n","        [0.8368, 0.2343],\n","        [0.8263, 0.2468],\n","        [0.9607, 0.0957],\n","        [0.0738, 0.8851]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4152, grad_fn=<NllLossBackward>)\n","epoch 770, loss 0.4152001440525055\n","outputs:  tensor([[0.1983, 0.6950],\n","        [0.8371, 0.2340],\n","        [0.8265, 0.2464],\n","        [0.9608, 0.0954],\n","        [0.0735, 0.8854]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4150, grad_fn=<NllLossBackward>)\n","epoch 771, loss 0.415000855922699\n","outputs:  tensor([[0.1979, 0.6954],\n","        [0.8373, 0.2337],\n","        [0.8267, 0.2461],\n","        [0.9610, 0.0951],\n","        [0.0733, 0.8858]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4148, grad_fn=<NllLossBackward>)\n","epoch 772, loss 0.41480207443237305\n","outputs:  tensor([[0.1976, 0.6959],\n","        [0.8376, 0.2334],\n","        [0.8270, 0.2458],\n","        [0.9611, 0.0948],\n","        [0.0730, 0.8862]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4146, grad_fn=<NllLossBackward>)\n","epoch 773, loss 0.4146037697792053\n","outputs:  tensor([[0.1973, 0.6963],\n","        [0.8378, 0.2331],\n","        [0.8272, 0.2455],\n","        [0.9612, 0.0945],\n","        [0.0728, 0.8865]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4144, grad_fn=<NllLossBackward>)\n","epoch 774, loss 0.4144059121608734\n","outputs:  tensor([[0.1970, 0.6968],\n","        [0.8380, 0.2328],\n","        [0.8274, 0.2452],\n","        [0.9614, 0.0942],\n","        [0.0726, 0.8869]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4142, grad_fn=<NllLossBackward>)\n","epoch 775, loss 0.41420865058898926\n","outputs:  tensor([[0.1967, 0.6972],\n","        [0.8383, 0.2324],\n","        [0.8277, 0.2449],\n","        [0.9615, 0.0939],\n","        [0.0723, 0.8873]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4140, grad_fn=<NllLossBackward>)\n","epoch 776, loss 0.4140118658542633\n","outputs:  tensor([[0.1963, 0.6976],\n","        [0.8385, 0.2321],\n","        [0.8279, 0.2446],\n","        [0.9616, 0.0936],\n","        [0.0721, 0.8876]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4138, grad_fn=<NllLossBackward>)\n","epoch 777, loss 0.41381555795669556\n","outputs:  tensor([[0.1960, 0.6981],\n","        [0.8387, 0.2318],\n","        [0.8281, 0.2443],\n","        [0.9617, 0.0933],\n","        [0.0719, 0.8880]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4136, grad_fn=<NllLossBackward>)\n","epoch 778, loss 0.4136196970939636\n","outputs:  tensor([[0.1957, 0.6985],\n","        [0.8390, 0.2315],\n","        [0.8284, 0.2440],\n","        [0.9619, 0.0930],\n","        [0.0716, 0.8884]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4134, grad_fn=<NllLossBackward>)\n","epoch 779, loss 0.41342440247535706\n","outputs:  tensor([[0.1954, 0.6989],\n","        [0.8392, 0.2312],\n","        [0.8286, 0.2437],\n","        [0.9620, 0.0927],\n","        [0.0714, 0.8887]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4132, grad_fn=<NllLossBackward>)\n","epoch 780, loss 0.4132295548915863\n","outputs:  tensor([[0.1951, 0.6994],\n","        [0.8394, 0.2309],\n","        [0.8288, 0.2434],\n","        [0.9621, 0.0924],\n","        [0.0712, 0.8891]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4130, grad_fn=<NllLossBackward>)\n","epoch 781, loss 0.41303524374961853\n","outputs:  tensor([[0.1947, 0.6998],\n","        [0.8397, 0.2306],\n","        [0.8290, 0.2431],\n","        [0.9622, 0.0921],\n","        [0.0709, 0.8894]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4128, grad_fn=<NllLossBackward>)\n","epoch 782, loss 0.41284140944480896\n","outputs:  tensor([[0.1944, 0.7002],\n","        [0.8399, 0.2303],\n","        [0.8293, 0.2428],\n","        [0.9624, 0.0918],\n","        [0.0707, 0.8898]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4126, grad_fn=<NllLossBackward>)\n","epoch 783, loss 0.4126480519771576\n","outputs:  tensor([[0.1941, 0.7007],\n","        [0.8401, 0.2300],\n","        [0.8295, 0.2425],\n","        [0.9625, 0.0915],\n","        [0.0705, 0.8902]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4125, grad_fn=<NllLossBackward>)\n","epoch 784, loss 0.4124552309513092\n","outputs:  tensor([[0.1938, 0.7011],\n","        [0.8404, 0.2296],\n","        [0.8297, 0.2422],\n","        [0.9626, 0.0912],\n","        [0.0702, 0.8905]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4123, grad_fn=<NllLossBackward>)\n","epoch 785, loss 0.41226282715797424\n","outputs:  tensor([[0.1935, 0.7016],\n","        [0.8406, 0.2293],\n","        [0.8299, 0.2419],\n","        [0.9627, 0.0909],\n","        [0.0700, 0.8909]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4121, grad_fn=<NllLossBackward>)\n","epoch 786, loss 0.4120709300041199\n","outputs:  tensor([[0.1931, 0.7020],\n","        [0.8408, 0.2290],\n","        [0.8302, 0.2416],\n","        [0.9628, 0.0906],\n","        [0.0698, 0.8912]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4119, grad_fn=<NllLossBackward>)\n","epoch 787, loss 0.4118794798851013\n","outputs:  tensor([[0.1928, 0.7024],\n","        [0.8411, 0.2287],\n","        [0.8304, 0.2413],\n","        [0.9630, 0.0903],\n","        [0.0696, 0.8916]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4117, grad_fn=<NllLossBackward>)\n","epoch 788, loss 0.4116886258125305\n","outputs:  tensor([[0.1925, 0.7028],\n","        [0.8413, 0.2284],\n","        [0.8306, 0.2410],\n","        [0.9631, 0.0900],\n","        [0.0693, 0.8919]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4115, grad_fn=<NllLossBackward>)\n","epoch 789, loss 0.41149815917015076\n","outputs:  tensor([[0.1922, 0.7033],\n","        [0.8415, 0.2281],\n","        [0.8309, 0.2407],\n","        [0.9632, 0.0897],\n","        [0.0691, 0.8923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4113, grad_fn=<NllLossBackward>)\n","epoch 790, loss 0.4113081991672516\n","outputs:  tensor([[0.1919, 0.7037],\n","        [0.8418, 0.2278],\n","        [0.8311, 0.2404],\n","        [0.9633, 0.0895],\n","        [0.0689, 0.8926]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4111, grad_fn=<NllLossBackward>)\n","epoch 791, loss 0.411118745803833\n","outputs:  tensor([[0.1916, 0.7041],\n","        [0.8420, 0.2275],\n","        [0.8313, 0.2402],\n","        [0.9634, 0.0892],\n","        [0.0687, 0.8930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4109, grad_fn=<NllLossBackward>)\n","epoch 792, loss 0.41092967987060547\n","outputs:  tensor([[0.1913, 0.7046],\n","        [0.8422, 0.2272],\n","        [0.8315, 0.2399],\n","        [0.9636, 0.0889],\n","        [0.0684, 0.8933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4107, grad_fn=<NllLossBackward>)\n","epoch 793, loss 0.4107411503791809\n","outputs:  tensor([[0.1910, 0.7050],\n","        [0.8425, 0.2269],\n","        [0.8318, 0.2396],\n","        [0.9637, 0.0886],\n","        [0.0682, 0.8936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4106, grad_fn=<NllLossBackward>)\n","epoch 794, loss 0.4105531573295593\n","outputs:  tensor([[0.1906, 0.7054],\n","        [0.8427, 0.2266],\n","        [0.8320, 0.2393],\n","        [0.9638, 0.0883],\n","        [0.0680, 0.8940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4104, grad_fn=<NllLossBackward>)\n","epoch 795, loss 0.41036558151245117\n","outputs:  tensor([[0.1903, 0.7059],\n","        [0.8429, 0.2263],\n","        [0.8322, 0.2390],\n","        [0.9639, 0.0880],\n","        [0.0678, 0.8943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4102, grad_fn=<NllLossBackward>)\n","epoch 796, loss 0.4101785123348236\n","outputs:  tensor([[0.1900, 0.7063],\n","        [0.8431, 0.2260],\n","        [0.8324, 0.2387],\n","        [0.9640, 0.0878],\n","        [0.0676, 0.8947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4100, grad_fn=<NllLossBackward>)\n","epoch 797, loss 0.4099918305873871\n","outputs:  tensor([[0.1897, 0.7067],\n","        [0.8434, 0.2257],\n","        [0.8326, 0.2384],\n","        [0.9642, 0.0875],\n","        [0.0673, 0.8950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4098, grad_fn=<NllLossBackward>)\n","epoch 798, loss 0.40980568528175354\n","outputs:  tensor([[0.1894, 0.7071],\n","        [0.8436, 0.2254],\n","        [0.8329, 0.2381],\n","        [0.9643, 0.0872],\n","        [0.0671, 0.8953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4096, grad_fn=<NllLossBackward>)\n","epoch 799, loss 0.4096200466156006\n","outputs:  tensor([[0.1891, 0.7076],\n","        [0.8438, 0.2251],\n","        [0.8331, 0.2378],\n","        [0.9644, 0.0869],\n","        [0.0669, 0.8957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4094, grad_fn=<NllLossBackward>)\n","epoch 800, loss 0.40943485498428345\n","outputs:  tensor([[0.1888, 0.7080],\n","        [0.8440, 0.2247],\n","        [0.8333, 0.2375],\n","        [0.9645, 0.0866],\n","        [0.0667, 0.8960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4093, grad_fn=<NllLossBackward>)\n","epoch 801, loss 0.40925008058547974\n","Parameter containing:\n","tensor([[-0.1575, -0.4600,  0.2028],\n","        [-0.7895, -0.4027, -0.0683],\n","        [-0.7967, -0.5530, -0.1147],\n","        [-0.3636, -0.3354, -0.0006]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4557, -0.3689,  0.0773,  0.0921], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7066,  0.5420,  0.8654, -0.0081],\n","        [ 0.0245, -0.6655, -0.4332, -0.3812]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3127, -0.5325], requires_grad=True)\n","outputs:  tensor([[0.1885, 0.7084],\n","        [0.8443, 0.2244],\n","        [0.8335, 0.2372],\n","        [0.9646, 0.0864],\n","        [0.0665, 0.8963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4091, grad_fn=<NllLossBackward>)\n","epoch 802, loss 0.4090658128261566\n","outputs:  tensor([[0.1882, 0.7088],\n","        [0.8445, 0.2241],\n","        [0.8337, 0.2369],\n","        [0.9647, 0.0861],\n","        [0.0663, 0.8967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4089, grad_fn=<NllLossBackward>)\n","epoch 803, loss 0.4088819622993469\n","outputs:  tensor([[0.1879, 0.7093],\n","        [0.8447, 0.2238],\n","        [0.8340, 0.2366],\n","        [0.9648, 0.0858],\n","        [0.0661, 0.8970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4087, grad_fn=<NllLossBackward>)\n","epoch 804, loss 0.4086986482143402\n","outputs:  tensor([[0.1876, 0.7097],\n","        [0.8449, 0.2235],\n","        [0.8342, 0.2363],\n","        [0.9650, 0.0855],\n","        [0.0658, 0.8973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4085, grad_fn=<NllLossBackward>)\n","epoch 805, loss 0.4085157811641693\n","outputs:  tensor([[0.1873, 0.7101],\n","        [0.8452, 0.2232],\n","        [0.8344, 0.2360],\n","        [0.9651, 0.0853],\n","        [0.0656, 0.8977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4083, grad_fn=<NllLossBackward>)\n","epoch 806, loss 0.40833336114883423\n","outputs:  tensor([[0.1870, 0.7105],\n","        [0.8454, 0.2229],\n","        [0.8346, 0.2357],\n","        [0.9652, 0.0850],\n","        [0.0654, 0.8980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4082, grad_fn=<NllLossBackward>)\n","epoch 807, loss 0.40815138816833496\n","outputs:  tensor([[0.1867, 0.7110],\n","        [0.8456, 0.2226],\n","        [0.8348, 0.2355],\n","        [0.9653, 0.0847],\n","        [0.0652, 0.8983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4080, grad_fn=<NllLossBackward>)\n","epoch 808, loss 0.40796995162963867\n","outputs:  tensor([[0.1864, 0.7114],\n","        [0.8458, 0.2223],\n","        [0.8351, 0.2352],\n","        [0.9654, 0.0845],\n","        [0.0650, 0.8986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4078, grad_fn=<NllLossBackward>)\n","epoch 809, loss 0.4077889025211334\n","outputs:  tensor([[0.1861, 0.7118],\n","        [0.8461, 0.2220],\n","        [0.8353, 0.2349],\n","        [0.9655, 0.0842],\n","        [0.0648, 0.8990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4076, grad_fn=<NllLossBackward>)\n","epoch 810, loss 0.4076083302497864\n","outputs:  tensor([[0.1858, 0.7122],\n","        [0.8463, 0.2217],\n","        [0.8355, 0.2346],\n","        [0.9656, 0.0839],\n","        [0.0646, 0.8993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4074, grad_fn=<NllLossBackward>)\n","epoch 811, loss 0.4074282646179199\n","outputs:  tensor([[0.1855, 0.7126],\n","        [0.8465, 0.2214],\n","        [0.8357, 0.2343],\n","        [0.9657, 0.0836],\n","        [0.0644, 0.8996]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4072, grad_fn=<NllLossBackward>)\n","epoch 812, loss 0.4072485864162445\n","outputs:  tensor([[0.1852, 0.7131],\n","        [0.8467, 0.2211],\n","        [0.8359, 0.2340],\n","        [0.9659, 0.0834],\n","        [0.0642, 0.8999]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4071, grad_fn=<NllLossBackward>)\n","epoch 813, loss 0.4070693850517273\n","outputs:  tensor([[0.1849, 0.7135],\n","        [0.8469, 0.2208],\n","        [0.8362, 0.2337],\n","        [0.9660, 0.0831],\n","        [0.0640, 0.9003]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4069, grad_fn=<NllLossBackward>)\n","epoch 814, loss 0.4068906307220459\n","outputs:  tensor([[0.1846, 0.7139],\n","        [0.8472, 0.2205],\n","        [0.8364, 0.2334],\n","        [0.9661, 0.0828],\n","        [0.0638, 0.9006]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4067, grad_fn=<NllLossBackward>)\n","epoch 815, loss 0.4067123532295227\n","outputs:  tensor([[0.1843, 0.7143],\n","        [0.8474, 0.2202],\n","        [0.8366, 0.2331],\n","        [0.9662, 0.0826],\n","        [0.0636, 0.9009]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4065, grad_fn=<NllLossBackward>)\n","epoch 816, loss 0.4065345227718353\n","outputs:  tensor([[0.1840, 0.7147],\n","        [0.8476, 0.2200],\n","        [0.8368, 0.2329],\n","        [0.9663, 0.0823],\n","        [0.0634, 0.9012]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4064, grad_fn=<NllLossBackward>)\n","epoch 817, loss 0.40635713934898376\n","outputs:  tensor([[0.1837, 0.7151],\n","        [0.8478, 0.2197],\n","        [0.8370, 0.2326],\n","        [0.9664, 0.0821],\n","        [0.0632, 0.9015]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4062, grad_fn=<NllLossBackward>)\n","epoch 818, loss 0.4061802327632904\n","outputs:  tensor([[0.1834, 0.7156],\n","        [0.8480, 0.2194],\n","        [0.8372, 0.2323],\n","        [0.9665, 0.0818],\n","        [0.0630, 0.9018]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4060, grad_fn=<NllLossBackward>)\n","epoch 819, loss 0.4060036540031433\n","outputs:  tensor([[0.1831, 0.7160],\n","        [0.8483, 0.2191],\n","        [0.8374, 0.2320],\n","        [0.9666, 0.0815],\n","        [0.0628, 0.9022]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4058, grad_fn=<NllLossBackward>)\n","epoch 820, loss 0.4058276116847992\n","outputs:  tensor([[0.1828, 0.7164],\n","        [0.8485, 0.2188],\n","        [0.8377, 0.2317],\n","        [0.9667, 0.0813],\n","        [0.0626, 0.9025]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4057, grad_fn=<NllLossBackward>)\n","epoch 821, loss 0.4056519865989685\n","outputs:  tensor([[0.1825, 0.7168],\n","        [0.8487, 0.2185],\n","        [0.8379, 0.2314],\n","        [0.9668, 0.0810],\n","        [0.0624, 0.9028]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4055, grad_fn=<NllLossBackward>)\n","epoch 822, loss 0.4054768979549408\n","outputs:  tensor([[0.1822, 0.7172],\n","        [0.8489, 0.2182],\n","        [0.8381, 0.2311],\n","        [0.9669, 0.0808],\n","        [0.0622, 0.9031]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4053, grad_fn=<NllLossBackward>)\n","epoch 823, loss 0.4053021967411041\n","outputs:  tensor([[0.1819, 0.7176],\n","        [0.8491, 0.2179],\n","        [0.8383, 0.2309],\n","        [0.9670, 0.0805],\n","        [0.0620, 0.9034]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4051, grad_fn=<NllLossBackward>)\n","epoch 824, loss 0.4051279127597809\n","outputs:  tensor([[0.1816, 0.7180],\n","        [0.8493, 0.2176],\n","        [0.8385, 0.2306],\n","        [0.9671, 0.0802],\n","        [0.0618, 0.9037]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4050, grad_fn=<NllLossBackward>)\n","epoch 825, loss 0.40495410561561584\n","outputs:  tensor([[0.1813, 0.7184],\n","        [0.8496, 0.2173],\n","        [0.8387, 0.2303],\n","        [0.9672, 0.0800],\n","        [0.0616, 0.9040]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4048, grad_fn=<NllLossBackward>)\n","epoch 826, loss 0.40478068590164185\n","outputs:  tensor([[0.1810, 0.7189],\n","        [0.8498, 0.2170],\n","        [0.8389, 0.2300],\n","        [0.9673, 0.0797],\n","        [0.0614, 0.9043]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4046, grad_fn=<NllLossBackward>)\n","epoch 827, loss 0.40460777282714844\n","outputs:  tensor([[0.1807, 0.7193],\n","        [0.8500, 0.2167],\n","        [0.8391, 0.2297],\n","        [0.9675, 0.0795],\n","        [0.0612, 0.9046]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4044, grad_fn=<NllLossBackward>)\n","epoch 828, loss 0.40443533658981323\n","outputs:  tensor([[0.1804, 0.7197],\n","        [0.8502, 0.2164],\n","        [0.8394, 0.2294],\n","        [0.9676, 0.0792],\n","        [0.0610, 0.9049]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4043, grad_fn=<NllLossBackward>)\n","epoch 829, loss 0.4042631983757019\n","outputs:  tensor([[0.1802, 0.7201],\n","        [0.8504, 0.2161],\n","        [0.8396, 0.2291],\n","        [0.9677, 0.0790],\n","        [0.0608, 0.9052]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4041, grad_fn=<NllLossBackward>)\n","epoch 830, loss 0.40409159660339355\n","outputs:  tensor([[0.1799, 0.7205],\n","        [0.8506, 0.2158],\n","        [0.8398, 0.2289],\n","        [0.9678, 0.0787],\n","        [0.0606, 0.9055]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4039, grad_fn=<NllLossBackward>)\n","epoch 831, loss 0.40392035245895386\n","outputs:  tensor([[0.1796, 0.7209],\n","        [0.8509, 0.2156],\n","        [0.8400, 0.2286],\n","        [0.9679, 0.0785],\n","        [0.0604, 0.9058]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4037, grad_fn=<NllLossBackward>)\n","epoch 832, loss 0.40374961495399475\n","outputs:  tensor([[0.1793, 0.7213],\n","        [0.8511, 0.2153],\n","        [0.8402, 0.2283],\n","        [0.9680, 0.0782],\n","        [0.0603, 0.9061]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4036, grad_fn=<NllLossBackward>)\n","epoch 833, loss 0.40357932448387146\n","outputs:  tensor([[0.1790, 0.7217],\n","        [0.8513, 0.2150],\n","        [0.8404, 0.2280],\n","        [0.9681, 0.0780],\n","        [0.0601, 0.9064]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4034, grad_fn=<NllLossBackward>)\n","epoch 834, loss 0.403409481048584\n","outputs:  tensor([[0.1787, 0.7221],\n","        [0.8515, 0.2147],\n","        [0.8406, 0.2277],\n","        [0.9682, 0.0777],\n","        [0.0599, 0.9067]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4032, grad_fn=<NllLossBackward>)\n","epoch 835, loss 0.403239905834198\n","outputs:  tensor([[0.1784, 0.7225],\n","        [0.8517, 0.2144],\n","        [0.8408, 0.2275],\n","        [0.9683, 0.0775],\n","        [0.0597, 0.9070]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4031, grad_fn=<NllLossBackward>)\n","epoch 836, loss 0.40307092666625977\n","outputs:  tensor([[0.1782, 0.7229],\n","        [0.8519, 0.2141],\n","        [0.8410, 0.2272],\n","        [0.9684, 0.0772],\n","        [0.0595, 0.9073]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4029, grad_fn=<NllLossBackward>)\n","epoch 837, loss 0.40290242433547974\n","outputs:  tensor([[0.1779, 0.7233],\n","        [0.8521, 0.2138],\n","        [0.8412, 0.2269],\n","        [0.9685, 0.0770],\n","        [0.0593, 0.9076]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4027, grad_fn=<NllLossBackward>)\n","epoch 838, loss 0.4027341902256012\n","outputs:  tensor([[0.1776, 0.7237],\n","        [0.8523, 0.2135],\n","        [0.8414, 0.2266],\n","        [0.9686, 0.0768],\n","        [0.0591, 0.9079]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4026, grad_fn=<NllLossBackward>)\n","epoch 839, loss 0.4025663733482361\n","outputs:  tensor([[0.1773, 0.7241],\n","        [0.8525, 0.2132],\n","        [0.8417, 0.2263],\n","        [0.9687, 0.0765],\n","        [0.0590, 0.9082]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4024, grad_fn=<NllLossBackward>)\n","epoch 840, loss 0.40239906311035156\n","outputs:  tensor([[0.1770, 0.7245],\n","        [0.8528, 0.2130],\n","        [0.8419, 0.2261],\n","        [0.9688, 0.0763],\n","        [0.0588, 0.9085]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4022, grad_fn=<NllLossBackward>)\n","epoch 841, loss 0.40223217010498047\n","outputs:  tensor([[0.1767, 0.7249],\n","        [0.8530, 0.2127],\n","        [0.8421, 0.2258],\n","        [0.9689, 0.0760],\n","        [0.0586, 0.9088]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4021, grad_fn=<NllLossBackward>)\n","epoch 842, loss 0.4020656943321228\n","outputs:  tensor([[0.1765, 0.7253],\n","        [0.8532, 0.2124],\n","        [0.8423, 0.2255],\n","        [0.9690, 0.0758],\n","        [0.0584, 0.9091]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4019, grad_fn=<NllLossBackward>)\n","epoch 843, loss 0.40189963579177856\n","outputs:  tensor([[0.1762, 0.7257],\n","        [0.8534, 0.2121],\n","        [0.8425, 0.2252],\n","        [0.9691, 0.0755],\n","        [0.0582, 0.9093]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4017, grad_fn=<NllLossBackward>)\n","epoch 844, loss 0.40173396468162537\n","outputs:  tensor([[0.1759, 0.7261],\n","        [0.8536, 0.2118],\n","        [0.8427, 0.2250],\n","        [0.9692, 0.0753],\n","        [0.0580, 0.9096]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4016, grad_fn=<NllLossBackward>)\n","epoch 845, loss 0.40156883001327515\n","outputs:  tensor([[0.1756, 0.7265],\n","        [0.8538, 0.2115],\n","        [0.8429, 0.2247],\n","        [0.9693, 0.0751],\n","        [0.0579, 0.9099]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4014, grad_fn=<NllLossBackward>)\n","epoch 846, loss 0.4014039933681488\n","outputs:  tensor([[0.1753, 0.7269],\n","        [0.8540, 0.2112],\n","        [0.8431, 0.2244],\n","        [0.9694, 0.0748],\n","        [0.0577, 0.9102]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4012, grad_fn=<NllLossBackward>)\n","epoch 847, loss 0.40123969316482544\n","outputs:  tensor([[0.1751, 0.7273],\n","        [0.8542, 0.2110],\n","        [0.8433, 0.2241],\n","        [0.9695, 0.0746],\n","        [0.0575, 0.9105]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4011, grad_fn=<NllLossBackward>)\n","epoch 848, loss 0.40107566118240356\n","outputs:  tensor([[0.1748, 0.7277],\n","        [0.8544, 0.2107],\n","        [0.8435, 0.2238],\n","        [0.9696, 0.0744],\n","        [0.0573, 0.9108]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4009, grad_fn=<NllLossBackward>)\n","epoch 849, loss 0.4009121060371399\n","outputs:  tensor([[0.1745, 0.7281],\n","        [0.8546, 0.2104],\n","        [0.8437, 0.2236],\n","        [0.9696, 0.0741],\n","        [0.0572, 0.9110]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4007, grad_fn=<NllLossBackward>)\n","epoch 850, loss 0.40074896812438965\n","outputs:  tensor([[0.1742, 0.7285],\n","        [0.8548, 0.2101],\n","        [0.8439, 0.2233],\n","        [0.9697, 0.0739],\n","        [0.0570, 0.9113]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4006, grad_fn=<NllLossBackward>)\n","epoch 851, loss 0.4005863070487976\n","Parameter containing:\n","tensor([[-0.1649, -0.4708,  0.2020],\n","        [-0.8063, -0.4266, -0.0698],\n","        [-0.8134, -0.5768, -0.1163],\n","        [-0.3699, -0.3440, -0.0011]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4577, -0.3645,  0.0818,  0.0937], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7168,  0.5562,  0.8834,  0.0015],\n","        [ 0.0098, -0.6863, -0.4594, -0.3952]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3156, -0.5367], requires_grad=True)\n","outputs:  tensor([[0.1739, 0.7289],\n","        [0.8550, 0.2098],\n","        [0.8441, 0.2230],\n","        [0.9698, 0.0737],\n","        [0.0568, 0.9116]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4004, grad_fn=<NllLossBackward>)\n","epoch 852, loss 0.4004240036010742\n","outputs:  tensor([[0.1737, 0.7293],\n","        [0.8552, 0.2095],\n","        [0.8443, 0.2227],\n","        [0.9699, 0.0734],\n","        [0.0566, 0.9119]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4003, grad_fn=<NllLossBackward>)\n","epoch 853, loss 0.40026211738586426\n","outputs:  tensor([[0.1734, 0.7297],\n","        [0.8555, 0.2093],\n","        [0.8445, 0.2225],\n","        [0.9700, 0.0732],\n","        [0.0565, 0.9122]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.4001, grad_fn=<NllLossBackward>)\n","epoch 854, loss 0.40010061860084534\n","outputs:  tensor([[0.1731, 0.7301],\n","        [0.8557, 0.2090],\n","        [0.8447, 0.2222],\n","        [0.9701, 0.0730],\n","        [0.0563, 0.9124]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3999, grad_fn=<NllLossBackward>)\n","epoch 855, loss 0.39993953704833984\n","outputs:  tensor([[0.1728, 0.7305],\n","        [0.8559, 0.2087],\n","        [0.8449, 0.2219],\n","        [0.9702, 0.0727],\n","        [0.0561, 0.9127]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3998, grad_fn=<NllLossBackward>)\n","epoch 856, loss 0.39977890253067017\n","outputs:  tensor([[0.1726, 0.7309],\n","        [0.8561, 0.2084],\n","        [0.8451, 0.2216],\n","        [0.9703, 0.0725],\n","        [0.0559, 0.9130]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3996, grad_fn=<NllLossBackward>)\n","epoch 857, loss 0.3996186852455139\n","outputs:  tensor([[0.1723, 0.7313],\n","        [0.8563, 0.2081],\n","        [0.8453, 0.2214],\n","        [0.9704, 0.0723],\n","        [0.0558, 0.9133]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3995, grad_fn=<NllLossBackward>)\n","epoch 858, loss 0.39945879578590393\n","outputs:  tensor([[0.1720, 0.7317],\n","        [0.8565, 0.2079],\n","        [0.8455, 0.2211],\n","        [0.9705, 0.0720],\n","        [0.0556, 0.9135]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3993, grad_fn=<NllLossBackward>)\n","epoch 859, loss 0.39929938316345215\n","outputs:  tensor([[0.1718, 0.7321],\n","        [0.8567, 0.2076],\n","        [0.8457, 0.2208],\n","        [0.9706, 0.0718],\n","        [0.0554, 0.9138]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3991, grad_fn=<NllLossBackward>)\n","epoch 860, loss 0.39914026856422424\n","outputs:  tensor([[0.1715, 0.7325],\n","        [0.8569, 0.2073],\n","        [0.8459, 0.2206],\n","        [0.9707, 0.0716],\n","        [0.0553, 0.9141]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3990, grad_fn=<NllLossBackward>)\n","epoch 861, loss 0.39898163080215454\n","outputs:  tensor([[0.1712, 0.7329],\n","        [0.8571, 0.2070],\n","        [0.8461, 0.2203],\n","        [0.9708, 0.0714],\n","        [0.0551, 0.9144]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3988, grad_fn=<NllLossBackward>)\n","epoch 862, loss 0.3988233804702759\n","outputs:  tensor([[0.1709, 0.7332],\n","        [0.8573, 0.2067],\n","        [0.8463, 0.2200],\n","        [0.9709, 0.0711],\n","        [0.0549, 0.9146]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3987, grad_fn=<NllLossBackward>)\n","epoch 863, loss 0.39866557717323303\n","outputs:  tensor([[0.1707, 0.7336],\n","        [0.8575, 0.2065],\n","        [0.8465, 0.2197],\n","        [0.9710, 0.0709],\n","        [0.0547, 0.9149]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3985, grad_fn=<NllLossBackward>)\n","epoch 864, loss 0.39850813150405884\n","outputs:  tensor([[0.1704, 0.7340],\n","        [0.8577, 0.2062],\n","        [0.8467, 0.2195],\n","        [0.9710, 0.0707],\n","        [0.0546, 0.9152]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3984, grad_fn=<NllLossBackward>)\n","epoch 865, loss 0.39835110306739807\n","outputs:  tensor([[0.1701, 0.7344],\n","        [0.8579, 0.2059],\n","        [0.8469, 0.2192],\n","        [0.9711, 0.0705],\n","        [0.0544, 0.9154]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3982, grad_fn=<NllLossBackward>)\n","epoch 866, loss 0.39819446206092834\n","outputs:  tensor([[0.1699, 0.7348],\n","        [0.8581, 0.2056],\n","        [0.8471, 0.2189],\n","        [0.9712, 0.0702],\n","        [0.0542, 0.9157]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3980, grad_fn=<NllLossBackward>)\n","epoch 867, loss 0.39803820848464966\n","outputs:  tensor([[0.1696, 0.7352],\n","        [0.8583, 0.2054],\n","        [0.8473, 0.2187],\n","        [0.9713, 0.0700],\n","        [0.0541, 0.9159]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3979, grad_fn=<NllLossBackward>)\n","epoch 868, loss 0.3978823721408844\n","outputs:  tensor([[0.1693, 0.7356],\n","        [0.8585, 0.2051],\n","        [0.8475, 0.2184],\n","        [0.9714, 0.0698],\n","        [0.0539, 0.9162]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3977, grad_fn=<NllLossBackward>)\n","epoch 869, loss 0.3977269232273102\n","outputs:  tensor([[0.1691, 0.7360],\n","        [0.8587, 0.2048],\n","        [0.8477, 0.2181],\n","        [0.9715, 0.0696],\n","        [0.0538, 0.9165]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3976, grad_fn=<NllLossBackward>)\n","epoch 870, loss 0.397571861743927\n","outputs:  tensor([[0.1688, 0.7363],\n","        [0.8589, 0.2045],\n","        [0.8479, 0.2179],\n","        [0.9716, 0.0694],\n","        [0.0536, 0.9167]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3974, grad_fn=<NllLossBackward>)\n","epoch 871, loss 0.3974171578884125\n","outputs:  tensor([[0.1685, 0.7367],\n","        [0.8591, 0.2043],\n","        [0.8481, 0.2176],\n","        [0.9717, 0.0691],\n","        [0.0534, 0.9170]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3973, grad_fn=<NllLossBackward>)\n","epoch 872, loss 0.39726290106773376\n","outputs:  tensor([[0.1683, 0.7371],\n","        [0.8593, 0.2040],\n","        [0.8483, 0.2173],\n","        [0.9718, 0.0689],\n","        [0.0533, 0.9173]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3971, grad_fn=<NllLossBackward>)\n","epoch 873, loss 0.3971090316772461\n","outputs:  tensor([[0.1680, 0.7375],\n","        [0.8595, 0.2037],\n","        [0.8485, 0.2171],\n","        [0.9718, 0.0687],\n","        [0.0531, 0.9175]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3970, grad_fn=<NllLossBackward>)\n","epoch 874, loss 0.3969555199146271\n","outputs:  tensor([[0.1677, 0.7379],\n","        [0.8597, 0.2034],\n","        [0.8487, 0.2168],\n","        [0.9719, 0.0685],\n","        [0.0529, 0.9178]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3968, grad_fn=<NllLossBackward>)\n","epoch 875, loss 0.3968024253845215\n","outputs:  tensor([[0.1675, 0.7383],\n","        [0.8599, 0.2032],\n","        [0.8489, 0.2165],\n","        [0.9720, 0.0683],\n","        [0.0528, 0.9180]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3966, grad_fn=<NllLossBackward>)\n","epoch 876, loss 0.39664971828460693\n","outputs:  tensor([[0.1672, 0.7386],\n","        [0.8601, 0.2029],\n","        [0.8491, 0.2163],\n","        [0.9721, 0.0681],\n","        [0.0526, 0.9183]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3965, grad_fn=<NllLossBackward>)\n","epoch 877, loss 0.3964974284172058\n","outputs:  tensor([[0.1670, 0.7390],\n","        [0.8603, 0.2026],\n","        [0.8493, 0.2160],\n","        [0.9722, 0.0679],\n","        [0.0525, 0.9185]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3963, grad_fn=<NllLossBackward>)\n","epoch 878, loss 0.39634543657302856\n","outputs:  tensor([[0.1667, 0.7394],\n","        [0.8605, 0.2024],\n","        [0.8495, 0.2157],\n","        [0.9723, 0.0676],\n","        [0.0523, 0.9188]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3962, grad_fn=<NllLossBackward>)\n","epoch 879, loss 0.39619383215904236\n","outputs:  tensor([[0.1664, 0.7398],\n","        [0.8607, 0.2021],\n","        [0.8497, 0.2155],\n","        [0.9724, 0.0674],\n","        [0.0522, 0.9190]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3960, grad_fn=<NllLossBackward>)\n","epoch 880, loss 0.39604267477989197\n","outputs:  tensor([[0.1662, 0.7402],\n","        [0.8609, 0.2018],\n","        [0.8499, 0.2152],\n","        [0.9724, 0.0672],\n","        [0.0520, 0.9193]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3959, grad_fn=<NllLossBackward>)\n","epoch 881, loss 0.3958919048309326\n","outputs:  tensor([[0.1659, 0.7405],\n","        [0.8610, 0.2015],\n","        [0.8500, 0.2149],\n","        [0.9725, 0.0670],\n","        [0.0518, 0.9195]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3957, grad_fn=<NllLossBackward>)\n","epoch 882, loss 0.39574146270751953\n","outputs:  tensor([[0.1657, 0.7409],\n","        [0.8612, 0.2013],\n","        [0.8502, 0.2147],\n","        [0.9726, 0.0668],\n","        [0.0517, 0.9198]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3956, grad_fn=<NllLossBackward>)\n","epoch 883, loss 0.3955914080142975\n","outputs:  tensor([[0.1654, 0.7413],\n","        [0.8614, 0.2010],\n","        [0.8504, 0.2144],\n","        [0.9727, 0.0666],\n","        [0.0515, 0.9200]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3954, grad_fn=<NllLossBackward>)\n","epoch 884, loss 0.3954417109489441\n","outputs:  tensor([[0.1651, 0.7417],\n","        [0.8616, 0.2007],\n","        [0.8506, 0.2142],\n","        [0.9728, 0.0664],\n","        [0.0514, 0.9203]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3953, grad_fn=<NllLossBackward>)\n","epoch 885, loss 0.3952924609184265\n","outputs:  tensor([[0.1649, 0.7420],\n","        [0.8618, 0.2005],\n","        [0.8508, 0.2139],\n","        [0.9729, 0.0662],\n","        [0.0512, 0.9205]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3951, grad_fn=<NllLossBackward>)\n","epoch 886, loss 0.3951435685157776\n","outputs:  tensor([[0.1646, 0.7424],\n","        [0.8620, 0.2002],\n","        [0.8510, 0.2136],\n","        [0.9729, 0.0660],\n","        [0.0511, 0.9208]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3950, grad_fn=<NllLossBackward>)\n","epoch 887, loss 0.3949950337409973\n","outputs:  tensor([[0.1644, 0.7428],\n","        [0.8622, 0.1999],\n","        [0.8512, 0.2134],\n","        [0.9730, 0.0658],\n","        [0.0509, 0.9210]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3948, grad_fn=<NllLossBackward>)\n","epoch 888, loss 0.3948468267917633\n","outputs:  tensor([[0.1641, 0.7432],\n","        [0.8624, 0.1997],\n","        [0.8514, 0.2131],\n","        [0.9731, 0.0656],\n","        [0.0508, 0.9213]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3947, grad_fn=<NllLossBackward>)\n","epoch 889, loss 0.3946990966796875\n","outputs:  tensor([[0.1639, 0.7435],\n","        [0.8626, 0.1994],\n","        [0.8516, 0.2128],\n","        [0.9732, 0.0654],\n","        [0.0506, 0.9215]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3946, grad_fn=<NllLossBackward>)\n","epoch 890, loss 0.39455166459083557\n","outputs:  tensor([[0.1636, 0.7439],\n","        [0.8628, 0.1991],\n","        [0.8518, 0.2126],\n","        [0.9733, 0.0651],\n","        [0.0505, 0.9218]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3944, grad_fn=<NllLossBackward>)\n","epoch 891, loss 0.39440464973449707\n","outputs:  tensor([[0.1633, 0.7443],\n","        [0.8630, 0.1989],\n","        [0.8520, 0.2123],\n","        [0.9734, 0.0649],\n","        [0.0503, 0.9220]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3943, grad_fn=<NllLossBackward>)\n","epoch 892, loss 0.39425793290138245\n","outputs:  tensor([[0.1631, 0.7447],\n","        [0.8632, 0.1986],\n","        [0.8521, 0.2121],\n","        [0.9734, 0.0647],\n","        [0.0502, 0.9222]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3941, grad_fn=<NllLossBackward>)\n","epoch 893, loss 0.39411163330078125\n","outputs:  tensor([[0.1628, 0.7450],\n","        [0.8634, 0.1983],\n","        [0.8523, 0.2118],\n","        [0.9735, 0.0645],\n","        [0.0500, 0.9225]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3940, grad_fn=<NllLossBackward>)\n","epoch 894, loss 0.3939656615257263\n","outputs:  tensor([[0.1626, 0.7454],\n","        [0.8635, 0.1981],\n","        [0.8525, 0.2115],\n","        [0.9736, 0.0643],\n","        [0.0499, 0.9227]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3938, grad_fn=<NllLossBackward>)\n","epoch 895, loss 0.3938201069831848\n","outputs:  tensor([[0.1623, 0.7458],\n","        [0.8637, 0.1978],\n","        [0.8527, 0.2113],\n","        [0.9737, 0.0641],\n","        [0.0497, 0.9230]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3937, grad_fn=<NllLossBackward>)\n","epoch 896, loss 0.39367491006851196\n","outputs:  tensor([[0.1621, 0.7461],\n","        [0.8639, 0.1975],\n","        [0.8529, 0.2110],\n","        [0.9738, 0.0639],\n","        [0.0496, 0.9232]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3935, grad_fn=<NllLossBackward>)\n","epoch 897, loss 0.39353013038635254\n","outputs:  tensor([[0.1618, 0.7465],\n","        [0.8641, 0.1973],\n","        [0.8531, 0.2108],\n","        [0.9738, 0.0637],\n","        [0.0494, 0.9234]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3934, grad_fn=<NllLossBackward>)\n","epoch 898, loss 0.3933855891227722\n","outputs:  tensor([[0.1616, 0.7469],\n","        [0.8643, 0.1970],\n","        [0.8533, 0.2105],\n","        [0.9739, 0.0635],\n","        [0.0493, 0.9237]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3932, grad_fn=<NllLossBackward>)\n","epoch 899, loss 0.3932415544986725\n","outputs:  tensor([[0.1613, 0.7472],\n","        [0.8645, 0.1967],\n","        [0.8535, 0.2103],\n","        [0.9740, 0.0633],\n","        [0.0491, 0.9239]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3931, grad_fn=<NllLossBackward>)\n","epoch 900, loss 0.39309781789779663\n","outputs:  tensor([[0.1611, 0.7476],\n","        [0.8647, 0.1965],\n","        [0.8536, 0.2100],\n","        [0.9741, 0.0631],\n","        [0.0490, 0.9241]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3930, grad_fn=<NllLossBackward>)\n","epoch 901, loss 0.39295440912246704\n","Parameter containing:\n","tensor([[-0.1719, -0.4811,  0.2013],\n","        [-0.8220, -0.4491, -0.0711],\n","        [-0.8290, -0.5994, -0.1176],\n","        [-0.3758, -0.3524, -0.0015]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4598, -0.3600,  0.0862,  0.0954], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7264,  0.5694,  0.9002,  0.0104],\n","        [-0.0042, -0.7058, -0.4840, -0.4082]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3184, -0.5407], requires_grad=True)\n","outputs:  tensor([[0.1608, 0.7480],\n","        [0.8649, 0.1962],\n","        [0.8538, 0.2097],\n","        [0.9742, 0.0629],\n","        [0.0488, 0.9244]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3928, grad_fn=<NllLossBackward>)\n","epoch 902, loss 0.3928113877773285\n","outputs:  tensor([[0.1606, 0.7483],\n","        [0.8651, 0.1960],\n","        [0.8540, 0.2095],\n","        [0.9742, 0.0628],\n","        [0.0487, 0.9246]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3927, grad_fn=<NllLossBackward>)\n","epoch 903, loss 0.3926686644554138\n","outputs:  tensor([[0.1603, 0.7487],\n","        [0.8652, 0.1957],\n","        [0.8542, 0.2092],\n","        [0.9743, 0.0626],\n","        [0.0485, 0.9248]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3925, grad_fn=<NllLossBackward>)\n","epoch 904, loss 0.39252638816833496\n","outputs:  tensor([[0.1601, 0.7491],\n","        [0.8654, 0.1954],\n","        [0.8544, 0.2090],\n","        [0.9744, 0.0624],\n","        [0.0484, 0.9251]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3924, grad_fn=<NllLossBackward>)\n","epoch 905, loss 0.39238449931144714\n","outputs:  tensor([[0.1598, 0.7494],\n","        [0.8656, 0.1952],\n","        [0.8546, 0.2087],\n","        [0.9745, 0.0622],\n","        [0.0483, 0.9253]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3922, grad_fn=<NllLossBackward>)\n","epoch 906, loss 0.3922428786754608\n","outputs:  tensor([[0.1596, 0.7498],\n","        [0.8658, 0.1949],\n","        [0.8548, 0.2085],\n","        [0.9746, 0.0620],\n","        [0.0481, 0.9255]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3921, grad_fn=<NllLossBackward>)\n","epoch 907, loss 0.39210161566734314\n","outputs:  tensor([[0.1593, 0.7502],\n","        [0.8660, 0.1947],\n","        [0.8549, 0.2082],\n","        [0.9746, 0.0618],\n","        [0.0480, 0.9258]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3920, grad_fn=<NllLossBackward>)\n","epoch 908, loss 0.3919607996940613\n","outputs:  tensor([[0.1591, 0.7505],\n","        [0.8662, 0.1944],\n","        [0.8551, 0.2080],\n","        [0.9747, 0.0616],\n","        [0.0478, 0.9260]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3918, grad_fn=<NllLossBackward>)\n","epoch 909, loss 0.39182019233703613\n","outputs:  tensor([[0.1589, 0.7509],\n","        [0.8664, 0.1941],\n","        [0.8553, 0.2077],\n","        [0.9748, 0.0614],\n","        [0.0477, 0.9262]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3917, grad_fn=<NllLossBackward>)\n","epoch 910, loss 0.3916800916194916\n","outputs:  tensor([[0.1586, 0.7512],\n","        [0.8665, 0.1939],\n","        [0.8555, 0.2074],\n","        [0.9749, 0.0612],\n","        [0.0476, 0.9264]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3915, grad_fn=<NllLossBackward>)\n","epoch 911, loss 0.3915402293205261\n","outputs:  tensor([[0.1584, 0.7516],\n","        [0.8667, 0.1936],\n","        [0.8557, 0.2072],\n","        [0.9749, 0.0610],\n","        [0.0474, 0.9267]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3914, grad_fn=<NllLossBackward>)\n","epoch 912, loss 0.3914008140563965\n","outputs:  tensor([[0.1581, 0.7520],\n","        [0.8669, 0.1934],\n","        [0.8559, 0.2069],\n","        [0.9750, 0.0608],\n","        [0.0473, 0.9269]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3913, grad_fn=<NllLossBackward>)\n","epoch 913, loss 0.39126166701316833\n","outputs:  tensor([[0.1579, 0.7523],\n","        [0.8671, 0.1931],\n","        [0.8560, 0.2067],\n","        [0.9751, 0.0606],\n","        [0.0471, 0.9271]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3911, grad_fn=<NllLossBackward>)\n","epoch 914, loss 0.3911229074001312\n","outputs:  tensor([[0.1576, 0.7527],\n","        [0.8673, 0.1929],\n","        [0.8562, 0.2064],\n","        [0.9752, 0.0605],\n","        [0.0470, 0.9273]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3910, grad_fn=<NllLossBackward>)\n","epoch 915, loss 0.39098453521728516\n","outputs:  tensor([[0.1574, 0.7530],\n","        [0.8675, 0.1926],\n","        [0.8564, 0.2062],\n","        [0.9752, 0.0603],\n","        [0.0469, 0.9276]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3908, grad_fn=<NllLossBackward>)\n","epoch 916, loss 0.3908464014530182\n","outputs:  tensor([[0.1572, 0.7534],\n","        [0.8676, 0.1923],\n","        [0.8566, 0.2059],\n","        [0.9753, 0.0601],\n","        [0.0467, 0.9278]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3907, grad_fn=<NllLossBackward>)\n","epoch 917, loss 0.3907087445259094\n","outputs:  tensor([[0.1569, 0.7538],\n","        [0.8678, 0.1921],\n","        [0.8568, 0.2057],\n","        [0.9754, 0.0599],\n","        [0.0466, 0.9280]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3906, grad_fn=<NllLossBackward>)\n","epoch 918, loss 0.390571266412735\n","outputs:  tensor([[0.1567, 0.7541],\n","        [0.8680, 0.1918],\n","        [0.8570, 0.2054],\n","        [0.9755, 0.0597],\n","        [0.0465, 0.9282]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3904, grad_fn=<NllLossBackward>)\n","epoch 919, loss 0.390434205532074\n","outputs:  tensor([[0.1564, 0.7545],\n","        [0.8682, 0.1916],\n","        [0.8571, 0.2052],\n","        [0.9755, 0.0595],\n","        [0.0463, 0.9284]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3903, grad_fn=<NllLossBackward>)\n","epoch 920, loss 0.3902975618839264\n","outputs:  tensor([[0.1562, 0.7548],\n","        [0.8684, 0.1913],\n","        [0.8573, 0.2049],\n","        [0.9756, 0.0593],\n","        [0.0462, 0.9287]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3902, grad_fn=<NllLossBackward>)\n","epoch 921, loss 0.3901612162590027\n","outputs:  tensor([[0.1560, 0.7552],\n","        [0.8685, 0.1911],\n","        [0.8575, 0.2047],\n","        [0.9757, 0.0592],\n","        [0.0461, 0.9289]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3900, grad_fn=<NllLossBackward>)\n","epoch 922, loss 0.39002513885498047\n","outputs:  tensor([[0.1557, 0.7555],\n","        [0.8687, 0.1908],\n","        [0.8577, 0.2044],\n","        [0.9757, 0.0590],\n","        [0.0459, 0.9291]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3899, grad_fn=<NllLossBackward>)\n","epoch 923, loss 0.38988953828811646\n","outputs:  tensor([[0.1555, 0.7559],\n","        [0.8689, 0.1906],\n","        [0.8579, 0.2042],\n","        [0.9758, 0.0588],\n","        [0.0458, 0.9293]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3898, grad_fn=<NllLossBackward>)\n","epoch 924, loss 0.38975417613983154\n","outputs:  tensor([[0.1552, 0.7562],\n","        [0.8691, 0.1903],\n","        [0.8580, 0.2039],\n","        [0.9759, 0.0586],\n","        [0.0457, 0.9295]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3896, grad_fn=<NllLossBackward>)\n","epoch 925, loss 0.38961920142173767\n","outputs:  tensor([[0.1550, 0.7566],\n","        [0.8693, 0.1901],\n","        [0.8582, 0.2037],\n","        [0.9760, 0.0584],\n","        [0.0455, 0.9297]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3895, grad_fn=<NllLossBackward>)\n","epoch 926, loss 0.3894844949245453\n","outputs:  tensor([[0.1548, 0.7570],\n","        [0.8694, 0.1898],\n","        [0.8584, 0.2034],\n","        [0.9760, 0.0583],\n","        [0.0454, 0.9299]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3894, grad_fn=<NllLossBackward>)\n","epoch 927, loss 0.38935017585754395\n","outputs:  tensor([[0.1545, 0.7573],\n","        [0.8696, 0.1895],\n","        [0.8586, 0.2032],\n","        [0.9761, 0.0581],\n","        [0.0453, 0.9302]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3892, grad_fn=<NllLossBackward>)\n","epoch 928, loss 0.38921618461608887\n","outputs:  tensor([[0.1543, 0.7577],\n","        [0.8698, 0.1893],\n","        [0.8587, 0.2029],\n","        [0.9762, 0.0579],\n","        [0.0451, 0.9304]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3891, grad_fn=<NllLossBackward>)\n","epoch 929, loss 0.3890826106071472\n","outputs:  tensor([[0.1541, 0.7580],\n","        [0.8700, 0.1890],\n","        [0.8589, 0.2027],\n","        [0.9763, 0.0577],\n","        [0.0450, 0.9306]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3889, grad_fn=<NllLossBackward>)\n","epoch 930, loss 0.3889492452144623\n","outputs:  tensor([[0.1538, 0.7584],\n","        [0.8702, 0.1888],\n","        [0.8591, 0.2025],\n","        [0.9763, 0.0575],\n","        [0.0449, 0.9308]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3888, grad_fn=<NllLossBackward>)\n","epoch 931, loss 0.388816237449646\n","outputs:  tensor([[0.1536, 0.7587],\n","        [0.8703, 0.1885],\n","        [0.8593, 0.2022],\n","        [0.9764, 0.0574],\n","        [0.0447, 0.9310]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3887, grad_fn=<NllLossBackward>)\n","epoch 932, loss 0.38868361711502075\n","outputs:  tensor([[0.1534, 0.7591],\n","        [0.8705, 0.1883],\n","        [0.8595, 0.2020],\n","        [0.9765, 0.0572],\n","        [0.0446, 0.9312]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3886, grad_fn=<NllLossBackward>)\n","epoch 933, loss 0.3885513246059418\n","outputs:  tensor([[0.1531, 0.7594],\n","        [0.8707, 0.1880],\n","        [0.8596, 0.2017],\n","        [0.9765, 0.0570],\n","        [0.0445, 0.9314]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3884, grad_fn=<NllLossBackward>)\n","epoch 934, loss 0.3884193003177643\n","outputs:  tensor([[0.1529, 0.7597],\n","        [0.8709, 0.1878],\n","        [0.8598, 0.2015],\n","        [0.9766, 0.0568],\n","        [0.0444, 0.9316]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3883, grad_fn=<NllLossBackward>)\n","epoch 935, loss 0.38828763365745544\n","outputs:  tensor([[0.1527, 0.7601],\n","        [0.8710, 0.1875],\n","        [0.8600, 0.2012],\n","        [0.9767, 0.0567],\n","        [0.0442, 0.9318]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3882, grad_fn=<NllLossBackward>)\n","epoch 936, loss 0.3881562650203705\n","outputs:  tensor([[0.1524, 0.7604],\n","        [0.8712, 0.1873],\n","        [0.8602, 0.2010],\n","        [0.9767, 0.0565],\n","        [0.0441, 0.9320]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3880, grad_fn=<NllLossBackward>)\n","epoch 937, loss 0.38802528381347656\n","outputs:  tensor([[0.1522, 0.7608],\n","        [0.8714, 0.1871],\n","        [0.8603, 0.2007],\n","        [0.9768, 0.0563],\n","        [0.0440, 0.9322]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3879, grad_fn=<NllLossBackward>)\n","epoch 938, loss 0.3878946304321289\n","outputs:  tensor([[0.1520, 0.7611],\n","        [0.8716, 0.1868],\n","        [0.8605, 0.2005],\n","        [0.9769, 0.0562],\n","        [0.0438, 0.9325]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3878, grad_fn=<NllLossBackward>)\n","epoch 939, loss 0.38776424527168274\n","outputs:  tensor([[0.1517, 0.7615],\n","        [0.8717, 0.1866],\n","        [0.8607, 0.2003],\n","        [0.9769, 0.0560],\n","        [0.0437, 0.9327]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3876, grad_fn=<NllLossBackward>)\n","epoch 940, loss 0.3876342177391052\n","outputs:  tensor([[0.1515, 0.7618],\n","        [0.8719, 0.1863],\n","        [0.8609, 0.2000],\n","        [0.9770, 0.0558],\n","        [0.0436, 0.9329]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3875, grad_fn=<NllLossBackward>)\n","epoch 941, loss 0.387504518032074\n","outputs:  tensor([[0.1513, 0.7622],\n","        [0.8721, 0.1861],\n","        [0.8610, 0.1998],\n","        [0.9771, 0.0556],\n","        [0.0435, 0.9331]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3874, grad_fn=<NllLossBackward>)\n","epoch 942, loss 0.3873750865459442\n","outputs:  tensor([[0.1511, 0.7625],\n","        [0.8723, 0.1858],\n","        [0.8612, 0.1995],\n","        [0.9772, 0.0555],\n","        [0.0433, 0.9333]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3872, grad_fn=<NllLossBackward>)\n","epoch 943, loss 0.3872460722923279\n","outputs:  tensor([[0.1508, 0.7628],\n","        [0.8724, 0.1856],\n","        [0.8614, 0.1993],\n","        [0.9772, 0.0553],\n","        [0.0432, 0.9335]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3871, grad_fn=<NllLossBackward>)\n","epoch 944, loss 0.38711732625961304\n","outputs:  tensor([[0.1506, 0.7632],\n","        [0.8726, 0.1853],\n","        [0.8615, 0.1990],\n","        [0.9773, 0.0551],\n","        [0.0431, 0.9337]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3870, grad_fn=<NllLossBackward>)\n","epoch 945, loss 0.38698890805244446\n","outputs:  tensor([[0.1504, 0.7635],\n","        [0.8728, 0.1851],\n","        [0.8617, 0.1988],\n","        [0.9774, 0.0550],\n","        [0.0430, 0.9339]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3869, grad_fn=<NllLossBackward>)\n","epoch 946, loss 0.38686075806617737\n","outputs:  tensor([[0.1502, 0.7639],\n","        [0.8730, 0.1848],\n","        [0.8619, 0.1986],\n","        [0.9774, 0.0548],\n","        [0.0429, 0.9341]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3867, grad_fn=<NllLossBackward>)\n","epoch 947, loss 0.3867330253124237\n","outputs:  tensor([[0.1499, 0.7642],\n","        [0.8731, 0.1846],\n","        [0.8621, 0.1983],\n","        [0.9775, 0.0546],\n","        [0.0427, 0.9343]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3866, grad_fn=<NllLossBackward>)\n","epoch 948, loss 0.38660550117492676\n","outputs:  tensor([[0.1497, 0.7645],\n","        [0.8733, 0.1844],\n","        [0.8622, 0.1981],\n","        [0.9776, 0.0545],\n","        [0.0426, 0.9345]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3865, grad_fn=<NllLossBackward>)\n","epoch 949, loss 0.38647836446762085\n","outputs:  tensor([[0.1495, 0.7649],\n","        [0.8735, 0.1841],\n","        [0.8624, 0.1978],\n","        [0.9776, 0.0543],\n","        [0.0425, 0.9346]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3864, grad_fn=<NllLossBackward>)\n","epoch 950, loss 0.38635149598121643\n","outputs:  tensor([[0.1493, 0.7652],\n","        [0.8736, 0.1839],\n","        [0.8626, 0.1976],\n","        [0.9777, 0.0541],\n","        [0.0424, 0.9348]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3862, grad_fn=<NllLossBackward>)\n","epoch 951, loss 0.38622498512268066\n","Parameter containing:\n","tensor([[-0.1784, -0.4909,  0.2007],\n","        [-0.8364, -0.4702, -0.0720],\n","        [-0.8435, -0.6207, -0.1187],\n","        [-0.3814, -0.3605, -0.0018]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4618, -0.3557,  0.0906,  0.0970], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7354,  0.5818,  0.9158,  0.0187],\n","        [-0.0173, -0.7241, -0.5070, -0.4203]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3212, -0.5446], requires_grad=True)\n","outputs:  tensor([[0.1490, 0.7656],\n","        [0.8738, 0.1836],\n","        [0.8627, 0.1974],\n","        [0.9778, 0.0540],\n","        [0.0422, 0.9350]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3861, grad_fn=<NllLossBackward>)\n","epoch 952, loss 0.38609880208969116\n","outputs:  tensor([[0.1488, 0.7659],\n","        [0.8740, 0.1834],\n","        [0.8629, 0.1971],\n","        [0.9778, 0.0538],\n","        [0.0421, 0.9352]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3860, grad_fn=<NllLossBackward>)\n","epoch 953, loss 0.38597288727760315\n","outputs:  tensor([[0.1486, 0.7662],\n","        [0.8742, 0.1831],\n","        [0.8631, 0.1969],\n","        [0.9779, 0.0536],\n","        [0.0420, 0.9354]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3858, grad_fn=<NllLossBackward>)\n","epoch 954, loss 0.3858473002910614\n","outputs:  tensor([[0.1484, 0.7666],\n","        [0.8743, 0.1829],\n","        [0.8633, 0.1966],\n","        [0.9779, 0.0535],\n","        [0.0419, 0.9356]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3857, grad_fn=<NllLossBackward>)\n","epoch 955, loss 0.38572201132774353\n","outputs:  tensor([[0.1481, 0.7669],\n","        [0.8745, 0.1827],\n","        [0.8634, 0.1964],\n","        [0.9780, 0.0533],\n","        [0.0418, 0.9358]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3856, grad_fn=<NllLossBackward>)\n","epoch 956, loss 0.3855970799922943\n","outputs:  tensor([[0.1479, 0.7672],\n","        [0.8747, 0.1824],\n","        [0.8636, 0.1962],\n","        [0.9781, 0.0531],\n","        [0.0417, 0.9360]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3855, grad_fn=<NllLossBackward>)\n","epoch 957, loss 0.38547244668006897\n","outputs:  tensor([[0.1477, 0.7676],\n","        [0.8748, 0.1822],\n","        [0.8638, 0.1959],\n","        [0.9781, 0.0530],\n","        [0.0415, 0.9362]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3853, grad_fn=<NllLossBackward>)\n","epoch 958, loss 0.3853480815887451\n","outputs:  tensor([[0.1475, 0.7679],\n","        [0.8750, 0.1819],\n","        [0.8639, 0.1957],\n","        [0.9782, 0.0528],\n","        [0.0414, 0.9364]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3852, grad_fn=<NllLossBackward>)\n","epoch 959, loss 0.38522404432296753\n","outputs:  tensor([[0.1473, 0.7682],\n","        [0.8752, 0.1817],\n","        [0.8641, 0.1955],\n","        [0.9783, 0.0527],\n","        [0.0413, 0.9366]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3851, grad_fn=<NllLossBackward>)\n","epoch 960, loss 0.38510027527809143\n","outputs:  tensor([[0.1470, 0.7686],\n","        [0.8753, 0.1815],\n","        [0.8643, 0.1952],\n","        [0.9783, 0.0525],\n","        [0.0412, 0.9368]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3850, grad_fn=<NllLossBackward>)\n","epoch 961, loss 0.38497689366340637\n","outputs:  tensor([[0.1468, 0.7689],\n","        [0.8755, 0.1812],\n","        [0.8644, 0.1950],\n","        [0.9784, 0.0523],\n","        [0.0411, 0.9370]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3849, grad_fn=<NllLossBackward>)\n","epoch 962, loss 0.3848537504673004\n","outputs:  tensor([[0.1466, 0.7692],\n","        [0.8757, 0.1810],\n","        [0.8646, 0.1948],\n","        [0.9785, 0.0522],\n","        [0.0410, 0.9371]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3847, grad_fn=<NllLossBackward>)\n","epoch 963, loss 0.3847309350967407\n","outputs:  tensor([[0.1464, 0.7696],\n","        [0.8758, 0.1807],\n","        [0.8648, 0.1945],\n","        [0.9785, 0.0520],\n","        [0.0408, 0.9373]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3846, grad_fn=<NllLossBackward>)\n","epoch 964, loss 0.3846084475517273\n","outputs:  tensor([[0.1462, 0.7699],\n","        [0.8760, 0.1805],\n","        [0.8649, 0.1943],\n","        [0.9786, 0.0519],\n","        [0.0407, 0.9375]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3845, grad_fn=<NllLossBackward>)\n","epoch 965, loss 0.3844861686229706\n","outputs:  tensor([[0.1459, 0.7702],\n","        [0.8762, 0.1803],\n","        [0.8651, 0.1941],\n","        [0.9786, 0.0517],\n","        [0.0406, 0.9377]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3844, grad_fn=<NllLossBackward>)\n","epoch 966, loss 0.38436421751976013\n","outputs:  tensor([[0.1457, 0.7706],\n","        [0.8763, 0.1800],\n","        [0.8653, 0.1938],\n","        [0.9787, 0.0516],\n","        [0.0405, 0.9379]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3842, grad_fn=<NllLossBackward>)\n","epoch 967, loss 0.3842426836490631\n","outputs:  tensor([[0.1455, 0.7709],\n","        [0.8765, 0.1798],\n","        [0.8654, 0.1936],\n","        [0.9788, 0.0514],\n","        [0.0404, 0.9381]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3841, grad_fn=<NllLossBackward>)\n","epoch 968, loss 0.3841213583946228\n","outputs:  tensor([[0.1453, 0.7712],\n","        [0.8767, 0.1796],\n","        [0.8656, 0.1934],\n","        [0.9788, 0.0513],\n","        [0.0403, 0.9382]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3840, grad_fn=<NllLossBackward>)\n","epoch 969, loss 0.38400039076805115\n","outputs:  tensor([[0.1451, 0.7715],\n","        [0.8768, 0.1793],\n","        [0.8658, 0.1931],\n","        [0.9789, 0.0511],\n","        [0.0402, 0.9384]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3839, grad_fn=<NllLossBackward>)\n","epoch 970, loss 0.3838796615600586\n","outputs:  tensor([[0.1449, 0.7719],\n","        [0.8770, 0.1791],\n","        [0.8659, 0.1929],\n","        [0.9790, 0.0509],\n","        [0.0401, 0.9386]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3838, grad_fn=<NllLossBackward>)\n","epoch 971, loss 0.3837592601776123\n","outputs:  tensor([[0.1446, 0.7722],\n","        [0.8772, 0.1789],\n","        [0.8661, 0.1927],\n","        [0.9790, 0.0508],\n","        [0.0399, 0.9388]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3836, grad_fn=<NllLossBackward>)\n","epoch 972, loss 0.3836390972137451\n","outputs:  tensor([[0.1444, 0.7725],\n","        [0.8773, 0.1786],\n","        [0.8663, 0.1924],\n","        [0.9791, 0.0506],\n","        [0.0398, 0.9390]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3835, grad_fn=<NllLossBackward>)\n","epoch 973, loss 0.38351932168006897\n","outputs:  tensor([[0.1442, 0.7729],\n","        [0.8775, 0.1784],\n","        [0.8664, 0.1922],\n","        [0.9791, 0.0505],\n","        [0.0397, 0.9392]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3834, grad_fn=<NllLossBackward>)\n","epoch 974, loss 0.3833997845649719\n","outputs:  tensor([[0.1440, 0.7732],\n","        [0.8777, 0.1782],\n","        [0.8666, 0.1920],\n","        [0.9792, 0.0503],\n","        [0.0396, 0.9393]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3833, grad_fn=<NllLossBackward>)\n","epoch 975, loss 0.38328057527542114\n","outputs:  tensor([[0.1438, 0.7735],\n","        [0.8778, 0.1779],\n","        [0.8668, 0.1917],\n","        [0.9793, 0.0502],\n","        [0.0395, 0.9395]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3832, grad_fn=<NllLossBackward>)\n","epoch 976, loss 0.38316160440444946\n","outputs:  tensor([[0.1436, 0.7738],\n","        [0.8780, 0.1777],\n","        [0.8669, 0.1915],\n","        [0.9793, 0.0500],\n","        [0.0394, 0.9397]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3830, grad_fn=<NllLossBackward>)\n","epoch 977, loss 0.38304299116134644\n","outputs:  tensor([[0.1434, 0.7741],\n","        [0.8781, 0.1775],\n","        [0.8671, 0.1913],\n","        [0.9794, 0.0499],\n","        [0.0393, 0.9399]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3829, grad_fn=<NllLossBackward>)\n","epoch 978, loss 0.3829246163368225\n","outputs:  tensor([[0.1431, 0.7745],\n","        [0.8783, 0.1772],\n","        [0.8672, 0.1910],\n","        [0.9794, 0.0497],\n","        [0.0392, 0.9400]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3828, grad_fn=<NllLossBackward>)\n","epoch 979, loss 0.38280653953552246\n","outputs:  tensor([[0.1429, 0.7748],\n","        [0.8785, 0.1770],\n","        [0.8674, 0.1908],\n","        [0.9795, 0.0496],\n","        [0.0391, 0.9402]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3827, grad_fn=<NllLossBackward>)\n","epoch 980, loss 0.3826887011528015\n","outputs:  tensor([[0.1427, 0.7751],\n","        [0.8786, 0.1768],\n","        [0.8676, 0.1906],\n","        [0.9796, 0.0494],\n","        [0.0390, 0.9404]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3826, grad_fn=<NllLossBackward>)\n","epoch 981, loss 0.3825712203979492\n","outputs:  tensor([[0.1425, 0.7754],\n","        [0.8788, 0.1765],\n","        [0.8677, 0.1904],\n","        [0.9796, 0.0493],\n","        [0.0388, 0.9406]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3825, grad_fn=<NllLossBackward>)\n","epoch 982, loss 0.3824540674686432\n","outputs:  tensor([[0.1423, 0.7758],\n","        [0.8790, 0.1763],\n","        [0.8679, 0.1901],\n","        [0.9797, 0.0491],\n","        [0.0387, 0.9407]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3823, grad_fn=<NllLossBackward>)\n","epoch 983, loss 0.3823370933532715\n","outputs:  tensor([[0.1421, 0.7761],\n","        [0.8791, 0.1761],\n","        [0.8681, 0.1899],\n","        [0.9797, 0.0490],\n","        [0.0386, 0.9409]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3822, grad_fn=<NllLossBackward>)\n","epoch 984, loss 0.3822205364704132\n","outputs:  tensor([[0.1419, 0.7764],\n","        [0.8793, 0.1758],\n","        [0.8682, 0.1897],\n","        [0.9798, 0.0488],\n","        [0.0385, 0.9411]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3821, grad_fn=<NllLossBackward>)\n","epoch 985, loss 0.3821040987968445\n","outputs:  tensor([[0.1417, 0.7767],\n","        [0.8794, 0.1756],\n","        [0.8684, 0.1894],\n","        [0.9798, 0.0487],\n","        [0.0384, 0.9413]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3820, grad_fn=<NllLossBackward>)\n","epoch 986, loss 0.3819881081581116\n","outputs:  tensor([[0.1415, 0.7770],\n","        [0.8796, 0.1754],\n","        [0.8685, 0.1892],\n","        [0.9799, 0.0485],\n","        [0.0383, 0.9414]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3819, grad_fn=<NllLossBackward>)\n","epoch 987, loss 0.3818723261356354\n","outputs:  tensor([[0.1413, 0.7773],\n","        [0.8798, 0.1751],\n","        [0.8687, 0.1890],\n","        [0.9800, 0.0484],\n","        [0.0382, 0.9416]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3818, grad_fn=<NllLossBackward>)\n","epoch 988, loss 0.38175684213638306\n","outputs:  tensor([[0.1411, 0.7777],\n","        [0.8799, 0.1749],\n","        [0.8689, 0.1888],\n","        [0.9800, 0.0483],\n","        [0.0381, 0.9418]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3816, grad_fn=<NllLossBackward>)\n","epoch 989, loss 0.3816416561603546\n","outputs:  tensor([[0.1408, 0.7780],\n","        [0.8801, 0.1747],\n","        [0.8690, 0.1885],\n","        [0.9801, 0.0481],\n","        [0.0380, 0.9420]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3815, grad_fn=<NllLossBackward>)\n","epoch 990, loss 0.3815267086029053\n","outputs:  tensor([[0.1406, 0.7783],\n","        [0.8802, 0.1745],\n","        [0.8692, 0.1883],\n","        [0.9801, 0.0480],\n","        [0.0379, 0.9421]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3814, grad_fn=<NllLossBackward>)\n","epoch 991, loss 0.3814120888710022\n","outputs:  tensor([[0.1404, 0.7786],\n","        [0.8804, 0.1742],\n","        [0.8693, 0.1881],\n","        [0.9802, 0.0478],\n","        [0.0378, 0.9423]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3813, grad_fn=<NllLossBackward>)\n","epoch 992, loss 0.38129764795303345\n","outputs:  tensor([[0.1402, 0.7789],\n","        [0.8806, 0.1740],\n","        [0.8695, 0.1879],\n","        [0.9802, 0.0477],\n","        [0.0377, 0.9425]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3812, grad_fn=<NllLossBackward>)\n","epoch 993, loss 0.38118359446525574\n","outputs:  tensor([[0.1400, 0.7792],\n","        [0.8807, 0.1738],\n","        [0.8697, 0.1876],\n","        [0.9803, 0.0475],\n","        [0.0376, 0.9426]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3811, grad_fn=<NllLossBackward>)\n","epoch 994, loss 0.3810698390007019\n","outputs:  tensor([[0.1398, 0.7796],\n","        [0.8809, 0.1736],\n","        [0.8698, 0.1874],\n","        [0.9804, 0.0474],\n","        [0.0375, 0.9428]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3810, grad_fn=<NllLossBackward>)\n","epoch 995, loss 0.3809563219547272\n","outputs:  tensor([[0.1396, 0.7799],\n","        [0.8810, 0.1733],\n","        [0.8700, 0.1872],\n","        [0.9804, 0.0473],\n","        [0.0374, 0.9430]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3808, grad_fn=<NllLossBackward>)\n","epoch 996, loss 0.38084298372268677\n","outputs:  tensor([[0.1394, 0.7802],\n","        [0.8812, 0.1731],\n","        [0.8701, 0.1870],\n","        [0.9805, 0.0471],\n","        [0.0373, 0.9431]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3807, grad_fn=<NllLossBackward>)\n","epoch 997, loss 0.3807300627231598\n","outputs:  tensor([[0.1392, 0.7805],\n","        [0.8813, 0.1729],\n","        [0.8703, 0.1867],\n","        [0.9805, 0.0470],\n","        [0.0372, 0.9433]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3806, grad_fn=<NllLossBackward>)\n","epoch 998, loss 0.3806173801422119\n","outputs:  tensor([[0.1390, 0.7808],\n","        [0.8815, 0.1727],\n","        [0.8704, 0.1865],\n","        [0.9806, 0.0468],\n","        [0.0371, 0.9435]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3805, grad_fn=<NllLossBackward>)\n","epoch 999, loss 0.3805049955844879\n","outputs:  tensor([[0.1388, 0.7811],\n","        [0.8817, 0.1724],\n","        [0.8706, 0.1863],\n","        [0.9806, 0.0467],\n","        [0.0370, 0.9436]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3804, grad_fn=<NllLossBackward>)\n","epoch 1000, loss 0.38039278984069824\n","outputs:  tensor([[0.1386, 0.7814],\n","        [0.8818, 0.1722],\n","        [0.8708, 0.1861],\n","        [0.9807, 0.0466],\n","        [0.0369, 0.9438]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3803, grad_fn=<NllLossBackward>)\n","epoch 1001, loss 0.38028091192245483\n","Parameter containing:\n","tensor([[-0.1846, -0.5002,  0.2002],\n","        [-0.8499, -0.4900, -0.0728],\n","        [-0.8570, -0.6408, -0.1195],\n","        [-0.3866, -0.3682, -0.0020]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4638, -0.3514,  0.0950,  0.0986], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7439,  0.5934,  0.9305,  0.0264],\n","        [-0.0297, -0.7413, -0.5286, -0.4317]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3238, -0.5483], requires_grad=True)\n","outputs:  tensor([[0.1384, 0.7817],\n","        [0.8820, 0.1720],\n","        [0.8709, 0.1859],\n","        [0.9807, 0.0464],\n","        [0.0368, 0.9439]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3802, grad_fn=<NllLossBackward>)\n","epoch 1002, loss 0.3801693022251129\n","outputs:  tensor([[0.1382, 0.7820],\n","        [0.8821, 0.1718],\n","        [0.8711, 0.1856],\n","        [0.9808, 0.0463],\n","        [0.0367, 0.9441]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3801, grad_fn=<NllLossBackward>)\n","epoch 1003, loss 0.3800579905509949\n","outputs:  tensor([[0.1380, 0.7824],\n","        [0.8823, 0.1715],\n","        [0.8712, 0.1854],\n","        [0.9809, 0.0461],\n","        [0.0366, 0.9443]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3799, grad_fn=<NllLossBackward>)\n","epoch 1004, loss 0.37994688749313354\n","outputs:  tensor([[0.1378, 0.7827],\n","        [0.8824, 0.1713],\n","        [0.8714, 0.1852],\n","        [0.9809, 0.0460],\n","        [0.0365, 0.9444]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3798, grad_fn=<NllLossBackward>)\n","epoch 1005, loss 0.3798360526561737\n","outputs:  tensor([[0.1376, 0.7830],\n","        [0.8826, 0.1711],\n","        [0.8715, 0.1850],\n","        [0.9810, 0.0459],\n","        [0.0364, 0.9446]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3797, grad_fn=<NllLossBackward>)\n","epoch 1006, loss 0.3797256052494049\n","outputs:  tensor([[0.1374, 0.7833],\n","        [0.8827, 0.1709],\n","        [0.8717, 0.1848],\n","        [0.9810, 0.0457],\n","        [0.0363, 0.9448]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3796, grad_fn=<NllLossBackward>)\n","epoch 1007, loss 0.37961530685424805\n","outputs:  tensor([[0.1372, 0.7836],\n","        [0.8829, 0.1706],\n","        [0.8718, 0.1845],\n","        [0.9811, 0.0456],\n","        [0.0362, 0.9449]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3795, grad_fn=<NllLossBackward>)\n","epoch 1008, loss 0.37950530648231506\n","outputs:  tensor([[0.1370, 0.7839],\n","        [0.8830, 0.1704],\n","        [0.8720, 0.1843],\n","        [0.9811, 0.0455],\n","        [0.0361, 0.9451]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3794, grad_fn=<NllLossBackward>)\n","epoch 1009, loss 0.3793955445289612\n","outputs:  tensor([[0.1368, 0.7842],\n","        [0.8832, 0.1702],\n","        [0.8722, 0.1841],\n","        [0.9812, 0.0453],\n","        [0.0360, 0.9452]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3793, grad_fn=<NllLossBackward>)\n","epoch 1010, loss 0.37928611040115356\n","outputs:  tensor([[0.1366, 0.7845],\n","        [0.8833, 0.1700],\n","        [0.8723, 0.1839],\n","        [0.9812, 0.0452],\n","        [0.0359, 0.9454]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3792, grad_fn=<NllLossBackward>)\n","epoch 1011, loss 0.37917694449424744\n","outputs:  tensor([[0.1364, 0.7848],\n","        [0.8835, 0.1698],\n","        [0.8725, 0.1837],\n","        [0.9813, 0.0451],\n","        [0.0358, 0.9455]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3791, grad_fn=<NllLossBackward>)\n","epoch 1012, loss 0.379067987203598\n","outputs:  tensor([[0.1362, 0.7851],\n","        [0.8837, 0.1695],\n","        [0.8726, 0.1834],\n","        [0.9813, 0.0449],\n","        [0.0357, 0.9457]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3790, grad_fn=<NllLossBackward>)\n","epoch 1013, loss 0.3789592683315277\n","outputs:  tensor([[0.1360, 0.7854],\n","        [0.8838, 0.1693],\n","        [0.8728, 0.1832],\n","        [0.9814, 0.0448],\n","        [0.0356, 0.9459]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3789, grad_fn=<NllLossBackward>)\n","epoch 1014, loss 0.37885090708732605\n","outputs:  tensor([[0.1358, 0.7857],\n","        [0.8840, 0.1691],\n","        [0.8729, 0.1830],\n","        [0.9814, 0.0447],\n","        [0.0355, 0.9460]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3787, grad_fn=<NllLossBackward>)\n","epoch 1015, loss 0.3787427842617035\n","outputs:  tensor([[0.1356, 0.7860],\n","        [0.8841, 0.1689],\n","        [0.8731, 0.1828],\n","        [0.9815, 0.0445],\n","        [0.0354, 0.9462]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3786, grad_fn=<NllLossBackward>)\n","epoch 1016, loss 0.37863487005233765\n","outputs:  tensor([[0.1354, 0.7863],\n","        [0.8843, 0.1687],\n","        [0.8732, 0.1826],\n","        [0.9815, 0.0444],\n","        [0.0353, 0.9463]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3785, grad_fn=<NllLossBackward>)\n","epoch 1017, loss 0.37852728366851807\n","outputs:  tensor([[0.1352, 0.7866],\n","        [0.8844, 0.1685],\n","        [0.8734, 0.1824],\n","        [0.9816, 0.0443],\n","        [0.0352, 0.9465]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3784, grad_fn=<NllLossBackward>)\n","epoch 1018, loss 0.3784199655056\n","outputs:  tensor([[0.1350, 0.7869],\n","        [0.8846, 0.1682],\n","        [0.8735, 0.1821],\n","        [0.9816, 0.0441],\n","        [0.0351, 0.9466]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3783, grad_fn=<NllLossBackward>)\n","epoch 1019, loss 0.3783128559589386\n","outputs:  tensor([[0.1348, 0.7872],\n","        [0.8847, 0.1680],\n","        [0.8737, 0.1819],\n","        [0.9817, 0.0440],\n","        [0.0350, 0.9468]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3782, grad_fn=<NllLossBackward>)\n","epoch 1020, loss 0.37820595502853394\n","outputs:  tensor([[0.1346, 0.7875],\n","        [0.8849, 0.1678],\n","        [0.8738, 0.1817],\n","        [0.9817, 0.0439],\n","        [0.0349, 0.9469]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3781, grad_fn=<NllLossBackward>)\n","epoch 1021, loss 0.37809938192367554\n","outputs:  tensor([[0.1345, 0.7878],\n","        [0.8850, 0.1676],\n","        [0.8740, 0.1815],\n","        [0.9818, 0.0438],\n","        [0.0349, 0.9471]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3780, grad_fn=<NllLossBackward>)\n","epoch 1022, loss 0.377993106842041\n","outputs:  tensor([[0.1343, 0.7881],\n","        [0.8852, 0.1674],\n","        [0.8741, 0.1813],\n","        [0.9818, 0.0436],\n","        [0.0348, 0.9472]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3779, grad_fn=<NllLossBackward>)\n","epoch 1023, loss 0.37788698077201843\n","outputs:  tensor([[0.1341, 0.7884],\n","        [0.8853, 0.1672],\n","        [0.8743, 0.1811],\n","        [0.9819, 0.0435],\n","        [0.0347, 0.9474]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3778, grad_fn=<NllLossBackward>)\n","epoch 1024, loss 0.3777811527252197\n","outputs:  tensor([[0.1339, 0.7887],\n","        [0.8855, 0.1669],\n","        [0.8744, 0.1809],\n","        [0.9819, 0.0434],\n","        [0.0346, 0.9475]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3777, grad_fn=<NllLossBackward>)\n","epoch 1025, loss 0.3776756525039673\n","outputs:  tensor([[0.1337, 0.7890],\n","        [0.8856, 0.1667],\n","        [0.8746, 0.1806],\n","        [0.9820, 0.0432],\n","        [0.0345, 0.9477]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3776, grad_fn=<NllLossBackward>)\n","epoch 1026, loss 0.37757033109664917\n","outputs:  tensor([[0.1335, 0.7893],\n","        [0.8858, 0.1665],\n","        [0.8747, 0.1804],\n","        [0.9820, 0.0431],\n","        [0.0344, 0.9478]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3775, grad_fn=<NllLossBackward>)\n","epoch 1027, loss 0.37746530771255493\n","outputs:  tensor([[0.1333, 0.7896],\n","        [0.8859, 0.1663],\n","        [0.8749, 0.1802],\n","        [0.9821, 0.0430],\n","        [0.0343, 0.9480]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3774, grad_fn=<NllLossBackward>)\n","epoch 1028, loss 0.3773605227470398\n","outputs:  tensor([[0.1331, 0.7899],\n","        [0.8861, 0.1661],\n","        [0.8750, 0.1800],\n","        [0.9821, 0.0429],\n","        [0.0342, 0.9481]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3773, grad_fn=<NllLossBackward>)\n","epoch 1029, loss 0.377255916595459\n","outputs:  tensor([[0.1329, 0.7902],\n","        [0.8862, 0.1659],\n","        [0.8752, 0.1798],\n","        [0.9822, 0.0427],\n","        [0.0341, 0.9483]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3772, grad_fn=<NllLossBackward>)\n","epoch 1030, loss 0.37715157866477966\n","outputs:  tensor([[0.1327, 0.7905],\n","        [0.8863, 0.1657],\n","        [0.8753, 0.1796],\n","        [0.9822, 0.0426],\n","        [0.0340, 0.9484]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3770, grad_fn=<NllLossBackward>)\n","epoch 1031, loss 0.377047598361969\n","outputs:  tensor([[0.1325, 0.7908],\n","        [0.8865, 0.1654],\n","        [0.8755, 0.1794],\n","        [0.9823, 0.0425],\n","        [0.0339, 0.9486]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3769, grad_fn=<NllLossBackward>)\n","epoch 1032, loss 0.37694376707077026\n","outputs:  tensor([[0.1324, 0.7911],\n","        [0.8866, 0.1652],\n","        [0.8756, 0.1792],\n","        [0.9823, 0.0424],\n","        [0.0339, 0.9487]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3768, grad_fn=<NllLossBackward>)\n","epoch 1033, loss 0.3768402636051178\n","outputs:  tensor([[0.1322, 0.7914],\n","        [0.8868, 0.1650],\n","        [0.8758, 0.1789],\n","        [0.9824, 0.0422],\n","        [0.0338, 0.9489]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3767, grad_fn=<NllLossBackward>)\n","epoch 1034, loss 0.37673696875572205\n","outputs:  tensor([[0.1320, 0.7917],\n","        [0.8869, 0.1648],\n","        [0.8759, 0.1787],\n","        [0.9824, 0.0421],\n","        [0.0337, 0.9490]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3766, grad_fn=<NllLossBackward>)\n","epoch 1035, loss 0.376633882522583\n","outputs:  tensor([[0.1318, 0.7920],\n","        [0.8871, 0.1646],\n","        [0.8761, 0.1785],\n","        [0.9825, 0.0420],\n","        [0.0336, 0.9492]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3765, grad_fn=<NllLossBackward>)\n","epoch 1036, loss 0.37653106451034546\n","outputs:  tensor([[0.1316, 0.7922],\n","        [0.8872, 0.1644],\n","        [0.8762, 0.1783],\n","        [0.9825, 0.0419],\n","        [0.0335, 0.9493]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3764, grad_fn=<NllLossBackward>)\n","epoch 1037, loss 0.3764285147190094\n","outputs:  tensor([[0.1314, 0.7925],\n","        [0.8874, 0.1642],\n","        [0.8764, 0.1781],\n","        [0.9826, 0.0418],\n","        [0.0334, 0.9494]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3763, grad_fn=<NllLossBackward>)\n","epoch 1038, loss 0.37632623314857483\n","outputs:  tensor([[0.1312, 0.7928],\n","        [0.8875, 0.1640],\n","        [0.8765, 0.1779],\n","        [0.9826, 0.0416],\n","        [0.0333, 0.9496]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3762, grad_fn=<NllLossBackward>)\n","epoch 1039, loss 0.3762241303920746\n","outputs:  tensor([[0.1310, 0.7931],\n","        [0.8877, 0.1638],\n","        [0.8767, 0.1777],\n","        [0.9827, 0.0415],\n","        [0.0332, 0.9497]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3761, grad_fn=<NllLossBackward>)\n","epoch 1040, loss 0.3761223256587982\n","outputs:  tensor([[0.1309, 0.7934],\n","        [0.8878, 0.1635],\n","        [0.8768, 0.1775],\n","        [0.9827, 0.0414],\n","        [0.0331, 0.9499]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3760, grad_fn=<NllLossBackward>)\n","epoch 1041, loss 0.37602072954177856\n","outputs:  tensor([[0.1307, 0.7937],\n","        [0.8880, 0.1633],\n","        [0.8769, 0.1773],\n","        [0.9828, 0.0413],\n","        [0.0331, 0.9500]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3759, grad_fn=<NllLossBackward>)\n","epoch 1042, loss 0.3759194016456604\n","outputs:  tensor([[0.1305, 0.7940],\n","        [0.8881, 0.1631],\n","        [0.8771, 0.1771],\n","        [0.9828, 0.0412],\n","        [0.0330, 0.9502]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3758, grad_fn=<NllLossBackward>)\n","epoch 1043, loss 0.37581831216812134\n","outputs:  tensor([[0.1303, 0.7943],\n","        [0.8882, 0.1629],\n","        [0.8772, 0.1768],\n","        [0.9829, 0.0410],\n","        [0.0329, 0.9503]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3757, grad_fn=<NllLossBackward>)\n","epoch 1044, loss 0.3757174611091614\n","outputs:  tensor([[0.1301, 0.7946],\n","        [0.8884, 0.1627],\n","        [0.8774, 0.1766],\n","        [0.9829, 0.0409],\n","        [0.0328, 0.9504]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3756, grad_fn=<NllLossBackward>)\n","epoch 1045, loss 0.3756168484687805\n","outputs:  tensor([[0.1299, 0.7948],\n","        [0.8885, 0.1625],\n","        [0.8775, 0.1764],\n","        [0.9830, 0.0408],\n","        [0.0327, 0.9506]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3755, grad_fn=<NllLossBackward>)\n","epoch 1046, loss 0.37551647424697876\n","outputs:  tensor([[0.1297, 0.7951],\n","        [0.8887, 0.1623],\n","        [0.8777, 0.1762],\n","        [0.9830, 0.0407],\n","        [0.0326, 0.9507]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3754, grad_fn=<NllLossBackward>)\n","epoch 1047, loss 0.3754163682460785\n","outputs:  tensor([[0.1296, 0.7954],\n","        [0.8888, 0.1621],\n","        [0.8778, 0.1760],\n","        [0.9831, 0.0406],\n","        [0.0325, 0.9508]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3753, grad_fn=<NllLossBackward>)\n","epoch 1048, loss 0.37531647086143494\n","outputs:  tensor([[0.1294, 0.7957],\n","        [0.8890, 0.1619],\n","        [0.8780, 0.1758],\n","        [0.9831, 0.0404],\n","        [0.0325, 0.9510]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3752, grad_fn=<NllLossBackward>)\n","epoch 1049, loss 0.3752168118953705\n","outputs:  tensor([[0.1292, 0.7960],\n","        [0.8891, 0.1617],\n","        [0.8781, 0.1756],\n","        [0.9832, 0.0403],\n","        [0.0324, 0.9511]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3751, grad_fn=<NllLossBackward>)\n","epoch 1050, loss 0.37511733174324036\n","outputs:  tensor([[0.1290, 0.7963],\n","        [0.8892, 0.1615],\n","        [0.8782, 0.1754],\n","        [0.9832, 0.0402],\n","        [0.0323, 0.9513]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3750, grad_fn=<NllLossBackward>)\n","epoch 1051, loss 0.3750181794166565\n","Parameter containing:\n","tensor([[-0.1904, -0.5090,  0.1998],\n","        [-0.8624, -0.5087, -0.0734],\n","        [-0.8696, -0.6599, -0.1203],\n","        [-0.3916, -0.3755, -0.0022]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4659, -0.3473,  0.0993,  0.1003], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7519,  0.6042,  0.9443,  0.0335],\n","        [-0.0415, -0.7575, -0.5489, -0.4422]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3264, -0.5518], requires_grad=True)\n","outputs:  tensor([[0.1288, 0.7966],\n","        [0.8894, 0.1613],\n","        [0.8784, 0.1752],\n","        [0.9832, 0.0401],\n","        [0.0322, 0.9514]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3749, grad_fn=<NllLossBackward>)\n","epoch 1052, loss 0.37491923570632935\n","outputs:  tensor([[0.1286, 0.7968],\n","        [0.8895, 0.1611],\n","        [0.8785, 0.1750],\n","        [0.9833, 0.0400],\n","        [0.0321, 0.9515]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3748, grad_fn=<NllLossBackward>)\n","epoch 1053, loss 0.3748205602169037\n","outputs:  tensor([[0.1285, 0.7971],\n","        [0.8897, 0.1608],\n","        [0.8787, 0.1748],\n","        [0.9833, 0.0399],\n","        [0.0320, 0.9517]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3747, grad_fn=<NllLossBackward>)\n","epoch 1054, loss 0.37472206354141235\n","outputs:  tensor([[0.1283, 0.7974],\n","        [0.8898, 0.1606],\n","        [0.8788, 0.1746],\n","        [0.9834, 0.0397],\n","        [0.0320, 0.9518]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3746, grad_fn=<NllLossBackward>)\n","epoch 1055, loss 0.3746238350868225\n","outputs:  tensor([[0.1281, 0.7977],\n","        [0.8899, 0.1604],\n","        [0.8790, 0.1744],\n","        [0.9834, 0.0396],\n","        [0.0319, 0.9519]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3745, grad_fn=<NllLossBackward>)\n","epoch 1056, loss 0.37452584505081177\n","outputs:  tensor([[0.1279, 0.7980],\n","        [0.8901, 0.1602],\n","        [0.8791, 0.1742],\n","        [0.9835, 0.0395],\n","        [0.0318, 0.9521]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3744, grad_fn=<NllLossBackward>)\n","epoch 1057, loss 0.37442803382873535\n","outputs:  tensor([[0.1277, 0.7982],\n","        [0.8902, 0.1600],\n","        [0.8792, 0.1740],\n","        [0.9835, 0.0394],\n","        [0.0317, 0.9522]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3743, grad_fn=<NllLossBackward>)\n","epoch 1058, loss 0.37433046102523804\n","outputs:  tensor([[0.1276, 0.7985],\n","        [0.8904, 0.1598],\n","        [0.8794, 0.1738],\n","        [0.9836, 0.0393],\n","        [0.0316, 0.9523]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3742, grad_fn=<NllLossBackward>)\n","epoch 1059, loss 0.3742331862449646\n","outputs:  tensor([[0.1274, 0.7988],\n","        [0.8905, 0.1596],\n","        [0.8795, 0.1736],\n","        [0.9836, 0.0392],\n","        [0.0316, 0.9525]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3741, grad_fn=<NllLossBackward>)\n","epoch 1060, loss 0.3741360306739807\n","outputs:  tensor([[0.1272, 0.7991],\n","        [0.8906, 0.1594],\n","        [0.8797, 0.1734],\n","        [0.9836, 0.0391],\n","        [0.0315, 0.9526]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3740, grad_fn=<NllLossBackward>)\n","epoch 1061, loss 0.3740391731262207\n","outputs:  tensor([[0.1270, 0.7994],\n","        [0.8908, 0.1592],\n","        [0.8798, 0.1732],\n","        [0.9837, 0.0390],\n","        [0.0314, 0.9527]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3739, grad_fn=<NllLossBackward>)\n","epoch 1062, loss 0.3739425837993622\n","outputs:  tensor([[0.1269, 0.7996],\n","        [0.8909, 0.1590],\n","        [0.8800, 0.1730],\n","        [0.9837, 0.0388],\n","        [0.0313, 0.9529]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3738, grad_fn=<NllLossBackward>)\n","epoch 1063, loss 0.373846173286438\n","outputs:  tensor([[0.1267, 0.7999],\n","        [0.8911, 0.1588],\n","        [0.8801, 0.1728],\n","        [0.9838, 0.0387],\n","        [0.0312, 0.9530]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3738, grad_fn=<NllLossBackward>)\n","epoch 1064, loss 0.37375006079673767\n","outputs:  tensor([[0.1265, 0.8002],\n","        [0.8912, 0.1586],\n","        [0.8802, 0.1726],\n","        [0.9838, 0.0386],\n","        [0.0312, 0.9531]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3737, grad_fn=<NllLossBackward>)\n","epoch 1065, loss 0.3736541271209717\n","outputs:  tensor([[0.1263, 0.8005],\n","        [0.8913, 0.1584],\n","        [0.8804, 0.1724],\n","        [0.9839, 0.0385],\n","        [0.0311, 0.9533]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3736, grad_fn=<NllLossBackward>)\n","epoch 1066, loss 0.37355837225914\n","outputs:  tensor([[0.1261, 0.8008],\n","        [0.8915, 0.1582],\n","        [0.8805, 0.1722],\n","        [0.9839, 0.0384],\n","        [0.0310, 0.9534]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3735, grad_fn=<NllLossBackward>)\n","epoch 1067, loss 0.37346288561820984\n","outputs:  tensor([[0.1260, 0.8010],\n","        [0.8916, 0.1580],\n","        [0.8807, 0.1720],\n","        [0.9840, 0.0383],\n","        [0.0309, 0.9535]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3734, grad_fn=<NllLossBackward>)\n","epoch 1068, loss 0.3733675479888916\n","outputs:  tensor([[0.1258, 0.8013],\n","        [0.8918, 0.1578],\n","        [0.8808, 0.1718],\n","        [0.9840, 0.0382],\n","        [0.0308, 0.9536]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3733, grad_fn=<NllLossBackward>)\n","epoch 1069, loss 0.3732725977897644\n","outputs:  tensor([[0.1256, 0.8016],\n","        [0.8919, 0.1576],\n","        [0.8809, 0.1716],\n","        [0.9840, 0.0381],\n","        [0.0308, 0.9538]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3732, grad_fn=<NllLossBackward>)\n","epoch 1070, loss 0.373177707195282\n","outputs:  tensor([[0.1254, 0.8019],\n","        [0.8920, 0.1574],\n","        [0.8811, 0.1714],\n","        [0.9841, 0.0380],\n","        [0.0307, 0.9539]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3731, grad_fn=<NllLossBackward>)\n","epoch 1071, loss 0.3730832040309906\n","outputs:  tensor([[0.1253, 0.8021],\n","        [0.8922, 0.1572],\n","        [0.8812, 0.1712],\n","        [0.9841, 0.0379],\n","        [0.0306, 0.9540]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3730, grad_fn=<NllLossBackward>)\n","epoch 1072, loss 0.3729887902736664\n","outputs:  tensor([[0.1251, 0.8024],\n","        [0.8923, 0.1570],\n","        [0.8813, 0.1710],\n","        [0.9842, 0.0377],\n","        [0.0305, 0.9542]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3729, grad_fn=<NllLossBackward>)\n","epoch 1073, loss 0.37289467453956604\n","outputs:  tensor([[0.1249, 0.8027],\n","        [0.8924, 0.1568],\n","        [0.8815, 0.1708],\n","        [0.9842, 0.0376],\n","        [0.0304, 0.9543]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3728, grad_fn=<NllLossBackward>)\n","epoch 1074, loss 0.3728007376194\n","outputs:  tensor([[0.1248, 0.8029],\n","        [0.8926, 0.1566],\n","        [0.8816, 0.1706],\n","        [0.9843, 0.0375],\n","        [0.0304, 0.9544]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3727, grad_fn=<NllLossBackward>)\n","epoch 1075, loss 0.37270697951316833\n","outputs:  tensor([[0.1246, 0.8032],\n","        [0.8927, 0.1564],\n","        [0.8818, 0.1704],\n","        [0.9843, 0.0374],\n","        [0.0303, 0.9545]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3726, grad_fn=<NllLossBackward>)\n","epoch 1076, loss 0.3726135194301605\n","outputs:  tensor([[0.1244, 0.8035],\n","        [0.8928, 0.1562],\n","        [0.8819, 0.1702],\n","        [0.9843, 0.0373],\n","        [0.0302, 0.9547]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3725, grad_fn=<NllLossBackward>)\n","epoch 1077, loss 0.3725202977657318\n","outputs:  tensor([[0.1242, 0.8038],\n","        [0.8930, 0.1560],\n","        [0.8820, 0.1700],\n","        [0.9844, 0.0372],\n","        [0.0301, 0.9548]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3724, grad_fn=<NllLossBackward>)\n","epoch 1078, loss 0.37242722511291504\n","outputs:  tensor([[0.1241, 0.8040],\n","        [0.8931, 0.1558],\n","        [0.8822, 0.1698],\n","        [0.9844, 0.0371],\n","        [0.0301, 0.9549]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3723, grad_fn=<NllLossBackward>)\n","epoch 1079, loss 0.37233442068099976\n","outputs:  tensor([[0.1239, 0.8043],\n","        [0.8932, 0.1556],\n","        [0.8823, 0.1696],\n","        [0.9845, 0.0370],\n","        [0.0300, 0.9550]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3722, grad_fn=<NllLossBackward>)\n","epoch 1080, loss 0.3722418248653412\n","outputs:  tensor([[0.1237, 0.8046],\n","        [0.8934, 0.1554],\n","        [0.8824, 0.1694],\n","        [0.9845, 0.0369],\n","        [0.0299, 0.9552]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3721, grad_fn=<NllLossBackward>)\n","epoch 1081, loss 0.37214937806129456\n","outputs:  tensor([[0.1235, 0.8048],\n","        [0.8935, 0.1552],\n","        [0.8826, 0.1692],\n","        [0.9845, 0.0368],\n","        [0.0298, 0.9553]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3721, grad_fn=<NllLossBackward>)\n","epoch 1082, loss 0.3720572590827942\n","outputs:  tensor([[0.1234, 0.8051],\n","        [0.8936, 0.1550],\n","        [0.8827, 0.1690],\n","        [0.9846, 0.0367],\n","        [0.0298, 0.9554]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3720, grad_fn=<NllLossBackward>)\n","epoch 1083, loss 0.3719652593135834\n","outputs:  tensor([[0.1232, 0.8054],\n","        [0.8938, 0.1548],\n","        [0.8829, 0.1688],\n","        [0.9846, 0.0366],\n","        [0.0297, 0.9555]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3719, grad_fn=<NllLossBackward>)\n","epoch 1084, loss 0.37187352776527405\n","outputs:  tensor([[0.1230, 0.8056],\n","        [0.8939, 0.1546],\n","        [0.8830, 0.1686],\n","        [0.9847, 0.0365],\n","        [0.0296, 0.9556]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3718, grad_fn=<NllLossBackward>)\n","epoch 1085, loss 0.37178197503089905\n","outputs:  tensor([[0.1229, 0.8059],\n","        [0.8940, 0.1545],\n","        [0.8831, 0.1684],\n","        [0.9847, 0.0364],\n","        [0.0295, 0.9558]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3717, grad_fn=<NllLossBackward>)\n","epoch 1086, loss 0.37169069051742554\n","outputs:  tensor([[0.1227, 0.8062],\n","        [0.8942, 0.1543],\n","        [0.8833, 0.1682],\n","        [0.9848, 0.0363],\n","        [0.0295, 0.9559]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3716, grad_fn=<NllLossBackward>)\n","epoch 1087, loss 0.37159958481788635\n","outputs:  tensor([[0.1225, 0.8064],\n","        [0.8943, 0.1541],\n","        [0.8834, 0.1680],\n","        [0.9848, 0.0362],\n","        [0.0294, 0.9560]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3715, grad_fn=<NllLossBackward>)\n","epoch 1088, loss 0.3715086877346039\n","outputs:  tensor([[0.1224, 0.8067],\n","        [0.8944, 0.1539],\n","        [0.8835, 0.1678],\n","        [0.9848, 0.0361],\n","        [0.0293, 0.9561]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3714, grad_fn=<NllLossBackward>)\n","epoch 1089, loss 0.3714179992675781\n","outputs:  tensor([[0.1222, 0.8070],\n","        [0.8946, 0.1537],\n","        [0.8837, 0.1676],\n","        [0.9849, 0.0360],\n","        [0.0292, 0.9562]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3713, grad_fn=<NllLossBackward>)\n","epoch 1090, loss 0.37132754921913147\n","outputs:  tensor([[0.1220, 0.8072],\n","        [0.8947, 0.1535],\n","        [0.8838, 0.1674],\n","        [0.9849, 0.0359],\n","        [0.0292, 0.9564]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3712, grad_fn=<NllLossBackward>)\n","epoch 1091, loss 0.3712373375892639\n","outputs:  tensor([[0.1219, 0.8075],\n","        [0.8948, 0.1533],\n","        [0.8839, 0.1672],\n","        [0.9850, 0.0358],\n","        [0.0291, 0.9565]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3711, grad_fn=<NllLossBackward>)\n","epoch 1092, loss 0.3711472153663635\n","outputs:  tensor([[0.1217, 0.8078],\n","        [0.8950, 0.1531],\n","        [0.8841, 0.1670],\n","        [0.9850, 0.0357],\n","        [0.0290, 0.9566]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3711, grad_fn=<NllLossBackward>)\n","epoch 1093, loss 0.3710574209690094\n","outputs:  tensor([[0.1215, 0.8080],\n","        [0.8951, 0.1529],\n","        [0.8842, 0.1669],\n","        [0.9850, 0.0356],\n","        [0.0289, 0.9567]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3710, grad_fn=<NllLossBackward>)\n","epoch 1094, loss 0.3709677755832672\n","outputs:  tensor([[0.1214, 0.8083],\n","        [0.8952, 0.1527],\n","        [0.8843, 0.1667],\n","        [0.9851, 0.0355],\n","        [0.0289, 0.9568]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3709, grad_fn=<NllLossBackward>)\n","epoch 1095, loss 0.3708783984184265\n","outputs:  tensor([[0.1212, 0.8086],\n","        [0.8954, 0.1525],\n","        [0.8845, 0.1665],\n","        [0.9851, 0.0354],\n","        [0.0288, 0.9570]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3708, grad_fn=<NllLossBackward>)\n","epoch 1096, loss 0.37078914046287537\n","outputs:  tensor([[0.1210, 0.8088],\n","        [0.8955, 0.1523],\n","        [0.8846, 0.1663],\n","        [0.9852, 0.0353],\n","        [0.0287, 0.9571]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3707, grad_fn=<NllLossBackward>)\n","epoch 1097, loss 0.3707002103328705\n","outputs:  tensor([[0.1209, 0.8091],\n","        [0.8956, 0.1521],\n","        [0.8847, 0.1661],\n","        [0.9852, 0.0352],\n","        [0.0287, 0.9572]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3706, grad_fn=<NllLossBackward>)\n","epoch 1098, loss 0.37061136960983276\n","outputs:  tensor([[0.1207, 0.8093],\n","        [0.8958, 0.1520],\n","        [0.8849, 0.1659],\n","        [0.9852, 0.0351],\n","        [0.0286, 0.9573]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3705, grad_fn=<NllLossBackward>)\n","epoch 1099, loss 0.3705228269100189\n","outputs:  tensor([[0.1205, 0.8096],\n","        [0.8959, 0.1518],\n","        [0.8850, 0.1657],\n","        [0.9853, 0.0350],\n","        [0.0285, 0.9574]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3704, grad_fn=<NllLossBackward>)\n","epoch 1100, loss 0.37043440341949463\n","outputs:  tensor([[0.1204, 0.8099],\n","        [0.8960, 0.1516],\n","        [0.8851, 0.1655],\n","        [0.9853, 0.0349],\n","        [0.0284, 0.9575]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3703, grad_fn=<NllLossBackward>)\n","epoch 1101, loss 0.37034621834754944\n","Parameter containing:\n","tensor([[-0.1958, -0.5175,  0.1994],\n","        [-0.8740, -0.5263, -0.0739],\n","        [-0.8815, -0.6779, -0.1209],\n","        [-0.3963, -0.3826, -0.0024]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4679, -0.3432,  0.1035,  0.1019], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7595,  0.6145,  0.9572,  0.0403],\n","        [-0.0526, -0.7726, -0.5679, -0.4521]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3288, -0.5552], requires_grad=True)\n","outputs:  tensor([[0.1202, 0.8101],\n","        [0.8961, 0.1514],\n","        [0.8853, 0.1653],\n","        [0.9853, 0.0348],\n","        [0.0284, 0.9577]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3703, grad_fn=<NllLossBackward>)\n","epoch 1102, loss 0.37025827169418335\n","outputs:  tensor([[0.1200, 0.8104],\n","        [0.8963, 0.1512],\n","        [0.8854, 0.1651],\n","        [0.9854, 0.0347],\n","        [0.0283, 0.9578]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3702, grad_fn=<NllLossBackward>)\n","epoch 1103, loss 0.3701704740524292\n","outputs:  tensor([[0.1199, 0.8106],\n","        [0.8964, 0.1510],\n","        [0.8855, 0.1649],\n","        [0.9854, 0.0346],\n","        [0.0282, 0.9579]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3701, grad_fn=<NllLossBackward>)\n","epoch 1104, loss 0.37008294463157654\n","outputs:  tensor([[0.1197, 0.8109],\n","        [0.8965, 0.1508],\n","        [0.8856, 0.1648],\n","        [0.9855, 0.0345],\n","        [0.0282, 0.9580]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3700, grad_fn=<NllLossBackward>)\n","epoch 1105, loss 0.3699955940246582\n","outputs:  tensor([[0.1196, 0.8111],\n","        [0.8967, 0.1506],\n","        [0.8858, 0.1646],\n","        [0.9855, 0.0344],\n","        [0.0281, 0.9581]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3699, grad_fn=<NllLossBackward>)\n","epoch 1106, loss 0.3699084222316742\n","outputs:  tensor([[0.1194, 0.8114],\n","        [0.8968, 0.1504],\n","        [0.8859, 0.1644],\n","        [0.9855, 0.0343],\n","        [0.0280, 0.9582]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3698, grad_fn=<NllLossBackward>)\n","epoch 1107, loss 0.3698214590549469\n","outputs:  tensor([[0.1192, 0.8117],\n","        [0.8969, 0.1503],\n","        [0.8860, 0.1642],\n","        [0.9856, 0.0342],\n","        [0.0280, 0.9583]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3697, grad_fn=<NllLossBackward>)\n","epoch 1108, loss 0.3697347342967987\n","outputs:  tensor([[0.1191, 0.8119],\n","        [0.8970, 0.1501],\n","        [0.8862, 0.1640],\n","        [0.9856, 0.0341],\n","        [0.0279, 0.9584]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3696, grad_fn=<NllLossBackward>)\n","epoch 1109, loss 0.36964812874794006\n","outputs:  tensor([[0.1189, 0.8122],\n","        [0.8972, 0.1499],\n","        [0.8863, 0.1638],\n","        [0.9857, 0.0340],\n","        [0.0278, 0.9586]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3696, grad_fn=<NllLossBackward>)\n","epoch 1110, loss 0.3695617616176605\n","outputs:  tensor([[0.1187, 0.8124],\n","        [0.8973, 0.1497],\n","        [0.8864, 0.1636],\n","        [0.9857, 0.0339],\n","        [0.0278, 0.9587]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3695, grad_fn=<NllLossBackward>)\n","epoch 1111, loss 0.36947566270828247\n","outputs:  tensor([[0.1186, 0.8127],\n","        [0.8974, 0.1495],\n","        [0.8866, 0.1634],\n","        [0.9857, 0.0338],\n","        [0.0277, 0.9588]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3694, grad_fn=<NllLossBackward>)\n","epoch 1112, loss 0.36938968300819397\n","outputs:  tensor([[0.1184, 0.8129],\n","        [0.8975, 0.1493],\n","        [0.8867, 0.1633],\n","        [0.9858, 0.0337],\n","        [0.0276, 0.9589]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3693, grad_fn=<NllLossBackward>)\n","epoch 1113, loss 0.36930397152900696\n","outputs:  tensor([[0.1183, 0.8132],\n","        [0.8977, 0.1491],\n","        [0.8868, 0.1631],\n","        [0.9858, 0.0336],\n","        [0.0275, 0.9590]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3692, grad_fn=<NllLossBackward>)\n","epoch 1114, loss 0.3692183792591095\n","outputs:  tensor([[0.1181, 0.8134],\n","        [0.8978, 0.1489],\n","        [0.8869, 0.1629],\n","        [0.9858, 0.0335],\n","        [0.0275, 0.9591]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3691, grad_fn=<NllLossBackward>)\n","epoch 1115, loss 0.36913296580314636\n","outputs:  tensor([[0.1179, 0.8137],\n","        [0.8979, 0.1488],\n","        [0.8871, 0.1627],\n","        [0.9859, 0.0334],\n","        [0.0274, 0.9592]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3690, grad_fn=<NllLossBackward>)\n","epoch 1116, loss 0.3690478503704071\n","outputs:  tensor([[0.1178, 0.8140],\n","        [0.8981, 0.1486],\n","        [0.8872, 0.1625],\n","        [0.9859, 0.0333],\n","        [0.0273, 0.9593]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3690, grad_fn=<NllLossBackward>)\n","epoch 1117, loss 0.368962824344635\n","outputs:  tensor([[0.1176, 0.8142],\n","        [0.8982, 0.1484],\n","        [0.8873, 0.1623],\n","        [0.9859, 0.0332],\n","        [0.0273, 0.9594]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3689, grad_fn=<NllLossBackward>)\n","epoch 1118, loss 0.3688780963420868\n","outputs:  tensor([[0.1175, 0.8145],\n","        [0.8983, 0.1482],\n","        [0.8875, 0.1621],\n","        [0.9860, 0.0332],\n","        [0.0272, 0.9595]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3688, grad_fn=<NllLossBackward>)\n","epoch 1119, loss 0.3687934875488281\n","outputs:  tensor([[0.1173, 0.8147],\n","        [0.8984, 0.1480],\n","        [0.8876, 0.1620],\n","        [0.9860, 0.0331],\n","        [0.0271, 0.9597]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3687, grad_fn=<NllLossBackward>)\n","epoch 1120, loss 0.36870908737182617\n","outputs:  tensor([[0.1172, 0.8150],\n","        [0.8986, 0.1478],\n","        [0.8877, 0.1618],\n","        [0.9861, 0.0330],\n","        [0.0271, 0.9598]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3686, grad_fn=<NllLossBackward>)\n","epoch 1121, loss 0.36862486600875854\n","outputs:  tensor([[0.1170, 0.8152],\n","        [0.8987, 0.1477],\n","        [0.8878, 0.1616],\n","        [0.9861, 0.0329],\n","        [0.0270, 0.9599]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3685, grad_fn=<NllLossBackward>)\n","epoch 1122, loss 0.36854085326194763\n","outputs:  tensor([[0.1168, 0.8155],\n","        [0.8988, 0.1475],\n","        [0.8880, 0.1614],\n","        [0.9861, 0.0328],\n","        [0.0269, 0.9600]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3685, grad_fn=<NllLossBackward>)\n","epoch 1123, loss 0.3684570789337158\n","outputs:  tensor([[0.1167, 0.8157],\n","        [0.8989, 0.1473],\n","        [0.8881, 0.1612],\n","        [0.9862, 0.0327],\n","        [0.0269, 0.9601]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3684, grad_fn=<NllLossBackward>)\n","epoch 1124, loss 0.36837348341941833\n","outputs:  tensor([[0.1165, 0.8160],\n","        [0.8991, 0.1471],\n","        [0.8882, 0.1610],\n","        [0.9862, 0.0326],\n","        [0.0268, 0.9602]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3683, grad_fn=<NllLossBackward>)\n","epoch 1125, loss 0.3682900667190552\n","outputs:  tensor([[0.1164, 0.8162],\n","        [0.8992, 0.1469],\n","        [0.8883, 0.1608],\n","        [0.9862, 0.0325],\n","        [0.0268, 0.9603]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3682, grad_fn=<NllLossBackward>)\n","epoch 1126, loss 0.36820685863494873\n","outputs:  tensor([[0.1162, 0.8165],\n","        [0.8993, 0.1467],\n","        [0.8885, 0.1607],\n","        [0.9863, 0.0324],\n","        [0.0267, 0.9604]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3681, grad_fn=<NllLossBackward>)\n","epoch 1127, loss 0.36812376976013184\n","outputs:  tensor([[0.1161, 0.8167],\n","        [0.8994, 0.1466],\n","        [0.8886, 0.1605],\n","        [0.9863, 0.0323],\n","        [0.0266, 0.9605]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3680, grad_fn=<NllLossBackward>)\n","epoch 1128, loss 0.36804094910621643\n","outputs:  tensor([[0.1159, 0.8169],\n","        [0.8995, 0.1464],\n","        [0.8887, 0.1603],\n","        [0.9863, 0.0322],\n","        [0.0266, 0.9606]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3680, grad_fn=<NllLossBackward>)\n","epoch 1129, loss 0.36795827746391296\n","outputs:  tensor([[0.1157, 0.8172],\n","        [0.8997, 0.1462],\n","        [0.8888, 0.1601],\n","        [0.9864, 0.0322],\n","        [0.0265, 0.9607]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3679, grad_fn=<NllLossBackward>)\n","epoch 1130, loss 0.36787575483322144\n","outputs:  tensor([[0.1156, 0.8174],\n","        [0.8998, 0.1460],\n","        [0.8890, 0.1599],\n","        [0.9864, 0.0321],\n","        [0.0264, 0.9608]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3678, grad_fn=<NllLossBackward>)\n","epoch 1131, loss 0.36779356002807617\n","outputs:  tensor([[0.1154, 0.8177],\n","        [0.8999, 0.1458],\n","        [0.8891, 0.1598],\n","        [0.9864, 0.0320],\n","        [0.0264, 0.9609]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3677, grad_fn=<NllLossBackward>)\n","epoch 1132, loss 0.36771145462989807\n","outputs:  tensor([[0.1153, 0.8179],\n","        [0.9000, 0.1457],\n","        [0.8892, 0.1596],\n","        [0.9865, 0.0319],\n","        [0.0263, 0.9610]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3676, grad_fn=<NllLossBackward>)\n","epoch 1133, loss 0.3676294982433319\n","outputs:  tensor([[0.1151, 0.8182],\n","        [0.9002, 0.1455],\n","        [0.8893, 0.1594],\n","        [0.9865, 0.0318],\n","        [0.0262, 0.9611]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3675, grad_fn=<NllLossBackward>)\n","epoch 1134, loss 0.36754775047302246\n","outputs:  tensor([[0.1150, 0.8184],\n","        [0.9003, 0.1453],\n","        [0.8895, 0.1592],\n","        [0.9866, 0.0317],\n","        [0.0262, 0.9612]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3675, grad_fn=<NllLossBackward>)\n","epoch 1135, loss 0.3674662709236145\n","outputs:  tensor([[0.1148, 0.8187],\n","        [0.9004, 0.1451],\n","        [0.8896, 0.1590],\n","        [0.9866, 0.0316],\n","        [0.0261, 0.9613]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3674, grad_fn=<NllLossBackward>)\n","epoch 1136, loss 0.3673848509788513\n","outputs:  tensor([[0.1147, 0.8189],\n","        [0.9005, 0.1449],\n","        [0.8897, 0.1589],\n","        [0.9866, 0.0315],\n","        [0.0260, 0.9614]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3673, grad_fn=<NllLossBackward>)\n","epoch 1137, loss 0.367303729057312\n","outputs:  tensor([[0.1145, 0.8191],\n","        [0.9006, 0.1448],\n","        [0.8898, 0.1587],\n","        [0.9867, 0.0315],\n","        [0.0260, 0.9615]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3672, grad_fn=<NllLossBackward>)\n","epoch 1138, loss 0.36722272634506226\n","outputs:  tensor([[0.1144, 0.8194],\n","        [0.9008, 0.1446],\n","        [0.8900, 0.1585],\n","        [0.9867, 0.0314],\n","        [0.0259, 0.9616]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3671, grad_fn=<NllLossBackward>)\n","epoch 1139, loss 0.3671419024467468\n","outputs:  tensor([[0.1142, 0.8196],\n","        [0.9009, 0.1444],\n","        [0.8901, 0.1583],\n","        [0.9867, 0.0313],\n","        [0.0259, 0.9617]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3671, grad_fn=<NllLossBackward>)\n","epoch 1140, loss 0.3670613169670105\n","outputs:  tensor([[0.1141, 0.8199],\n","        [0.9010, 0.1442],\n","        [0.8902, 0.1581],\n","        [0.9868, 0.0312],\n","        [0.0258, 0.9618]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3670, grad_fn=<NllLossBackward>)\n","epoch 1141, loss 0.3669808804988861\n","outputs:  tensor([[0.1139, 0.8201],\n","        [0.9011, 0.1441],\n","        [0.8903, 0.1580],\n","        [0.9868, 0.0311],\n","        [0.0257, 0.9619]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3669, grad_fn=<NllLossBackward>)\n","epoch 1142, loss 0.36690059304237366\n","outputs:  tensor([[0.1138, 0.8204],\n","        [0.9012, 0.1439],\n","        [0.8905, 0.1578],\n","        [0.9868, 0.0310],\n","        [0.0257, 0.9620]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3668, grad_fn=<NllLossBackward>)\n","epoch 1143, loss 0.36682063341140747\n","outputs:  tensor([[0.1136, 0.8206],\n","        [0.9014, 0.1437],\n","        [0.8906, 0.1576],\n","        [0.9869, 0.0309],\n","        [0.0256, 0.9621]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3667, grad_fn=<NllLossBackward>)\n","epoch 1144, loss 0.36674070358276367\n","outputs:  tensor([[0.1135, 0.8208],\n","        [0.9015, 0.1435],\n","        [0.8907, 0.1574],\n","        [0.9869, 0.0309],\n","        [0.0256, 0.9622]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3667, grad_fn=<NllLossBackward>)\n","epoch 1145, loss 0.366661012172699\n","outputs:  tensor([[0.1133, 0.8211],\n","        [0.9016, 0.1433],\n","        [0.8908, 0.1572],\n","        [0.9869, 0.0308],\n","        [0.0255, 0.9623]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3666, grad_fn=<NllLossBackward>)\n","epoch 1146, loss 0.3665814697742462\n","outputs:  tensor([[0.1132, 0.8213],\n","        [0.9017, 0.1432],\n","        [0.8909, 0.1571],\n","        [0.9870, 0.0307],\n","        [0.0254, 0.9624]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3665, grad_fn=<NllLossBackward>)\n","epoch 1147, loss 0.36650216579437256\n","outputs:  tensor([[0.1130, 0.8216],\n","        [0.9018, 0.1430],\n","        [0.8911, 0.1569],\n","        [0.9870, 0.0306],\n","        [0.0254, 0.9625]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3664, grad_fn=<NllLossBackward>)\n","epoch 1148, loss 0.36642295122146606\n","outputs:  tensor([[0.1129, 0.8218],\n","        [0.9020, 0.1428],\n","        [0.8912, 0.1567],\n","        [0.9870, 0.0305],\n","        [0.0253, 0.9626]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3663, grad_fn=<NllLossBackward>)\n","epoch 1149, loss 0.3663439154624939\n","outputs:  tensor([[0.1127, 0.8220],\n","        [0.9021, 0.1426],\n","        [0.8913, 0.1565],\n","        [0.9871, 0.0304],\n","        [0.0253, 0.9627]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3663, grad_fn=<NllLossBackward>)\n","epoch 1150, loss 0.3662651777267456\n","outputs:  tensor([[0.1126, 0.8223],\n","        [0.9022, 0.1425],\n","        [0.8914, 0.1564],\n","        [0.9871, 0.0304],\n","        [0.0252, 0.9628]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3662, grad_fn=<NllLossBackward>)\n","epoch 1151, loss 0.3661865293979645\n","Parameter containing:\n","tensor([[-0.2010, -0.5255,  0.1991],\n","        [-0.8849, -0.5429, -0.0743],\n","        [-0.8926, -0.6950, -0.1214],\n","        [-0.4007, -0.3893, -0.0025]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4699, -0.3392,  0.1076,  0.1034], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7667,  0.6241,  0.9694,  0.0466],\n","        [-0.0630, -0.7869, -0.5858, -0.4614]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3312, -0.5584], requires_grad=True)\n","outputs:  tensor([[0.1124, 0.8225],\n","        [0.9023, 0.1423],\n","        [0.8915, 0.1562],\n","        [0.9871, 0.0303],\n","        [0.0251, 0.9629]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3661, grad_fn=<NllLossBackward>)\n","epoch 1152, loss 0.3661080598831177\n","outputs:  tensor([[0.1123, 0.8227],\n","        [0.9024, 0.1421],\n","        [0.8917, 0.1560],\n","        [0.9872, 0.0302],\n","        [0.0251, 0.9630]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3660, grad_fn=<NllLossBackward>)\n","epoch 1153, loss 0.3660297989845276\n","outputs:  tensor([[0.1121, 0.8230],\n","        [0.9025, 0.1419],\n","        [0.8918, 0.1558],\n","        [0.9872, 0.0301],\n","        [0.0250, 0.9631]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3660, grad_fn=<NllLossBackward>)\n","epoch 1154, loss 0.3659517168998718\n","outputs:  tensor([[0.1120, 0.8232],\n","        [0.9027, 0.1418],\n","        [0.8919, 0.1557],\n","        [0.9872, 0.0300],\n","        [0.0250, 0.9632]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3659, grad_fn=<NllLossBackward>)\n","epoch 1155, loss 0.36587387323379517\n","outputs:  tensor([[0.1118, 0.8234],\n","        [0.9028, 0.1416],\n","        [0.8920, 0.1555],\n","        [0.9873, 0.0300],\n","        [0.0249, 0.9633]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3658, grad_fn=<NllLossBackward>)\n","epoch 1156, loss 0.3657960295677185\n","outputs:  tensor([[0.1117, 0.8237],\n","        [0.9029, 0.1414],\n","        [0.8921, 0.1553],\n","        [0.9873, 0.0299],\n","        [0.0248, 0.9634]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3657, grad_fn=<NllLossBackward>)\n","epoch 1157, loss 0.3657184839248657\n","outputs:  tensor([[0.1115, 0.8239],\n","        [0.9030, 0.1413],\n","        [0.8923, 0.1551],\n","        [0.9873, 0.0298],\n","        [0.0248, 0.9635]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3656, grad_fn=<NllLossBackward>)\n","epoch 1158, loss 0.3656410574913025\n","outputs:  tensor([[0.1114, 0.8242],\n","        [0.9031, 0.1411],\n","        [0.8924, 0.1550],\n","        [0.9873, 0.0297],\n","        [0.0247, 0.9636]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3656, grad_fn=<NllLossBackward>)\n","epoch 1159, loss 0.36556386947631836\n","outputs:  tensor([[0.1112, 0.8244],\n","        [0.9032, 0.1409],\n","        [0.8925, 0.1548],\n","        [0.9874, 0.0296],\n","        [0.0247, 0.9637]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3655, grad_fn=<NllLossBackward>)\n","epoch 1160, loss 0.3654868006706238\n","outputs:  tensor([[0.1111, 0.8246],\n","        [0.9034, 0.1407],\n","        [0.8926, 0.1546],\n","        [0.9874, 0.0295],\n","        [0.0246, 0.9638]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3654, grad_fn=<NllLossBackward>)\n","epoch 1161, loss 0.3654099702835083\n","outputs:  tensor([[0.1110, 0.8249],\n","        [0.9035, 0.1406],\n","        [0.8927, 0.1544],\n","        [0.9874, 0.0295],\n","        [0.0245, 0.9639]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3653, grad_fn=<NllLossBackward>)\n","epoch 1162, loss 0.3653332591056824\n","outputs:  tensor([[0.1108, 0.8251],\n","        [0.9036, 0.1404],\n","        [0.8929, 0.1543],\n","        [0.9875, 0.0294],\n","        [0.0245, 0.9640]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3653, grad_fn=<NllLossBackward>)\n","epoch 1163, loss 0.36525672674179077\n","outputs:  tensor([[0.1107, 0.8253],\n","        [0.9037, 0.1402],\n","        [0.8930, 0.1541],\n","        [0.9875, 0.0293],\n","        [0.0244, 0.9641]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3652, grad_fn=<NllLossBackward>)\n","epoch 1164, loss 0.3651803433895111\n","outputs:  tensor([[0.1105, 0.8255],\n","        [0.9038, 0.1401],\n","        [0.8931, 0.1539],\n","        [0.9875, 0.0292],\n","        [0.0244, 0.9641]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3651, grad_fn=<NllLossBackward>)\n","epoch 1165, loss 0.36510416865348816\n","outputs:  tensor([[0.1104, 0.8258],\n","        [0.9039, 0.1399],\n","        [0.8932, 0.1538],\n","        [0.9876, 0.0292],\n","        [0.0243, 0.9642]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3650, grad_fn=<NllLossBackward>)\n","epoch 1166, loss 0.36502811312675476\n","outputs:  tensor([[0.1102, 0.8260],\n","        [0.9041, 0.1397],\n","        [0.8933, 0.1536],\n","        [0.9876, 0.0291],\n","        [0.0243, 0.9643]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3650, grad_fn=<NllLossBackward>)\n","epoch 1167, loss 0.36495232582092285\n","outputs:  tensor([[0.1101, 0.8262],\n","        [0.9042, 0.1395],\n","        [0.8934, 0.1534],\n","        [0.9876, 0.0290],\n","        [0.0242, 0.9644]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3649, grad_fn=<NllLossBackward>)\n","epoch 1168, loss 0.3648765981197357\n","outputs:  tensor([[0.1099, 0.8265],\n","        [0.9043, 0.1394],\n","        [0.8936, 0.1532],\n","        [0.9877, 0.0289],\n","        [0.0241, 0.9645]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3648, grad_fn=<NllLossBackward>)\n","epoch 1169, loss 0.3648011088371277\n","outputs:  tensor([[0.1098, 0.8267],\n","        [0.9044, 0.1392],\n","        [0.8937, 0.1531],\n","        [0.9877, 0.0288],\n","        [0.0241, 0.9646]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3647, grad_fn=<NllLossBackward>)\n","epoch 1170, loss 0.364725798368454\n","outputs:  tensor([[0.1097, 0.8269],\n","        [0.9045, 0.1390],\n","        [0.8938, 0.1529],\n","        [0.9877, 0.0288],\n","        [0.0240, 0.9647]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3647, grad_fn=<NllLossBackward>)\n","epoch 1171, loss 0.3646506369113922\n","outputs:  tensor([[0.1095, 0.8272],\n","        [0.9046, 0.1389],\n","        [0.8939, 0.1527],\n","        [0.9878, 0.0287],\n","        [0.0240, 0.9648]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3646, grad_fn=<NllLossBackward>)\n","epoch 1172, loss 0.3645755350589752\n","outputs:  tensor([[0.1094, 0.8274],\n","        [0.9047, 0.1387],\n","        [0.8940, 0.1526],\n","        [0.9878, 0.0286],\n","        [0.0239, 0.9649]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3645, grad_fn=<NllLossBackward>)\n","epoch 1173, loss 0.36450082063674927\n","outputs:  tensor([[0.1092, 0.8276],\n","        [0.9049, 0.1385],\n","        [0.8942, 0.1524],\n","        [0.9878, 0.0285],\n","        [0.0239, 0.9650]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3644, grad_fn=<NllLossBackward>)\n","epoch 1174, loss 0.3644260764122009\n","outputs:  tensor([[0.1091, 0.8278],\n","        [0.9050, 0.1384],\n","        [0.8943, 0.1522],\n","        [0.9878, 0.0285],\n","        [0.0238, 0.9651]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3644, grad_fn=<NllLossBackward>)\n","epoch 1175, loss 0.36435166001319885\n","outputs:  tensor([[0.1090, 0.8281],\n","        [0.9051, 0.1382],\n","        [0.8944, 0.1520],\n","        [0.9879, 0.0284],\n","        [0.0238, 0.9651]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3643, grad_fn=<NllLossBackward>)\n","epoch 1176, loss 0.3642772436141968\n","outputs:  tensor([[0.1088, 0.8283],\n","        [0.9052, 0.1380],\n","        [0.8945, 0.1519],\n","        [0.9879, 0.0283],\n","        [0.0237, 0.9652]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3642, grad_fn=<NllLossBackward>)\n","epoch 1177, loss 0.3642031252384186\n","outputs:  tensor([[0.1087, 0.8285],\n","        [0.9053, 0.1379],\n","        [0.8946, 0.1517],\n","        [0.9879, 0.0282],\n","        [0.0236, 0.9653]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3641, grad_fn=<NllLossBackward>)\n","epoch 1178, loss 0.36412912607192993\n","outputs:  tensor([[0.1085, 0.8287],\n","        [0.9054, 0.1377],\n","        [0.8947, 0.1515],\n","        [0.9880, 0.0281],\n","        [0.0236, 0.9654]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3641, grad_fn=<NllLossBackward>)\n","epoch 1179, loss 0.36405524611473083\n","outputs:  tensor([[0.1084, 0.8290],\n","        [0.9055, 0.1375],\n","        [0.8948, 0.1514],\n","        [0.9880, 0.0281],\n","        [0.0235, 0.9655]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3640, grad_fn=<NllLossBackward>)\n","epoch 1180, loss 0.36398157477378845\n","outputs:  tensor([[0.1082, 0.8292],\n","        [0.9056, 0.1374],\n","        [0.8950, 0.1512],\n","        [0.9880, 0.0280],\n","        [0.0235, 0.9656]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3639, grad_fn=<NllLossBackward>)\n","epoch 1181, loss 0.363908052444458\n","outputs:  tensor([[0.1081, 0.8294],\n","        [0.9058, 0.1372],\n","        [0.8951, 0.1510],\n","        [0.9881, 0.0279],\n","        [0.0234, 0.9657]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3638, grad_fn=<NllLossBackward>)\n","epoch 1182, loss 0.36383476853370667\n","outputs:  tensor([[0.1080, 0.8296],\n","        [0.9059, 0.1370],\n","        [0.8952, 0.1509],\n","        [0.9881, 0.0279],\n","        [0.0234, 0.9658]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3638, grad_fn=<NllLossBackward>)\n","epoch 1183, loss 0.3637615144252777\n","outputs:  tensor([[0.1078, 0.8299],\n","        [0.9060, 0.1369],\n","        [0.8953, 0.1507],\n","        [0.9881, 0.0278],\n","        [0.0233, 0.9659]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3637, grad_fn=<NllLossBackward>)\n","epoch 1184, loss 0.36368852853775024\n","outputs:  tensor([[0.1077, 0.8301],\n","        [0.9061, 0.1367],\n","        [0.8954, 0.1505],\n","        [0.9881, 0.0277],\n","        [0.0233, 0.9659]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3636, grad_fn=<NllLossBackward>)\n","epoch 1185, loss 0.36361566185951233\n","outputs:  tensor([[0.1076, 0.8303],\n","        [0.9062, 0.1365],\n","        [0.8955, 0.1504],\n","        [0.9882, 0.0276],\n","        [0.0232, 0.9660]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3635, grad_fn=<NllLossBackward>)\n","epoch 1186, loss 0.36354294419288635\n","outputs:  tensor([[0.1074, 0.8305],\n","        [0.9063, 0.1364],\n","        [0.8956, 0.1502],\n","        [0.9882, 0.0276],\n","        [0.0232, 0.9661]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3635, grad_fn=<NllLossBackward>)\n","epoch 1187, loss 0.3634704649448395\n","outputs:  tensor([[0.1073, 0.8308],\n","        [0.9064, 0.1362],\n","        [0.8958, 0.1500],\n","        [0.9882, 0.0275],\n","        [0.0231, 0.9662]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3634, grad_fn=<NllLossBackward>)\n","epoch 1188, loss 0.36339807510375977\n","outputs:  tensor([[0.1071, 0.8310],\n","        [0.9065, 0.1360],\n","        [0.8959, 0.1499],\n","        [0.9883, 0.0274],\n","        [0.0230, 0.9663]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3633, grad_fn=<NllLossBackward>)\n","epoch 1189, loss 0.3633258640766144\n","outputs:  tensor([[0.1070, 0.8312],\n","        [0.9066, 0.1359],\n","        [0.8960, 0.1497],\n","        [0.9883, 0.0273],\n","        [0.0230, 0.9664]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3633, grad_fn=<NllLossBackward>)\n","epoch 1190, loss 0.36325377225875854\n","outputs:  tensor([[0.1069, 0.8314],\n","        [0.9067, 0.1357],\n","        [0.8961, 0.1495],\n","        [0.9883, 0.0273],\n","        [0.0229, 0.9665]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3632, grad_fn=<NllLossBackward>)\n","epoch 1191, loss 0.36318185925483704\n","outputs:  tensor([[0.1067, 0.8316],\n","        [0.9069, 0.1356],\n","        [0.8962, 0.1494],\n","        [0.9883, 0.0272],\n","        [0.0229, 0.9665]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3631, grad_fn=<NllLossBackward>)\n","epoch 1192, loss 0.36311012506484985\n","outputs:  tensor([[0.1066, 0.8319],\n","        [0.9070, 0.1354],\n","        [0.8963, 0.1492],\n","        [0.9884, 0.0271],\n","        [0.0228, 0.9666]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3630, grad_fn=<NllLossBackward>)\n","epoch 1193, loss 0.3630385398864746\n","outputs:  tensor([[0.1065, 0.8321],\n","        [0.9071, 0.1352],\n","        [0.8964, 0.1490],\n","        [0.9884, 0.0270],\n","        [0.0228, 0.9667]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3630, grad_fn=<NllLossBackward>)\n","epoch 1194, loss 0.3629671037197113\n","outputs:  tensor([[0.1063, 0.8323],\n","        [0.9072, 0.1351],\n","        [0.8965, 0.1489],\n","        [0.9884, 0.0270],\n","        [0.0227, 0.9668]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3629, grad_fn=<NllLossBackward>)\n","epoch 1195, loss 0.3628958761692047\n","outputs:  tensor([[0.1062, 0.8325],\n","        [0.9073, 0.1349],\n","        [0.8967, 0.1487],\n","        [0.9885, 0.0269],\n","        [0.0227, 0.9669]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3628, grad_fn=<NllLossBackward>)\n","epoch 1196, loss 0.36282476782798767\n","outputs:  tensor([[0.1060, 0.8327],\n","        [0.9074, 0.1347],\n","        [0.8968, 0.1486],\n","        [0.9885, 0.0268],\n","        [0.0226, 0.9670]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3628, grad_fn=<NllLossBackward>)\n","epoch 1197, loss 0.36275380849838257\n","outputs:  tensor([[0.1059, 0.8330],\n","        [0.9075, 0.1346],\n","        [0.8969, 0.1484],\n","        [0.9885, 0.0268],\n","        [0.0226, 0.9670]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3627, grad_fn=<NllLossBackward>)\n","epoch 1198, loss 0.362682968378067\n","outputs:  tensor([[0.1058, 0.8332],\n","        [0.9076, 0.1344],\n","        [0.8970, 0.1482],\n","        [0.9885, 0.0267],\n","        [0.0225, 0.9671]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3626, grad_fn=<NllLossBackward>)\n","epoch 1199, loss 0.36261239647865295\n","outputs:  tensor([[0.1056, 0.8334],\n","        [0.9077, 0.1343],\n","        [0.8971, 0.1481],\n","        [0.9886, 0.0266],\n","        [0.0225, 0.9672]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3625, grad_fn=<NllLossBackward>)\n","epoch 1200, loss 0.3625418543815613\n","outputs:  tensor([[0.1055, 0.8336],\n","        [0.9078, 0.1341],\n","        [0.8972, 0.1479],\n","        [0.9886, 0.0266],\n","        [0.0224, 0.9673]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3625, grad_fn=<NllLossBackward>)\n","epoch 1201, loss 0.3624715209007263\n","Parameter containing:\n","tensor([[-0.2059, -0.5331,  0.1988],\n","        [-0.8950, -0.5587, -0.0746],\n","        [-0.9030, -0.7111, -0.1218],\n","        [-0.4049, -0.3957, -0.0025]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4719, -0.3353,  0.1117,  0.1050], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7734,  0.6332,  0.9809,  0.0525],\n","        [-0.0730, -0.8004, -0.6027, -0.4702]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3335, -0.5615], requires_grad=True)\n","outputs:  tensor([[0.1054, 0.8338],\n","        [0.9079, 0.1339],\n","        [0.8973, 0.1477],\n","        [0.9886, 0.0265],\n","        [0.0224, 0.9674]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3624, grad_fn=<NllLossBackward>)\n","epoch 1202, loss 0.36240142583847046\n","outputs:  tensor([[0.1052, 0.8340],\n","        [0.9081, 0.1338],\n","        [0.8974, 0.1476],\n","        [0.9887, 0.0264],\n","        [0.0223, 0.9675]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3623, grad_fn=<NllLossBackward>)\n","epoch 1203, loss 0.3623313307762146\n","outputs:  tensor([[0.1051, 0.8343],\n","        [0.9082, 0.1336],\n","        [0.8975, 0.1474],\n","        [0.9887, 0.0263],\n","        [0.0223, 0.9675]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3623, grad_fn=<NllLossBackward>)\n","epoch 1204, loss 0.3622615337371826\n","outputs:  tensor([[0.1050, 0.8345],\n","        [0.9083, 0.1335],\n","        [0.8977, 0.1473],\n","        [0.9887, 0.0263],\n","        [0.0222, 0.9676]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3622, grad_fn=<NllLossBackward>)\n","epoch 1205, loss 0.362191766500473\n","outputs:  tensor([[0.1048, 0.8347],\n","        [0.9084, 0.1333],\n","        [0.8978, 0.1471],\n","        [0.9887, 0.0262],\n","        [0.0222, 0.9677]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3621, grad_fn=<NllLossBackward>)\n","epoch 1206, loss 0.36212220788002014\n","outputs:  tensor([[0.1047, 0.8349],\n","        [0.9085, 0.1331],\n","        [0.8979, 0.1469],\n","        [0.9888, 0.0261],\n","        [0.0221, 0.9678]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3621, grad_fn=<NllLossBackward>)\n","epoch 1207, loss 0.3620528280735016\n","outputs:  tensor([[0.1046, 0.8351],\n","        [0.9086, 0.1330],\n","        [0.8980, 0.1468],\n","        [0.9888, 0.0261],\n","        [0.0221, 0.9679]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3620, grad_fn=<NllLossBackward>)\n","epoch 1208, loss 0.3619835376739502\n","outputs:  tensor([[0.1044, 0.8353],\n","        [0.9087, 0.1328],\n","        [0.8981, 0.1466],\n","        [0.9888, 0.0260],\n","        [0.0220, 0.9679]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3619, grad_fn=<NllLossBackward>)\n","epoch 1209, loss 0.3619144558906555\n","outputs:  tensor([[0.1043, 0.8355],\n","        [0.9088, 0.1327],\n","        [0.8982, 0.1464],\n","        [0.9888, 0.0259],\n","        [0.0220, 0.9680]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3618, grad_fn=<NllLossBackward>)\n","epoch 1210, loss 0.3618454933166504\n","outputs:  tensor([[0.1042, 0.8358],\n","        [0.9089, 0.1325],\n","        [0.8983, 0.1463],\n","        [0.9889, 0.0259],\n","        [0.0219, 0.9681]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3618, grad_fn=<NllLossBackward>)\n","epoch 1211, loss 0.3617766499519348\n","outputs:  tensor([[0.1040, 0.8360],\n","        [0.9090, 0.1324],\n","        [0.8984, 0.1461],\n","        [0.9889, 0.0258],\n","        [0.0219, 0.9682]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3617, grad_fn=<NllLossBackward>)\n","epoch 1212, loss 0.36170798540115356\n","outputs:  tensor([[0.1039, 0.8362],\n","        [0.9091, 0.1322],\n","        [0.8985, 0.1460],\n","        [0.9889, 0.0257],\n","        [0.0218, 0.9683]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3616, grad_fn=<NllLossBackward>)\n","epoch 1213, loss 0.36163944005966187\n","outputs:  tensor([[0.1038, 0.8364],\n","        [0.9092, 0.1320],\n","        [0.8986, 0.1458],\n","        [0.9890, 0.0257],\n","        [0.0218, 0.9683]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3616, grad_fn=<NllLossBackward>)\n","epoch 1214, loss 0.36157113313674927\n","outputs:  tensor([[0.1037, 0.8366],\n","        [0.9093, 0.1319],\n","        [0.8988, 0.1456],\n","        [0.9890, 0.0256],\n","        [0.0217, 0.9684]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3615, grad_fn=<NllLossBackward>)\n","epoch 1215, loss 0.3615029454231262\n","outputs:  tensor([[0.1035, 0.8368],\n","        [0.9094, 0.1317],\n","        [0.8989, 0.1455],\n","        [0.9890, 0.0255],\n","        [0.0217, 0.9685]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3614, grad_fn=<NllLossBackward>)\n","epoch 1216, loss 0.3614348769187927\n","outputs:  tensor([[0.1034, 0.8370],\n","        [0.9095, 0.1316],\n","        [0.8990, 0.1453],\n","        [0.9890, 0.0255],\n","        [0.0216, 0.9686]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3614, grad_fn=<NllLossBackward>)\n","epoch 1217, loss 0.36136695742607117\n","outputs:  tensor([[0.1033, 0.8372],\n","        [0.9096, 0.1314],\n","        [0.8991, 0.1452],\n","        [0.9891, 0.0254],\n","        [0.0216, 0.9687]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3613, grad_fn=<NllLossBackward>)\n","epoch 1218, loss 0.3612992465496063\n","outputs:  tensor([[0.1031, 0.8374],\n","        [0.9098, 0.1313],\n","        [0.8992, 0.1450],\n","        [0.9891, 0.0253],\n","        [0.0215, 0.9687]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3612, grad_fn=<NllLossBackward>)\n","epoch 1219, loss 0.36123159527778625\n","outputs:  tensor([[0.1030, 0.8377],\n","        [0.9099, 0.1311],\n","        [0.8993, 0.1449],\n","        [0.9891, 0.0253],\n","        [0.0215, 0.9688]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3612, grad_fn=<NllLossBackward>)\n","epoch 1220, loss 0.3611640930175781\n","outputs:  tensor([[0.1029, 0.8379],\n","        [0.9100, 0.1309],\n","        [0.8994, 0.1447],\n","        [0.9891, 0.0252],\n","        [0.0214, 0.9689]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3611, grad_fn=<NllLossBackward>)\n","epoch 1221, loss 0.3610967993736267\n","outputs:  tensor([[0.1027, 0.8381],\n","        [0.9101, 0.1308],\n","        [0.8995, 0.1445],\n","        [0.9892, 0.0251],\n","        [0.0214, 0.9690]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3610, grad_fn=<NllLossBackward>)\n","epoch 1222, loss 0.36102965474128723\n","outputs:  tensor([[0.1026, 0.8383],\n","        [0.9102, 0.1306],\n","        [0.8996, 0.1444],\n","        [0.9892, 0.0251],\n","        [0.0213, 0.9690]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3610, grad_fn=<NllLossBackward>)\n","epoch 1223, loss 0.3609626293182373\n","outputs:  tensor([[0.1025, 0.8385],\n","        [0.9103, 0.1305],\n","        [0.8997, 0.1442],\n","        [0.9892, 0.0250],\n","        [0.0213, 0.9691]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3609, grad_fn=<NllLossBackward>)\n","epoch 1224, loss 0.36089572310447693\n","outputs:  tensor([[0.1024, 0.8387],\n","        [0.9104, 0.1303],\n","        [0.8998, 0.1441],\n","        [0.9892, 0.0249],\n","        [0.0212, 0.9692]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3608, grad_fn=<NllLossBackward>)\n","epoch 1225, loss 0.3608289361000061\n","outputs:  tensor([[0.1022, 0.8389],\n","        [0.9105, 0.1302],\n","        [0.8999, 0.1439],\n","        [0.9893, 0.0249],\n","        [0.0212, 0.9693]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3608, grad_fn=<NllLossBackward>)\n","epoch 1226, loss 0.360762357711792\n","outputs:  tensor([[0.1021, 0.8391],\n","        [0.9106, 0.1300],\n","        [0.9000, 0.1438],\n","        [0.9893, 0.0248],\n","        [0.0212, 0.9693]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3607, grad_fn=<NllLossBackward>)\n","epoch 1227, loss 0.3606959283351898\n","outputs:  tensor([[0.1020, 0.8393],\n","        [0.9107, 0.1299],\n","        [0.9001, 0.1436],\n","        [0.9893, 0.0247],\n","        [0.0211, 0.9694]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3606, grad_fn=<NllLossBackward>)\n","epoch 1228, loss 0.3606295883655548\n","outputs:  tensor([[0.1019, 0.8395],\n","        [0.9108, 0.1297],\n","        [0.9003, 0.1434],\n","        [0.9893, 0.0247],\n","        [0.0211, 0.9695]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3606, grad_fn=<NllLossBackward>)\n","epoch 1229, loss 0.3605634570121765\n","outputs:  tensor([[0.1017, 0.8397],\n","        [0.9109, 0.1296],\n","        [0.9004, 0.1433],\n","        [0.9894, 0.0246],\n","        [0.0210, 0.9696]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3605, grad_fn=<NllLossBackward>)\n","epoch 1230, loss 0.3604974150657654\n","outputs:  tensor([[0.1016, 0.8399],\n","        [0.9110, 0.1294],\n","        [0.9005, 0.1431],\n","        [0.9894, 0.0245],\n","        [0.0210, 0.9696]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3604, grad_fn=<NllLossBackward>)\n","epoch 1231, loss 0.36043158173561096\n","outputs:  tensor([[0.1015, 0.8401],\n","        [0.9111, 0.1292],\n","        [0.9006, 0.1430],\n","        [0.9894, 0.0245],\n","        [0.0209, 0.9697]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3604, grad_fn=<NllLossBackward>)\n","epoch 1232, loss 0.3603658080101013\n","outputs:  tensor([[0.1013, 0.8403],\n","        [0.9112, 0.1291],\n","        [0.9007, 0.1428],\n","        [0.9894, 0.0244],\n","        [0.0209, 0.9698]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3603, grad_fn=<NllLossBackward>)\n","epoch 1233, loss 0.3603002429008484\n","outputs:  tensor([[0.1012, 0.8405],\n","        [0.9113, 0.1289],\n","        [0.9008, 0.1427],\n","        [0.9895, 0.0244],\n","        [0.0208, 0.9699]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3602, grad_fn=<NllLossBackward>)\n","epoch 1234, loss 0.360234797000885\n","outputs:  tensor([[0.1011, 0.8408],\n","        [0.9114, 0.1288],\n","        [0.9009, 0.1425],\n","        [0.9895, 0.0243],\n","        [0.0208, 0.9699]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3602, grad_fn=<NllLossBackward>)\n","epoch 1235, loss 0.36016950011253357\n","outputs:  tensor([[0.1010, 0.8410],\n","        [0.9115, 0.1286],\n","        [0.9010, 0.1424],\n","        [0.9895, 0.0242],\n","        [0.0207, 0.9700]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3601, grad_fn=<NllLossBackward>)\n","epoch 1236, loss 0.36010435223579407\n","outputs:  tensor([[0.1008, 0.8412],\n","        [0.9116, 0.1285],\n","        [0.9011, 0.1422],\n","        [0.9895, 0.0242],\n","        [0.0207, 0.9701]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3600, grad_fn=<NllLossBackward>)\n","epoch 1237, loss 0.36003929376602173\n","outputs:  tensor([[0.1007, 0.8414],\n","        [0.9117, 0.1283],\n","        [0.9012, 0.1420],\n","        [0.9896, 0.0241],\n","        [0.0206, 0.9702]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3600, grad_fn=<NllLossBackward>)\n","epoch 1238, loss 0.35997438430786133\n","outputs:  tensor([[0.1006, 0.8416],\n","        [0.9118, 0.1282],\n","        [0.9013, 0.1419],\n","        [0.9896, 0.0240],\n","        [0.0206, 0.9702]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3599, grad_fn=<NllLossBackward>)\n","epoch 1239, loss 0.35990962386131287\n","outputs:  tensor([[0.1005, 0.8418],\n","        [0.9119, 0.1280],\n","        [0.9014, 0.1417],\n","        [0.9896, 0.0240],\n","        [0.0206, 0.9703]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3598, grad_fn=<NllLossBackward>)\n","epoch 1240, loss 0.3598450720310211\n","outputs:  tensor([[0.1003, 0.8420],\n","        [0.9120, 0.1279],\n","        [0.9015, 0.1416],\n","        [0.9896, 0.0239],\n","        [0.0205, 0.9704]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3598, grad_fn=<NllLossBackward>)\n","epoch 1241, loss 0.35978055000305176\n","outputs:  tensor([[0.1002, 0.8422],\n","        [0.9121, 0.1277],\n","        [0.9016, 0.1414],\n","        [0.9897, 0.0239],\n","        [0.0205, 0.9704]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3597, grad_fn=<NllLossBackward>)\n","epoch 1242, loss 0.35971617698669434\n","outputs:  tensor([[0.1001, 0.8424],\n","        [0.9122, 0.1276],\n","        [0.9017, 0.1413],\n","        [0.9897, 0.0238],\n","        [0.0204, 0.9705]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3597, grad_fn=<NllLossBackward>)\n","epoch 1243, loss 0.35965201258659363\n","outputs:  tensor([[0.1000, 0.8426],\n","        [0.9123, 0.1274],\n","        [0.9018, 0.1411],\n","        [0.9897, 0.0237],\n","        [0.0204, 0.9706]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3596, grad_fn=<NllLossBackward>)\n","epoch 1244, loss 0.35958796739578247\n","outputs:  tensor([[0.0999, 0.8428],\n","        [0.9124, 0.1273],\n","        [0.9019, 0.1410],\n","        [0.9897, 0.0237],\n","        [0.0203, 0.9707]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3595, grad_fn=<NllLossBackward>)\n","epoch 1245, loss 0.35952407121658325\n","outputs:  tensor([[0.0997, 0.8430],\n","        [0.9125, 0.1271],\n","        [0.9020, 0.1408],\n","        [0.9898, 0.0236],\n","        [0.0203, 0.9707]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3595, grad_fn=<NllLossBackward>)\n","epoch 1246, loss 0.3594602644443512\n","outputs:  tensor([[0.0996, 0.8432],\n","        [0.9126, 0.1270],\n","        [0.9021, 0.1407],\n","        [0.9898, 0.0236],\n","        [0.0202, 0.9708]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3594, grad_fn=<NllLossBackward>)\n","epoch 1247, loss 0.35939663648605347\n","outputs:  tensor([[0.0995, 0.8434],\n","        [0.9127, 0.1268],\n","        [0.9022, 0.1405],\n","        [0.9898, 0.0235],\n","        [0.0202, 0.9709]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3593, grad_fn=<NllLossBackward>)\n","epoch 1248, loss 0.3593330979347229\n","outputs:  tensor([[0.0994, 0.8436],\n","        [0.9128, 0.1267],\n","        [0.9023, 0.1404],\n","        [0.9898, 0.0234],\n","        [0.0201, 0.9709]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3593, grad_fn=<NllLossBackward>)\n","epoch 1249, loss 0.35926976799964905\n","outputs:  tensor([[0.0992, 0.8438],\n","        [0.9129, 0.1265],\n","        [0.9024, 0.1402],\n","        [0.9899, 0.0234],\n","        [0.0201, 0.9710]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3592, grad_fn=<NllLossBackward>)\n","epoch 1250, loss 0.35920649766921997\n","outputs:  tensor([[0.0991, 0.8440],\n","        [0.9130, 0.1264],\n","        [0.9025, 0.1401],\n","        [0.9899, 0.0233],\n","        [0.0201, 0.9711]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3591, grad_fn=<NllLossBackward>)\n","epoch 1251, loss 0.3591434061527252\n","Parameter containing:\n","tensor([[-0.2105, -0.5404,  0.1985],\n","        [-0.9046, -0.5735, -0.0749],\n","        [-0.9129, -0.7265, -0.1222],\n","        [-0.4089, -0.4018, -0.0026]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4738, -0.3315,  0.1156,  0.1065], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7799,  0.6418,  0.9918,  0.0581],\n","        [-0.0824, -0.8132, -0.6187, -0.4784]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3357, -0.5645], requires_grad=True)\n","outputs:  tensor([[0.0990, 0.8442],\n","        [0.9131, 0.1263],\n","        [0.9026, 0.1399],\n","        [0.9899, 0.0233],\n","        [0.0200, 0.9712]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3591, grad_fn=<NllLossBackward>)\n","epoch 1252, loss 0.3590804636478424\n","outputs:  tensor([[0.0989, 0.8444],\n","        [0.9132, 0.1261],\n","        [0.9027, 0.1398],\n","        [0.9899, 0.0232],\n","        [0.0200, 0.9712]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3590, grad_fn=<NllLossBackward>)\n","epoch 1253, loss 0.35901758074760437\n","outputs:  tensor([[0.0988, 0.8446],\n","        [0.9133, 0.1260],\n","        [0.9029, 0.1396],\n","        [0.9900, 0.0231],\n","        [0.0199, 0.9713]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3590, grad_fn=<NllLossBackward>)\n","epoch 1254, loss 0.35895484685897827\n","outputs:  tensor([[0.0986, 0.8448],\n","        [0.9134, 0.1258],\n","        [0.9030, 0.1395],\n","        [0.9900, 0.0231],\n","        [0.0199, 0.9714]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3589, grad_fn=<NllLossBackward>)\n","epoch 1255, loss 0.3588922917842865\n","outputs:  tensor([[0.0985, 0.8449],\n","        [0.9135, 0.1257],\n","        [0.9031, 0.1393],\n","        [0.9900, 0.0230],\n","        [0.0198, 0.9714]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3588, grad_fn=<NllLossBackward>)\n","epoch 1256, loss 0.35882988572120667\n","outputs:  tensor([[0.0984, 0.8451],\n","        [0.9136, 0.1255],\n","        [0.9032, 0.1392],\n","        [0.9900, 0.0230],\n","        [0.0198, 0.9715]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3588, grad_fn=<NllLossBackward>)\n","epoch 1257, loss 0.358767569065094\n","outputs:  tensor([[0.0983, 0.8453],\n","        [0.9137, 0.1254],\n","        [0.9033, 0.1390],\n","        [0.9901, 0.0229],\n","        [0.0198, 0.9716]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3587, grad_fn=<NllLossBackward>)\n","epoch 1258, loss 0.35870540142059326\n","outputs:  tensor([[0.0981, 0.8455],\n","        [0.9138, 0.1252],\n","        [0.9034, 0.1389],\n","        [0.9901, 0.0228],\n","        [0.0197, 0.9716]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3586, grad_fn=<NllLossBackward>)\n","epoch 1259, loss 0.3586433529853821\n","outputs:  tensor([[0.0980, 0.8457],\n","        [0.9139, 0.1251],\n","        [0.9035, 0.1387],\n","        [0.9901, 0.0228],\n","        [0.0197, 0.9717]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3586, grad_fn=<NllLossBackward>)\n","epoch 1260, loss 0.3585814833641052\n","outputs:  tensor([[0.0979, 0.8459],\n","        [0.9140, 0.1249],\n","        [0.9036, 0.1386],\n","        [0.9901, 0.0227],\n","        [0.0196, 0.9718]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3585, grad_fn=<NllLossBackward>)\n","epoch 1261, loss 0.35851964354515076\n","outputs:  tensor([[0.0978, 0.8461],\n","        [0.9141, 0.1248],\n","        [0.9037, 0.1384],\n","        [0.9901, 0.0227],\n","        [0.0196, 0.9718]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3585, grad_fn=<NllLossBackward>)\n","epoch 1262, loss 0.3584580421447754\n","outputs:  tensor([[0.0977, 0.8463],\n","        [0.9142, 0.1246],\n","        [0.9038, 0.1383],\n","        [0.9902, 0.0226],\n","        [0.0195, 0.9719]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3584, grad_fn=<NllLossBackward>)\n","epoch 1263, loss 0.3583965003490448\n","outputs:  tensor([[0.0976, 0.8465],\n","        [0.9143, 0.1245],\n","        [0.9039, 0.1381],\n","        [0.9902, 0.0226],\n","        [0.0195, 0.9720]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3583, grad_fn=<NllLossBackward>)\n","epoch 1264, loss 0.35833510756492615\n","outputs:  tensor([[0.0974, 0.8467],\n","        [0.9144, 0.1244],\n","        [0.9040, 0.1380],\n","        [0.9902, 0.0225],\n","        [0.0195, 0.9720]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3583, grad_fn=<NllLossBackward>)\n","epoch 1265, loss 0.3582739233970642\n","outputs:  tensor([[0.0973, 0.8469],\n","        [0.9145, 0.1242],\n","        [0.9041, 0.1378],\n","        [0.9902, 0.0224],\n","        [0.0194, 0.9721]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3582, grad_fn=<NllLossBackward>)\n","epoch 1266, loss 0.35821276903152466\n","outputs:  tensor([[0.0972, 0.8471],\n","        [0.9146, 0.1241],\n","        [0.9042, 0.1377],\n","        [0.9903, 0.0224],\n","        [0.0194, 0.9722]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3582, grad_fn=<NllLossBackward>)\n","epoch 1267, loss 0.35815176367759705\n","outputs:  tensor([[0.0971, 0.8473],\n","        [0.9147, 0.1239],\n","        [0.9043, 0.1375],\n","        [0.9903, 0.0223],\n","        [0.0193, 0.9722]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3581, grad_fn=<NllLossBackward>)\n","epoch 1268, loss 0.35809093713760376\n","outputs:  tensor([[0.0970, 0.8475],\n","        [0.9148, 0.1238],\n","        [0.9044, 0.1374],\n","        [0.9903, 0.0223],\n","        [0.0193, 0.9723]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3580, grad_fn=<NllLossBackward>)\n","epoch 1269, loss 0.35803017020225525\n","outputs:  tensor([[0.0968, 0.8477],\n","        [0.9149, 0.1236],\n","        [0.9045, 0.1373],\n","        [0.9903, 0.0222],\n","        [0.0193, 0.9724]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3580, grad_fn=<NllLossBackward>)\n","epoch 1270, loss 0.3579695224761963\n","outputs:  tensor([[0.0967, 0.8479],\n","        [0.9149, 0.1235],\n","        [0.9046, 0.1371],\n","        [0.9904, 0.0222],\n","        [0.0192, 0.9724]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3579, grad_fn=<NllLossBackward>)\n","epoch 1271, loss 0.35790905356407166\n","outputs:  tensor([[0.0966, 0.8480],\n","        [0.9150, 0.1233],\n","        [0.9047, 0.1370],\n","        [0.9904, 0.0221],\n","        [0.0192, 0.9725]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3578, grad_fn=<NllLossBackward>)\n","epoch 1272, loss 0.3578487038612366\n","outputs:  tensor([[0.0965, 0.8482],\n","        [0.9151, 0.1232],\n","        [0.9048, 0.1368],\n","        [0.9904, 0.0221],\n","        [0.0191, 0.9726]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3578, grad_fn=<NllLossBackward>)\n","epoch 1273, loss 0.3577885031700134\n","outputs:  tensor([[0.0964, 0.8484],\n","        [0.9152, 0.1231],\n","        [0.9049, 0.1367],\n","        [0.9904, 0.0220],\n","        [0.0191, 0.9726]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3577, grad_fn=<NllLossBackward>)\n","epoch 1274, loss 0.35772842168807983\n","outputs:  tensor([[0.0963, 0.8486],\n","        [0.9153, 0.1229],\n","        [0.9049, 0.1365],\n","        [0.9904, 0.0219],\n","        [0.0190, 0.9727]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3577, grad_fn=<NllLossBackward>)\n","epoch 1275, loss 0.3576684594154358\n","outputs:  tensor([[0.0961, 0.8488],\n","        [0.9154, 0.1228],\n","        [0.9050, 0.1364],\n","        [0.9905, 0.0219],\n","        [0.0190, 0.9728]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3576, grad_fn=<NllLossBackward>)\n","epoch 1276, loss 0.3576085567474365\n","outputs:  tensor([[0.0960, 0.8490],\n","        [0.9155, 0.1226],\n","        [0.9051, 0.1362],\n","        [0.9905, 0.0218],\n","        [0.0190, 0.9728]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3575, grad_fn=<NllLossBackward>)\n","epoch 1277, loss 0.3575488030910492\n","outputs:  tensor([[0.0959, 0.8492],\n","        [0.9156, 0.1225],\n","        [0.9052, 0.1361],\n","        [0.9905, 0.0218],\n","        [0.0189, 0.9729]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3575, grad_fn=<NllLossBackward>)\n","epoch 1278, loss 0.35748928785324097\n","outputs:  tensor([[0.0958, 0.8494],\n","        [0.9157, 0.1224],\n","        [0.9053, 0.1359],\n","        [0.9905, 0.0217],\n","        [0.0189, 0.9730]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3574, grad_fn=<NllLossBackward>)\n","epoch 1279, loss 0.3574298024177551\n","outputs:  tensor([[0.0957, 0.8496],\n","        [0.9158, 0.1222],\n","        [0.9054, 0.1358],\n","        [0.9906, 0.0217],\n","        [0.0188, 0.9730]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3574, grad_fn=<NllLossBackward>)\n","epoch 1280, loss 0.35737043619155884\n","outputs:  tensor([[0.0956, 0.8497],\n","        [0.9159, 0.1221],\n","        [0.9055, 0.1357],\n","        [0.9906, 0.0216],\n","        [0.0188, 0.9731]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3573, grad_fn=<NllLossBackward>)\n","epoch 1281, loss 0.3573112487792969\n","outputs:  tensor([[0.0955, 0.8499],\n","        [0.9160, 0.1219],\n","        [0.9056, 0.1355],\n","        [0.9906, 0.0216],\n","        [0.0188, 0.9732]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3573, grad_fn=<NllLossBackward>)\n","epoch 1282, loss 0.3572521209716797\n","outputs:  tensor([[0.0953, 0.8501],\n","        [0.9161, 0.1218],\n","        [0.9057, 0.1354],\n","        [0.9906, 0.0215],\n","        [0.0187, 0.9732]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3572, grad_fn=<NllLossBackward>)\n","epoch 1283, loss 0.3571931719779968\n","outputs:  tensor([[0.0952, 0.8503],\n","        [0.9162, 0.1217],\n","        [0.9058, 0.1352],\n","        [0.9906, 0.0214],\n","        [0.0187, 0.9733]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3571, grad_fn=<NllLossBackward>)\n","epoch 1284, loss 0.3571343421936035\n","outputs:  tensor([[0.0951, 0.8505],\n","        [0.9163, 0.1215],\n","        [0.9059, 0.1351],\n","        [0.9907, 0.0214],\n","        [0.0186, 0.9733]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3571, grad_fn=<NllLossBackward>)\n","epoch 1285, loss 0.357075572013855\n","outputs:  tensor([[0.0950, 0.8507],\n","        [0.9164, 0.1214],\n","        [0.9060, 0.1349],\n","        [0.9907, 0.0213],\n","        [0.0186, 0.9734]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3570, grad_fn=<NllLossBackward>)\n","epoch 1286, loss 0.35701698064804077\n","outputs:  tensor([[0.0949, 0.8509],\n","        [0.9165, 0.1212],\n","        [0.9061, 0.1348],\n","        [0.9907, 0.0213],\n","        [0.0186, 0.9735]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3570, grad_fn=<NllLossBackward>)\n","epoch 1287, loss 0.35695844888687134\n","outputs:  tensor([[0.0948, 0.8510],\n","        [0.9165, 0.1211],\n","        [0.9062, 0.1347],\n","        [0.9907, 0.0212],\n","        [0.0185, 0.9735]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3569, grad_fn=<NllLossBackward>)\n","epoch 1288, loss 0.35690009593963623\n","outputs:  tensor([[0.0947, 0.8512],\n","        [0.9166, 0.1210],\n","        [0.9063, 0.1345],\n","        [0.9907, 0.0212],\n","        [0.0185, 0.9736]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3568, grad_fn=<NllLossBackward>)\n","epoch 1289, loss 0.35684189200401306\n","outputs:  tensor([[0.0945, 0.8514],\n","        [0.9167, 0.1208],\n","        [0.9064, 0.1344],\n","        [0.9908, 0.0211],\n","        [0.0185, 0.9737]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3568, grad_fn=<NllLossBackward>)\n","epoch 1290, loss 0.35678377747535706\n","outputs:  tensor([[0.0944, 0.8516],\n","        [0.9168, 0.1207],\n","        [0.9065, 0.1342],\n","        [0.9908, 0.0211],\n","        [0.0184, 0.9737]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3567, grad_fn=<NllLossBackward>)\n","epoch 1291, loss 0.3567257523536682\n","outputs:  tensor([[0.0943, 0.8518],\n","        [0.9169, 0.1205],\n","        [0.9066, 0.1341],\n","        [0.9908, 0.0210],\n","        [0.0184, 0.9738]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3567, grad_fn=<NllLossBackward>)\n","epoch 1292, loss 0.3566678762435913\n","outputs:  tensor([[0.0942, 0.8520],\n","        [0.9170, 0.1204],\n","        [0.9067, 0.1339],\n","        [0.9908, 0.0210],\n","        [0.0183, 0.9738]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3566, grad_fn=<NllLossBackward>)\n","epoch 1293, loss 0.35661011934280396\n","outputs:  tensor([[0.0941, 0.8522],\n","        [0.9171, 0.1203],\n","        [0.9068, 0.1338],\n","        [0.9909, 0.0209],\n","        [0.0183, 0.9739]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3566, grad_fn=<NllLossBackward>)\n","epoch 1294, loss 0.3565525412559509\n","outputs:  tensor([[0.0940, 0.8523],\n","        [0.9172, 0.1201],\n","        [0.9069, 0.1337],\n","        [0.9909, 0.0209],\n","        [0.0183, 0.9740]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3565, grad_fn=<NllLossBackward>)\n","epoch 1295, loss 0.3564949631690979\n","outputs:  tensor([[0.0939, 0.8525],\n","        [0.9173, 0.1200],\n","        [0.9070, 0.1335],\n","        [0.9909, 0.0208],\n","        [0.0182, 0.9740]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3564, grad_fn=<NllLossBackward>)\n","epoch 1296, loss 0.3564375936985016\n","outputs:  tensor([[0.0938, 0.8527],\n","        [0.9174, 0.1199],\n","        [0.9071, 0.1334],\n","        [0.9909, 0.0208],\n","        [0.0182, 0.9741]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3564, grad_fn=<NllLossBackward>)\n","epoch 1297, loss 0.35638031363487244\n","outputs:  tensor([[0.0936, 0.8529],\n","        [0.9175, 0.1197],\n","        [0.9072, 0.1332],\n","        [0.9909, 0.0207],\n","        [0.0181, 0.9741]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3563, grad_fn=<NllLossBackward>)\n","epoch 1298, loss 0.35632315278053284\n","outputs:  tensor([[0.0935, 0.8531],\n","        [0.9176, 0.1196],\n","        [0.9073, 0.1331],\n","        [0.9910, 0.0207],\n","        [0.0181, 0.9742]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3563, grad_fn=<NllLossBackward>)\n","epoch 1299, loss 0.35626617074012756\n","outputs:  tensor([[0.0934, 0.8532],\n","        [0.9176, 0.1194],\n","        [0.9074, 0.1330],\n","        [0.9910, 0.0206],\n","        [0.0181, 0.9743]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3562, grad_fn=<NllLossBackward>)\n","epoch 1300, loss 0.3562091886997223\n","outputs:  tensor([[0.0933, 0.8534],\n","        [0.9177, 0.1193],\n","        [0.9075, 0.1328],\n","        [0.9910, 0.0206],\n","        [0.0180, 0.9743]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3562, grad_fn=<NllLossBackward>)\n","epoch 1301, loss 0.3561524450778961\n","Parameter containing:\n","tensor([[-0.2149, -0.5474,  0.1983],\n","        [-0.9136, -0.5876, -0.0751],\n","        [-0.9222, -0.7411, -0.1225],\n","        [-0.4126, -0.4077, -0.0026]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4757, -0.3279,  0.1195,  0.1080], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7860,  0.6499,  1.0021,  0.0634],\n","        [-0.0913, -0.8252, -0.6338, -0.4861]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3378, -0.5673], requires_grad=True)\n","outputs:  tensor([[0.0932, 0.8536],\n","        [0.9178, 0.1192],\n","        [0.9075, 0.1327],\n","        [0.9910, 0.0205],\n","        [0.0180, 0.9744]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3561, grad_fn=<NllLossBackward>)\n","epoch 1302, loss 0.35609573125839233\n","outputs:  tensor([[0.0931, 0.8538],\n","        [0.9179, 0.1190],\n","        [0.9076, 0.1325],\n","        [0.9910, 0.0205],\n","        [0.0180, 0.9744]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3560, grad_fn=<NllLossBackward>)\n","epoch 1303, loss 0.35603922605514526\n","outputs:  tensor([[0.0930, 0.8540],\n","        [0.9180, 0.1189],\n","        [0.9077, 0.1324],\n","        [0.9911, 0.0204],\n","        [0.0179, 0.9745]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3560, grad_fn=<NllLossBackward>)\n","epoch 1304, loss 0.3559827208518982\n","outputs:  tensor([[0.0929, 0.8542],\n","        [0.9181, 0.1188],\n","        [0.9078, 0.1323],\n","        [0.9911, 0.0204],\n","        [0.0179, 0.9746]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3559, grad_fn=<NllLossBackward>)\n","epoch 1305, loss 0.35592642426490784\n","outputs:  tensor([[0.0928, 0.8543],\n","        [0.9182, 0.1186],\n","        [0.9079, 0.1321],\n","        [0.9911, 0.0203],\n","        [0.0178, 0.9746]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3559, grad_fn=<NllLossBackward>)\n","epoch 1306, loss 0.35587015748023987\n","outputs:  tensor([[0.0926, 0.8545],\n","        [0.9183, 0.1185],\n","        [0.9080, 0.1320],\n","        [0.9911, 0.0203],\n","        [0.0178, 0.9747]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3558, grad_fn=<NllLossBackward>)\n","epoch 1307, loss 0.3558140993118286\n","outputs:  tensor([[0.0925, 0.8547],\n","        [0.9184, 0.1184],\n","        [0.9081, 0.1319],\n","        [0.9911, 0.0202],\n","        [0.0178, 0.9747]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3558, grad_fn=<NllLossBackward>)\n","epoch 1308, loss 0.35575810074806213\n","outputs:  tensor([[0.0924, 0.8549],\n","        [0.9185, 0.1182],\n","        [0.9082, 0.1317],\n","        [0.9912, 0.0202],\n","        [0.0177, 0.9748]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3557, grad_fn=<NllLossBackward>)\n","epoch 1309, loss 0.35570231080055237\n","outputs:  tensor([[0.0923, 0.8550],\n","        [0.9185, 0.1181],\n","        [0.9083, 0.1316],\n","        [0.9912, 0.0201],\n","        [0.0177, 0.9749]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3556, grad_fn=<NllLossBackward>)\n","epoch 1310, loss 0.35564643144607544\n","outputs:  tensor([[0.0922, 0.8552],\n","        [0.9186, 0.1180],\n","        [0.9084, 0.1314],\n","        [0.9912, 0.0201],\n","        [0.0177, 0.9749]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3556, grad_fn=<NllLossBackward>)\n","epoch 1311, loss 0.3555908799171448\n","outputs:  tensor([[0.0921, 0.8554],\n","        [0.9187, 0.1178],\n","        [0.9085, 0.1313],\n","        [0.9912, 0.0200],\n","        [0.0176, 0.9750]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3555, grad_fn=<NllLossBackward>)\n","epoch 1312, loss 0.3555353581905365\n","outputs:  tensor([[0.0920, 0.8556],\n","        [0.9188, 0.1177],\n","        [0.9086, 0.1312],\n","        [0.9912, 0.0200],\n","        [0.0176, 0.9750]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3555, grad_fn=<NllLossBackward>)\n","epoch 1313, loss 0.355479896068573\n","outputs:  tensor([[0.0919, 0.8558],\n","        [0.9189, 0.1176],\n","        [0.9087, 0.1310],\n","        [0.9913, 0.0199],\n","        [0.0175, 0.9751]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3554, grad_fn=<NllLossBackward>)\n","epoch 1314, loss 0.35542458295822144\n","outputs:  tensor([[0.0918, 0.8559],\n","        [0.9190, 0.1174],\n","        [0.9088, 0.1309],\n","        [0.9913, 0.0199],\n","        [0.0175, 0.9751]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3554, grad_fn=<NllLossBackward>)\n","epoch 1315, loss 0.3553694188594818\n","outputs:  tensor([[0.0917, 0.8561],\n","        [0.9191, 0.1173],\n","        [0.9088, 0.1308],\n","        [0.9913, 0.0198],\n","        [0.0175, 0.9752]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3553, grad_fn=<NllLossBackward>)\n","epoch 1316, loss 0.3553144037723541\n","outputs:  tensor([[0.0916, 0.8563],\n","        [0.9192, 0.1172],\n","        [0.9089, 0.1306],\n","        [0.9913, 0.0198],\n","        [0.0174, 0.9753]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3553, grad_fn=<NllLossBackward>)\n","epoch 1317, loss 0.3552594780921936\n","outputs:  tensor([[0.0915, 0.8565],\n","        [0.9193, 0.1170],\n","        [0.9090, 0.1305],\n","        [0.9913, 0.0197],\n","        [0.0174, 0.9753]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3552, grad_fn=<NllLossBackward>)\n","epoch 1318, loss 0.35520458221435547\n","outputs:  tensor([[0.0913, 0.8566],\n","        [0.9193, 0.1169],\n","        [0.9091, 0.1303],\n","        [0.9914, 0.0197],\n","        [0.0174, 0.9754]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3551, grad_fn=<NllLossBackward>)\n","epoch 1319, loss 0.35514986515045166\n","outputs:  tensor([[0.0912, 0.8568],\n","        [0.9194, 0.1168],\n","        [0.9092, 0.1302],\n","        [0.9914, 0.0196],\n","        [0.0173, 0.9754]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3551, grad_fn=<NllLossBackward>)\n","epoch 1320, loss 0.355095237493515\n","outputs:  tensor([[0.0911, 0.8570],\n","        [0.9195, 0.1166],\n","        [0.9093, 0.1301],\n","        [0.9914, 0.0196],\n","        [0.0173, 0.9755]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3550, grad_fn=<NllLossBackward>)\n","epoch 1321, loss 0.3550407290458679\n","outputs:  tensor([[0.0910, 0.8572],\n","        [0.9196, 0.1165],\n","        [0.9094, 0.1299],\n","        [0.9914, 0.0195],\n","        [0.0173, 0.9755]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3550, grad_fn=<NllLossBackward>)\n","epoch 1322, loss 0.3549863398075104\n","outputs:  tensor([[0.0909, 0.8573],\n","        [0.9197, 0.1164],\n","        [0.9095, 0.1298],\n","        [0.9914, 0.0195],\n","        [0.0172, 0.9756]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3549, grad_fn=<NllLossBackward>)\n","epoch 1323, loss 0.35493212938308716\n","outputs:  tensor([[0.0908, 0.8575],\n","        [0.9198, 0.1162],\n","        [0.9096, 0.1297],\n","        [0.9914, 0.0194],\n","        [0.0172, 0.9757]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3549, grad_fn=<NllLossBackward>)\n","epoch 1324, loss 0.35487785935401917\n","outputs:  tensor([[0.0907, 0.8577],\n","        [0.9199, 0.1161],\n","        [0.9097, 0.1295],\n","        [0.9915, 0.0194],\n","        [0.0172, 0.9757]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3548, grad_fn=<NllLossBackward>)\n","epoch 1325, loss 0.3548238277435303\n","outputs:  tensor([[0.0906, 0.8579],\n","        [0.9200, 0.1160],\n","        [0.9098, 0.1294],\n","        [0.9915, 0.0193],\n","        [0.0171, 0.9758]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3548, grad_fn=<NllLossBackward>)\n","epoch 1326, loss 0.35476988554000854\n","outputs:  tensor([[0.0905, 0.8580],\n","        [0.9200, 0.1158],\n","        [0.9099, 0.1293],\n","        [0.9915, 0.0193],\n","        [0.0171, 0.9758]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3547, grad_fn=<NllLossBackward>)\n","epoch 1327, loss 0.35471606254577637\n","outputs:  tensor([[0.0904, 0.8582],\n","        [0.9201, 0.1157],\n","        [0.9099, 0.1291],\n","        [0.9915, 0.0192],\n","        [0.0171, 0.9759]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3547, grad_fn=<NllLossBackward>)\n","epoch 1328, loss 0.35466235876083374\n","outputs:  tensor([[0.0903, 0.8584],\n","        [0.9202, 0.1156],\n","        [0.9100, 0.1290],\n","        [0.9915, 0.0192],\n","        [0.0170, 0.9759]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3546, grad_fn=<NllLossBackward>)\n","epoch 1329, loss 0.3546087145805359\n","outputs:  tensor([[0.0902, 0.8585],\n","        [0.9203, 0.1155],\n","        [0.9101, 0.1289],\n","        [0.9916, 0.0192],\n","        [0.0170, 0.9760]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3546, grad_fn=<NllLossBackward>)\n","epoch 1330, loss 0.3545551300048828\n","outputs:  tensor([[0.0901, 0.8587],\n","        [0.9204, 0.1153],\n","        [0.9102, 0.1287],\n","        [0.9916, 0.0191],\n","        [0.0169, 0.9760]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3545, grad_fn=<NllLossBackward>)\n","epoch 1331, loss 0.35450178384780884\n","outputs:  tensor([[0.0900, 0.8589],\n","        [0.9205, 0.1152],\n","        [0.9103, 0.1286],\n","        [0.9916, 0.0191],\n","        [0.0169, 0.9761]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3544, grad_fn=<NllLossBackward>)\n","epoch 1332, loss 0.354448527097702\n","outputs:  tensor([[0.0899, 0.8591],\n","        [0.9206, 0.1151],\n","        [0.9104, 0.1285],\n","        [0.9916, 0.0190],\n","        [0.0169, 0.9761]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3544, grad_fn=<NllLossBackward>)\n","epoch 1333, loss 0.35439532995224\n","outputs:  tensor([[0.0898, 0.8592],\n","        [0.9206, 0.1149],\n","        [0.9105, 0.1283],\n","        [0.9916, 0.0190],\n","        [0.0168, 0.9762]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3543, grad_fn=<NllLossBackward>)\n","epoch 1334, loss 0.3543422818183899\n","outputs:  tensor([[0.0897, 0.8594],\n","        [0.9207, 0.1148],\n","        [0.9106, 0.1282],\n","        [0.9917, 0.0189],\n","        [0.0168, 0.9763]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3543, grad_fn=<NllLossBackward>)\n","epoch 1335, loss 0.3542892336845398\n","outputs:  tensor([[0.0896, 0.8596],\n","        [0.9208, 0.1147],\n","        [0.9107, 0.1281],\n","        [0.9917, 0.0189],\n","        [0.0168, 0.9763]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3542, grad_fn=<NllLossBackward>)\n","epoch 1336, loss 0.3542364239692688\n","outputs:  tensor([[0.0895, 0.8597],\n","        [0.9209, 0.1146],\n","        [0.9107, 0.1279],\n","        [0.9917, 0.0188],\n","        [0.0167, 0.9764]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3542, grad_fn=<NllLossBackward>)\n","epoch 1337, loss 0.3541836142539978\n","outputs:  tensor([[0.0894, 0.8599],\n","        [0.9210, 0.1144],\n","        [0.9108, 0.1278],\n","        [0.9917, 0.0188],\n","        [0.0167, 0.9764]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3541, grad_fn=<NllLossBackward>)\n","epoch 1338, loss 0.35413098335266113\n","outputs:  tensor([[0.0892, 0.8601],\n","        [0.9211, 0.1143],\n","        [0.9109, 0.1277],\n","        [0.9917, 0.0187],\n","        [0.0167, 0.9765]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3541, grad_fn=<NllLossBackward>)\n","epoch 1339, loss 0.354078471660614\n","outputs:  tensor([[0.0891, 0.8603],\n","        [0.9212, 0.1142],\n","        [0.9110, 0.1275],\n","        [0.9917, 0.0187],\n","        [0.0166, 0.9765]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3540, grad_fn=<NllLossBackward>)\n","epoch 1340, loss 0.35402607917785645\n","outputs:  tensor([[0.0890, 0.8604],\n","        [0.9212, 0.1140],\n","        [0.9111, 0.1274],\n","        [0.9918, 0.0186],\n","        [0.0166, 0.9766]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3540, grad_fn=<NllLossBackward>)\n","epoch 1341, loss 0.3539736866950989\n","outputs:  tensor([[0.0889, 0.8606],\n","        [0.9213, 0.1139],\n","        [0.9112, 0.1273],\n","        [0.9918, 0.0186],\n","        [0.0166, 0.9766]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3539, grad_fn=<NllLossBackward>)\n","epoch 1342, loss 0.353921502828598\n","outputs:  tensor([[0.0888, 0.8608],\n","        [0.9214, 0.1138],\n","        [0.9113, 0.1272],\n","        [0.9918, 0.0186],\n","        [0.0165, 0.9767]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3539, grad_fn=<NllLossBackward>)\n","epoch 1343, loss 0.3538692891597748\n","outputs:  tensor([[0.0887, 0.8609],\n","        [0.9215, 0.1137],\n","        [0.9114, 0.1270],\n","        [0.9918, 0.0185],\n","        [0.0165, 0.9767]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3538, grad_fn=<NllLossBackward>)\n","epoch 1344, loss 0.3538173735141754\n","outputs:  tensor([[0.0886, 0.8611],\n","        [0.9216, 0.1135],\n","        [0.9115, 0.1269],\n","        [0.9918, 0.0185],\n","        [0.0165, 0.9768]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3538, grad_fn=<NllLossBackward>)\n","epoch 1345, loss 0.35376542806625366\n","outputs:  tensor([[0.0885, 0.8613],\n","        [0.9217, 0.1134],\n","        [0.9115, 0.1268],\n","        [0.9919, 0.0184],\n","        [0.0164, 0.9768]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3537, grad_fn=<NllLossBackward>)\n","epoch 1346, loss 0.35371366143226624\n","outputs:  tensor([[0.0884, 0.8614],\n","        [0.9218, 0.1133],\n","        [0.9116, 0.1266],\n","        [0.9919, 0.0184],\n","        [0.0164, 0.9769]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3537, grad_fn=<NllLossBackward>)\n","epoch 1347, loss 0.3536619544029236\n","outputs:  tensor([[0.0883, 0.8616],\n","        [0.9218, 0.1132],\n","        [0.9117, 0.1265],\n","        [0.9919, 0.0183],\n","        [0.0164, 0.9769]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3536, grad_fn=<NllLossBackward>)\n","epoch 1348, loss 0.3536103367805481\n","outputs:  tensor([[0.0882, 0.8618],\n","        [0.9219, 0.1130],\n","        [0.9118, 0.1264],\n","        [0.9919, 0.0183],\n","        [0.0163, 0.9770]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3536, grad_fn=<NllLossBackward>)\n","epoch 1349, loss 0.35355883836746216\n","outputs:  tensor([[0.0881, 0.8619],\n","        [0.9220, 0.1129],\n","        [0.9119, 0.1262],\n","        [0.9919, 0.0182],\n","        [0.0163, 0.9770]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3535, grad_fn=<NllLossBackward>)\n","epoch 1350, loss 0.35350751876831055\n","outputs:  tensor([[0.0880, 0.8621],\n","        [0.9221, 0.1128],\n","        [0.9120, 0.1261],\n","        [0.9919, 0.0182],\n","        [0.0163, 0.9771]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3535, grad_fn=<NllLossBackward>)\n","epoch 1351, loss 0.35345619916915894\n","Parameter containing:\n","tensor([[-0.2191, -0.5540,  0.1981],\n","        [-0.9220, -0.6010, -0.0753],\n","        [-0.9310, -0.7550, -0.1227],\n","        [-0.4162, -0.4133, -0.0026]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4775, -0.3243,  0.1232,  0.1095], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7918,  0.6577,  1.0119,  0.0685],\n","        [-0.0998, -0.8367, -0.6481, -0.4935]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3398, -0.5700], requires_grad=True)\n","outputs:  tensor([[0.0879, 0.8623],\n","        [0.9222, 0.1127],\n","        [0.9121, 0.1260],\n","        [0.9920, 0.0182],\n","        [0.0162, 0.9772]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3534, grad_fn=<NllLossBackward>)\n","epoch 1352, loss 0.35340508818626404\n","outputs:  tensor([[0.0878, 0.8624],\n","        [0.9223, 0.1125],\n","        [0.9122, 0.1259],\n","        [0.9920, 0.0181],\n","        [0.0162, 0.9772]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3534, grad_fn=<NllLossBackward>)\n","epoch 1353, loss 0.35335397720336914\n","outputs:  tensor([[0.0877, 0.8626],\n","        [0.9223, 0.1124],\n","        [0.9122, 0.1257],\n","        [0.9920, 0.0181],\n","        [0.0162, 0.9773]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3533, grad_fn=<NllLossBackward>)\n","epoch 1354, loss 0.3533029854297638\n","outputs:  tensor([[0.0876, 0.8628],\n","        [0.9224, 0.1123],\n","        [0.9123, 0.1256],\n","        [0.9920, 0.0180],\n","        [0.0161, 0.9773]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3533, grad_fn=<NllLossBackward>)\n","epoch 1355, loss 0.353252112865448\n","outputs:  tensor([[0.0875, 0.8629],\n","        [0.9225, 0.1122],\n","        [0.9124, 0.1255],\n","        [0.9920, 0.0180],\n","        [0.0161, 0.9774]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3532, grad_fn=<NllLossBackward>)\n","epoch 1356, loss 0.35320135951042175\n","outputs:  tensor([[0.0874, 0.8631],\n","        [0.9226, 0.1120],\n","        [0.9125, 0.1253],\n","        [0.9921, 0.0179],\n","        [0.0161, 0.9774]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3532, grad_fn=<NllLossBackward>)\n","epoch 1357, loss 0.3531506359577179\n","outputs:  tensor([[0.0873, 0.8632],\n","        [0.9227, 0.1119],\n","        [0.9126, 0.1252],\n","        [0.9921, 0.0179],\n","        [0.0160, 0.9775]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3531, grad_fn=<NllLossBackward>)\n","epoch 1358, loss 0.35310012102127075\n","outputs:  tensor([[0.0872, 0.8634],\n","        [0.9227, 0.1118],\n","        [0.9127, 0.1251],\n","        [0.9921, 0.0179],\n","        [0.0160, 0.9775]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3530, grad_fn=<NllLossBackward>)\n","epoch 1359, loss 0.35304969549179077\n","outputs:  tensor([[0.0871, 0.8636],\n","        [0.9228, 0.1117],\n","        [0.9128, 0.1250],\n","        [0.9921, 0.0178],\n","        [0.0160, 0.9776]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3530, grad_fn=<NllLossBackward>)\n","epoch 1360, loss 0.3529992997646332\n","outputs:  tensor([[0.0870, 0.8637],\n","        [0.9229, 0.1115],\n","        [0.9128, 0.1248],\n","        [0.9921, 0.0178],\n","        [0.0160, 0.9776]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3529, grad_fn=<NllLossBackward>)\n","epoch 1361, loss 0.3529490828514099\n","outputs:  tensor([[0.0869, 0.8639],\n","        [0.9230, 0.1114],\n","        [0.9129, 0.1247],\n","        [0.9921, 0.0177],\n","        [0.0159, 0.9777]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3529, grad_fn=<NllLossBackward>)\n","epoch 1362, loss 0.35289886593818665\n","outputs:  tensor([[0.0868, 0.8641],\n","        [0.9231, 0.1113],\n","        [0.9130, 0.1246],\n","        [0.9922, 0.0177],\n","        [0.0159, 0.9777]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3528, grad_fn=<NllLossBackward>)\n","epoch 1363, loss 0.3528488278388977\n","outputs:  tensor([[0.0867, 0.8642],\n","        [0.9232, 0.1112],\n","        [0.9131, 0.1245],\n","        [0.9922, 0.0176],\n","        [0.0159, 0.9778]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3528, grad_fn=<NllLossBackward>)\n","epoch 1364, loss 0.3527988791465759\n","outputs:  tensor([[0.0866, 0.8644],\n","        [0.9232, 0.1110],\n","        [0.9132, 0.1243],\n","        [0.9922, 0.0176],\n","        [0.0158, 0.9778]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3527, grad_fn=<NllLossBackward>)\n","epoch 1365, loss 0.35274896025657654\n","outputs:  tensor([[0.0865, 0.8645],\n","        [0.9233, 0.1109],\n","        [0.9133, 0.1242],\n","        [0.9922, 0.0176],\n","        [0.0158, 0.9779]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3527, grad_fn=<NllLossBackward>)\n","epoch 1366, loss 0.3526992201805115\n","outputs:  tensor([[0.0864, 0.8647],\n","        [0.9234, 0.1108],\n","        [0.9134, 0.1241],\n","        [0.9922, 0.0175],\n","        [0.0158, 0.9779]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3526, grad_fn=<NllLossBackward>)\n","epoch 1367, loss 0.3526495397090912\n","outputs:  tensor([[0.0863, 0.8649],\n","        [0.9235, 0.1107],\n","        [0.9134, 0.1239],\n","        [0.9922, 0.0175],\n","        [0.0157, 0.9780]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3526, grad_fn=<NllLossBackward>)\n","epoch 1368, loss 0.35260000824928284\n","outputs:  tensor([[0.0862, 0.8650],\n","        [0.9236, 0.1106],\n","        [0.9135, 0.1238],\n","        [0.9923, 0.0174],\n","        [0.0157, 0.9780]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3526, grad_fn=<NllLossBackward>)\n","epoch 1369, loss 0.35255056619644165\n","outputs:  tensor([[0.0861, 0.8652],\n","        [0.9236, 0.1104],\n","        [0.9136, 0.1237],\n","        [0.9923, 0.0174],\n","        [0.0157, 0.9781]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3525, grad_fn=<NllLossBackward>)\n","epoch 1370, loss 0.3525010943412781\n","outputs:  tensor([[0.0860, 0.8653],\n","        [0.9237, 0.1103],\n","        [0.9137, 0.1236],\n","        [0.9923, 0.0174],\n","        [0.0156, 0.9781]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3525, grad_fn=<NllLossBackward>)\n","epoch 1371, loss 0.352451890707016\n","outputs:  tensor([[0.0859, 0.8655],\n","        [0.9238, 0.1102],\n","        [0.9138, 0.1234],\n","        [0.9923, 0.0173],\n","        [0.0156, 0.9781]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3524, grad_fn=<NllLossBackward>)\n","epoch 1372, loss 0.3524027466773987\n","outputs:  tensor([[0.0858, 0.8657],\n","        [0.9239, 0.1101],\n","        [0.9139, 0.1233],\n","        [0.9923, 0.0173],\n","        [0.0156, 0.9782]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3524, grad_fn=<NllLossBackward>)\n","epoch 1373, loss 0.35235363245010376\n","outputs:  tensor([[0.0858, 0.8658],\n","        [0.9240, 0.1099],\n","        [0.9139, 0.1232],\n","        [0.9923, 0.0172],\n","        [0.0155, 0.9782]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3523, grad_fn=<NllLossBackward>)\n","epoch 1374, loss 0.3523046374320984\n","outputs:  tensor([[0.0857, 0.8660],\n","        [0.9240, 0.1098],\n","        [0.9140, 0.1231],\n","        [0.9924, 0.0172],\n","        [0.0155, 0.9783]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3523, grad_fn=<NllLossBackward>)\n","epoch 1375, loss 0.35225582122802734\n","outputs:  tensor([[0.0856, 0.8661],\n","        [0.9241, 0.1097],\n","        [0.9141, 0.1229],\n","        [0.9924, 0.0172],\n","        [0.0155, 0.9783]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3522, grad_fn=<NllLossBackward>)\n","epoch 1376, loss 0.3522070348262787\n","outputs:  tensor([[0.0855, 0.8663],\n","        [0.9242, 0.1096],\n","        [0.9142, 0.1228],\n","        [0.9924, 0.0171],\n","        [0.0155, 0.9784]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3522, grad_fn=<NllLossBackward>)\n","epoch 1377, loss 0.3521583676338196\n","outputs:  tensor([[0.0854, 0.8665],\n","        [0.9243, 0.1095],\n","        [0.9143, 0.1227],\n","        [0.9924, 0.0171],\n","        [0.0154, 0.9784]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3521, grad_fn=<NllLossBackward>)\n","epoch 1378, loss 0.35210973024368286\n","outputs:  tensor([[0.0853, 0.8666],\n","        [0.9244, 0.1093],\n","        [0.9144, 0.1226],\n","        [0.9924, 0.0170],\n","        [0.0154, 0.9785]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3521, grad_fn=<NllLossBackward>)\n","epoch 1379, loss 0.35206127166748047\n","outputs:  tensor([[0.0852, 0.8668],\n","        [0.9244, 0.1092],\n","        [0.9144, 0.1225],\n","        [0.9924, 0.0170],\n","        [0.0154, 0.9785]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3520, grad_fn=<NllLossBackward>)\n","epoch 1380, loss 0.35201287269592285\n","outputs:  tensor([[0.0851, 0.8669],\n","        [0.9245, 0.1091],\n","        [0.9145, 0.1223],\n","        [0.9925, 0.0170],\n","        [0.0153, 0.9786]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3520, grad_fn=<NllLossBackward>)\n","epoch 1381, loss 0.3519645929336548\n","outputs:  tensor([[0.0850, 0.8671],\n","        [0.9246, 0.1090],\n","        [0.9146, 0.1222],\n","        [0.9925, 0.0169],\n","        [0.0153, 0.9786]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3519, grad_fn=<NllLossBackward>)\n","epoch 1382, loss 0.3519163131713867\n","outputs:  tensor([[0.0849, 0.8672],\n","        [0.9247, 0.1089],\n","        [0.9147, 0.1221],\n","        [0.9925, 0.0169],\n","        [0.0153, 0.9787]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3519, grad_fn=<NllLossBackward>)\n","epoch 1383, loss 0.35186824202537537\n","outputs:  tensor([[0.0848, 0.8674],\n","        [0.9248, 0.1087],\n","        [0.9148, 0.1220],\n","        [0.9925, 0.0168],\n","        [0.0152, 0.9787]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3518, grad_fn=<NllLossBackward>)\n","epoch 1384, loss 0.3518202304840088\n","outputs:  tensor([[0.0847, 0.8676],\n","        [0.9248, 0.1086],\n","        [0.9149, 0.1218],\n","        [0.9925, 0.0168],\n","        [0.0152, 0.9788]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3518, grad_fn=<NllLossBackward>)\n","epoch 1385, loss 0.35177236795425415\n","outputs:  tensor([[0.0846, 0.8677],\n","        [0.9249, 0.1085],\n","        [0.9149, 0.1217],\n","        [0.9925, 0.0168],\n","        [0.0152, 0.9788]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3517, grad_fn=<NllLossBackward>)\n","epoch 1386, loss 0.3517245054244995\n","outputs:  tensor([[0.0845, 0.8679],\n","        [0.9250, 0.1084],\n","        [0.9150, 0.1216],\n","        [0.9925, 0.0167],\n","        [0.0152, 0.9789]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3517, grad_fn=<NllLossBackward>)\n","epoch 1387, loss 0.3516767621040344\n","outputs:  tensor([[0.0844, 0.8680],\n","        [0.9251, 0.1083],\n","        [0.9151, 0.1215],\n","        [0.9926, 0.0167],\n","        [0.0151, 0.9789]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3516, grad_fn=<NllLossBackward>)\n","epoch 1388, loss 0.3516291379928589\n","outputs:  tensor([[0.0843, 0.8682],\n","        [0.9252, 0.1082],\n","        [0.9152, 0.1213],\n","        [0.9926, 0.0166],\n","        [0.0151, 0.9789]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3516, grad_fn=<NllLossBackward>)\n","epoch 1389, loss 0.3515815734863281\n","outputs:  tensor([[0.0842, 0.8683],\n","        [0.9252, 0.1080],\n","        [0.9153, 0.1212],\n","        [0.9926, 0.0166],\n","        [0.0151, 0.9790]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3515, grad_fn=<NllLossBackward>)\n","epoch 1390, loss 0.3515341281890869\n","outputs:  tensor([[0.0841, 0.8685],\n","        [0.9253, 0.1079],\n","        [0.9154, 0.1211],\n","        [0.9926, 0.0166],\n","        [0.0150, 0.9790]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3515, grad_fn=<NllLossBackward>)\n","epoch 1391, loss 0.35148677229881287\n","outputs:  tensor([[0.0840, 0.8686],\n","        [0.9254, 0.1078],\n","        [0.9154, 0.1210],\n","        [0.9926, 0.0165],\n","        [0.0150, 0.9791]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3514, grad_fn=<NllLossBackward>)\n","epoch 1392, loss 0.35143953561782837\n","outputs:  tensor([[0.0839, 0.8688],\n","        [0.9255, 0.1077],\n","        [0.9155, 0.1209],\n","        [0.9926, 0.0165],\n","        [0.0150, 0.9791]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3514, grad_fn=<NllLossBackward>)\n","epoch 1393, loss 0.35139232873916626\n","outputs:  tensor([[0.0839, 0.8690],\n","        [0.9255, 0.1076],\n","        [0.9156, 0.1207],\n","        [0.9927, 0.0164],\n","        [0.0150, 0.9792]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3513, grad_fn=<NllLossBackward>)\n","epoch 1394, loss 0.3513453006744385\n","outputs:  tensor([[0.0838, 0.8691],\n","        [0.9256, 0.1074],\n","        [0.9157, 0.1206],\n","        [0.9927, 0.0164],\n","        [0.0149, 0.9792]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3513, grad_fn=<NllLossBackward>)\n","epoch 1395, loss 0.3512982726097107\n","outputs:  tensor([[0.0837, 0.8693],\n","        [0.9257, 0.1073],\n","        [0.9158, 0.1205],\n","        [0.9927, 0.0164],\n","        [0.0149, 0.9793]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3513, grad_fn=<NllLossBackward>)\n","epoch 1396, loss 0.35125139355659485\n","outputs:  tensor([[0.0836, 0.8694],\n","        [0.9258, 0.1072],\n","        [0.9158, 0.1204],\n","        [0.9927, 0.0163],\n","        [0.0149, 0.9793]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3512, grad_fn=<NllLossBackward>)\n","epoch 1397, loss 0.3512045741081238\n","outputs:  tensor([[0.0835, 0.8696],\n","        [0.9259, 0.1071],\n","        [0.9159, 0.1203],\n","        [0.9927, 0.0163],\n","        [0.0148, 0.9794]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3512, grad_fn=<NllLossBackward>)\n","epoch 1398, loss 0.3511578440666199\n","outputs:  tensor([[0.0834, 0.8697],\n","        [0.9259, 0.1070],\n","        [0.9160, 0.1201],\n","        [0.9927, 0.0163],\n","        [0.0148, 0.9794]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3511, grad_fn=<NllLossBackward>)\n","epoch 1399, loss 0.3511112332344055\n","outputs:  tensor([[0.0833, 0.8699],\n","        [0.9260, 0.1069],\n","        [0.9161, 0.1200],\n","        [0.9928, 0.0162],\n","        [0.0148, 0.9794]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3511, grad_fn=<NllLossBackward>)\n","epoch 1400, loss 0.3510647416114807\n","outputs:  tensor([[0.0832, 0.8700],\n","        [0.9261, 0.1068],\n","        [0.9162, 0.1199],\n","        [0.9928, 0.0162],\n","        [0.0147, 0.9795]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3510, grad_fn=<NllLossBackward>)\n","epoch 1401, loss 0.3510182797908783\n","Parameter containing:\n","tensor([[-0.2231, -0.5604,  0.1979],\n","        [-0.9300, -0.6137, -0.0754],\n","        [-0.9393, -0.7683, -0.1230],\n","        [-0.4195, -0.4186, -0.0026]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4793, -0.3208,  0.1269,  0.1109], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.7974,  0.6650,  1.0212,  0.0732],\n","        [-0.1079, -0.8475, -0.6616, -0.5004]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3417, -0.5726], requires_grad=True)\n","outputs:  tensor([[0.0831, 0.8702],\n","        [0.9262, 0.1066],\n","        [0.9162, 0.1198],\n","        [0.9928, 0.0161],\n","        [0.0147, 0.9795]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3510, grad_fn=<NllLossBackward>)\n","epoch 1402, loss 0.35097193717956543\n","outputs:  tensor([[0.0830, 0.8703],\n","        [0.9262, 0.1065],\n","        [0.9163, 0.1197],\n","        [0.9928, 0.0161],\n","        [0.0147, 0.9796]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3509, grad_fn=<NllLossBackward>)\n","epoch 1403, loss 0.3509257435798645\n","outputs:  tensor([[0.0829, 0.8705],\n","        [0.9263, 0.1064],\n","        [0.9164, 0.1195],\n","        [0.9928, 0.0161],\n","        [0.0147, 0.9796]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3509, grad_fn=<NllLossBackward>)\n","epoch 1404, loss 0.3508795201778412\n","outputs:  tensor([[0.0828, 0.8706],\n","        [0.9264, 0.1063],\n","        [0.9165, 0.1194],\n","        [0.9928, 0.0160],\n","        [0.0146, 0.9797]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3508, grad_fn=<NllLossBackward>)\n","epoch 1405, loss 0.3508334457874298\n","outputs:  tensor([[0.0827, 0.8708],\n","        [0.9265, 0.1062],\n","        [0.9166, 0.1193],\n","        [0.9928, 0.0160],\n","        [0.0146, 0.9797]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3508, grad_fn=<NllLossBackward>)\n","epoch 1406, loss 0.3507874608039856\n","outputs:  tensor([[0.0827, 0.8709],\n","        [0.9265, 0.1061],\n","        [0.9166, 0.1192],\n","        [0.9929, 0.0160],\n","        [0.0146, 0.9798]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3507, grad_fn=<NllLossBackward>)\n","epoch 1407, loss 0.35074159502983093\n","outputs:  tensor([[0.0826, 0.8711],\n","        [0.9266, 0.1059],\n","        [0.9167, 0.1191],\n","        [0.9929, 0.0159],\n","        [0.0146, 0.9798]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3507, grad_fn=<NllLossBackward>)\n","epoch 1408, loss 0.35069575905799866\n","outputs:  tensor([[0.0825, 0.8712],\n","        [0.9267, 0.1058],\n","        [0.9168, 0.1189],\n","        [0.9929, 0.0159],\n","        [0.0145, 0.9798]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3507, grad_fn=<NllLossBackward>)\n","epoch 1409, loss 0.35065004229545593\n","outputs:  tensor([[0.0824, 0.8714],\n","        [0.9268, 0.1057],\n","        [0.9169, 0.1188],\n","        [0.9929, 0.0158],\n","        [0.0145, 0.9799]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3506, grad_fn=<NllLossBackward>)\n","epoch 1410, loss 0.350604385137558\n","outputs:  tensor([[0.0823, 0.8715],\n","        [0.9268, 0.1056],\n","        [0.9170, 0.1187],\n","        [0.9929, 0.0158],\n","        [0.0145, 0.9799]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3506, grad_fn=<NllLossBackward>)\n","epoch 1411, loss 0.3505588471889496\n","outputs:  tensor([[0.0822, 0.8717],\n","        [0.9269, 0.1055],\n","        [0.9170, 0.1186],\n","        [0.9929, 0.0158],\n","        [0.0144, 0.9800]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3505, grad_fn=<NllLossBackward>)\n","epoch 1412, loss 0.35051342844963074\n","outputs:  tensor([[0.0821, 0.8718],\n","        [0.9270, 0.1054],\n","        [0.9171, 0.1185],\n","        [0.9929, 0.0157],\n","        [0.0144, 0.9800]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3505, grad_fn=<NllLossBackward>)\n","epoch 1413, loss 0.3504680097103119\n","outputs:  tensor([[0.0820, 0.8720],\n","        [0.9271, 0.1053],\n","        [0.9172, 0.1184],\n","        [0.9930, 0.0157],\n","        [0.0144, 0.9801]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3504, grad_fn=<NllLossBackward>)\n","epoch 1414, loss 0.35042279958724976\n","outputs:  tensor([[0.0819, 0.8721],\n","        [0.9271, 0.1051],\n","        [0.9173, 0.1182],\n","        [0.9930, 0.0157],\n","        [0.0144, 0.9801]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3504, grad_fn=<NllLossBackward>)\n","epoch 1415, loss 0.35037755966186523\n","outputs:  tensor([[0.0818, 0.8723],\n","        [0.9272, 0.1050],\n","        [0.9174, 0.1181],\n","        [0.9930, 0.0156],\n","        [0.0143, 0.9801]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3503, grad_fn=<NllLossBackward>)\n","epoch 1416, loss 0.35033249855041504\n","outputs:  tensor([[0.0817, 0.8724],\n","        [0.9273, 0.1049],\n","        [0.9174, 0.1180],\n","        [0.9930, 0.0156],\n","        [0.0143, 0.9802]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3503, grad_fn=<NllLossBackward>)\n","epoch 1417, loss 0.3502874970436096\n","outputs:  tensor([[0.0817, 0.8726],\n","        [0.9274, 0.1048],\n","        [0.9175, 0.1179],\n","        [0.9930, 0.0156],\n","        [0.0143, 0.9802]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3502, grad_fn=<NllLossBackward>)\n","epoch 1418, loss 0.350242555141449\n","outputs:  tensor([[0.0816, 0.8727],\n","        [0.9274, 0.1047],\n","        [0.9176, 0.1178],\n","        [0.9930, 0.0155],\n","        [0.0143, 0.9803]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3502, grad_fn=<NllLossBackward>)\n","epoch 1419, loss 0.3501977026462555\n","outputs:  tensor([[0.0815, 0.8729],\n","        [0.9275, 0.1046],\n","        [0.9177, 0.1177],\n","        [0.9931, 0.0155],\n","        [0.0142, 0.9803]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3502, grad_fn=<NllLossBackward>)\n","epoch 1420, loss 0.35015296936035156\n","outputs:  tensor([[0.0814, 0.8730],\n","        [0.9276, 0.1045],\n","        [0.9177, 0.1175],\n","        [0.9931, 0.0155],\n","        [0.0142, 0.9804]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3501, grad_fn=<NllLossBackward>)\n","epoch 1421, loss 0.35010826587677\n","outputs:  tensor([[0.0813, 0.8732],\n","        [0.9277, 0.1044],\n","        [0.9178, 0.1174],\n","        [0.9931, 0.0154],\n","        [0.0142, 0.9804]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3501, grad_fn=<NllLossBackward>)\n","epoch 1422, loss 0.3500637114048004\n","outputs:  tensor([[0.0812, 0.8733],\n","        [0.9277, 0.1043],\n","        [0.9179, 0.1173],\n","        [0.9931, 0.0154],\n","        [0.0141, 0.9804]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3500, grad_fn=<NllLossBackward>)\n","epoch 1423, loss 0.3500192165374756\n","outputs:  tensor([[0.0811, 0.8734],\n","        [0.9278, 0.1041],\n","        [0.9180, 0.1172],\n","        [0.9931, 0.0153],\n","        [0.0141, 0.9805]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3500, grad_fn=<NllLossBackward>)\n","epoch 1424, loss 0.3499748706817627\n","outputs:  tensor([[0.0810, 0.8736],\n","        [0.9279, 0.1040],\n","        [0.9181, 0.1171],\n","        [0.9931, 0.0153],\n","        [0.0141, 0.9805]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3499, grad_fn=<NllLossBackward>)\n","epoch 1425, loss 0.34993043541908264\n","outputs:  tensor([[0.0809, 0.8737],\n","        [0.9280, 0.1039],\n","        [0.9181, 0.1170],\n","        [0.9931, 0.0153],\n","        [0.0141, 0.9806]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3499, grad_fn=<NllLossBackward>)\n","epoch 1426, loss 0.3498862385749817\n","outputs:  tensor([[0.0809, 0.8739],\n","        [0.9280, 0.1038],\n","        [0.9182, 0.1168],\n","        [0.9932, 0.0152],\n","        [0.0140, 0.9806]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3498, grad_fn=<NllLossBackward>)\n","epoch 1427, loss 0.3498421311378479\n","outputs:  tensor([[0.0808, 0.8740],\n","        [0.9281, 0.1037],\n","        [0.9183, 0.1167],\n","        [0.9932, 0.0152],\n","        [0.0140, 0.9806]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3498, grad_fn=<NllLossBackward>)\n","epoch 1428, loss 0.3497980237007141\n","outputs:  tensor([[0.0807, 0.8742],\n","        [0.9282, 0.1036],\n","        [0.9184, 0.1166],\n","        [0.9932, 0.0152],\n","        [0.0140, 0.9807]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3498, grad_fn=<NllLossBackward>)\n","epoch 1429, loss 0.34975406527519226\n","outputs:  tensor([[0.0806, 0.8743],\n","        [0.9283, 0.1035],\n","        [0.9184, 0.1165],\n","        [0.9932, 0.0151],\n","        [0.0140, 0.9807]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3497, grad_fn=<NllLossBackward>)\n","epoch 1430, loss 0.3497101366519928\n","outputs:  tensor([[0.0805, 0.8745],\n","        [0.9283, 0.1034],\n","        [0.9185, 0.1164],\n","        [0.9932, 0.0151],\n","        [0.0139, 0.9808]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3497, grad_fn=<NllLossBackward>)\n","epoch 1431, loss 0.3496663570404053\n","outputs:  tensor([[0.0804, 0.8746],\n","        [0.9284, 0.1033],\n","        [0.9186, 0.1163],\n","        [0.9932, 0.0151],\n","        [0.0139, 0.9808]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3496, grad_fn=<NllLossBackward>)\n","epoch 1432, loss 0.34962257742881775\n","outputs:  tensor([[0.0803, 0.8747],\n","        [0.9285, 0.1031],\n","        [0.9187, 0.1162],\n","        [0.9932, 0.0150],\n","        [0.0139, 0.9808]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3496, grad_fn=<NllLossBackward>)\n","epoch 1433, loss 0.34957894682884216\n","outputs:  tensor([[0.0802, 0.8749],\n","        [0.9286, 0.1030],\n","        [0.9188, 0.1160],\n","        [0.9932, 0.0150],\n","        [0.0139, 0.9809]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3495, grad_fn=<NllLossBackward>)\n","epoch 1434, loss 0.34953537583351135\n","outputs:  tensor([[0.0802, 0.8750],\n","        [0.9286, 0.1029],\n","        [0.9188, 0.1159],\n","        [0.9933, 0.0150],\n","        [0.0138, 0.9809]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3495, grad_fn=<NllLossBackward>)\n","epoch 1435, loss 0.3494919240474701\n","outputs:  tensor([[0.0801, 0.8752],\n","        [0.9287, 0.1028],\n","        [0.9189, 0.1158],\n","        [0.9933, 0.0149],\n","        [0.0138, 0.9810]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3494, grad_fn=<NllLossBackward>)\n","epoch 1436, loss 0.3494485020637512\n","outputs:  tensor([[0.0800, 0.8753],\n","        [0.9288, 0.1027],\n","        [0.9190, 0.1157],\n","        [0.9933, 0.0149],\n","        [0.0138, 0.9810]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3494, grad_fn=<NllLossBackward>)\n","epoch 1437, loss 0.3494051694869995\n","outputs:  tensor([[0.0799, 0.8755],\n","        [0.9288, 0.1026],\n","        [0.9191, 0.1156],\n","        [0.9933, 0.0149],\n","        [0.0137, 0.9810]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3494, grad_fn=<NllLossBackward>)\n","epoch 1438, loss 0.34936198592185974\n","outputs:  tensor([[0.0798, 0.8756],\n","        [0.9289, 0.1025],\n","        [0.9191, 0.1155],\n","        [0.9933, 0.0148],\n","        [0.0137, 0.9811]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3493, grad_fn=<NllLossBackward>)\n","epoch 1439, loss 0.34931880235671997\n","outputs:  tensor([[0.0797, 0.8757],\n","        [0.9290, 0.1024],\n","        [0.9192, 0.1154],\n","        [0.9933, 0.0148],\n","        [0.0137, 0.9811]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3493, grad_fn=<NllLossBackward>)\n","epoch 1440, loss 0.3492757976055145\n","outputs:  tensor([[0.0796, 0.8759],\n","        [0.9291, 0.1023],\n","        [0.9193, 0.1152],\n","        [0.9933, 0.0148],\n","        [0.0137, 0.9812]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3492, grad_fn=<NllLossBackward>)\n","epoch 1441, loss 0.3492327630519867\n","outputs:  tensor([[0.0796, 0.8760],\n","        [0.9291, 0.1022],\n","        [0.9194, 0.1151],\n","        [0.9934, 0.0147],\n","        [0.0136, 0.9812]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3492, grad_fn=<NllLossBackward>)\n","epoch 1442, loss 0.3491899073123932\n","outputs:  tensor([[0.0795, 0.8762],\n","        [0.9292, 0.1021],\n","        [0.9194, 0.1150],\n","        [0.9934, 0.0147],\n","        [0.0136, 0.9812]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3491, grad_fn=<NllLossBackward>)\n","epoch 1443, loss 0.34914708137512207\n","outputs:  tensor([[0.0794, 0.8763],\n","        [0.9293, 0.1019],\n","        [0.9195, 0.1149],\n","        [0.9934, 0.0147],\n","        [0.0136, 0.9813]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3491, grad_fn=<NllLossBackward>)\n","epoch 1444, loss 0.3491043448448181\n","outputs:  tensor([[0.0793, 0.8765],\n","        [0.9293, 0.1018],\n","        [0.9196, 0.1148],\n","        [0.9934, 0.0146],\n","        [0.0136, 0.9813]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3491, grad_fn=<NllLossBackward>)\n","epoch 1445, loss 0.34906163811683655\n","outputs:  tensor([[0.0792, 0.8766],\n","        [0.9294, 0.1017],\n","        [0.9197, 0.1147],\n","        [0.9934, 0.0146],\n","        [0.0135, 0.9814]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3490, grad_fn=<NllLossBackward>)\n","epoch 1446, loss 0.3490191102027893\n","outputs:  tensor([[0.0791, 0.8767],\n","        [0.9295, 0.1016],\n","        [0.9197, 0.1146],\n","        [0.9934, 0.0146],\n","        [0.0135, 0.9814]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3490, grad_fn=<NllLossBackward>)\n","epoch 1447, loss 0.34897658228874207\n","outputs:  tensor([[0.0790, 0.8769],\n","        [0.9296, 0.1015],\n","        [0.9198, 0.1145],\n","        [0.9934, 0.0145],\n","        [0.0135, 0.9814]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3489, grad_fn=<NllLossBackward>)\n","epoch 1448, loss 0.3489341139793396\n","outputs:  tensor([[0.0790, 0.8770],\n","        [0.9296, 0.1014],\n","        [0.9199, 0.1143],\n","        [0.9935, 0.0145],\n","        [0.0135, 0.9815]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3489, grad_fn=<NllLossBackward>)\n","epoch 1449, loss 0.34889188408851624\n","outputs:  tensor([[0.0789, 0.8772],\n","        [0.9297, 0.1013],\n","        [0.9200, 0.1142],\n","        [0.9935, 0.0145],\n","        [0.0134, 0.9815]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3488, grad_fn=<NllLossBackward>)\n","epoch 1450, loss 0.3488495647907257\n","outputs:  tensor([[0.0788, 0.8773],\n","        [0.9298, 0.1012],\n","        [0.9200, 0.1141],\n","        [0.9935, 0.0144],\n","        [0.0134, 0.9816]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3488, grad_fn=<NllLossBackward>)\n","epoch 1451, loss 0.3488074243068695\n","Parameter containing:\n","tensor([[-0.2269, -0.5665,  0.1977],\n","        [-0.9376, -0.6257, -0.0755],\n","        [-0.9472, -0.7809, -0.1232],\n","        [-0.4227, -0.4237, -0.0026]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4811, -0.3175,  0.1305,  0.1123], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8027,  0.6721,  1.0301,  0.0778],\n","        [-0.1156, -0.8578, -0.6745, -0.5070]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3435, -0.5751], requires_grad=True)\n","outputs:  tensor([[0.0787, 0.8774],\n","        [0.9298, 0.1011],\n","        [0.9201, 0.1140],\n","        [0.9935, 0.0144],\n","        [0.0134, 0.9816]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3488, grad_fn=<NllLossBackward>)\n","epoch 1452, loss 0.34876543283462524\n","outputs:  tensor([[0.0786, 0.8776],\n","        [0.9299, 0.1010],\n","        [0.9202, 0.1139],\n","        [0.9935, 0.0144],\n","        [0.0134, 0.9816]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3487, grad_fn=<NllLossBackward>)\n","epoch 1453, loss 0.34872332215309143\n","outputs:  tensor([[0.0785, 0.8777],\n","        [0.9300, 0.1009],\n","        [0.9203, 0.1138],\n","        [0.9935, 0.0143],\n","        [0.0133, 0.9817]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3487, grad_fn=<NllLossBackward>)\n","epoch 1454, loss 0.34868139028549194\n","outputs:  tensor([[0.0785, 0.8778],\n","        [0.9301, 0.1008],\n","        [0.9203, 0.1137],\n","        [0.9935, 0.0143],\n","        [0.0133, 0.9817]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3486, grad_fn=<NllLossBackward>)\n","epoch 1455, loss 0.34863948822021484\n","outputs:  tensor([[0.0784, 0.8780],\n","        [0.9301, 0.1007],\n","        [0.9204, 0.1136],\n","        [0.9935, 0.0143],\n","        [0.0133, 0.9817]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3486, grad_fn=<NllLossBackward>)\n","epoch 1456, loss 0.34859776496887207\n","outputs:  tensor([[0.0783, 0.8781],\n","        [0.9302, 0.1006],\n","        [0.9205, 0.1135],\n","        [0.9936, 0.0142],\n","        [0.0133, 0.9818]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3486, grad_fn=<NllLossBackward>)\n","epoch 1457, loss 0.3485560417175293\n","outputs:  tensor([[0.0782, 0.8783],\n","        [0.9303, 0.1004],\n","        [0.9206, 0.1134],\n","        [0.9936, 0.0142],\n","        [0.0132, 0.9818]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3485, grad_fn=<NllLossBackward>)\n","epoch 1458, loss 0.34851446747779846\n","outputs:  tensor([[0.0781, 0.8784],\n","        [0.9303, 0.1003],\n","        [0.9206, 0.1132],\n","        [0.9936, 0.0142],\n","        [0.0132, 0.9819]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3485, grad_fn=<NllLossBackward>)\n","epoch 1459, loss 0.3484728932380676\n","outputs:  tensor([[0.0780, 0.8785],\n","        [0.9304, 0.1002],\n","        [0.9207, 0.1131],\n","        [0.9936, 0.0141],\n","        [0.0132, 0.9819]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3484, grad_fn=<NllLossBackward>)\n","epoch 1460, loss 0.34843143820762634\n","outputs:  tensor([[0.0780, 0.8787],\n","        [0.9305, 0.1001],\n","        [0.9208, 0.1130],\n","        [0.9936, 0.0141],\n","        [0.0132, 0.9819]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3484, grad_fn=<NllLossBackward>)\n","epoch 1461, loss 0.34839004278182983\n","outputs:  tensor([[0.0779, 0.8788],\n","        [0.9305, 0.1000],\n","        [0.9208, 0.1129],\n","        [0.9936, 0.0141],\n","        [0.0131, 0.9820]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3483, grad_fn=<NllLossBackward>)\n","epoch 1462, loss 0.3483487069606781\n","outputs:  tensor([[0.0778, 0.8789],\n","        [0.9306, 0.0999],\n","        [0.9209, 0.1128],\n","        [0.9936, 0.0141],\n","        [0.0131, 0.9820]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3483, grad_fn=<NllLossBackward>)\n","epoch 1463, loss 0.3483075201511383\n","outputs:  tensor([[0.0777, 0.8791],\n","        [0.9307, 0.0998],\n","        [0.9210, 0.1127],\n","        [0.9937, 0.0140],\n","        [0.0131, 0.9820]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3483, grad_fn=<NllLossBackward>)\n","epoch 1464, loss 0.3482663035392761\n","outputs:  tensor([[0.0776, 0.8792],\n","        [0.9307, 0.0997],\n","        [0.9211, 0.1126],\n","        [0.9937, 0.0140],\n","        [0.0131, 0.9821]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3482, grad_fn=<NllLossBackward>)\n","epoch 1465, loss 0.34822529554367065\n","outputs:  tensor([[0.0775, 0.8794],\n","        [0.9308, 0.0996],\n","        [0.9211, 0.1125],\n","        [0.9937, 0.0140],\n","        [0.0131, 0.9821]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3482, grad_fn=<NllLossBackward>)\n","epoch 1466, loss 0.34818434715270996\n","outputs:  tensor([[0.0775, 0.8795],\n","        [0.9309, 0.0995],\n","        [0.9212, 0.1124],\n","        [0.9937, 0.0139],\n","        [0.0130, 0.9822]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3481, grad_fn=<NllLossBackward>)\n","epoch 1467, loss 0.34814342856407166\n","outputs:  tensor([[0.0774, 0.8796],\n","        [0.9310, 0.0994],\n","        [0.9213, 0.1123],\n","        [0.9937, 0.0139],\n","        [0.0130, 0.9822]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3481, grad_fn=<NllLossBackward>)\n","epoch 1468, loss 0.34810253977775574\n","outputs:  tensor([[0.0773, 0.8798],\n","        [0.9310, 0.0993],\n","        [0.9214, 0.1122],\n","        [0.9937, 0.0139],\n","        [0.0130, 0.9822]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3481, grad_fn=<NllLossBackward>)\n","epoch 1469, loss 0.348061740398407\n","outputs:  tensor([[0.0772, 0.8799],\n","        [0.9311, 0.0992],\n","        [0.9214, 0.1120],\n","        [0.9937, 0.0138],\n","        [0.0130, 0.9823]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3480, grad_fn=<NllLossBackward>)\n","epoch 1470, loss 0.34802109003067017\n","outputs:  tensor([[0.0771, 0.8800],\n","        [0.9312, 0.0991],\n","        [0.9215, 0.1119],\n","        [0.9937, 0.0138],\n","        [0.0129, 0.9823]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3480, grad_fn=<NllLossBackward>)\n","epoch 1471, loss 0.34798043966293335\n","outputs:  tensor([[0.0771, 0.8802],\n","        [0.9312, 0.0990],\n","        [0.9216, 0.1118],\n","        [0.9938, 0.0138],\n","        [0.0129, 0.9823]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3479, grad_fn=<NllLossBackward>)\n","epoch 1472, loss 0.34793996810913086\n","outputs:  tensor([[0.0770, 0.8803],\n","        [0.9313, 0.0989],\n","        [0.9216, 0.1117],\n","        [0.9938, 0.0137],\n","        [0.0129, 0.9824]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3479, grad_fn=<NllLossBackward>)\n","epoch 1473, loss 0.34789949655532837\n","outputs:  tensor([[0.0769, 0.8804],\n","        [0.9314, 0.0988],\n","        [0.9217, 0.1116],\n","        [0.9938, 0.0137],\n","        [0.0129, 0.9824]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3479, grad_fn=<NllLossBackward>)\n","epoch 1474, loss 0.34785914421081543\n","outputs:  tensor([[0.0768, 0.8806],\n","        [0.9314, 0.0987],\n","        [0.9218, 0.1115],\n","        [0.9938, 0.0137],\n","        [0.0128, 0.9825]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3478, grad_fn=<NllLossBackward>)\n","epoch 1475, loss 0.3478187918663025\n","outputs:  tensor([[0.0767, 0.8807],\n","        [0.9315, 0.0986],\n","        [0.9219, 0.1114],\n","        [0.9938, 0.0137],\n","        [0.0128, 0.9825]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3478, grad_fn=<NllLossBackward>)\n","epoch 1476, loss 0.3477785587310791\n","outputs:  tensor([[0.0766, 0.8808],\n","        [0.9316, 0.0985],\n","        [0.9219, 0.1113],\n","        [0.9938, 0.0136],\n","        [0.0128, 0.9825]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3477, grad_fn=<NllLossBackward>)\n","epoch 1477, loss 0.3477384150028229\n","outputs:  tensor([[0.0766, 0.8810],\n","        [0.9316, 0.0984],\n","        [0.9220, 0.1112],\n","        [0.9938, 0.0136],\n","        [0.0128, 0.9826]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3477, grad_fn=<NllLossBackward>)\n","epoch 1478, loss 0.3476983308792114\n","outputs:  tensor([[0.0765, 0.8811],\n","        [0.9317, 0.0983],\n","        [0.9221, 0.1111],\n","        [0.9938, 0.0136],\n","        [0.0127, 0.9826]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3477, grad_fn=<NllLossBackward>)\n","epoch 1479, loss 0.34765830636024475\n","outputs:  tensor([[0.0764, 0.8812],\n","        [0.9318, 0.0982],\n","        [0.9221, 0.1110],\n","        [0.9939, 0.0135],\n","        [0.0127, 0.9826]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3476, grad_fn=<NllLossBackward>)\n","epoch 1480, loss 0.3476184010505676\n","outputs:  tensor([[0.0763, 0.8814],\n","        [0.9318, 0.0981],\n","        [0.9222, 0.1109],\n","        [0.9939, 0.0135],\n","        [0.0127, 0.9827]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3476, grad_fn=<NllLossBackward>)\n","epoch 1481, loss 0.34757858514785767\n","outputs:  tensor([[0.0762, 0.8815],\n","        [0.9319, 0.0980],\n","        [0.9223, 0.1108],\n","        [0.9939, 0.0135],\n","        [0.0127, 0.9827]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3475, grad_fn=<NllLossBackward>)\n","epoch 1482, loss 0.34753870964050293\n","outputs:  tensor([[0.0762, 0.8816],\n","        [0.9320, 0.0979],\n","        [0.9224, 0.1107],\n","        [0.9939, 0.0134],\n","        [0.0127, 0.9827]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3475, grad_fn=<NllLossBackward>)\n","epoch 1483, loss 0.3474990427494049\n","outputs:  tensor([[0.0761, 0.8818],\n","        [0.9320, 0.0978],\n","        [0.9224, 0.1105],\n","        [0.9939, 0.0134],\n","        [0.0126, 0.9828]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3475, grad_fn=<NllLossBackward>)\n","epoch 1484, loss 0.34745943546295166\n","outputs:  tensor([[0.0760, 0.8819],\n","        [0.9321, 0.0977],\n","        [0.9225, 0.1104],\n","        [0.9939, 0.0134],\n","        [0.0126, 0.9828]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3474, grad_fn=<NllLossBackward>)\n","epoch 1485, loss 0.3474198877811432\n","outputs:  tensor([[0.0759, 0.8820],\n","        [0.9322, 0.0975],\n","        [0.9226, 0.1103],\n","        [0.9939, 0.0134],\n","        [0.0126, 0.9828]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3474, grad_fn=<NllLossBackward>)\n","epoch 1486, loss 0.34738031029701233\n","outputs:  tensor([[0.0758, 0.8822],\n","        [0.9322, 0.0974],\n","        [0.9226, 0.1102],\n","        [0.9939, 0.0133],\n","        [0.0126, 0.9829]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3473, grad_fn=<NllLossBackward>)\n","epoch 1487, loss 0.3473408818244934\n","outputs:  tensor([[0.0758, 0.8823],\n","        [0.9323, 0.0973],\n","        [0.9227, 0.1101],\n","        [0.9939, 0.0133],\n","        [0.0125, 0.9829]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3473, grad_fn=<NllLossBackward>)\n","epoch 1488, loss 0.34730157256126404\n","outputs:  tensor([[0.0757, 0.8824],\n","        [0.9324, 0.0972],\n","        [0.9228, 0.1100],\n","        [0.9940, 0.0133],\n","        [0.0125, 0.9829]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3473, grad_fn=<NllLossBackward>)\n","epoch 1489, loss 0.34726232290267944\n","outputs:  tensor([[0.0756, 0.8826],\n","        [0.9324, 0.0971],\n","        [0.9229, 0.1099],\n","        [0.9940, 0.0132],\n","        [0.0125, 0.9830]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3472, grad_fn=<NllLossBackward>)\n","epoch 1490, loss 0.34722310304641724\n","outputs:  tensor([[0.0755, 0.8827],\n","        [0.9325, 0.0970],\n","        [0.9229, 0.1098],\n","        [0.9940, 0.0132],\n","        [0.0125, 0.9830]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3472, grad_fn=<NllLossBackward>)\n","epoch 1491, loss 0.3471840023994446\n","outputs:  tensor([[0.0755, 0.8828],\n","        [0.9326, 0.0969],\n","        [0.9230, 0.1097],\n","        [0.9940, 0.0132],\n","        [0.0125, 0.9830]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3471, grad_fn=<NllLossBackward>)\n","epoch 1492, loss 0.3471449315547943\n","outputs:  tensor([[0.0754, 0.8829],\n","        [0.9326, 0.0968],\n","        [0.9231, 0.1096],\n","        [0.9940, 0.0132],\n","        [0.0124, 0.9831]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3471, grad_fn=<NllLossBackward>)\n","epoch 1493, loss 0.3471059799194336\n","outputs:  tensor([[0.0753, 0.8831],\n","        [0.9327, 0.0967],\n","        [0.9231, 0.1095],\n","        [0.9940, 0.0131],\n","        [0.0124, 0.9831]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3471, grad_fn=<NllLossBackward>)\n","epoch 1494, loss 0.34706705808639526\n","outputs:  tensor([[0.0752, 0.8832],\n","        [0.9328, 0.0966],\n","        [0.9232, 0.1094],\n","        [0.9940, 0.0131],\n","        [0.0124, 0.9832]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3470, grad_fn=<NllLossBackward>)\n","epoch 1495, loss 0.3470282554626465\n","outputs:  tensor([[0.0751, 0.8833],\n","        [0.9328, 0.0965],\n","        [0.9233, 0.1093],\n","        [0.9940, 0.0131],\n","        [0.0124, 0.9832]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3470, grad_fn=<NllLossBackward>)\n","epoch 1496, loss 0.3469894826412201\n","outputs:  tensor([[0.0751, 0.8835],\n","        [0.9329, 0.0964],\n","        [0.9233, 0.1092],\n","        [0.9941, 0.0130],\n","        [0.0123, 0.9832]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3470, grad_fn=<NllLossBackward>)\n","epoch 1497, loss 0.3469507098197937\n","outputs:  tensor([[0.0750, 0.8836],\n","        [0.9330, 0.0963],\n","        [0.9234, 0.1091],\n","        [0.9941, 0.0130],\n","        [0.0123, 0.9833]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3469, grad_fn=<NllLossBackward>)\n","epoch 1498, loss 0.346912145614624\n","outputs:  tensor([[0.0749, 0.8837],\n","        [0.9330, 0.0962],\n","        [0.9235, 0.1090],\n","        [0.9941, 0.0130],\n","        [0.0123, 0.9833]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3469, grad_fn=<NllLossBackward>)\n","epoch 1499, loss 0.34687355160713196\n","outputs:  tensor([[0.0748, 0.8838],\n","        [0.9331, 0.0961],\n","        [0.9236, 0.1089],\n","        [0.9941, 0.0130],\n","        [0.0123, 0.9833]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3468, grad_fn=<NllLossBackward>)\n","epoch 1500, loss 0.34683507680892944\n","outputs:  tensor([[0.0748, 0.8840],\n","        [0.9332, 0.0960],\n","        [0.9236, 0.1088],\n","        [0.9941, 0.0129],\n","        [0.0123, 0.9834]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3468, grad_fn=<NllLossBackward>)\n","epoch 1501, loss 0.3467966914176941\n","Parameter containing:\n","tensor([[-0.2305, -0.5723,  0.1976],\n","        [-0.9447, -0.6373, -0.0756],\n","        [-0.9547, -0.7930, -0.1233],\n","        [-0.4258, -0.4286, -0.0026]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4828, -0.3142,  0.1339,  0.1136], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8077,  0.6788,  1.0386,  0.0821],\n","        [-0.1229, -0.8676, -0.6868, -0.5133]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3453, -0.5775], requires_grad=True)\n","outputs:  tensor([[0.0747, 0.8841],\n","        [0.9332, 0.0960],\n","        [0.9237, 0.1087],\n","        [0.9941, 0.0129],\n","        [0.0122, 0.9834]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3468, grad_fn=<NllLossBackward>)\n","epoch 1502, loss 0.3467583656311035\n","outputs:  tensor([[0.0746, 0.8842],\n","        [0.9333, 0.0959],\n","        [0.9238, 0.1086],\n","        [0.9941, 0.0129],\n","        [0.0122, 0.9834]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3467, grad_fn=<NllLossBackward>)\n","epoch 1503, loss 0.3467201292514801\n","outputs:  tensor([[0.0745, 0.8844],\n","        [0.9334, 0.0958],\n","        [0.9238, 0.1085],\n","        [0.9941, 0.0128],\n","        [0.0122, 0.9835]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3467, grad_fn=<NllLossBackward>)\n","epoch 1504, loss 0.3466818928718567\n","outputs:  tensor([[0.0744, 0.8845],\n","        [0.9334, 0.0957],\n","        [0.9239, 0.1084],\n","        [0.9942, 0.0128],\n","        [0.0122, 0.9835]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3466, grad_fn=<NllLossBackward>)\n","epoch 1505, loss 0.3466437757015228\n","outputs:  tensor([[0.0744, 0.8846],\n","        [0.9335, 0.0956],\n","        [0.9240, 0.1083],\n","        [0.9942, 0.0128],\n","        [0.0121, 0.9835]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3466, grad_fn=<NllLossBackward>)\n","epoch 1506, loss 0.34660568833351135\n","outputs:  tensor([[0.0743, 0.8847],\n","        [0.9336, 0.0955],\n","        [0.9240, 0.1082],\n","        [0.9942, 0.0128],\n","        [0.0121, 0.9836]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3466, grad_fn=<NllLossBackward>)\n","epoch 1507, loss 0.3465677499771118\n","outputs:  tensor([[0.0742, 0.8849],\n","        [0.9336, 0.0954],\n","        [0.9241, 0.1080],\n","        [0.9942, 0.0127],\n","        [0.0121, 0.9836]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3465, grad_fn=<NllLossBackward>)\n","epoch 1508, loss 0.3465297818183899\n","outputs:  tensor([[0.0741, 0.8850],\n","        [0.9337, 0.0953],\n","        [0.9242, 0.1079],\n","        [0.9942, 0.0127],\n","        [0.0121, 0.9836]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3465, grad_fn=<NllLossBackward>)\n","epoch 1509, loss 0.3464919626712799\n","outputs:  tensor([[0.0741, 0.8851],\n","        [0.9338, 0.0952],\n","        [0.9242, 0.1078],\n","        [0.9942, 0.0127],\n","        [0.0121, 0.9837]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3465, grad_fn=<NllLossBackward>)\n","epoch 1510, loss 0.3464541435241699\n","outputs:  tensor([[0.0740, 0.8852],\n","        [0.9338, 0.0951],\n","        [0.9243, 0.1077],\n","        [0.9942, 0.0127],\n","        [0.0120, 0.9837]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3464, grad_fn=<NllLossBackward>)\n","epoch 1511, loss 0.3464164733886719\n","outputs:  tensor([[0.0739, 0.8854],\n","        [0.9339, 0.0950],\n","        [0.9244, 0.1076],\n","        [0.9942, 0.0126],\n","        [0.0120, 0.9837]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3464, grad_fn=<NllLossBackward>)\n","epoch 1512, loss 0.3463788330554962\n","outputs:  tensor([[0.0738, 0.8855],\n","        [0.9339, 0.0949],\n","        [0.9244, 0.1075],\n","        [0.9942, 0.0126],\n","        [0.0120, 0.9837]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3463, grad_fn=<NllLossBackward>)\n","epoch 1513, loss 0.34634125232696533\n","outputs:  tensor([[0.0738, 0.8856],\n","        [0.9340, 0.0948],\n","        [0.9245, 0.1074],\n","        [0.9943, 0.0126],\n","        [0.0120, 0.9838]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3463, grad_fn=<NllLossBackward>)\n","epoch 1514, loss 0.34630370140075684\n","outputs:  tensor([[0.0737, 0.8857],\n","        [0.9341, 0.0947],\n","        [0.9246, 0.1073],\n","        [0.9943, 0.0125],\n","        [0.0120, 0.9838]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3463, grad_fn=<NllLossBackward>)\n","epoch 1515, loss 0.34626632928848267\n","outputs:  tensor([[0.0736, 0.8859],\n","        [0.9341, 0.0946],\n","        [0.9246, 0.1072],\n","        [0.9943, 0.0125],\n","        [0.0119, 0.9838]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3462, grad_fn=<NllLossBackward>)\n","epoch 1516, loss 0.3462289571762085\n","outputs:  tensor([[0.0735, 0.8860],\n","        [0.9342, 0.0945],\n","        [0.9247, 0.1071],\n","        [0.9943, 0.0125],\n","        [0.0119, 0.9839]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3462, grad_fn=<NllLossBackward>)\n","epoch 1517, loss 0.3461916446685791\n","outputs:  tensor([[0.0735, 0.8861],\n","        [0.9343, 0.0944],\n","        [0.9248, 0.1070],\n","        [0.9943, 0.0125],\n","        [0.0119, 0.9839]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3462, grad_fn=<NllLossBackward>)\n","epoch 1518, loss 0.34615445137023926\n","outputs:  tensor([[0.0734, 0.8862],\n","        [0.9343, 0.0943],\n","        [0.9249, 0.1069],\n","        [0.9943, 0.0124],\n","        [0.0119, 0.9839]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3461, grad_fn=<NllLossBackward>)\n","epoch 1519, loss 0.3461172580718994\n","outputs:  tensor([[0.0733, 0.8864],\n","        [0.9344, 0.0942],\n","        [0.9249, 0.1068],\n","        [0.9943, 0.0124],\n","        [0.0118, 0.9840]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3461, grad_fn=<NllLossBackward>)\n","epoch 1520, loss 0.3460802137851715\n","outputs:  tensor([[0.0732, 0.8865],\n","        [0.9345, 0.0941],\n","        [0.9250, 0.1067],\n","        [0.9943, 0.0124],\n","        [0.0118, 0.9840]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3460, grad_fn=<NllLossBackward>)\n","epoch 1521, loss 0.3460431694984436\n","outputs:  tensor([[0.0732, 0.8866],\n","        [0.9345, 0.0940],\n","        [0.9251, 0.1066],\n","        [0.9943, 0.0124],\n","        [0.0118, 0.9840]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3460, grad_fn=<NllLossBackward>)\n","epoch 1522, loss 0.34600621461868286\n","outputs:  tensor([[0.0731, 0.8867],\n","        [0.9346, 0.0939],\n","        [0.9251, 0.1065],\n","        [0.9944, 0.0123],\n","        [0.0118, 0.9841]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3460, grad_fn=<NllLossBackward>)\n","epoch 1523, loss 0.3459692895412445\n","outputs:  tensor([[0.0730, 0.8869],\n","        [0.9346, 0.0938],\n","        [0.9252, 0.1064],\n","        [0.9944, 0.0123],\n","        [0.0118, 0.9841]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3459, grad_fn=<NllLossBackward>)\n","epoch 1524, loss 0.3459324836730957\n","outputs:  tensor([[0.0729, 0.8870],\n","        [0.9347, 0.0937],\n","        [0.9253, 0.1063],\n","        [0.9944, 0.0123],\n","        [0.0117, 0.9841]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3459, grad_fn=<NllLossBackward>)\n","epoch 1525, loss 0.34589576721191406\n","outputs:  tensor([[0.0729, 0.8871],\n","        [0.9348, 0.0936],\n","        [0.9253, 0.1062],\n","        [0.9944, 0.0122],\n","        [0.0117, 0.9842]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3459, grad_fn=<NllLossBackward>)\n","epoch 1526, loss 0.34585902094841003\n","outputs:  tensor([[0.0728, 0.8872],\n","        [0.9348, 0.0935],\n","        [0.9254, 0.1061],\n","        [0.9944, 0.0122],\n","        [0.0117, 0.9842]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3458, grad_fn=<NllLossBackward>)\n","epoch 1527, loss 0.34582242369651794\n","outputs:  tensor([[0.0727, 0.8874],\n","        [0.9349, 0.0934],\n","        [0.9255, 0.1060],\n","        [0.9944, 0.0122],\n","        [0.0117, 0.9842]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3458, grad_fn=<NllLossBackward>)\n","epoch 1528, loss 0.34578588604927063\n","outputs:  tensor([[0.0726, 0.8875],\n","        [0.9350, 0.0933],\n","        [0.9255, 0.1059],\n","        [0.9944, 0.0122],\n","        [0.0117, 0.9843]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3457, grad_fn=<NllLossBackward>)\n","epoch 1529, loss 0.3457493782043457\n","outputs:  tensor([[0.0726, 0.8876],\n","        [0.9350, 0.0932],\n","        [0.9256, 0.1058],\n","        [0.9944, 0.0121],\n","        [0.0116, 0.9843]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3457, grad_fn=<NllLossBackward>)\n","epoch 1530, loss 0.34571295976638794\n","outputs:  tensor([[0.0725, 0.8877],\n","        [0.9351, 0.0932],\n","        [0.9257, 0.1057],\n","        [0.9944, 0.0121],\n","        [0.0116, 0.9843]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3457, grad_fn=<NllLossBackward>)\n","epoch 1531, loss 0.34567657113075256\n","outputs:  tensor([[0.0724, 0.8878],\n","        [0.9352, 0.0931],\n","        [0.9257, 0.1056],\n","        [0.9945, 0.0121],\n","        [0.0116, 0.9843]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3456, grad_fn=<NllLossBackward>)\n","epoch 1532, loss 0.34564027190208435\n","outputs:  tensor([[0.0723, 0.8880],\n","        [0.9352, 0.0930],\n","        [0.9258, 0.1055],\n","        [0.9945, 0.0121],\n","        [0.0116, 0.9844]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3456, grad_fn=<NllLossBackward>)\n","epoch 1533, loss 0.3456040322780609\n","outputs:  tensor([[0.0723, 0.8881],\n","        [0.9353, 0.0929],\n","        [0.9259, 0.1054],\n","        [0.9945, 0.0120],\n","        [0.0116, 0.9844]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3456, grad_fn=<NllLossBackward>)\n","epoch 1534, loss 0.34556788206100464\n","outputs:  tensor([[0.0722, 0.8882],\n","        [0.9353, 0.0928],\n","        [0.9259, 0.1053],\n","        [0.9945, 0.0120],\n","        [0.0115, 0.9844]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3455, grad_fn=<NllLossBackward>)\n","epoch 1535, loss 0.34553176164627075\n","outputs:  tensor([[0.0721, 0.8883],\n","        [0.9354, 0.0927],\n","        [0.9260, 0.1052],\n","        [0.9945, 0.0120],\n","        [0.0115, 0.9845]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3455, grad_fn=<NllLossBackward>)\n","epoch 1536, loss 0.3454957902431488\n","outputs:  tensor([[0.0720, 0.8884],\n","        [0.9355, 0.0926],\n","        [0.9260, 0.1051],\n","        [0.9945, 0.0120],\n","        [0.0115, 0.9845]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3455, grad_fn=<NllLossBackward>)\n","epoch 1537, loss 0.34545978903770447\n","outputs:  tensor([[0.0720, 0.8886],\n","        [0.9355, 0.0925],\n","        [0.9261, 0.1050],\n","        [0.9945, 0.0119],\n","        [0.0115, 0.9845]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3454, grad_fn=<NllLossBackward>)\n","epoch 1538, loss 0.3454238772392273\n","outputs:  tensor([[0.0719, 0.8887],\n","        [0.9356, 0.0924],\n","        [0.9262, 0.1050],\n","        [0.9945, 0.0119],\n","        [0.0115, 0.9846]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3454, grad_fn=<NllLossBackward>)\n","epoch 1539, loss 0.3453880250453949\n","outputs:  tensor([[0.0718, 0.8888],\n","        [0.9356, 0.0923],\n","        [0.9262, 0.1049],\n","        [0.9945, 0.0119],\n","        [0.0114, 0.9846]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3454, grad_fn=<NllLossBackward>)\n","epoch 1540, loss 0.34535226225852966\n","outputs:  tensor([[0.0718, 0.8889],\n","        [0.9357, 0.0922],\n","        [0.9263, 0.1048],\n","        [0.9945, 0.0119],\n","        [0.0114, 0.9846]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3453, grad_fn=<NllLossBackward>)\n","epoch 1541, loss 0.3453165590763092\n","outputs:  tensor([[0.0717, 0.8890],\n","        [0.9358, 0.0921],\n","        [0.9264, 0.1047],\n","        [0.9946, 0.0118],\n","        [0.0114, 0.9847]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3453, grad_fn=<NllLossBackward>)\n","epoch 1542, loss 0.3452809453010559\n","outputs:  tensor([[0.0716, 0.8892],\n","        [0.9358, 0.0920],\n","        [0.9264, 0.1046],\n","        [0.9946, 0.0118],\n","        [0.0114, 0.9847]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3452, grad_fn=<NllLossBackward>)\n","epoch 1543, loss 0.3452453017234802\n","outputs:  tensor([[0.0715, 0.8893],\n","        [0.9359, 0.0919],\n","        [0.9265, 0.1045],\n","        [0.9946, 0.0118],\n","        [0.0114, 0.9847]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3452, grad_fn=<NllLossBackward>)\n","epoch 1544, loss 0.3452097773551941\n","outputs:  tensor([[0.0715, 0.8894],\n","        [0.9360, 0.0918],\n","        [0.9266, 0.1044],\n","        [0.9946, 0.0118],\n","        [0.0113, 0.9847]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3452, grad_fn=<NllLossBackward>)\n","epoch 1545, loss 0.3451743423938751\n","outputs:  tensor([[0.0714, 0.8895],\n","        [0.9360, 0.0918],\n","        [0.9266, 0.1043],\n","        [0.9946, 0.0117],\n","        [0.0113, 0.9848]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3451, grad_fn=<NllLossBackward>)\n","epoch 1546, loss 0.3451389670372009\n","outputs:  tensor([[0.0713, 0.8896],\n","        [0.9361, 0.0917],\n","        [0.9267, 0.1042],\n","        [0.9946, 0.0117],\n","        [0.0113, 0.9848]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3451, grad_fn=<NllLossBackward>)\n","epoch 1547, loss 0.3451036512851715\n","outputs:  tensor([[0.0713, 0.8898],\n","        [0.9361, 0.0916],\n","        [0.9268, 0.1041],\n","        [0.9946, 0.0117],\n","        [0.0113, 0.9848]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3451, grad_fn=<NllLossBackward>)\n","epoch 1548, loss 0.3450683653354645\n","outputs:  tensor([[0.0712, 0.8899],\n","        [0.9362, 0.0915],\n","        [0.9268, 0.1040],\n","        [0.9946, 0.0117],\n","        [0.0113, 0.9849]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3450, grad_fn=<NllLossBackward>)\n","epoch 1549, loss 0.345033198595047\n","outputs:  tensor([[0.0711, 0.8900],\n","        [0.9363, 0.0914],\n","        [0.9269, 0.1039],\n","        [0.9946, 0.0116],\n","        [0.0112, 0.9849]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3450, grad_fn=<NllLossBackward>)\n","epoch 1550, loss 0.3449980616569519\n","outputs:  tensor([[0.0710, 0.8901],\n","        [0.9363, 0.0913],\n","        [0.9270, 0.1038],\n","        [0.9946, 0.0116],\n","        [0.0112, 0.9849]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3450, grad_fn=<NllLossBackward>)\n","epoch 1551, loss 0.344963014125824\n","Parameter containing:\n","tensor([[-0.2339, -0.5779,  0.1974],\n","        [-0.9515, -0.6483, -0.0757],\n","        [-0.9618, -0.8046, -0.1235],\n","        [-0.4287, -0.4333, -0.0026]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4845, -0.3111,  0.1373,  0.1150], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8126,  0.6852,  1.0467,  0.0862],\n","        [-0.1299, -0.8770, -0.6985, -0.5192]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3470, -0.5798], requires_grad=True)\n","outputs:  tensor([[0.0710, 0.8902],\n","        [0.9364, 0.0912],\n","        [0.9270, 0.1037],\n","        [0.9947, 0.0116],\n","        [0.0112, 0.9849]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3449, grad_fn=<NllLossBackward>)\n","epoch 1552, loss 0.34492790699005127\n","outputs:  tensor([[0.0709, 0.8903],\n","        [0.9364, 0.0911],\n","        [0.9271, 0.1036],\n","        [0.9947, 0.0116],\n","        [0.0112, 0.9850]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3449, grad_fn=<NllLossBackward>)\n","epoch 1553, loss 0.34489303827285767\n","outputs:  tensor([[0.0708, 0.8905],\n","        [0.9365, 0.0910],\n","        [0.9272, 0.1035],\n","        [0.9947, 0.0115],\n","        [0.0112, 0.9850]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3449, grad_fn=<NllLossBackward>)\n","epoch 1554, loss 0.3448581397533417\n","outputs:  tensor([[0.0708, 0.8906],\n","        [0.9366, 0.0909],\n","        [0.9272, 0.1034],\n","        [0.9947, 0.0115],\n","        [0.0111, 0.9850]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3448, grad_fn=<NllLossBackward>)\n","epoch 1555, loss 0.34482327103614807\n","outputs:  tensor([[0.0707, 0.8907],\n","        [0.9366, 0.0908],\n","        [0.9273, 0.1033],\n","        [0.9947, 0.0115],\n","        [0.0111, 0.9851]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3448, grad_fn=<NllLossBackward>)\n","epoch 1556, loss 0.3447885513305664\n","outputs:  tensor([[0.0706, 0.8908],\n","        [0.9367, 0.0907],\n","        [0.9273, 0.1032],\n","        [0.9947, 0.0115],\n","        [0.0111, 0.9851]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3448, grad_fn=<NllLossBackward>)\n","epoch 1557, loss 0.34475380182266235\n","outputs:  tensor([[0.0705, 0.8909],\n","        [0.9367, 0.0907],\n","        [0.9274, 0.1031],\n","        [0.9947, 0.0114],\n","        [0.0111, 0.9851]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3447, grad_fn=<NllLossBackward>)\n","epoch 1558, loss 0.34471917152404785\n","outputs:  tensor([[0.0705, 0.8911],\n","        [0.9368, 0.0906],\n","        [0.9275, 0.1030],\n","        [0.9947, 0.0114],\n","        [0.0111, 0.9852]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3447, grad_fn=<NllLossBackward>)\n","epoch 1559, loss 0.3446846008300781\n","outputs:  tensor([[0.0704, 0.8912],\n","        [0.9369, 0.0905],\n","        [0.9275, 0.1029],\n","        [0.9947, 0.0114],\n","        [0.0111, 0.9852]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3447, grad_fn=<NllLossBackward>)\n","epoch 1560, loss 0.3446500897407532\n","outputs:  tensor([[0.0703, 0.8913],\n","        [0.9369, 0.0904],\n","        [0.9276, 0.1028],\n","        [0.9948, 0.0114],\n","        [0.0110, 0.9852]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3446, grad_fn=<NllLossBackward>)\n","epoch 1561, loss 0.344615638256073\n","outputs:  tensor([[0.0703, 0.8914],\n","        [0.9370, 0.0903],\n","        [0.9277, 0.1027],\n","        [0.9948, 0.0114],\n","        [0.0110, 0.9852]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3446, grad_fn=<NllLossBackward>)\n","epoch 1562, loss 0.34458127617836\n","outputs:  tensor([[0.0702, 0.8915],\n","        [0.9370, 0.0902],\n","        [0.9277, 0.1026],\n","        [0.9948, 0.0113],\n","        [0.0110, 0.9853]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3445, grad_fn=<NllLossBackward>)\n","epoch 1563, loss 0.34454694390296936\n","outputs:  tensor([[0.0701, 0.8916],\n","        [0.9371, 0.0901],\n","        [0.9278, 0.1026],\n","        [0.9948, 0.0113],\n","        [0.0110, 0.9853]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3445, grad_fn=<NllLossBackward>)\n","epoch 1564, loss 0.3445126414299011\n","outputs:  tensor([[0.0701, 0.8917],\n","        [0.9372, 0.0900],\n","        [0.9278, 0.1025],\n","        [0.9948, 0.0113],\n","        [0.0110, 0.9853]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3445, grad_fn=<NllLossBackward>)\n","epoch 1565, loss 0.34447842836380005\n","outputs:  tensor([[0.0700, 0.8919],\n","        [0.9372, 0.0899],\n","        [0.9279, 0.1024],\n","        [0.9948, 0.0113],\n","        [0.0109, 0.9854]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3444, grad_fn=<NllLossBackward>)\n","epoch 1566, loss 0.34444430470466614\n","outputs:  tensor([[0.0699, 0.8920],\n","        [0.9373, 0.0898],\n","        [0.9280, 0.1023],\n","        [0.9948, 0.0112],\n","        [0.0109, 0.9854]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3444, grad_fn=<NllLossBackward>)\n","epoch 1567, loss 0.3444102108478546\n","outputs:  tensor([[0.0698, 0.8921],\n","        [0.9373, 0.0898],\n","        [0.9280, 0.1022],\n","        [0.9948, 0.0112],\n","        [0.0109, 0.9854]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3444, grad_fn=<NllLossBackward>)\n","epoch 1568, loss 0.34437617659568787\n","outputs:  tensor([[0.0698, 0.8922],\n","        [0.9374, 0.0897],\n","        [0.9281, 0.1021],\n","        [0.9948, 0.0112],\n","        [0.0109, 0.9854]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3443, grad_fn=<NllLossBackward>)\n","epoch 1569, loss 0.3443421721458435\n","outputs:  tensor([[0.0697, 0.8923],\n","        [0.9375, 0.0896],\n","        [0.9282, 0.1020],\n","        [0.9948, 0.0112],\n","        [0.0109, 0.9855]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3443, grad_fn=<NllLossBackward>)\n","epoch 1570, loss 0.3443083167076111\n","outputs:  tensor([[0.0696, 0.8924],\n","        [0.9375, 0.0895],\n","        [0.9282, 0.1019],\n","        [0.9948, 0.0111],\n","        [0.0108, 0.9855]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3443, grad_fn=<NllLossBackward>)\n","epoch 1571, loss 0.3442744314670563\n","outputs:  tensor([[0.0696, 0.8925],\n","        [0.9376, 0.0894],\n","        [0.9283, 0.1018],\n","        [0.9949, 0.0111],\n","        [0.0108, 0.9855]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3442, grad_fn=<NllLossBackward>)\n","epoch 1572, loss 0.34424060583114624\n","outputs:  tensor([[0.0695, 0.8927],\n","        [0.9376, 0.0893],\n","        [0.9283, 0.1017],\n","        [0.9949, 0.0111],\n","        [0.0108, 0.9855]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3442, grad_fn=<NllLossBackward>)\n","epoch 1573, loss 0.34420695900917053\n","outputs:  tensor([[0.0694, 0.8928],\n","        [0.9377, 0.0892],\n","        [0.9284, 0.1016],\n","        [0.9949, 0.0111],\n","        [0.0108, 0.9856]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3442, grad_fn=<NllLossBackward>)\n","epoch 1574, loss 0.34417325258255005\n","outputs:  tensor([[0.0694, 0.8929],\n","        [0.9377, 0.0891],\n","        [0.9285, 0.1015],\n","        [0.9949, 0.0110],\n","        [0.0108, 0.9856]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3441, grad_fn=<NllLossBackward>)\n","epoch 1575, loss 0.34413963556289673\n","outputs:  tensor([[0.0693, 0.8930],\n","        [0.9378, 0.0890],\n","        [0.9285, 0.1014],\n","        [0.9949, 0.0110],\n","        [0.0108, 0.9856]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3441, grad_fn=<NllLossBackward>)\n","epoch 1576, loss 0.34410610795021057\n","outputs:  tensor([[0.0692, 0.8931],\n","        [0.9379, 0.0890],\n","        [0.9286, 0.1013],\n","        [0.9949, 0.0110],\n","        [0.0107, 0.9857]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3441, grad_fn=<NllLossBackward>)\n","epoch 1577, loss 0.3440725803375244\n","outputs:  tensor([[0.0692, 0.8932],\n","        [0.9379, 0.0889],\n","        [0.9287, 0.1012],\n","        [0.9949, 0.0110],\n","        [0.0107, 0.9857]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3440, grad_fn=<NllLossBackward>)\n","epoch 1578, loss 0.3440392017364502\n","outputs:  tensor([[0.0691, 0.8933],\n","        [0.9380, 0.0888],\n","        [0.9287, 0.1012],\n","        [0.9949, 0.0110],\n","        [0.0107, 0.9857]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3440, grad_fn=<NllLossBackward>)\n","epoch 1579, loss 0.3440057635307312\n","outputs:  tensor([[0.0690, 0.8935],\n","        [0.9380, 0.0887],\n","        [0.9288, 0.1011],\n","        [0.9949, 0.0109],\n","        [0.0107, 0.9857]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3440, grad_fn=<NllLossBackward>)\n","epoch 1580, loss 0.34397247433662415\n","outputs:  tensor([[0.0690, 0.8936],\n","        [0.9381, 0.0886],\n","        [0.9288, 0.1010],\n","        [0.9949, 0.0109],\n","        [0.0107, 0.9858]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3439, grad_fn=<NllLossBackward>)\n","epoch 1581, loss 0.3439392149448395\n","outputs:  tensor([[0.0689, 0.8937],\n","        [0.9381, 0.0885],\n","        [0.9289, 0.1009],\n","        [0.9950, 0.0109],\n","        [0.0106, 0.9858]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3439, grad_fn=<NllLossBackward>)\n","epoch 1582, loss 0.3439060151576996\n","outputs:  tensor([[0.0688, 0.8938],\n","        [0.9382, 0.0884],\n","        [0.9290, 0.1008],\n","        [0.9950, 0.0109],\n","        [0.0106, 0.9858]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3439, grad_fn=<NllLossBackward>)\n","epoch 1583, loss 0.34387287497520447\n","outputs:  tensor([[0.0688, 0.8939],\n","        [0.9383, 0.0883],\n","        [0.9290, 0.1007],\n","        [0.9950, 0.0108],\n","        [0.0106, 0.9858]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3438, grad_fn=<NllLossBackward>)\n","epoch 1584, loss 0.3438398241996765\n","outputs:  tensor([[0.0687, 0.8940],\n","        [0.9383, 0.0883],\n","        [0.9291, 0.1006],\n","        [0.9950, 0.0108],\n","        [0.0106, 0.9859]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3438, grad_fn=<NllLossBackward>)\n","epoch 1585, loss 0.34380674362182617\n","outputs:  tensor([[0.0686, 0.8941],\n","        [0.9384, 0.0882],\n","        [0.9292, 0.1005],\n","        [0.9950, 0.0108],\n","        [0.0106, 0.9859]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3438, grad_fn=<NllLossBackward>)\n","epoch 1586, loss 0.34377381205558777\n","outputs:  tensor([[0.0686, 0.8942],\n","        [0.9384, 0.0881],\n","        [0.9292, 0.1004],\n","        [0.9950, 0.0108],\n","        [0.0106, 0.9859]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3437, grad_fn=<NllLossBackward>)\n","epoch 1587, loss 0.34374088048934937\n","outputs:  tensor([[0.0685, 0.8943],\n","        [0.9385, 0.0880],\n","        [0.9293, 0.1003],\n","        [0.9950, 0.0108],\n","        [0.0105, 0.9860]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3437, grad_fn=<NllLossBackward>)\n","epoch 1588, loss 0.3437080383300781\n","outputs:  tensor([[0.0684, 0.8945],\n","        [0.9386, 0.0879],\n","        [0.9293, 0.1002],\n","        [0.9950, 0.0107],\n","        [0.0105, 0.9860]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3437, grad_fn=<NllLossBackward>)\n","epoch 1589, loss 0.34367528557777405\n","outputs:  tensor([[0.0683, 0.8946],\n","        [0.9386, 0.0878],\n","        [0.9294, 0.1001],\n","        [0.9950, 0.0107],\n","        [0.0105, 0.9860]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3436, grad_fn=<NllLossBackward>)\n","epoch 1590, loss 0.34364253282546997\n","outputs:  tensor([[0.0683, 0.8947],\n","        [0.9387, 0.0877],\n","        [0.9295, 0.1001],\n","        [0.9950, 0.0107],\n","        [0.0105, 0.9860]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3436, grad_fn=<NllLossBackward>)\n","epoch 1591, loss 0.34360986948013306\n","outputs:  tensor([[0.0682, 0.8948],\n","        [0.9387, 0.0877],\n","        [0.9295, 0.1000],\n","        [0.9950, 0.0107],\n","        [0.0105, 0.9861]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3436, grad_fn=<NllLossBackward>)\n","epoch 1592, loss 0.34357723593711853\n","outputs:  tensor([[0.0681, 0.8949],\n","        [0.9388, 0.0876],\n","        [0.9296, 0.0999],\n","        [0.9951, 0.0106],\n","        [0.0105, 0.9861]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3435, grad_fn=<NllLossBackward>)\n","epoch 1593, loss 0.3435446619987488\n","outputs:  tensor([[0.0681, 0.8950],\n","        [0.9388, 0.0875],\n","        [0.9296, 0.0998],\n","        [0.9951, 0.0106],\n","        [0.0104, 0.9861]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3435, grad_fn=<NllLossBackward>)\n","epoch 1594, loss 0.3435121178627014\n","outputs:  tensor([[0.0680, 0.8951],\n","        [0.9389, 0.0874],\n","        [0.9297, 0.0997],\n","        [0.9951, 0.0106],\n","        [0.0104, 0.9861]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3435, grad_fn=<NllLossBackward>)\n","epoch 1595, loss 0.3434796631336212\n","outputs:  tensor([[0.0680, 0.8952],\n","        [0.9389, 0.0873],\n","        [0.9298, 0.0996],\n","        [0.9951, 0.0106],\n","        [0.0104, 0.9862]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3434, grad_fn=<NllLossBackward>)\n","epoch 1596, loss 0.3434472978115082\n","outputs:  tensor([[0.0679, 0.8953],\n","        [0.9390, 0.0872],\n","        [0.9298, 0.0995],\n","        [0.9951, 0.0106],\n","        [0.0104, 0.9862]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3434, grad_fn=<NllLossBackward>)\n","epoch 1597, loss 0.34341496229171753\n","outputs:  tensor([[0.0678, 0.8954],\n","        [0.9391, 0.0871],\n","        [0.9299, 0.0994],\n","        [0.9951, 0.0105],\n","        [0.0104, 0.9862]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3434, grad_fn=<NllLossBackward>)\n","epoch 1598, loss 0.34338274598121643\n","outputs:  tensor([[0.0678, 0.8956],\n","        [0.9391, 0.0871],\n","        [0.9299, 0.0993],\n","        [0.9951, 0.0105],\n","        [0.0104, 0.9862]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3434, grad_fn=<NllLossBackward>)\n","epoch 1599, loss 0.34335049986839294\n","outputs:  tensor([[0.0677, 0.8957],\n","        [0.9392, 0.0870],\n","        [0.9300, 0.0992],\n","        [0.9951, 0.0105],\n","        [0.0103, 0.9863]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3433, grad_fn=<NllLossBackward>)\n","epoch 1600, loss 0.34331831336021423\n","outputs:  tensor([[0.0676, 0.8958],\n","        [0.9392, 0.0869],\n","        [0.9301, 0.0992],\n","        [0.9951, 0.0105],\n","        [0.0103, 0.9863]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3433, grad_fn=<NllLossBackward>)\n","epoch 1601, loss 0.3432861864566803\n","Parameter containing:\n","tensor([[-0.2372, -0.5833,  0.1973],\n","        [-0.9580, -0.6588, -0.0758],\n","        [-0.9686, -0.8157, -0.1236],\n","        [-0.4315, -0.4378, -0.0026]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4861, -0.3080,  0.1406,  0.1163], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8172,  0.6913,  1.0544,  0.0901],\n","        [-0.1366, -0.8859, -0.7097, -0.5249]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3487, -0.5820], requires_grad=True)\n","outputs:  tensor([[0.0676, 0.8959],\n","        [0.9393, 0.0868],\n","        [0.9301, 0.0991],\n","        [0.9951, 0.0105],\n","        [0.0103, 0.9863]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3433, grad_fn=<NllLossBackward>)\n","epoch 1602, loss 0.34325411915779114\n","outputs:  tensor([[0.0675, 0.8960],\n","        [0.9393, 0.0867],\n","        [0.9302, 0.0990],\n","        [0.9951, 0.0104],\n","        [0.0103, 0.9863]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3432, grad_fn=<NllLossBackward>)\n","epoch 1603, loss 0.34322211146354675\n","outputs:  tensor([[0.0674, 0.8961],\n","        [0.9394, 0.0866],\n","        [0.9302, 0.0989],\n","        [0.9952, 0.0104],\n","        [0.0103, 0.9864]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3432, grad_fn=<NllLossBackward>)\n","epoch 1604, loss 0.34319019317626953\n","outputs:  tensor([[0.0674, 0.8962],\n","        [0.9395, 0.0865],\n","        [0.9303, 0.0988],\n","        [0.9952, 0.0104],\n","        [0.0102, 0.9864]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3432, grad_fn=<NllLossBackward>)\n","epoch 1605, loss 0.3431583046913147\n","outputs:  tensor([[0.0673, 0.8963],\n","        [0.9395, 0.0865],\n","        [0.9304, 0.0987],\n","        [0.9952, 0.0104],\n","        [0.0102, 0.9864]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3431, grad_fn=<NllLossBackward>)\n","epoch 1606, loss 0.3431263864040375\n","outputs:  tensor([[0.0672, 0.8964],\n","        [0.9396, 0.0864],\n","        [0.9304, 0.0986],\n","        [0.9952, 0.0103],\n","        [0.0102, 0.9864]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3431, grad_fn=<NllLossBackward>)\n","epoch 1607, loss 0.34309467673301697\n","outputs:  tensor([[0.0672, 0.8965],\n","        [0.9396, 0.0863],\n","        [0.9305, 0.0985],\n","        [0.9952, 0.0103],\n","        [0.0102, 0.9865]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3431, grad_fn=<NllLossBackward>)\n","epoch 1608, loss 0.34306296706199646\n","outputs:  tensor([[0.0671, 0.8966],\n","        [0.9397, 0.0862],\n","        [0.9305, 0.0984],\n","        [0.9952, 0.0103],\n","        [0.0102, 0.9865]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3430, grad_fn=<NllLossBackward>)\n","epoch 1609, loss 0.34303125739097595\n","outputs:  tensor([[0.0670, 0.8967],\n","        [0.9397, 0.0861],\n","        [0.9306, 0.0984],\n","        [0.9952, 0.0103],\n","        [0.0102, 0.9865]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3430, grad_fn=<NllLossBackward>)\n","epoch 1610, loss 0.3429996073246002\n","outputs:  tensor([[0.0670, 0.8969],\n","        [0.9398, 0.0860],\n","        [0.9307, 0.0983],\n","        [0.9952, 0.0103],\n","        [0.0101, 0.9865]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3430, grad_fn=<NllLossBackward>)\n","epoch 1611, loss 0.3429681360721588\n","outputs:  tensor([[0.0669, 0.8970],\n","        [0.9398, 0.0860],\n","        [0.9307, 0.0982],\n","        [0.9952, 0.0102],\n","        [0.0101, 0.9866]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3429, grad_fn=<NllLossBackward>)\n","epoch 1612, loss 0.34293660521507263\n","outputs:  tensor([[0.0668, 0.8971],\n","        [0.9399, 0.0859],\n","        [0.9308, 0.0981],\n","        [0.9952, 0.0102],\n","        [0.0101, 0.9866]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3429, grad_fn=<NllLossBackward>)\n","epoch 1613, loss 0.34290510416030884\n","outputs:  tensor([[0.0668, 0.8972],\n","        [0.9400, 0.0858],\n","        [0.9308, 0.0980],\n","        [0.9952, 0.0102],\n","        [0.0101, 0.9866]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3429, grad_fn=<NllLossBackward>)\n","epoch 1614, loss 0.3428737223148346\n","outputs:  tensor([[0.0667, 0.8973],\n","        [0.9400, 0.0857],\n","        [0.9309, 0.0979],\n","        [0.9953, 0.0102],\n","        [0.0101, 0.9866]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3428, grad_fn=<NllLossBackward>)\n","epoch 1615, loss 0.3428424000740051\n","outputs:  tensor([[0.0666, 0.8974],\n","        [0.9401, 0.0856],\n","        [0.9309, 0.0978],\n","        [0.9953, 0.0102],\n","        [0.0101, 0.9867]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3428, grad_fn=<NllLossBackward>)\n","epoch 1616, loss 0.34281104803085327\n","outputs:  tensor([[0.0666, 0.8975],\n","        [0.9401, 0.0855],\n","        [0.9310, 0.0977],\n","        [0.9953, 0.0101],\n","        [0.0100, 0.9867]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3428, grad_fn=<NllLossBackward>)\n","epoch 1617, loss 0.34277987480163574\n","outputs:  tensor([[0.0665, 0.8976],\n","        [0.9402, 0.0855],\n","        [0.9311, 0.0976],\n","        [0.9953, 0.0101],\n","        [0.0100, 0.9867]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3427, grad_fn=<NllLossBackward>)\n","epoch 1618, loss 0.3427487015724182\n","outputs:  tensor([[0.0665, 0.8977],\n","        [0.9402, 0.0854],\n","        [0.9311, 0.0976],\n","        [0.9953, 0.0101],\n","        [0.0100, 0.9867]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3427, grad_fn=<NllLossBackward>)\n","epoch 1619, loss 0.34271755814552307\n","outputs:  tensor([[0.0664, 0.8978],\n","        [0.9403, 0.0853],\n","        [0.9312, 0.0975],\n","        [0.9953, 0.0101],\n","        [0.0100, 0.9868]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3427, grad_fn=<NllLossBackward>)\n","epoch 1620, loss 0.3426865041255951\n","outputs:  tensor([[0.0663, 0.8979],\n","        [0.9403, 0.0852],\n","        [0.9312, 0.0974],\n","        [0.9953, 0.0101],\n","        [0.0100, 0.9868]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3427, grad_fn=<NllLossBackward>)\n","epoch 1621, loss 0.3426554799079895\n","outputs:  tensor([[0.0663, 0.8980],\n","        [0.9404, 0.0851],\n","        [0.9313, 0.0973],\n","        [0.9953, 0.0100],\n","        [0.0100, 0.9868]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3426, grad_fn=<NllLossBackward>)\n","epoch 1622, loss 0.3426244556903839\n","outputs:  tensor([[0.0662, 0.8981],\n","        [0.9404, 0.0850],\n","        [0.9314, 0.0972],\n","        [0.9953, 0.0100],\n","        [0.0099, 0.9868]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3426, grad_fn=<NllLossBackward>)\n","epoch 1623, loss 0.34259361028671265\n","outputs:  tensor([[0.0661, 0.8982],\n","        [0.9405, 0.0850],\n","        [0.9314, 0.0971],\n","        [0.9953, 0.0100],\n","        [0.0099, 0.9869]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3426, grad_fn=<NllLossBackward>)\n","epoch 1624, loss 0.3425627052783966\n","outputs:  tensor([[0.0661, 0.8983],\n","        [0.9406, 0.0849],\n","        [0.9315, 0.0970],\n","        [0.9953, 0.0100],\n","        [0.0099, 0.9869]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3425, grad_fn=<NllLossBackward>)\n","epoch 1625, loss 0.3425319194793701\n","outputs:  tensor([[0.0660, 0.8984],\n","        [0.9406, 0.0848],\n","        [0.9315, 0.0970],\n","        [0.9953, 0.0100],\n","        [0.0099, 0.9869]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3425, grad_fn=<NllLossBackward>)\n","epoch 1626, loss 0.34250110387802124\n","outputs:  tensor([[0.0660, 0.8985],\n","        [0.9407, 0.0847],\n","        [0.9316, 0.0969],\n","        [0.9954, 0.0099],\n","        [0.0099, 0.9869]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3425, grad_fn=<NllLossBackward>)\n","epoch 1627, loss 0.3424704372882843\n","outputs:  tensor([[0.0659, 0.8986],\n","        [0.9407, 0.0846],\n","        [0.9316, 0.0968],\n","        [0.9954, 0.0099],\n","        [0.0099, 0.9870]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3424, grad_fn=<NllLossBackward>)\n","epoch 1628, loss 0.34243980050086975\n","outputs:  tensor([[0.0658, 0.8987],\n","        [0.9408, 0.0846],\n","        [0.9317, 0.0967],\n","        [0.9954, 0.0099],\n","        [0.0099, 0.9870]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3424, grad_fn=<NllLossBackward>)\n","epoch 1629, loss 0.3424091935157776\n","outputs:  tensor([[0.0658, 0.8989],\n","        [0.9408, 0.0845],\n","        [0.9318, 0.0966],\n","        [0.9954, 0.0099],\n","        [0.0098, 0.9870]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3424, grad_fn=<NllLossBackward>)\n","epoch 1630, loss 0.3423786163330078\n","outputs:  tensor([[0.0657, 0.8990],\n","        [0.9409, 0.0844],\n","        [0.9318, 0.0965],\n","        [0.9954, 0.0099],\n","        [0.0098, 0.9870]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3423, grad_fn=<NllLossBackward>)\n","epoch 1631, loss 0.3423480987548828\n","outputs:  tensor([[0.0656, 0.8991],\n","        [0.9409, 0.0843],\n","        [0.9319, 0.0964],\n","        [0.9954, 0.0098],\n","        [0.0098, 0.9871]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3423, grad_fn=<NllLossBackward>)\n","epoch 1632, loss 0.342317670583725\n","outputs:  tensor([[0.0656, 0.8992],\n","        [0.9410, 0.0842],\n","        [0.9319, 0.0964],\n","        [0.9954, 0.0098],\n","        [0.0098, 0.9871]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3423, grad_fn=<NllLossBackward>)\n","epoch 1633, loss 0.34228724241256714\n","outputs:  tensor([[0.0655, 0.8993],\n","        [0.9410, 0.0841],\n","        [0.9320, 0.0963],\n","        [0.9954, 0.0098],\n","        [0.0098, 0.9871]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3423, grad_fn=<NllLossBackward>)\n","epoch 1634, loss 0.34225693345069885\n","outputs:  tensor([[0.0654, 0.8994],\n","        [0.9411, 0.0841],\n","        [0.9320, 0.0962],\n","        [0.9954, 0.0098],\n","        [0.0098, 0.9871]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3422, grad_fn=<NllLossBackward>)\n","epoch 1635, loss 0.34222668409347534\n","outputs:  tensor([[0.0654, 0.8995],\n","        [0.9411, 0.0840],\n","        [0.9321, 0.0961],\n","        [0.9954, 0.0098],\n","        [0.0097, 0.9872]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3422, grad_fn=<NllLossBackward>)\n","epoch 1636, loss 0.3421964645385742\n","outputs:  tensor([[0.0653, 0.8996],\n","        [0.9412, 0.0839],\n","        [0.9322, 0.0960],\n","        [0.9954, 0.0097],\n","        [0.0097, 0.9872]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3422, grad_fn=<NllLossBackward>)\n","epoch 1637, loss 0.3421662449836731\n","outputs:  tensor([[0.0653, 0.8997],\n","        [0.9413, 0.0838],\n","        [0.9322, 0.0959],\n","        [0.9954, 0.0097],\n","        [0.0097, 0.9872]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3421, grad_fn=<NllLossBackward>)\n","epoch 1638, loss 0.34213608503341675\n","outputs:  tensor([[0.0652, 0.8998],\n","        [0.9413, 0.0837],\n","        [0.9323, 0.0958],\n","        [0.9955, 0.0097],\n","        [0.0097, 0.9872]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3421, grad_fn=<NllLossBackward>)\n","epoch 1639, loss 0.34210604429244995\n","outputs:  tensor([[0.0651, 0.8999],\n","        [0.9414, 0.0837],\n","        [0.9323, 0.0958],\n","        [0.9955, 0.0097],\n","        [0.0097, 0.9872]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3421, grad_fn=<NllLossBackward>)\n","epoch 1640, loss 0.34207597374916077\n","outputs:  tensor([[0.0651, 0.9000],\n","        [0.9414, 0.0836],\n","        [0.9324, 0.0957],\n","        [0.9955, 0.0097],\n","        [0.0097, 0.9873]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3420, grad_fn=<NllLossBackward>)\n","epoch 1641, loss 0.34204602241516113\n","outputs:  tensor([[0.0650, 0.9001],\n","        [0.9415, 0.0835],\n","        [0.9324, 0.0956],\n","        [0.9955, 0.0096],\n","        [0.0096, 0.9873]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3420, grad_fn=<NllLossBackward>)\n","epoch 1642, loss 0.3420160412788391\n","outputs:  tensor([[0.0650, 0.9002],\n","        [0.9415, 0.0834],\n","        [0.9325, 0.0955],\n","        [0.9955, 0.0096],\n","        [0.0096, 0.9873]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3420, grad_fn=<NllLossBackward>)\n","epoch 1643, loss 0.34198617935180664\n","outputs:  tensor([[0.0649, 0.9003],\n","        [0.9416, 0.0833],\n","        [0.9326, 0.0954],\n","        [0.9955, 0.0096],\n","        [0.0096, 0.9873]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3420, grad_fn=<NllLossBackward>)\n","epoch 1644, loss 0.34195637702941895\n","outputs:  tensor([[0.0648, 0.9004],\n","        [0.9416, 0.0833],\n","        [0.9326, 0.0953],\n","        [0.9955, 0.0096],\n","        [0.0096, 0.9874]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3419, grad_fn=<NllLossBackward>)\n","epoch 1645, loss 0.34192657470703125\n","outputs:  tensor([[0.0648, 0.9005],\n","        [0.9417, 0.0832],\n","        [0.9327, 0.0952],\n","        [0.9955, 0.0096],\n","        [0.0096, 0.9874]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3419, grad_fn=<NllLossBackward>)\n","epoch 1646, loss 0.3418968617916107\n","outputs:  tensor([[0.0647, 0.9006],\n","        [0.9417, 0.0831],\n","        [0.9327, 0.0952],\n","        [0.9955, 0.0095],\n","        [0.0096, 0.9874]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3419, grad_fn=<NllLossBackward>)\n","epoch 1647, loss 0.3418671488761902\n","outputs:  tensor([[0.0646, 0.9007],\n","        [0.9418, 0.0830],\n","        [0.9328, 0.0951],\n","        [0.9955, 0.0095],\n","        [0.0096, 0.9874]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3418, grad_fn=<NllLossBackward>)\n","epoch 1648, loss 0.3418375551700592\n","outputs:  tensor([[0.0646, 0.9008],\n","        [0.9418, 0.0829],\n","        [0.9328, 0.0950],\n","        [0.9955, 0.0095],\n","        [0.0095, 0.9875]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3418, grad_fn=<NllLossBackward>)\n","epoch 1649, loss 0.341808021068573\n","outputs:  tensor([[0.0645, 0.9009],\n","        [0.9419, 0.0829],\n","        [0.9329, 0.0949],\n","        [0.9955, 0.0095],\n","        [0.0095, 0.9875]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3418, grad_fn=<NllLossBackward>)\n","epoch 1650, loss 0.3417784571647644\n","outputs:  tensor([[0.0645, 0.9010],\n","        [0.9419, 0.0828],\n","        [0.9329, 0.0948],\n","        [0.9956, 0.0095],\n","        [0.0095, 0.9875]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n","epoch 1651, loss 0.3417489528656006\n","Parameter containing:\n","tensor([[-0.2404, -0.5885,  0.1972],\n","        [-0.9641, -0.6688, -0.0758],\n","        [-0.9751, -0.8263, -0.1238],\n","        [-0.4341, -0.4422, -0.0026]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4877, -0.3050,  0.1438,  0.1175], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8217,  0.6972,  1.0618,  0.0939],\n","        [-0.1430, -0.8944, -0.7203, -0.5303]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3503, -0.5841], requires_grad=True)\n","outputs:  tensor([[0.0644, 0.9011],\n","        [0.9420, 0.0827],\n","        [0.9330, 0.0947],\n","        [0.9956, 0.0095],\n","        [0.0095, 0.9875]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n","epoch 1652, loss 0.34171953797340393\n","outputs:  tensor([[0.0643, 0.9012],\n","        [0.9420, 0.0826],\n","        [0.9331, 0.0947],\n","        [0.9956, 0.0094],\n","        [0.0095, 0.9875]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n","epoch 1653, loss 0.3416901230812073\n","outputs:  tensor([[0.0643, 0.9013],\n","        [0.9421, 0.0826],\n","        [0.9331, 0.0946],\n","        [0.9956, 0.0094],\n","        [0.0095, 0.9876]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3417, grad_fn=<NllLossBackward>)\n","epoch 1654, loss 0.34166088700294495\n","outputs:  tensor([[0.0642, 0.9014],\n","        [0.9421, 0.0825],\n","        [0.9332, 0.0945],\n","        [0.9956, 0.0094],\n","        [0.0094, 0.9876]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3416, grad_fn=<NllLossBackward>)\n","epoch 1655, loss 0.34163159132003784\n","outputs:  tensor([[0.0642, 0.9015],\n","        [0.9422, 0.0824],\n","        [0.9332, 0.0944],\n","        [0.9956, 0.0094],\n","        [0.0094, 0.9876]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3416, grad_fn=<NllLossBackward>)\n","epoch 1656, loss 0.3416023254394531\n","outputs:  tensor([[0.0641, 0.9016],\n","        [0.9422, 0.0823],\n","        [0.9333, 0.0943],\n","        [0.9956, 0.0094],\n","        [0.0094, 0.9876]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3416, grad_fn=<NllLossBackward>)\n","epoch 1657, loss 0.34157314896583557\n","outputs:  tensor([[0.0640, 0.9017],\n","        [0.9423, 0.0822],\n","        [0.9333, 0.0942],\n","        [0.9956, 0.0093],\n","        [0.0094, 0.9877]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3415, grad_fn=<NllLossBackward>)\n","epoch 1658, loss 0.3415440618991852\n","outputs:  tensor([[0.0640, 0.9018],\n","        [0.9424, 0.0822],\n","        [0.9334, 0.0942],\n","        [0.9956, 0.0093],\n","        [0.0094, 0.9877]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3415, grad_fn=<NllLossBackward>)\n","epoch 1659, loss 0.3415149748325348\n","outputs:  tensor([[0.0639, 0.9019],\n","        [0.9424, 0.0821],\n","        [0.9334, 0.0941],\n","        [0.9956, 0.0093],\n","        [0.0094, 0.9877]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3415, grad_fn=<NllLossBackward>)\n","epoch 1660, loss 0.3414859175682068\n","outputs:  tensor([[0.0639, 0.9020],\n","        [0.9425, 0.0820],\n","        [0.9335, 0.0940],\n","        [0.9956, 0.0093],\n","        [0.0094, 0.9877]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3415, grad_fn=<NllLossBackward>)\n","epoch 1661, loss 0.34145694971084595\n","outputs:  tensor([[0.0638, 0.9021],\n","        [0.9425, 0.0819],\n","        [0.9336, 0.0939],\n","        [0.9956, 0.0093],\n","        [0.0093, 0.9877]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3414, grad_fn=<NllLossBackward>)\n","epoch 1662, loss 0.3414279818534851\n","outputs:  tensor([[0.0637, 0.9022],\n","        [0.9426, 0.0818],\n","        [0.9336, 0.0938],\n","        [0.9956, 0.0093],\n","        [0.0093, 0.9878]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3414, grad_fn=<NllLossBackward>)\n","epoch 1663, loss 0.34139907360076904\n","outputs:  tensor([[0.0637, 0.9023],\n","        [0.9426, 0.0818],\n","        [0.9337, 0.0938],\n","        [0.9957, 0.0092],\n","        [0.0093, 0.9878]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3414, grad_fn=<NllLossBackward>)\n","epoch 1664, loss 0.34137025475502014\n","outputs:  tensor([[0.0636, 0.9024],\n","        [0.9427, 0.0817],\n","        [0.9337, 0.0937],\n","        [0.9957, 0.0092],\n","        [0.0093, 0.9878]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3413, grad_fn=<NllLossBackward>)\n","epoch 1665, loss 0.34134143590927124\n","outputs:  tensor([[0.0636, 0.9025],\n","        [0.9427, 0.0816],\n","        [0.9338, 0.0936],\n","        [0.9957, 0.0092],\n","        [0.0093, 0.9878]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3413, grad_fn=<NllLossBackward>)\n","epoch 1666, loss 0.3413127362728119\n","outputs:  tensor([[0.0635, 0.9026],\n","        [0.9428, 0.0815],\n","        [0.9338, 0.0935],\n","        [0.9957, 0.0092],\n","        [0.0093, 0.9879]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3413, grad_fn=<NllLossBackward>)\n","epoch 1667, loss 0.34128403663635254\n","outputs:  tensor([[0.0635, 0.9027],\n","        [0.9428, 0.0815],\n","        [0.9339, 0.0934],\n","        [0.9957, 0.0092],\n","        [0.0093, 0.9879]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3413, grad_fn=<NllLossBackward>)\n","epoch 1668, loss 0.3412553668022156\n","outputs:  tensor([[0.0634, 0.9028],\n","        [0.9429, 0.0814],\n","        [0.9339, 0.0933],\n","        [0.9957, 0.0091],\n","        [0.0092, 0.9879]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3412, grad_fn=<NllLossBackward>)\n","epoch 1669, loss 0.34122681617736816\n","outputs:  tensor([[0.0633, 0.9029],\n","        [0.9429, 0.0813],\n","        [0.9340, 0.0933],\n","        [0.9957, 0.0091],\n","        [0.0092, 0.9879]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3412, grad_fn=<NllLossBackward>)\n","epoch 1670, loss 0.34119823575019836\n","outputs:  tensor([[0.0633, 0.9030],\n","        [0.9430, 0.0812],\n","        [0.9340, 0.0932],\n","        [0.9957, 0.0091],\n","        [0.0092, 0.9879]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3412, grad_fn=<NllLossBackward>)\n","epoch 1671, loss 0.34116968512535095\n","outputs:  tensor([[0.0632, 0.9031],\n","        [0.9430, 0.0812],\n","        [0.9341, 0.0931],\n","        [0.9957, 0.0091],\n","        [0.0092, 0.9880]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3411, grad_fn=<NllLossBackward>)\n","epoch 1672, loss 0.3411412239074707\n","outputs:  tensor([[0.0632, 0.9032],\n","        [0.9431, 0.0811],\n","        [0.9342, 0.0930],\n","        [0.9957, 0.0091],\n","        [0.0092, 0.9880]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3411, grad_fn=<NllLossBackward>)\n","epoch 1673, loss 0.3411128520965576\n","outputs:  tensor([[0.0631, 0.9033],\n","        [0.9431, 0.0810],\n","        [0.9342, 0.0929],\n","        [0.9957, 0.0091],\n","        [0.0092, 0.9880]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3411, grad_fn=<NllLossBackward>)\n","epoch 1674, loss 0.34108448028564453\n","outputs:  tensor([[0.0630, 0.9034],\n","        [0.9432, 0.0809],\n","        [0.9343, 0.0929],\n","        [0.9957, 0.0090],\n","        [0.0092, 0.9880]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3411, grad_fn=<NllLossBackward>)\n","epoch 1675, loss 0.3410561978816986\n","outputs:  tensor([[0.0630, 0.9035],\n","        [0.9432, 0.0809],\n","        [0.9343, 0.0928],\n","        [0.9957, 0.0090],\n","        [0.0091, 0.9880]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3410, grad_fn=<NllLossBackward>)\n","epoch 1676, loss 0.3410279154777527\n","outputs:  tensor([[0.0629, 0.9035],\n","        [0.9433, 0.0808],\n","        [0.9344, 0.0927],\n","        [0.9958, 0.0090],\n","        [0.0091, 0.9881]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3410, grad_fn=<NllLossBackward>)\n","epoch 1677, loss 0.34099966287612915\n","outputs:  tensor([[0.0629, 0.9036],\n","        [0.9433, 0.0807],\n","        [0.9344, 0.0926],\n","        [0.9958, 0.0090],\n","        [0.0091, 0.9881]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3410, grad_fn=<NllLossBackward>)\n","epoch 1678, loss 0.34097152948379517\n","outputs:  tensor([[0.0628, 0.9037],\n","        [0.9434, 0.0806],\n","        [0.9345, 0.0925],\n","        [0.9958, 0.0090],\n","        [0.0091, 0.9881]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3409, grad_fn=<NllLossBackward>)\n","epoch 1679, loss 0.3409433960914612\n","outputs:  tensor([[0.0627, 0.9038],\n","        [0.9434, 0.0805],\n","        [0.9345, 0.0925],\n","        [0.9958, 0.0089],\n","        [0.0091, 0.9881]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3409, grad_fn=<NllLossBackward>)\n","epoch 1680, loss 0.3409152925014496\n","outputs:  tensor([[0.0627, 0.9039],\n","        [0.9435, 0.0805],\n","        [0.9346, 0.0924],\n","        [0.9958, 0.0089],\n","        [0.0091, 0.9882]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3409, grad_fn=<NllLossBackward>)\n","epoch 1681, loss 0.34088727831840515\n","outputs:  tensor([[0.0626, 0.9040],\n","        [0.9435, 0.0804],\n","        [0.9346, 0.0923],\n","        [0.9958, 0.0089],\n","        [0.0091, 0.9882]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3409, grad_fn=<NllLossBackward>)\n","epoch 1682, loss 0.3408592641353607\n","outputs:  tensor([[0.0626, 0.9041],\n","        [0.9436, 0.0803],\n","        [0.9347, 0.0922],\n","        [0.9958, 0.0089],\n","        [0.0090, 0.9882]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3408, grad_fn=<NllLossBackward>)\n","epoch 1683, loss 0.34083133935928345\n","outputs:  tensor([[0.0625, 0.9042],\n","        [0.9436, 0.0802],\n","        [0.9347, 0.0921],\n","        [0.9958, 0.0089],\n","        [0.0090, 0.9882]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3408, grad_fn=<NllLossBackward>)\n","epoch 1684, loss 0.3408035337924957\n","outputs:  tensor([[0.0625, 0.9043],\n","        [0.9437, 0.0802],\n","        [0.9348, 0.0921],\n","        [0.9958, 0.0089],\n","        [0.0090, 0.9882]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3408, grad_fn=<NllLossBackward>)\n","epoch 1685, loss 0.34077563881874084\n","outputs:  tensor([[0.0624, 0.9044],\n","        [0.9437, 0.0801],\n","        [0.9349, 0.0920],\n","        [0.9958, 0.0088],\n","        [0.0090, 0.9883]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3407, grad_fn=<NllLossBackward>)\n","epoch 1686, loss 0.34074780344963074\n","outputs:  tensor([[0.0623, 0.9045],\n","        [0.9438, 0.0800],\n","        [0.9349, 0.0919],\n","        [0.9958, 0.0088],\n","        [0.0090, 0.9883]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3407, grad_fn=<NllLossBackward>)\n","epoch 1687, loss 0.3407200872898102\n","outputs:  tensor([[0.0623, 0.9046],\n","        [0.9438, 0.0799],\n","        [0.9350, 0.0918],\n","        [0.9958, 0.0088],\n","        [0.0090, 0.9883]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3407, grad_fn=<NllLossBackward>)\n","epoch 1688, loss 0.340692400932312\n","outputs:  tensor([[0.0622, 0.9047],\n","        [0.9439, 0.0799],\n","        [0.9350, 0.0917],\n","        [0.9958, 0.0088],\n","        [0.0090, 0.9883]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3407, grad_fn=<NllLossBackward>)\n","epoch 1689, loss 0.34066468477249146\n","outputs:  tensor([[0.0622, 0.9048],\n","        [0.9439, 0.0798],\n","        [0.9351, 0.0917],\n","        [0.9958, 0.0088],\n","        [0.0089, 0.9883]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3406, grad_fn=<NllLossBackward>)\n","epoch 1690, loss 0.34063705801963806\n","outputs:  tensor([[0.0621, 0.9049],\n","        [0.9440, 0.0797],\n","        [0.9351, 0.0916],\n","        [0.9959, 0.0088],\n","        [0.0089, 0.9884]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3406, grad_fn=<NllLossBackward>)\n","epoch 1691, loss 0.3406095504760742\n","outputs:  tensor([[0.0621, 0.9050],\n","        [0.9440, 0.0796],\n","        [0.9352, 0.0915],\n","        [0.9959, 0.0087],\n","        [0.0089, 0.9884]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3406, grad_fn=<NllLossBackward>)\n","epoch 1692, loss 0.3405819535255432\n","outputs:  tensor([[0.0620, 0.9051],\n","        [0.9441, 0.0796],\n","        [0.9352, 0.0914],\n","        [0.9959, 0.0087],\n","        [0.0089, 0.9884]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3406, grad_fn=<NllLossBackward>)\n","epoch 1693, loss 0.34055453538894653\n","outputs:  tensor([[0.0619, 0.9052],\n","        [0.9441, 0.0795],\n","        [0.9353, 0.0913],\n","        [0.9959, 0.0087],\n","        [0.0089, 0.9884]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3405, grad_fn=<NllLossBackward>)\n","epoch 1694, loss 0.34052711725234985\n","outputs:  tensor([[0.0619, 0.9053],\n","        [0.9442, 0.0794],\n","        [0.9353, 0.0913],\n","        [0.9959, 0.0087],\n","        [0.0089, 0.9884]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3405, grad_fn=<NllLossBackward>)\n","epoch 1695, loss 0.3404996991157532\n","outputs:  tensor([[0.0618, 0.9054],\n","        [0.9442, 0.0794],\n","        [0.9354, 0.0912],\n","        [0.9959, 0.0087],\n","        [0.0089, 0.9885]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3405, grad_fn=<NllLossBackward>)\n","epoch 1696, loss 0.3404723107814789\n","outputs:  tensor([[0.0618, 0.9054],\n","        [0.9443, 0.0793],\n","        [0.9354, 0.0911],\n","        [0.9959, 0.0087],\n","        [0.0088, 0.9885]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3404, grad_fn=<NllLossBackward>)\n","epoch 1697, loss 0.34044498205184937\n","outputs:  tensor([[0.0617, 0.9055],\n","        [0.9443, 0.0792],\n","        [0.9355, 0.0910],\n","        [0.9959, 0.0086],\n","        [0.0088, 0.9885]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3404, grad_fn=<NllLossBackward>)\n","epoch 1698, loss 0.3404178023338318\n","outputs:  tensor([[0.0617, 0.9056],\n","        [0.9444, 0.0791],\n","        [0.9355, 0.0910],\n","        [0.9959, 0.0086],\n","        [0.0088, 0.9885]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3404, grad_fn=<NllLossBackward>)\n","epoch 1699, loss 0.34039053320884705\n","outputs:  tensor([[0.0616, 0.9057],\n","        [0.9444, 0.0791],\n","        [0.9356, 0.0909],\n","        [0.9959, 0.0086],\n","        [0.0088, 0.9885]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3404, grad_fn=<NllLossBackward>)\n","epoch 1700, loss 0.34036341309547424\n","outputs:  tensor([[0.0616, 0.9058],\n","        [0.9445, 0.0790],\n","        [0.9356, 0.0908],\n","        [0.9959, 0.0086],\n","        [0.0088, 0.9886]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3403, grad_fn=<NllLossBackward>)\n","epoch 1701, loss 0.34033626317977905\n","Parameter containing:\n","tensor([[-0.2434, -0.5935,  0.1971],\n","        [-0.9700, -0.6784, -0.0759],\n","        [-0.9813, -0.8365, -0.1239],\n","        [-0.4367, -0.4463, -0.0026]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4892, -0.3021,  0.1469,  0.1187], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8260,  0.7028,  1.0690,  0.0975],\n","        [-0.1491, -0.9026, -0.7305, -0.5355]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3518, -0.5861], requires_grad=True)\n","outputs:  tensor([[0.0615, 0.9059],\n","        [0.9445, 0.0789],\n","        [0.9357, 0.0907],\n","        [0.9959, 0.0086],\n","        [0.0088, 0.9886]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3403, grad_fn=<NllLossBackward>)\n","epoch 1702, loss 0.34030914306640625\n","outputs:  tensor([[0.0614, 0.9060],\n","        [0.9445, 0.0788],\n","        [0.9357, 0.0906],\n","        [0.9959, 0.0086],\n","        [0.0088, 0.9886]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3403, grad_fn=<NllLossBackward>)\n","epoch 1703, loss 0.340282142162323\n","outputs:  tensor([[0.0614, 0.9061],\n","        [0.9446, 0.0788],\n","        [0.9358, 0.0906],\n","        [0.9959, 0.0085],\n","        [0.0087, 0.9886]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3403, grad_fn=<NllLossBackward>)\n","epoch 1704, loss 0.3402552008628845\n","outputs:  tensor([[0.0613, 0.9062],\n","        [0.9446, 0.0787],\n","        [0.9359, 0.0905],\n","        [0.9960, 0.0085],\n","        [0.0087, 0.9886]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3402, grad_fn=<NllLossBackward>)\n","epoch 1705, loss 0.34022825956344604\n","outputs:  tensor([[0.0613, 0.9063],\n","        [0.9447, 0.0786],\n","        [0.9359, 0.0904],\n","        [0.9960, 0.0085],\n","        [0.0087, 0.9887]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3402, grad_fn=<NllLossBackward>)\n","epoch 1706, loss 0.34020131826400757\n","outputs:  tensor([[0.0612, 0.9064],\n","        [0.9447, 0.0785],\n","        [0.9360, 0.0903],\n","        [0.9960, 0.0085],\n","        [0.0087, 0.9887]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3402, grad_fn=<NllLossBackward>)\n","epoch 1707, loss 0.34017449617385864\n","outputs:  tensor([[0.0612, 0.9065],\n","        [0.9448, 0.0785],\n","        [0.9360, 0.0903],\n","        [0.9960, 0.0085],\n","        [0.0087, 0.9887]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3401, grad_fn=<NllLossBackward>)\n","epoch 1708, loss 0.34014764428138733\n","outputs:  tensor([[0.0611, 0.9066],\n","        [0.9448, 0.0784],\n","        [0.9361, 0.0902],\n","        [0.9960, 0.0085],\n","        [0.0087, 0.9887]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3401, grad_fn=<NllLossBackward>)\n","epoch 1709, loss 0.34012091159820557\n","outputs:  tensor([[0.0611, 0.9066],\n","        [0.9449, 0.0783],\n","        [0.9361, 0.0901],\n","        [0.9960, 0.0084],\n","        [0.0087, 0.9887]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3401, grad_fn=<NllLossBackward>)\n","epoch 1710, loss 0.3400941789150238\n","outputs:  tensor([[0.0610, 0.9067],\n","        [0.9449, 0.0783],\n","        [0.9362, 0.0900],\n","        [0.9960, 0.0084],\n","        [0.0087, 0.9888]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3401, grad_fn=<NllLossBackward>)\n","epoch 1711, loss 0.34006747603416443\n","outputs:  tensor([[0.0609, 0.9068],\n","        [0.9450, 0.0782],\n","        [0.9362, 0.0899],\n","        [0.9960, 0.0084],\n","        [0.0086, 0.9888]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3400, grad_fn=<NllLossBackward>)\n","epoch 1712, loss 0.340040922164917\n","outputs:  tensor([[0.0609, 0.9069],\n","        [0.9450, 0.0781],\n","        [0.9363, 0.0899],\n","        [0.9960, 0.0084],\n","        [0.0086, 0.9888]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3400, grad_fn=<NllLossBackward>)\n","epoch 1713, loss 0.34001424908638\n","outputs:  tensor([[0.0608, 0.9070],\n","        [0.9451, 0.0780],\n","        [0.9363, 0.0898],\n","        [0.9960, 0.0084],\n","        [0.0086, 0.9888]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3400, grad_fn=<NllLossBackward>)\n","epoch 1714, loss 0.3399876356124878\n","outputs:  tensor([[0.0608, 0.9071],\n","        [0.9451, 0.0780],\n","        [0.9364, 0.0897],\n","        [0.9960, 0.0084],\n","        [0.0086, 0.9888]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3400, grad_fn=<NllLossBackward>)\n","epoch 1715, loss 0.3399612009525299\n","outputs:  tensor([[0.0607, 0.9072],\n","        [0.9452, 0.0779],\n","        [0.9364, 0.0896],\n","        [0.9960, 0.0083],\n","        [0.0086, 0.9889]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3399, grad_fn=<NllLossBackward>)\n","epoch 1716, loss 0.33993473649024963\n","outputs:  tensor([[0.0607, 0.9073],\n","        [0.9452, 0.0778],\n","        [0.9365, 0.0896],\n","        [0.9960, 0.0083],\n","        [0.0086, 0.9889]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3399, grad_fn=<NllLossBackward>)\n","epoch 1717, loss 0.33990830183029175\n","outputs:  tensor([[0.0606, 0.9074],\n","        [0.9453, 0.0778],\n","        [0.9365, 0.0895],\n","        [0.9960, 0.0083],\n","        [0.0086, 0.9889]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3399, grad_fn=<NllLossBackward>)\n","epoch 1718, loss 0.339881956577301\n","outputs:  tensor([[0.0606, 0.9075],\n","        [0.9453, 0.0777],\n","        [0.9366, 0.0894],\n","        [0.9961, 0.0083],\n","        [0.0085, 0.9889]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3399, grad_fn=<NllLossBackward>)\n","epoch 1719, loss 0.3398556113243103\n","outputs:  tensor([[0.0605, 0.9076],\n","        [0.9454, 0.0776],\n","        [0.9366, 0.0893],\n","        [0.9961, 0.0083],\n","        [0.0085, 0.9889]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3398, grad_fn=<NllLossBackward>)\n","epoch 1720, loss 0.33982932567596436\n","outputs:  tensor([[0.0604, 0.9076],\n","        [0.9454, 0.0775],\n","        [0.9367, 0.0893],\n","        [0.9961, 0.0083],\n","        [0.0085, 0.9890]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3398, grad_fn=<NllLossBackward>)\n","epoch 1721, loss 0.3398030400276184\n","outputs:  tensor([[0.0604, 0.9077],\n","        [0.9455, 0.0775],\n","        [0.9367, 0.0892],\n","        [0.9961, 0.0083],\n","        [0.0085, 0.9890]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3398, grad_fn=<NllLossBackward>)\n","epoch 1722, loss 0.339776873588562\n","outputs:  tensor([[0.0603, 0.9078],\n","        [0.9455, 0.0774],\n","        [0.9368, 0.0891],\n","        [0.9961, 0.0082],\n","        [0.0085, 0.9890]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3398, grad_fn=<NllLossBackward>)\n","epoch 1723, loss 0.33975061774253845\n","outputs:  tensor([[0.0603, 0.9079],\n","        [0.9455, 0.0773],\n","        [0.9368, 0.0890],\n","        [0.9961, 0.0082],\n","        [0.0085, 0.9890]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3397, grad_fn=<NllLossBackward>)\n","epoch 1724, loss 0.3397245407104492\n","outputs:  tensor([[0.0602, 0.9080],\n","        [0.9456, 0.0773],\n","        [0.9369, 0.0890],\n","        [0.9961, 0.0082],\n","        [0.0085, 0.9890]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3397, grad_fn=<NllLossBackward>)\n","epoch 1725, loss 0.33969846367836\n","outputs:  tensor([[0.0602, 0.9081],\n","        [0.9456, 0.0772],\n","        [0.9369, 0.0889],\n","        [0.9961, 0.0082],\n","        [0.0085, 0.9891]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3397, grad_fn=<NllLossBackward>)\n","epoch 1726, loss 0.3396724462509155\n","outputs:  tensor([[0.0601, 0.9082],\n","        [0.9457, 0.0771],\n","        [0.9370, 0.0888],\n","        [0.9961, 0.0082],\n","        [0.0084, 0.9891]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3396, grad_fn=<NllLossBackward>)\n","epoch 1727, loss 0.3396463990211487\n","outputs:  tensor([[0.0601, 0.9083],\n","        [0.9457, 0.0770],\n","        [0.9370, 0.0887],\n","        [0.9961, 0.0082],\n","        [0.0084, 0.9891]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3396, grad_fn=<NllLossBackward>)\n","epoch 1728, loss 0.3396204710006714\n","outputs:  tensor([[0.0600, 0.9084],\n","        [0.9458, 0.0770],\n","        [0.9371, 0.0887],\n","        [0.9961, 0.0081],\n","        [0.0084, 0.9891]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3396, grad_fn=<NllLossBackward>)\n","epoch 1729, loss 0.33959460258483887\n","outputs:  tensor([[0.0600, 0.9084],\n","        [0.9458, 0.0769],\n","        [0.9371, 0.0886],\n","        [0.9961, 0.0081],\n","        [0.0084, 0.9891]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3396, grad_fn=<NllLossBackward>)\n","epoch 1730, loss 0.3395686745643616\n","outputs:  tensor([[0.0599, 0.9085],\n","        [0.9459, 0.0768],\n","        [0.9372, 0.0885],\n","        [0.9961, 0.0081],\n","        [0.0084, 0.9891]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3395, grad_fn=<NllLossBackward>)\n","epoch 1731, loss 0.3395429253578186\n","outputs:  tensor([[0.0599, 0.9086],\n","        [0.9459, 0.0768],\n","        [0.9372, 0.0884],\n","        [0.9961, 0.0081],\n","        [0.0084, 0.9892]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3395, grad_fn=<NllLossBackward>)\n","epoch 1732, loss 0.33951708674430847\n","outputs:  tensor([[0.0598, 0.9087],\n","        [0.9460, 0.0767],\n","        [0.9373, 0.0884],\n","        [0.9961, 0.0081],\n","        [0.0084, 0.9892]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3395, grad_fn=<NllLossBackward>)\n","epoch 1733, loss 0.3394912779331207\n","outputs:  tensor([[0.0597, 0.9088],\n","        [0.9460, 0.0766],\n","        [0.9373, 0.0883],\n","        [0.9962, 0.0081],\n","        [0.0084, 0.9892]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3395, grad_fn=<NllLossBackward>)\n","epoch 1734, loss 0.3394656479358673\n","outputs:  tensor([[0.0597, 0.9089],\n","        [0.9461, 0.0765],\n","        [0.9374, 0.0882],\n","        [0.9962, 0.0081],\n","        [0.0083, 0.9892]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3394, grad_fn=<NllLossBackward>)\n","epoch 1735, loss 0.3394399583339691\n","outputs:  tensor([[0.0596, 0.9090],\n","        [0.9461, 0.0765],\n","        [0.9374, 0.0881],\n","        [0.9962, 0.0080],\n","        [0.0083, 0.9892]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3394, grad_fn=<NllLossBackward>)\n","epoch 1736, loss 0.3394143581390381\n","outputs:  tensor([[0.0596, 0.9091],\n","        [0.9462, 0.0764],\n","        [0.9375, 0.0881],\n","        [0.9962, 0.0080],\n","        [0.0083, 0.9893]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3394, grad_fn=<NllLossBackward>)\n","epoch 1737, loss 0.33938875794410706\n","outputs:  tensor([[0.0595, 0.9092],\n","        [0.9462, 0.0763],\n","        [0.9375, 0.0880],\n","        [0.9962, 0.0080],\n","        [0.0083, 0.9893]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3394, grad_fn=<NllLossBackward>)\n","epoch 1738, loss 0.3393632471561432\n","outputs:  tensor([[0.0595, 0.9092],\n","        [0.9462, 0.0763],\n","        [0.9376, 0.0879],\n","        [0.9962, 0.0080],\n","        [0.0083, 0.9893]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3393, grad_fn=<NllLossBackward>)\n","epoch 1739, loss 0.3393377661705017\n","outputs:  tensor([[0.0594, 0.9093],\n","        [0.9463, 0.0762],\n","        [0.9376, 0.0878],\n","        [0.9962, 0.0080],\n","        [0.0083, 0.9893]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3393, grad_fn=<NllLossBackward>)\n","epoch 1740, loss 0.33931225538253784\n","outputs:  tensor([[0.0594, 0.9094],\n","        [0.9463, 0.0761],\n","        [0.9377, 0.0878],\n","        [0.9962, 0.0080],\n","        [0.0083, 0.9893]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3393, grad_fn=<NllLossBackward>)\n","epoch 1741, loss 0.3392868936061859\n","outputs:  tensor([[0.0593, 0.9095],\n","        [0.9464, 0.0761],\n","        [0.9377, 0.0877],\n","        [0.9962, 0.0080],\n","        [0.0083, 0.9893]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3393, grad_fn=<NllLossBackward>)\n","epoch 1742, loss 0.3392614722251892\n","outputs:  tensor([[0.0593, 0.9096],\n","        [0.9464, 0.0760],\n","        [0.9378, 0.0876],\n","        [0.9962, 0.0079],\n","        [0.0082, 0.9894]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3392, grad_fn=<NllLossBackward>)\n","epoch 1743, loss 0.3392361104488373\n","outputs:  tensor([[0.0592, 0.9097],\n","        [0.9465, 0.0759],\n","        [0.9378, 0.0875],\n","        [0.9962, 0.0079],\n","        [0.0082, 0.9894]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3392, grad_fn=<NllLossBackward>)\n","epoch 1744, loss 0.3392108976840973\n","outputs:  tensor([[0.0592, 0.9098],\n","        [0.9465, 0.0759],\n","        [0.9379, 0.0875],\n","        [0.9962, 0.0079],\n","        [0.0082, 0.9894]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3392, grad_fn=<NllLossBackward>)\n","epoch 1745, loss 0.3391856253147125\n","outputs:  tensor([[0.0591, 0.9099],\n","        [0.9466, 0.0758],\n","        [0.9379, 0.0874],\n","        [0.9962, 0.0079],\n","        [0.0082, 0.9894]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3392, grad_fn=<NllLossBackward>)\n","epoch 1746, loss 0.33916038274765015\n","outputs:  tensor([[0.0591, 0.9099],\n","        [0.9466, 0.0757],\n","        [0.9380, 0.0873],\n","        [0.9962, 0.0079],\n","        [0.0082, 0.9894]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3391, grad_fn=<NllLossBackward>)\n","epoch 1747, loss 0.33913522958755493\n","outputs:  tensor([[0.0590, 0.9100],\n","        [0.9467, 0.0756],\n","        [0.9380, 0.0872],\n","        [0.9962, 0.0079],\n","        [0.0082, 0.9895]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3391, grad_fn=<NllLossBackward>)\n","epoch 1748, loss 0.3391100764274597\n","outputs:  tensor([[0.0590, 0.9101],\n","        [0.9467, 0.0756],\n","        [0.9381, 0.0872],\n","        [0.9962, 0.0078],\n","        [0.0082, 0.9895]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3391, grad_fn=<NllLossBackward>)\n","epoch 1749, loss 0.3390849530696869\n","outputs:  tensor([[0.0589, 0.9102],\n","        [0.9467, 0.0755],\n","        [0.9381, 0.0871],\n","        [0.9963, 0.0078],\n","        [0.0082, 0.9895]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3391, grad_fn=<NllLossBackward>)\n","epoch 1750, loss 0.339059978723526\n","outputs:  tensor([[0.0589, 0.9103],\n","        [0.9468, 0.0754],\n","        [0.9382, 0.0870],\n","        [0.9963, 0.0078],\n","        [0.0081, 0.9895]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3390, grad_fn=<NllLossBackward>)\n","epoch 1751, loss 0.33903494477272034\n","Parameter containing:\n","tensor([[-0.2464, -0.5983,  0.1970],\n","        [-0.9756, -0.6877, -0.0759],\n","        [-0.9872, -0.8462, -0.1240],\n","        [-0.4391, -0.4503, -0.0025]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4908, -0.2993,  0.1499,  0.1199], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8301,  0.7083,  1.0758,  0.1010],\n","        [-0.1550, -0.9104, -0.7403, -0.5404]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3533, -0.5881], requires_grad=True)\n","outputs:  tensor([[0.0588, 0.9104],\n","        [0.9468, 0.0754],\n","        [0.9382, 0.0870],\n","        [0.9963, 0.0078],\n","        [0.0081, 0.9895]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3390, grad_fn=<NllLossBackward>)\n","epoch 1752, loss 0.33900997042655945\n","outputs:  tensor([[0.0587, 0.9105],\n","        [0.9469, 0.0753],\n","        [0.9383, 0.0869],\n","        [0.9963, 0.0078],\n","        [0.0081, 0.9895]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3390, grad_fn=<NllLossBackward>)\n","epoch 1753, loss 0.33898502588272095\n","outputs:  tensor([[0.0587, 0.9105],\n","        [0.9469, 0.0752],\n","        [0.9383, 0.0868],\n","        [0.9963, 0.0078],\n","        [0.0081, 0.9896]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3390, grad_fn=<NllLossBackward>)\n","epoch 1754, loss 0.3389601707458496\n","outputs:  tensor([[0.0586, 0.9106],\n","        [0.9470, 0.0752],\n","        [0.9384, 0.0867],\n","        [0.9963, 0.0078],\n","        [0.0081, 0.9896]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3389, grad_fn=<NllLossBackward>)\n","epoch 1755, loss 0.3389352858066559\n","outputs:  tensor([[0.0586, 0.9107],\n","        [0.9470, 0.0751],\n","        [0.9384, 0.0867],\n","        [0.9963, 0.0077],\n","        [0.0081, 0.9896]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3389, grad_fn=<NllLossBackward>)\n","epoch 1756, loss 0.3389104902744293\n","outputs:  tensor([[0.0585, 0.9108],\n","        [0.9471, 0.0750],\n","        [0.9385, 0.0866],\n","        [0.9963, 0.0077],\n","        [0.0081, 0.9896]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3389, grad_fn=<NllLossBackward>)\n","epoch 1757, loss 0.338885635137558\n","outputs:  tensor([[0.0585, 0.9109],\n","        [0.9471, 0.0750],\n","        [0.9385, 0.0865],\n","        [0.9963, 0.0077],\n","        [0.0081, 0.9896]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3389, grad_fn=<NllLossBackward>)\n","epoch 1758, loss 0.3388609290122986\n","outputs:  tensor([[0.0584, 0.9110],\n","        [0.9472, 0.0749],\n","        [0.9386, 0.0865],\n","        [0.9963, 0.0077],\n","        [0.0080, 0.9896]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3388, grad_fn=<NllLossBackward>)\n","epoch 1759, loss 0.33883628249168396\n","outputs:  tensor([[0.0584, 0.9111],\n","        [0.9472, 0.0748],\n","        [0.9386, 0.0864],\n","        [0.9963, 0.0077],\n","        [0.0080, 0.9897]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3388, grad_fn=<NllLossBackward>)\n","epoch 1760, loss 0.33881157636642456\n","outputs:  tensor([[0.0583, 0.9111],\n","        [0.9472, 0.0748],\n","        [0.9386, 0.0863],\n","        [0.9963, 0.0077],\n","        [0.0080, 0.9897]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3388, grad_fn=<NllLossBackward>)\n","epoch 1761, loss 0.3387869894504547\n","outputs:  tensor([[0.0583, 0.9112],\n","        [0.9473, 0.0747],\n","        [0.9387, 0.0862],\n","        [0.9963, 0.0077],\n","        [0.0080, 0.9897]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3388, grad_fn=<NllLossBackward>)\n","epoch 1762, loss 0.3387623727321625\n","outputs:  tensor([[0.0582, 0.9113],\n","        [0.9473, 0.0746],\n","        [0.9387, 0.0862],\n","        [0.9963, 0.0076],\n","        [0.0080, 0.9897]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3387, grad_fn=<NllLossBackward>)\n","epoch 1763, loss 0.3387378454208374\n","outputs:  tensor([[0.0582, 0.9114],\n","        [0.9474, 0.0746],\n","        [0.9388, 0.0861],\n","        [0.9963, 0.0076],\n","        [0.0080, 0.9897]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3387, grad_fn=<NllLossBackward>)\n","epoch 1764, loss 0.3387133777141571\n","outputs:  tensor([[0.0581, 0.9115],\n","        [0.9474, 0.0745],\n","        [0.9388, 0.0860],\n","        [0.9963, 0.0076],\n","        [0.0080, 0.9898]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3387, grad_fn=<NllLossBackward>)\n","epoch 1765, loss 0.3386889100074768\n","outputs:  tensor([[0.0581, 0.9116],\n","        [0.9475, 0.0744],\n","        [0.9389, 0.0859],\n","        [0.9964, 0.0076],\n","        [0.0080, 0.9898]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3387, grad_fn=<NllLossBackward>)\n","epoch 1766, loss 0.3386644721031189\n","outputs:  tensor([[0.0580, 0.9116],\n","        [0.9475, 0.0744],\n","        [0.9389, 0.0859],\n","        [0.9964, 0.0076],\n","        [0.0080, 0.9898]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3386, grad_fn=<NllLossBackward>)\n","epoch 1767, loss 0.33864009380340576\n","outputs:  tensor([[0.0580, 0.9117],\n","        [0.9476, 0.0743],\n","        [0.9390, 0.0858],\n","        [0.9964, 0.0076],\n","        [0.0079, 0.9898]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3386, grad_fn=<NllLossBackward>)\n","epoch 1768, loss 0.338615745306015\n","outputs:  tensor([[0.0579, 0.9118],\n","        [0.9476, 0.0742],\n","        [0.9390, 0.0857],\n","        [0.9964, 0.0076],\n","        [0.0079, 0.9898]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3386, grad_fn=<NllLossBackward>)\n","epoch 1769, loss 0.33859142661094666\n","outputs:  tensor([[0.0579, 0.9119],\n","        [0.9476, 0.0742],\n","        [0.9391, 0.0857],\n","        [0.9964, 0.0075],\n","        [0.0079, 0.9898]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3386, grad_fn=<NllLossBackward>)\n","epoch 1770, loss 0.33856716752052307\n","outputs:  tensor([[0.0578, 0.9120],\n","        [0.9477, 0.0741],\n","        [0.9391, 0.0856],\n","        [0.9964, 0.0075],\n","        [0.0079, 0.9899]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3385, grad_fn=<NllLossBackward>)\n","epoch 1771, loss 0.3385429382324219\n","outputs:  tensor([[0.0578, 0.9121],\n","        [0.9477, 0.0740],\n","        [0.9392, 0.0855],\n","        [0.9964, 0.0075],\n","        [0.0079, 0.9899]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3385, grad_fn=<NllLossBackward>)\n","epoch 1772, loss 0.33851873874664307\n","outputs:  tensor([[0.0577, 0.9121],\n","        [0.9478, 0.0740],\n","        [0.9392, 0.0855],\n","        [0.9964, 0.0075],\n","        [0.0079, 0.9899]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3385, grad_fn=<NllLossBackward>)\n","epoch 1773, loss 0.33849459886550903\n","outputs:  tensor([[0.0577, 0.9122],\n","        [0.9478, 0.0739],\n","        [0.9393, 0.0854],\n","        [0.9964, 0.0075],\n","        [0.0079, 0.9899]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3385, grad_fn=<NllLossBackward>)\n","epoch 1774, loss 0.33847054839134216\n","outputs:  tensor([[0.0576, 0.9123],\n","        [0.9479, 0.0738],\n","        [0.9393, 0.0853],\n","        [0.9964, 0.0075],\n","        [0.0079, 0.9899]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3384, grad_fn=<NllLossBackward>)\n","epoch 1775, loss 0.33844637870788574\n","outputs:  tensor([[0.0576, 0.9124],\n","        [0.9479, 0.0738],\n","        [0.9394, 0.0852],\n","        [0.9964, 0.0075],\n","        [0.0078, 0.9899]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3384, grad_fn=<NllLossBackward>)\n","epoch 1776, loss 0.33842238783836365\n","outputs:  tensor([[0.0575, 0.9125],\n","        [0.9479, 0.0737],\n","        [0.9394, 0.0852],\n","        [0.9964, 0.0075],\n","        [0.0078, 0.9900]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3384, grad_fn=<NllLossBackward>)\n","epoch 1777, loss 0.33839839696884155\n","outputs:  tensor([[0.0575, 0.9126],\n","        [0.9480, 0.0736],\n","        [0.9395, 0.0851],\n","        [0.9964, 0.0074],\n","        [0.0078, 0.9900]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3384, grad_fn=<NllLossBackward>)\n","epoch 1778, loss 0.33837443590164185\n","outputs:  tensor([[0.0574, 0.9126],\n","        [0.9480, 0.0736],\n","        [0.9395, 0.0850],\n","        [0.9964, 0.0074],\n","        [0.0078, 0.9900]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3384, grad_fn=<NllLossBackward>)\n","epoch 1779, loss 0.33835044503211975\n","outputs:  tensor([[0.0574, 0.9127],\n","        [0.9481, 0.0735],\n","        [0.9395, 0.0850],\n","        [0.9964, 0.0074],\n","        [0.0078, 0.9900]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3383, grad_fn=<NllLossBackward>)\n","epoch 1780, loss 0.3383265435695648\n","outputs:  tensor([[0.0573, 0.9128],\n","        [0.9481, 0.0734],\n","        [0.9396, 0.0849],\n","        [0.9964, 0.0074],\n","        [0.0078, 0.9900]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3383, grad_fn=<NllLossBackward>)\n","epoch 1781, loss 0.33830276131629944\n","outputs:  tensor([[0.0573, 0.9129],\n","        [0.9482, 0.0734],\n","        [0.9396, 0.0848],\n","        [0.9964, 0.0074],\n","        [0.0078, 0.9900]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3383, grad_fn=<NllLossBackward>)\n","epoch 1782, loss 0.3382789194583893\n","outputs:  tensor([[0.0572, 0.9130],\n","        [0.9482, 0.0733],\n","        [0.9397, 0.0847],\n","        [0.9965, 0.0074],\n","        [0.0078, 0.9901]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3383, grad_fn=<NllLossBackward>)\n","epoch 1783, loss 0.3382551074028015\n","outputs:  tensor([[0.0572, 0.9131],\n","        [0.9483, 0.0732],\n","        [0.9397, 0.0847],\n","        [0.9965, 0.0074],\n","        [0.0078, 0.9901]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3382, grad_fn=<NllLossBackward>)\n","epoch 1784, loss 0.3382314145565033\n","outputs:  tensor([[0.0571, 0.9131],\n","        [0.9483, 0.0732],\n","        [0.9398, 0.0846],\n","        [0.9965, 0.0073],\n","        [0.0077, 0.9901]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3382, grad_fn=<NllLossBackward>)\n","epoch 1785, loss 0.3382076919078827\n","outputs:  tensor([[0.0571, 0.9132],\n","        [0.9483, 0.0731],\n","        [0.9398, 0.0845],\n","        [0.9965, 0.0073],\n","        [0.0077, 0.9901]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3382, grad_fn=<NllLossBackward>)\n","epoch 1786, loss 0.33818402886390686\n","outputs:  tensor([[0.0570, 0.9133],\n","        [0.9484, 0.0730],\n","        [0.9399, 0.0845],\n","        [0.9965, 0.0073],\n","        [0.0077, 0.9901]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3382, grad_fn=<NllLossBackward>)\n","epoch 1787, loss 0.33816036581993103\n","outputs:  tensor([[0.0570, 0.9134],\n","        [0.9484, 0.0730],\n","        [0.9399, 0.0844],\n","        [0.9965, 0.0073],\n","        [0.0077, 0.9901]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3381, grad_fn=<NllLossBackward>)\n","epoch 1788, loss 0.33813682198524475\n","outputs:  tensor([[0.0569, 0.9135],\n","        [0.9485, 0.0729],\n","        [0.9400, 0.0843],\n","        [0.9965, 0.0073],\n","        [0.0077, 0.9902]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3381, grad_fn=<NllLossBackward>)\n","epoch 1789, loss 0.3381132483482361\n","outputs:  tensor([[0.0569, 0.9135],\n","        [0.9485, 0.0729],\n","        [0.9400, 0.0843],\n","        [0.9965, 0.0073],\n","        [0.0077, 0.9902]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3381, grad_fn=<NllLossBackward>)\n","epoch 1790, loss 0.3380897045135498\n","outputs:  tensor([[0.0568, 0.9136],\n","        [0.9486, 0.0728],\n","        [0.9401, 0.0842],\n","        [0.9965, 0.0073],\n","        [0.0077, 0.9902]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3381, grad_fn=<NllLossBackward>)\n","epoch 1791, loss 0.3380662500858307\n","outputs:  tensor([[0.0568, 0.9137],\n","        [0.9486, 0.0727],\n","        [0.9401, 0.0841],\n","        [0.9965, 0.0072],\n","        [0.0077, 0.9902]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3380, grad_fn=<NllLossBackward>)\n","epoch 1792, loss 0.3380427956581116\n","outputs:  tensor([[0.0567, 0.9138],\n","        [0.9486, 0.0727],\n","        [0.9402, 0.0841],\n","        [0.9965, 0.0072],\n","        [0.0077, 0.9902]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3380, grad_fn=<NllLossBackward>)\n","epoch 1793, loss 0.33801940083503723\n","outputs:  tensor([[0.0567, 0.9139],\n","        [0.9487, 0.0726],\n","        [0.9402, 0.0840],\n","        [0.9965, 0.0072],\n","        [0.0076, 0.9902]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3380, grad_fn=<NllLossBackward>)\n","epoch 1794, loss 0.3379960060119629\n","outputs:  tensor([[0.0566, 0.9139],\n","        [0.9487, 0.0725],\n","        [0.9402, 0.0839],\n","        [0.9965, 0.0072],\n","        [0.0076, 0.9903]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3380, grad_fn=<NllLossBackward>)\n","epoch 1795, loss 0.3379727005958557\n","outputs:  tensor([[0.0566, 0.9140],\n","        [0.9488, 0.0725],\n","        [0.9403, 0.0838],\n","        [0.9965, 0.0072],\n","        [0.0076, 0.9903]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3379, grad_fn=<NllLossBackward>)\n","epoch 1796, loss 0.33794933557510376\n","outputs:  tensor([[0.0565, 0.9141],\n","        [0.9488, 0.0724],\n","        [0.9403, 0.0838],\n","        [0.9965, 0.0072],\n","        [0.0076, 0.9903]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3379, grad_fn=<NllLossBackward>)\n","epoch 1797, loss 0.33792614936828613\n","outputs:  tensor([[0.0565, 0.9142],\n","        [0.9488, 0.0723],\n","        [0.9404, 0.0837],\n","        [0.9965, 0.0072],\n","        [0.0076, 0.9903]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3379, grad_fn=<NllLossBackward>)\n","epoch 1798, loss 0.33790284395217896\n","outputs:  tensor([[0.0564, 0.9143],\n","        [0.9489, 0.0723],\n","        [0.9404, 0.0836],\n","        [0.9965, 0.0072],\n","        [0.0076, 0.9903]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3379, grad_fn=<NllLossBackward>)\n","epoch 1799, loss 0.3378797173500061\n","outputs:  tensor([[0.0564, 0.9143],\n","        [0.9489, 0.0722],\n","        [0.9405, 0.0836],\n","        [0.9966, 0.0071],\n","        [0.0076, 0.9903]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3379, grad_fn=<NllLossBackward>)\n","epoch 1800, loss 0.33785659074783325\n","outputs:  tensor([[0.0563, 0.9144],\n","        [0.9490, 0.0721],\n","        [0.9405, 0.0835],\n","        [0.9966, 0.0071],\n","        [0.0076, 0.9903]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3378, grad_fn=<NllLossBackward>)\n","epoch 1801, loss 0.3378334641456604\n","Parameter containing:\n","tensor([[-0.2492, -0.6030,  0.1969],\n","        [-0.9810, -0.6965, -0.0759],\n","        [-0.9929, -0.8557, -0.1240],\n","        [-0.4415, -0.4542, -0.0025]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4922, -0.2966,  0.1528,  0.1211], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8341,  0.7135,  1.0824,  0.1043],\n","        [-0.1607, -0.9179, -0.7497, -0.5452]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3547, -0.5899], requires_grad=True)\n","outputs:  tensor([[0.0563, 0.9145],\n","        [0.9490, 0.0721],\n","        [0.9406, 0.0834],\n","        [0.9966, 0.0071],\n","        [0.0076, 0.9904]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3378, grad_fn=<NllLossBackward>)\n","epoch 1802, loss 0.33781036734580994\n","outputs:  tensor([[0.0562, 0.9146],\n","        [0.9491, 0.0720],\n","        [0.9406, 0.0834],\n","        [0.9966, 0.0071],\n","        [0.0075, 0.9904]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3378, grad_fn=<NllLossBackward>)\n","epoch 1803, loss 0.33778733015060425\n","outputs:  tensor([[0.0562, 0.9147],\n","        [0.9491, 0.0720],\n","        [0.9407, 0.0833],\n","        [0.9966, 0.0071],\n","        [0.0075, 0.9904]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3378, grad_fn=<NllLossBackward>)\n","epoch 1804, loss 0.33776426315307617\n","outputs:  tensor([[0.0562, 0.9147],\n","        [0.9491, 0.0719],\n","        [0.9407, 0.0832],\n","        [0.9966, 0.0071],\n","        [0.0075, 0.9904]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3377, grad_fn=<NllLossBackward>)\n","epoch 1805, loss 0.33774131536483765\n","outputs:  tensor([[0.0561, 0.9148],\n","        [0.9492, 0.0718],\n","        [0.9407, 0.0832],\n","        [0.9966, 0.0071],\n","        [0.0075, 0.9904]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3377, grad_fn=<NllLossBackward>)\n","epoch 1806, loss 0.3377183675765991\n","outputs:  tensor([[0.0561, 0.9149],\n","        [0.9492, 0.0718],\n","        [0.9408, 0.0831],\n","        [0.9966, 0.0071],\n","        [0.0075, 0.9904]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3377, grad_fn=<NllLossBackward>)\n","epoch 1807, loss 0.337695449590683\n","outputs:  tensor([[0.0560, 0.9150],\n","        [0.9493, 0.0717],\n","        [0.9408, 0.0830],\n","        [0.9966, 0.0070],\n","        [0.0075, 0.9905]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3377, grad_fn=<NllLossBackward>)\n","epoch 1808, loss 0.3376726508140564\n","outputs:  tensor([[0.0560, 0.9151],\n","        [0.9493, 0.0716],\n","        [0.9409, 0.0830],\n","        [0.9966, 0.0070],\n","        [0.0075, 0.9905]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3376, grad_fn=<NllLossBackward>)\n","epoch 1809, loss 0.33764976263046265\n","outputs:  tensor([[0.0559, 0.9151],\n","        [0.9494, 0.0716],\n","        [0.9409, 0.0829],\n","        [0.9966, 0.0070],\n","        [0.0075, 0.9905]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3376, grad_fn=<NllLossBackward>)\n","epoch 1810, loss 0.33762699365615845\n","outputs:  tensor([[0.0559, 0.9152],\n","        [0.9494, 0.0715],\n","        [0.9410, 0.0828],\n","        [0.9966, 0.0070],\n","        [0.0075, 0.9905]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3376, grad_fn=<NllLossBackward>)\n","epoch 1811, loss 0.33760419487953186\n","outputs:  tensor([[0.0558, 0.9153],\n","        [0.9494, 0.0714],\n","        [0.9410, 0.0828],\n","        [0.9966, 0.0070],\n","        [0.0074, 0.9905]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3376, grad_fn=<NllLossBackward>)\n","epoch 1812, loss 0.3375815153121948\n","outputs:  tensor([[0.0558, 0.9154],\n","        [0.9495, 0.0714],\n","        [0.9411, 0.0827],\n","        [0.9966, 0.0070],\n","        [0.0074, 0.9905]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3376, grad_fn=<NllLossBackward>)\n","epoch 1813, loss 0.3375588059425354\n","outputs:  tensor([[0.0557, 0.9155],\n","        [0.9495, 0.0713],\n","        [0.9411, 0.0826],\n","        [0.9966, 0.0070],\n","        [0.0074, 0.9906]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3375, grad_fn=<NllLossBackward>)\n","epoch 1814, loss 0.33753615617752075\n","outputs:  tensor([[0.0557, 0.9155],\n","        [0.9496, 0.0713],\n","        [0.9412, 0.0826],\n","        [0.9966, 0.0070],\n","        [0.0074, 0.9906]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3375, grad_fn=<NllLossBackward>)\n","epoch 1815, loss 0.3375135064125061\n","outputs:  tensor([[0.0556, 0.9156],\n","        [0.9496, 0.0712],\n","        [0.9412, 0.0825],\n","        [0.9966, 0.0069],\n","        [0.0074, 0.9906]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3375, grad_fn=<NllLossBackward>)\n","epoch 1816, loss 0.33749091625213623\n","outputs:  tensor([[0.0556, 0.9157],\n","        [0.9496, 0.0711],\n","        [0.9412, 0.0824],\n","        [0.9966, 0.0069],\n","        [0.0074, 0.9906]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3375, grad_fn=<NllLossBackward>)\n","epoch 1817, loss 0.33746832609176636\n","outputs:  tensor([[0.0555, 0.9158],\n","        [0.9497, 0.0711],\n","        [0.9413, 0.0824],\n","        [0.9967, 0.0069],\n","        [0.0074, 0.9906]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3374, grad_fn=<NllLossBackward>)\n","epoch 1818, loss 0.33744582533836365\n","outputs:  tensor([[0.0555, 0.9158],\n","        [0.9497, 0.0710],\n","        [0.9413, 0.0823],\n","        [0.9967, 0.0069],\n","        [0.0074, 0.9906]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3374, grad_fn=<NllLossBackward>)\n","epoch 1819, loss 0.3374233841896057\n","outputs:  tensor([[0.0554, 0.9159],\n","        [0.9498, 0.0710],\n","        [0.9414, 0.0822],\n","        [0.9967, 0.0069],\n","        [0.0074, 0.9906]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3374, grad_fn=<NllLossBackward>)\n","epoch 1820, loss 0.3374009132385254\n","outputs:  tensor([[0.0554, 0.9160],\n","        [0.9498, 0.0709],\n","        [0.9414, 0.0822],\n","        [0.9967, 0.0069],\n","        [0.0074, 0.9907]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3374, grad_fn=<NllLossBackward>)\n","epoch 1821, loss 0.3373785614967346\n","outputs:  tensor([[0.0553, 0.9161],\n","        [0.9499, 0.0708],\n","        [0.9415, 0.0821],\n","        [0.9967, 0.0069],\n","        [0.0073, 0.9907]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3374, grad_fn=<NllLossBackward>)\n","epoch 1822, loss 0.3373560905456543\n","outputs:  tensor([[0.0553, 0.9162],\n","        [0.9499, 0.0708],\n","        [0.9415, 0.0820],\n","        [0.9967, 0.0069],\n","        [0.0073, 0.9907]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3373, grad_fn=<NllLossBackward>)\n","epoch 1823, loss 0.3373338282108307\n","outputs:  tensor([[0.0552, 0.9162],\n","        [0.9499, 0.0707],\n","        [0.9416, 0.0820],\n","        [0.9967, 0.0068],\n","        [0.0073, 0.9907]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3373, grad_fn=<NllLossBackward>)\n","epoch 1824, loss 0.33731144666671753\n","outputs:  tensor([[0.0552, 0.9163],\n","        [0.9500, 0.0706],\n","        [0.9416, 0.0819],\n","        [0.9967, 0.0068],\n","        [0.0073, 0.9907]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3373, grad_fn=<NllLossBackward>)\n","epoch 1825, loss 0.3372892439365387\n","outputs:  tensor([[0.0552, 0.9164],\n","        [0.9500, 0.0706],\n","        [0.9416, 0.0818],\n","        [0.9967, 0.0068],\n","        [0.0073, 0.9907]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3373, grad_fn=<NllLossBackward>)\n","epoch 1826, loss 0.3372668921947479\n","outputs:  tensor([[0.0551, 0.9165],\n","        [0.9501, 0.0705],\n","        [0.9417, 0.0818],\n","        [0.9967, 0.0068],\n","        [0.0073, 0.9907]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3372, grad_fn=<NllLossBackward>)\n","epoch 1827, loss 0.33724474906921387\n","outputs:  tensor([[0.0551, 0.9165],\n","        [0.9501, 0.0705],\n","        [0.9417, 0.0817],\n","        [0.9967, 0.0068],\n","        [0.0073, 0.9908]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3372, grad_fn=<NllLossBackward>)\n","epoch 1828, loss 0.33722251653671265\n","outputs:  tensor([[0.0550, 0.9166],\n","        [0.9501, 0.0704],\n","        [0.9418, 0.0816],\n","        [0.9967, 0.0068],\n","        [0.0073, 0.9908]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3372, grad_fn=<NllLossBackward>)\n","epoch 1829, loss 0.33720043301582336\n","outputs:  tensor([[0.0550, 0.9167],\n","        [0.9502, 0.0703],\n","        [0.9418, 0.0816],\n","        [0.9967, 0.0068],\n","        [0.0073, 0.9908]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3372, grad_fn=<NllLossBackward>)\n","epoch 1830, loss 0.3371783196926117\n","outputs:  tensor([[0.0549, 0.9168],\n","        [0.9502, 0.0703],\n","        [0.9419, 0.0815],\n","        [0.9967, 0.0068],\n","        [0.0072, 0.9908]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3372, grad_fn=<NllLossBackward>)\n","epoch 1831, loss 0.3371562063694\n","outputs:  tensor([[0.0549, 0.9168],\n","        [0.9503, 0.0702],\n","        [0.9419, 0.0814],\n","        [0.9967, 0.0067],\n","        [0.0072, 0.9908]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3371, grad_fn=<NllLossBackward>)\n","epoch 1832, loss 0.3371341824531555\n","outputs:  tensor([[0.0548, 0.9169],\n","        [0.9503, 0.0702],\n","        [0.9420, 0.0814],\n","        [0.9967, 0.0067],\n","        [0.0072, 0.9908]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3371, grad_fn=<NllLossBackward>)\n","epoch 1833, loss 0.3371121883392334\n","outputs:  tensor([[0.0548, 0.9170],\n","        [0.9503, 0.0701],\n","        [0.9420, 0.0813],\n","        [0.9967, 0.0067],\n","        [0.0072, 0.9909]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3371, grad_fn=<NllLossBackward>)\n","epoch 1834, loss 0.33709025382995605\n","outputs:  tensor([[0.0547, 0.9171],\n","        [0.9504, 0.0700],\n","        [0.9420, 0.0812],\n","        [0.9967, 0.0067],\n","        [0.0072, 0.9909]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3371, grad_fn=<NllLossBackward>)\n","epoch 1835, loss 0.33706825971603394\n","outputs:  tensor([[0.0547, 0.9171],\n","        [0.9504, 0.0700],\n","        [0.9421, 0.0812],\n","        [0.9967, 0.0067],\n","        [0.0072, 0.9909]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3370, grad_fn=<NllLossBackward>)\n","epoch 1836, loss 0.3370463252067566\n","outputs:  tensor([[0.0546, 0.9172],\n","        [0.9505, 0.0699],\n","        [0.9421, 0.0811],\n","        [0.9968, 0.0067],\n","        [0.0072, 0.9909]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3370, grad_fn=<NllLossBackward>)\n","epoch 1837, loss 0.3370245099067688\n","outputs:  tensor([[0.0546, 0.9173],\n","        [0.9505, 0.0698],\n","        [0.9422, 0.0810],\n","        [0.9968, 0.0067],\n","        [0.0072, 0.9909]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3370, grad_fn=<NllLossBackward>)\n","epoch 1838, loss 0.337002694606781\n","outputs:  tensor([[0.0546, 0.9174],\n","        [0.9505, 0.0698],\n","        [0.9422, 0.0810],\n","        [0.9968, 0.0067],\n","        [0.0072, 0.9909]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3370, grad_fn=<NllLossBackward>)\n","epoch 1839, loss 0.3369808793067932\n","outputs:  tensor([[0.0545, 0.9174],\n","        [0.9506, 0.0697],\n","        [0.9423, 0.0809],\n","        [0.9968, 0.0067],\n","        [0.0072, 0.9909]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3370, grad_fn=<NllLossBackward>)\n","epoch 1840, loss 0.3369590640068054\n","outputs:  tensor([[0.0545, 0.9175],\n","        [0.9506, 0.0697],\n","        [0.9423, 0.0808],\n","        [0.9968, 0.0066],\n","        [0.0071, 0.9910]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3369, grad_fn=<NllLossBackward>)\n","epoch 1841, loss 0.3369373381137848\n","outputs:  tensor([[0.0544, 0.9176],\n","        [0.9507, 0.0696],\n","        [0.9423, 0.0808],\n","        [0.9968, 0.0066],\n","        [0.0071, 0.9910]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3369, grad_fn=<NllLossBackward>)\n","epoch 1842, loss 0.33691564202308655\n","outputs:  tensor([[0.0544, 0.9177],\n","        [0.9507, 0.0695],\n","        [0.9424, 0.0807],\n","        [0.9968, 0.0066],\n","        [0.0071, 0.9910]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3369, grad_fn=<NllLossBackward>)\n","epoch 1843, loss 0.3368939757347107\n","outputs:  tensor([[0.0543, 0.9177],\n","        [0.9507, 0.0695],\n","        [0.9424, 0.0807],\n","        [0.9968, 0.0066],\n","        [0.0071, 0.9910]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3369, grad_fn=<NllLossBackward>)\n","epoch 1844, loss 0.33687230944633484\n","outputs:  tensor([[0.0543, 0.9178],\n","        [0.9508, 0.0694],\n","        [0.9425, 0.0806],\n","        [0.9968, 0.0066],\n","        [0.0071, 0.9910]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3369, grad_fn=<NllLossBackward>)\n","epoch 1845, loss 0.336850643157959\n","outputs:  tensor([[0.0542, 0.9179],\n","        [0.9508, 0.0694],\n","        [0.9425, 0.0805],\n","        [0.9968, 0.0066],\n","        [0.0071, 0.9910]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3368, grad_fn=<NllLossBackward>)\n","epoch 1846, loss 0.33682912588119507\n","outputs:  tensor([[0.0542, 0.9180],\n","        [0.9509, 0.0693],\n","        [0.9426, 0.0805],\n","        [0.9968, 0.0066],\n","        [0.0071, 0.9910]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3368, grad_fn=<NllLossBackward>)\n","epoch 1847, loss 0.33680757880210876\n","outputs:  tensor([[0.0541, 0.9180],\n","        [0.9509, 0.0692],\n","        [0.9426, 0.0804],\n","        [0.9968, 0.0066],\n","        [0.0071, 0.9911]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3368, grad_fn=<NllLossBackward>)\n","epoch 1848, loss 0.33678603172302246\n","outputs:  tensor([[0.0541, 0.9181],\n","        [0.9509, 0.0692],\n","        [0.9426, 0.0803],\n","        [0.9968, 0.0065],\n","        [0.0071, 0.9911]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3368, grad_fn=<NllLossBackward>)\n","epoch 1849, loss 0.3367646038532257\n","outputs:  tensor([[0.0541, 0.9182],\n","        [0.9510, 0.0691],\n","        [0.9427, 0.0803],\n","        [0.9968, 0.0065],\n","        [0.0071, 0.9911]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3367, grad_fn=<NllLossBackward>)\n","epoch 1850, loss 0.33674317598342896\n","outputs:  tensor([[0.0540, 0.9183],\n","        [0.9510, 0.0691],\n","        [0.9427, 0.0802],\n","        [0.9968, 0.0065],\n","        [0.0070, 0.9911]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3367, grad_fn=<NllLossBackward>)\n","epoch 1851, loss 0.3367217183113098\n","Parameter containing:\n","tensor([[-0.2519, -0.6074,  0.1968],\n","        [-0.9861, -0.7050, -0.0759],\n","        [-0.9984, -0.8647, -0.1241],\n","        [-0.4437, -0.4579, -0.0025]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4937, -0.2939,  0.1557,  0.1222], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8379,  0.7185,  1.0888,  0.1075],\n","        [-0.1661, -0.9251, -0.7587, -0.5497]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3561, -0.5918], requires_grad=True)\n","outputs:  tensor([[0.0540, 0.9183],\n","        [0.9511, 0.0690],\n","        [0.9428, 0.0801],\n","        [0.9968, 0.0065],\n","        [0.0070, 0.9911]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3367, grad_fn=<NllLossBackward>)\n","epoch 1852, loss 0.33670029044151306\n","outputs:  tensor([[0.0539, 0.9184],\n","        [0.9511, 0.0689],\n","        [0.9428, 0.0801],\n","        [0.9968, 0.0065],\n","        [0.0070, 0.9911]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3367, grad_fn=<NllLossBackward>)\n","epoch 1853, loss 0.336679071187973\n","outputs:  tensor([[0.0539, 0.9185],\n","        [0.9511, 0.0689],\n","        [0.9429, 0.0800],\n","        [0.9968, 0.0065],\n","        [0.0070, 0.9911]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3367, grad_fn=<NllLossBackward>)\n","epoch 1854, loss 0.33665770292282104\n","outputs:  tensor([[0.0538, 0.9186],\n","        [0.9512, 0.0688],\n","        [0.9429, 0.0799],\n","        [0.9968, 0.0065],\n","        [0.0070, 0.9912]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3366, grad_fn=<NllLossBackward>)\n","epoch 1855, loss 0.33663639426231384\n","outputs:  tensor([[0.0538, 0.9186],\n","        [0.9512, 0.0688],\n","        [0.9429, 0.0799],\n","        [0.9968, 0.0065],\n","        [0.0070, 0.9912]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3366, grad_fn=<NllLossBackward>)\n","epoch 1856, loss 0.3366151452064514\n","outputs:  tensor([[0.0537, 0.9187],\n","        [0.9513, 0.0687],\n","        [0.9430, 0.0798],\n","        [0.9969, 0.0065],\n","        [0.0070, 0.9912]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3366, grad_fn=<NllLossBackward>)\n","epoch 1857, loss 0.3365939259529114\n","outputs:  tensor([[0.0537, 0.9188],\n","        [0.9513, 0.0687],\n","        [0.9430, 0.0798],\n","        [0.9969, 0.0064],\n","        [0.0070, 0.9912]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3366, grad_fn=<NllLossBackward>)\n","epoch 1858, loss 0.3365727961063385\n","outputs:  tensor([[0.0537, 0.9189],\n","        [0.9513, 0.0686],\n","        [0.9431, 0.0797],\n","        [0.9969, 0.0064],\n","        [0.0070, 0.9912]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3366, grad_fn=<NllLossBackward>)\n","epoch 1859, loss 0.33655160665512085\n","outputs:  tensor([[0.0536, 0.9189],\n","        [0.9514, 0.0685],\n","        [0.9431, 0.0796],\n","        [0.9969, 0.0064],\n","        [0.0070, 0.9912]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3365, grad_fn=<NllLossBackward>)\n","epoch 1860, loss 0.33653050661087036\n","outputs:  tensor([[0.0536, 0.9190],\n","        [0.9514, 0.0685],\n","        [0.9432, 0.0796],\n","        [0.9969, 0.0064],\n","        [0.0070, 0.9912]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3365, grad_fn=<NllLossBackward>)\n","epoch 1861, loss 0.3365094065666199\n","outputs:  tensor([[0.0535, 0.9191],\n","        [0.9514, 0.0684],\n","        [0.9432, 0.0795],\n","        [0.9969, 0.0064],\n","        [0.0069, 0.9913]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3365, grad_fn=<NllLossBackward>)\n","epoch 1862, loss 0.3364883363246918\n","outputs:  tensor([[0.0535, 0.9192],\n","        [0.9515, 0.0684],\n","        [0.9432, 0.0794],\n","        [0.9969, 0.0064],\n","        [0.0069, 0.9913]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3365, grad_fn=<NllLossBackward>)\n","epoch 1863, loss 0.33646726608276367\n","outputs:  tensor([[0.0534, 0.9192],\n","        [0.9515, 0.0683],\n","        [0.9433, 0.0794],\n","        [0.9969, 0.0064],\n","        [0.0069, 0.9913]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3364, grad_fn=<NllLossBackward>)\n","epoch 1864, loss 0.3364463448524475\n","outputs:  tensor([[0.0534, 0.9193],\n","        [0.9516, 0.0682],\n","        [0.9433, 0.0793],\n","        [0.9969, 0.0064],\n","        [0.0069, 0.9913]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3364, grad_fn=<NllLossBackward>)\n","epoch 1865, loss 0.3364253044128418\n","outputs:  tensor([[0.0533, 0.9194],\n","        [0.9516, 0.0682],\n","        [0.9434, 0.0793],\n","        [0.9969, 0.0064],\n","        [0.0069, 0.9913]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3364, grad_fn=<NllLossBackward>)\n","epoch 1866, loss 0.336404412984848\n","outputs:  tensor([[0.0533, 0.9194],\n","        [0.9516, 0.0681],\n","        [0.9434, 0.0792],\n","        [0.9969, 0.0063],\n","        [0.0069, 0.9913]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3364, grad_fn=<NllLossBackward>)\n","epoch 1867, loss 0.33638349175453186\n","outputs:  tensor([[0.0533, 0.9195],\n","        [0.9517, 0.0681],\n","        [0.9435, 0.0791],\n","        [0.9969, 0.0063],\n","        [0.0069, 0.9913]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3364, grad_fn=<NllLossBackward>)\n","epoch 1868, loss 0.33636265993118286\n","outputs:  tensor([[0.0532, 0.9196],\n","        [0.9517, 0.0680],\n","        [0.9435, 0.0791],\n","        [0.9969, 0.0063],\n","        [0.0069, 0.9913]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n","epoch 1869, loss 0.3363417685031891\n","outputs:  tensor([[0.0532, 0.9197],\n","        [0.9518, 0.0680],\n","        [0.9435, 0.0790],\n","        [0.9969, 0.0063],\n","        [0.0069, 0.9914]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n","epoch 1870, loss 0.3363209366798401\n","outputs:  tensor([[0.0531, 0.9197],\n","        [0.9518, 0.0679],\n","        [0.9436, 0.0789],\n","        [0.9969, 0.0063],\n","        [0.0069, 0.9914]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n","epoch 1871, loss 0.33630022406578064\n","outputs:  tensor([[0.0531, 0.9198],\n","        [0.9518, 0.0678],\n","        [0.9436, 0.0789],\n","        [0.9969, 0.0063],\n","        [0.0068, 0.9914]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n","epoch 1872, loss 0.3362794816493988\n","outputs:  tensor([[0.0530, 0.9199],\n","        [0.9519, 0.0678],\n","        [0.9437, 0.0788],\n","        [0.9969, 0.0063],\n","        [0.0068, 0.9914]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3363, grad_fn=<NllLossBackward>)\n","epoch 1873, loss 0.3362587094306946\n","outputs:  tensor([[0.0530, 0.9199],\n","        [0.9519, 0.0677],\n","        [0.9437, 0.0788],\n","        [0.9969, 0.0063],\n","        [0.0068, 0.9914]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3362, grad_fn=<NllLossBackward>)\n","epoch 1874, loss 0.3362380564212799\n","outputs:  tensor([[0.0529, 0.9200],\n","        [0.9519, 0.0677],\n","        [0.9437, 0.0787],\n","        [0.9969, 0.0063],\n","        [0.0068, 0.9914]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3362, grad_fn=<NllLossBackward>)\n","epoch 1875, loss 0.33621740341186523\n","outputs:  tensor([[0.0529, 0.9201],\n","        [0.9520, 0.0676],\n","        [0.9438, 0.0786],\n","        [0.9969, 0.0062],\n","        [0.0068, 0.9914]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3362, grad_fn=<NllLossBackward>)\n","epoch 1876, loss 0.33619681000709534\n","outputs:  tensor([[0.0529, 0.9202],\n","        [0.9520, 0.0675],\n","        [0.9438, 0.0786],\n","        [0.9970, 0.0062],\n","        [0.0068, 0.9915]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3362, grad_fn=<NllLossBackward>)\n","epoch 1877, loss 0.33617615699768066\n","outputs:  tensor([[0.0528, 0.9202],\n","        [0.9521, 0.0675],\n","        [0.9439, 0.0785],\n","        [0.9970, 0.0062],\n","        [0.0068, 0.9915]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3362, grad_fn=<NllLossBackward>)\n","epoch 1878, loss 0.33615559339523315\n","outputs:  tensor([[0.0528, 0.9203],\n","        [0.9521, 0.0674],\n","        [0.9439, 0.0784],\n","        [0.9970, 0.0062],\n","        [0.0068, 0.9915]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3361, grad_fn=<NllLossBackward>)\n","epoch 1879, loss 0.33613505959510803\n","outputs:  tensor([[0.0527, 0.9204],\n","        [0.9521, 0.0674],\n","        [0.9440, 0.0784],\n","        [0.9970, 0.0062],\n","        [0.0068, 0.9915]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3361, grad_fn=<NllLossBackward>)\n","epoch 1880, loss 0.3361145853996277\n","outputs:  tensor([[0.0527, 0.9204],\n","        [0.9522, 0.0673],\n","        [0.9440, 0.0783],\n","        [0.9970, 0.0062],\n","        [0.0068, 0.9915]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3361, grad_fn=<NllLossBackward>)\n","epoch 1881, loss 0.3360941410064697\n","outputs:  tensor([[0.0526, 0.9205],\n","        [0.9522, 0.0673],\n","        [0.9440, 0.0783],\n","        [0.9970, 0.0062],\n","        [0.0068, 0.9915]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3361, grad_fn=<NllLossBackward>)\n","epoch 1882, loss 0.3360736668109894\n","outputs:  tensor([[0.0526, 0.9206],\n","        [0.9523, 0.0672],\n","        [0.9441, 0.0782],\n","        [0.9970, 0.0062],\n","        [0.0067, 0.9915]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3361, grad_fn=<NllLossBackward>)\n","epoch 1883, loss 0.3360532224178314\n","outputs:  tensor([[0.0526, 0.9207],\n","        [0.9523, 0.0671],\n","        [0.9441, 0.0781],\n","        [0.9970, 0.0062],\n","        [0.0067, 0.9915]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3360, grad_fn=<NllLossBackward>)\n","epoch 1884, loss 0.3360328674316406\n","outputs:  tensor([[0.0525, 0.9207],\n","        [0.9523, 0.0671],\n","        [0.9442, 0.0781],\n","        [0.9970, 0.0061],\n","        [0.0067, 0.9916]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3360, grad_fn=<NllLossBackward>)\n","epoch 1885, loss 0.33601251244544983\n","outputs:  tensor([[0.0525, 0.9208],\n","        [0.9524, 0.0670],\n","        [0.9442, 0.0780],\n","        [0.9970, 0.0061],\n","        [0.0067, 0.9916]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3360, grad_fn=<NllLossBackward>)\n","epoch 1886, loss 0.3359922766685486\n","outputs:  tensor([[0.0524, 0.9209],\n","        [0.9524, 0.0670],\n","        [0.9442, 0.0780],\n","        [0.9970, 0.0061],\n","        [0.0067, 0.9916]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3360, grad_fn=<NllLossBackward>)\n","epoch 1887, loss 0.3359719216823578\n","outputs:  tensor([[0.0524, 0.9209],\n","        [0.9524, 0.0669],\n","        [0.9443, 0.0779],\n","        [0.9970, 0.0061],\n","        [0.0067, 0.9916]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3360, grad_fn=<NllLossBackward>)\n","epoch 1888, loss 0.33595171570777893\n","outputs:  tensor([[0.0523, 0.9210],\n","        [0.9525, 0.0669],\n","        [0.9443, 0.0778],\n","        [0.9970, 0.0061],\n","        [0.0067, 0.9916]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3359, grad_fn=<NllLossBackward>)\n","epoch 1889, loss 0.3359314501285553\n","outputs:  tensor([[0.0523, 0.9211],\n","        [0.9525, 0.0668],\n","        [0.9444, 0.0778],\n","        [0.9970, 0.0061],\n","        [0.0067, 0.9916]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3359, grad_fn=<NllLossBackward>)\n","epoch 1890, loss 0.3359113037586212\n","outputs:  tensor([[0.0523, 0.9212],\n","        [0.9526, 0.0667],\n","        [0.9444, 0.0777],\n","        [0.9970, 0.0061],\n","        [0.0067, 0.9916]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3359, grad_fn=<NllLossBackward>)\n","epoch 1891, loss 0.33589109778404236\n","outputs:  tensor([[0.0522, 0.9212],\n","        [0.9526, 0.0667],\n","        [0.9444, 0.0777],\n","        [0.9970, 0.0061],\n","        [0.0067, 0.9917]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3359, grad_fn=<NllLossBackward>)\n","epoch 1892, loss 0.33587098121643066\n","outputs:  tensor([[0.0522, 0.9213],\n","        [0.9526, 0.0666],\n","        [0.9445, 0.0776],\n","        [0.9970, 0.0061],\n","        [0.0067, 0.9917]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3359, grad_fn=<NllLossBackward>)\n","epoch 1893, loss 0.3358508050441742\n","outputs:  tensor([[0.0521, 0.9214],\n","        [0.9527, 0.0666],\n","        [0.9445, 0.0775],\n","        [0.9970, 0.0061],\n","        [0.0066, 0.9917]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3358, grad_fn=<NllLossBackward>)\n","epoch 1894, loss 0.3358307480812073\n","outputs:  tensor([[0.0521, 0.9214],\n","        [0.9527, 0.0665],\n","        [0.9446, 0.0775],\n","        [0.9970, 0.0060],\n","        [0.0066, 0.9917]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3358, grad_fn=<NllLossBackward>)\n","epoch 1895, loss 0.33581072092056274\n","outputs:  tensor([[0.0520, 0.9215],\n","        [0.9527, 0.0665],\n","        [0.9446, 0.0774],\n","        [0.9970, 0.0060],\n","        [0.0066, 0.9917]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3358, grad_fn=<NllLossBackward>)\n","epoch 1896, loss 0.3357906937599182\n","outputs:  tensor([[0.0520, 0.9216],\n","        [0.9528, 0.0664],\n","        [0.9446, 0.0773],\n","        [0.9970, 0.0060],\n","        [0.0066, 0.9917]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3358, grad_fn=<NllLossBackward>)\n","epoch 1897, loss 0.33577069640159607\n","outputs:  tensor([[0.0520, 0.9216],\n","        [0.9528, 0.0664],\n","        [0.9447, 0.0773],\n","        [0.9970, 0.0060],\n","        [0.0066, 0.9917]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3358, grad_fn=<NllLossBackward>)\n","epoch 1898, loss 0.3357507288455963\n","outputs:  tensor([[0.0519, 0.9217],\n","        [0.9529, 0.0663],\n","        [0.9447, 0.0772],\n","        [0.9971, 0.0060],\n","        [0.0066, 0.9917]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3357, grad_fn=<NllLossBackward>)\n","epoch 1899, loss 0.33573082089424133\n","outputs:  tensor([[0.0519, 0.9218],\n","        [0.9529, 0.0662],\n","        [0.9448, 0.0772],\n","        [0.9971, 0.0060],\n","        [0.0066, 0.9918]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3357, grad_fn=<NllLossBackward>)\n","epoch 1900, loss 0.33571094274520874\n","outputs:  tensor([[0.0518, 0.9218],\n","        [0.9529, 0.0662],\n","        [0.9448, 0.0771],\n","        [0.9971, 0.0060],\n","        [0.0066, 0.9918]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3357, grad_fn=<NllLossBackward>)\n","epoch 1901, loss 0.33569106459617615\n","Parameter containing:\n","tensor([[-0.2545, -0.6118,  0.1967],\n","        [-0.9910, -0.7132, -0.0760],\n","        [-1.0037, -0.8735, -0.1242],\n","        [-0.4459, -0.4615, -0.0025]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4951, -0.2913,  0.1585,  0.1234], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8416,  0.7234,  1.0949,  0.1106],\n","        [-0.1713, -0.9320, -0.7674, -0.5541]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3574, -0.5935], requires_grad=True)\n","outputs:  tensor([[0.0518, 0.9219],\n","        [0.9530, 0.0661],\n","        [0.9448, 0.0770],\n","        [0.9971, 0.0060],\n","        [0.0066, 0.9918]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3357, grad_fn=<NllLossBackward>)\n","epoch 1902, loss 0.33567124605178833\n","outputs:  tensor([[0.0518, 0.9220],\n","        [0.9530, 0.0661],\n","        [0.9449, 0.0770],\n","        [0.9971, 0.0060],\n","        [0.0066, 0.9918]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3357, grad_fn=<NllLossBackward>)\n","epoch 1903, loss 0.3356513977050781\n","outputs:  tensor([[0.0517, 0.9221],\n","        [0.9530, 0.0660],\n","        [0.9449, 0.0769],\n","        [0.9971, 0.0060],\n","        [0.0066, 0.9918]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3356, grad_fn=<NllLossBackward>)\n","epoch 1904, loss 0.3356316089630127\n","outputs:  tensor([[0.0517, 0.9221],\n","        [0.9531, 0.0660],\n","        [0.9450, 0.0769],\n","        [0.9971, 0.0059],\n","        [0.0065, 0.9918]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3356, grad_fn=<NllLossBackward>)\n","epoch 1905, loss 0.33561185002326965\n","outputs:  tensor([[0.0516, 0.9222],\n","        [0.9531, 0.0659],\n","        [0.9450, 0.0768],\n","        [0.9971, 0.0059],\n","        [0.0065, 0.9918]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3356, grad_fn=<NllLossBackward>)\n","epoch 1906, loss 0.3355921804904938\n","outputs:  tensor([[0.0516, 0.9223],\n","        [0.9531, 0.0659],\n","        [0.9450, 0.0767],\n","        [0.9971, 0.0059],\n","        [0.0065, 0.9918]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3356, grad_fn=<NllLossBackward>)\n","epoch 1907, loss 0.33557239174842834\n","outputs:  tensor([[0.0515, 0.9223],\n","        [0.9532, 0.0658],\n","        [0.9451, 0.0767],\n","        [0.9971, 0.0059],\n","        [0.0065, 0.9919]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3356, grad_fn=<NllLossBackward>)\n","epoch 1908, loss 0.33555275201797485\n","outputs:  tensor([[0.0515, 0.9224],\n","        [0.9532, 0.0657],\n","        [0.9451, 0.0766],\n","        [0.9971, 0.0059],\n","        [0.0065, 0.9919]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3355, grad_fn=<NllLossBackward>)\n","epoch 1909, loss 0.335533082485199\n","outputs:  tensor([[0.0515, 0.9225],\n","        [0.9533, 0.0657],\n","        [0.9452, 0.0766],\n","        [0.9971, 0.0059],\n","        [0.0065, 0.9919]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3355, grad_fn=<NllLossBackward>)\n","epoch 1910, loss 0.3355134427547455\n","outputs:  tensor([[0.0514, 0.9225],\n","        [0.9533, 0.0656],\n","        [0.9452, 0.0765],\n","        [0.9971, 0.0059],\n","        [0.0065, 0.9919]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3355, grad_fn=<NllLossBackward>)\n","epoch 1911, loss 0.33549389243125916\n","outputs:  tensor([[0.0514, 0.9226],\n","        [0.9533, 0.0656],\n","        [0.9452, 0.0765],\n","        [0.9971, 0.0059],\n","        [0.0065, 0.9919]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3355, grad_fn=<NllLossBackward>)\n","epoch 1912, loss 0.3354743421077728\n","outputs:  tensor([[0.0513, 0.9227],\n","        [0.9534, 0.0655],\n","        [0.9453, 0.0764],\n","        [0.9971, 0.0059],\n","        [0.0065, 0.9919]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3355, grad_fn=<NllLossBackward>)\n","epoch 1913, loss 0.3354548513889313\n","outputs:  tensor([[0.0513, 0.9227],\n","        [0.9534, 0.0655],\n","        [0.9453, 0.0763],\n","        [0.9971, 0.0059],\n","        [0.0065, 0.9919]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3354, grad_fn=<NllLossBackward>)\n","epoch 1914, loss 0.33543533086776733\n","outputs:  tensor([[0.0513, 0.9228],\n","        [0.9534, 0.0654],\n","        [0.9454, 0.0763],\n","        [0.9971, 0.0058],\n","        [0.0065, 0.9919]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3354, grad_fn=<NllLossBackward>)\n","epoch 1915, loss 0.33541589975357056\n","outputs:  tensor([[0.0512, 0.9229],\n","        [0.9535, 0.0654],\n","        [0.9454, 0.0762],\n","        [0.9971, 0.0058],\n","        [0.0064, 0.9920]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3354, grad_fn=<NllLossBackward>)\n","epoch 1916, loss 0.3353964388370514\n","outputs:  tensor([[0.0512, 0.9229],\n","        [0.9535, 0.0653],\n","        [0.9454, 0.0762],\n","        [0.9971, 0.0058],\n","        [0.0064, 0.9920]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3354, grad_fn=<NllLossBackward>)\n","epoch 1917, loss 0.335377037525177\n","outputs:  tensor([[0.0511, 0.9230],\n","        [0.9535, 0.0653],\n","        [0.9455, 0.0761],\n","        [0.9971, 0.0058],\n","        [0.0064, 0.9920]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3354, grad_fn=<NllLossBackward>)\n","epoch 1918, loss 0.33535757660865784\n","outputs:  tensor([[0.0511, 0.9231],\n","        [0.9536, 0.0652],\n","        [0.9455, 0.0760],\n","        [0.9971, 0.0058],\n","        [0.0064, 0.9920]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3353, grad_fn=<NllLossBackward>)\n","epoch 1919, loss 0.335338294506073\n","outputs:  tensor([[0.0511, 0.9231],\n","        [0.9536, 0.0651],\n","        [0.9456, 0.0760],\n","        [0.9971, 0.0058],\n","        [0.0064, 0.9920]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3353, grad_fn=<NllLossBackward>)\n","epoch 1920, loss 0.3353189527988434\n","outputs:  tensor([[0.0510, 0.9232],\n","        [0.9537, 0.0651],\n","        [0.9456, 0.0759],\n","        [0.9972, 0.0058],\n","        [0.0064, 0.9920]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3353, grad_fn=<NllLossBackward>)\n","epoch 1921, loss 0.33529967069625854\n","outputs:  tensor([[0.0510, 0.9233],\n","        [0.9537, 0.0650],\n","        [0.9456, 0.0759],\n","        [0.9972, 0.0058],\n","        [0.0064, 0.9920]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3353, grad_fn=<NllLossBackward>)\n","epoch 1922, loss 0.3352803587913513\n","outputs:  tensor([[0.0509, 0.9233],\n","        [0.9537, 0.0650],\n","        [0.9457, 0.0758],\n","        [0.9972, 0.0058],\n","        [0.0064, 0.9920]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3353, grad_fn=<NllLossBackward>)\n","epoch 1923, loss 0.33526116609573364\n","outputs:  tensor([[0.0509, 0.9234],\n","        [0.9538, 0.0649],\n","        [0.9457, 0.0757],\n","        [0.9972, 0.0058],\n","        [0.0064, 0.9921]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3352, grad_fn=<NllLossBackward>)\n","epoch 1924, loss 0.3352419137954712\n","outputs:  tensor([[0.0508, 0.9235],\n","        [0.9538, 0.0649],\n","        [0.9458, 0.0757],\n","        [0.9972, 0.0057],\n","        [0.0064, 0.9921]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3352, grad_fn=<NllLossBackward>)\n","epoch 1925, loss 0.3352227210998535\n","outputs:  tensor([[0.0508, 0.9235],\n","        [0.9538, 0.0648],\n","        [0.9458, 0.0756],\n","        [0.9972, 0.0057],\n","        [0.0064, 0.9921]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3352, grad_fn=<NllLossBackward>)\n","epoch 1926, loss 0.3352035880088806\n","outputs:  tensor([[0.0508, 0.9236],\n","        [0.9539, 0.0648],\n","        [0.9458, 0.0756],\n","        [0.9972, 0.0057],\n","        [0.0064, 0.9921]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3352, grad_fn=<NllLossBackward>)\n","epoch 1927, loss 0.3351844251155853\n","outputs:  tensor([[0.0507, 0.9237],\n","        [0.9539, 0.0647],\n","        [0.9459, 0.0755],\n","        [0.9972, 0.0057],\n","        [0.0063, 0.9921]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3352, grad_fn=<NllLossBackward>)\n","epoch 1928, loss 0.3351653218269348\n","outputs:  tensor([[0.0507, 0.9237],\n","        [0.9539, 0.0647],\n","        [0.9459, 0.0755],\n","        [0.9972, 0.0057],\n","        [0.0063, 0.9921]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3351, grad_fn=<NllLossBackward>)\n","epoch 1929, loss 0.3351462483406067\n","outputs:  tensor([[0.0506, 0.9238],\n","        [0.9540, 0.0646],\n","        [0.9460, 0.0754],\n","        [0.9972, 0.0057],\n","        [0.0063, 0.9921]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3351, grad_fn=<NllLossBackward>)\n","epoch 1930, loss 0.3351272642612457\n","outputs:  tensor([[0.0506, 0.9239],\n","        [0.9540, 0.0646],\n","        [0.9460, 0.0753],\n","        [0.9972, 0.0057],\n","        [0.0063, 0.9921]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3351, grad_fn=<NllLossBackward>)\n","epoch 1931, loss 0.3351081907749176\n","outputs:  tensor([[0.0506, 0.9239],\n","        [0.9540, 0.0645],\n","        [0.9460, 0.0753],\n","        [0.9972, 0.0057],\n","        [0.0063, 0.9921]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3351, grad_fn=<NllLossBackward>)\n","epoch 1932, loss 0.3350892663002014\n","outputs:  tensor([[0.0505, 0.9240],\n","        [0.9541, 0.0644],\n","        [0.9461, 0.0752],\n","        [0.9972, 0.0057],\n","        [0.0063, 0.9922]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3351, grad_fn=<NllLossBackward>)\n","epoch 1933, loss 0.3350702226161957\n","outputs:  tensor([[0.0505, 0.9241],\n","        [0.9541, 0.0644],\n","        [0.9461, 0.0752],\n","        [0.9972, 0.0057],\n","        [0.0063, 0.9922]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3351, grad_fn=<NllLossBackward>)\n","epoch 1934, loss 0.3350513279438019\n","outputs:  tensor([[0.0504, 0.9241],\n","        [0.9542, 0.0643],\n","        [0.9461, 0.0751],\n","        [0.9972, 0.0056],\n","        [0.0063, 0.9922]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3350, grad_fn=<NllLossBackward>)\n","epoch 1935, loss 0.3350324034690857\n","outputs:  tensor([[0.0504, 0.9242],\n","        [0.9542, 0.0643],\n","        [0.9462, 0.0751],\n","        [0.9972, 0.0056],\n","        [0.0063, 0.9922]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3350, grad_fn=<NllLossBackward>)\n","epoch 1936, loss 0.3350134491920471\n","outputs:  tensor([[0.0504, 0.9243],\n","        [0.9542, 0.0642],\n","        [0.9462, 0.0750],\n","        [0.9972, 0.0056],\n","        [0.0063, 0.9922]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3350, grad_fn=<NllLossBackward>)\n","epoch 1937, loss 0.33499470353126526\n","outputs:  tensor([[0.0503, 0.9243],\n","        [0.9543, 0.0642],\n","        [0.9463, 0.0749],\n","        [0.9972, 0.0056],\n","        [0.0063, 0.9922]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3350, grad_fn=<NllLossBackward>)\n","epoch 1938, loss 0.33497583866119385\n","outputs:  tensor([[0.0503, 0.9244],\n","        [0.9543, 0.0641],\n","        [0.9463, 0.0749],\n","        [0.9972, 0.0056],\n","        [0.0063, 0.9922]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3350, grad_fn=<NllLossBackward>)\n","epoch 1939, loss 0.33495697379112244\n","outputs:  tensor([[0.0502, 0.9245],\n","        [0.9543, 0.0641],\n","        [0.9463, 0.0748],\n","        [0.9972, 0.0056],\n","        [0.0062, 0.9922]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3349, grad_fn=<NllLossBackward>)\n","epoch 1940, loss 0.3349382281303406\n","outputs:  tensor([[0.0502, 0.9245],\n","        [0.9544, 0.0640],\n","        [0.9464, 0.0748],\n","        [0.9972, 0.0056],\n","        [0.0062, 0.9923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3349, grad_fn=<NllLossBackward>)\n","epoch 1941, loss 0.3349195122718811\n","outputs:  tensor([[0.0502, 0.9246],\n","        [0.9544, 0.0640],\n","        [0.9464, 0.0747],\n","        [0.9972, 0.0056],\n","        [0.0062, 0.9923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3349, grad_fn=<NllLossBackward>)\n","epoch 1942, loss 0.33490079641342163\n","outputs:  tensor([[0.0501, 0.9247],\n","        [0.9544, 0.0639],\n","        [0.9465, 0.0747],\n","        [0.9972, 0.0056],\n","        [0.0062, 0.9923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3349, grad_fn=<NllLossBackward>)\n","epoch 1943, loss 0.33488208055496216\n","outputs:  tensor([[0.0501, 0.9247],\n","        [0.9545, 0.0639],\n","        [0.9465, 0.0746],\n","        [0.9972, 0.0056],\n","        [0.0062, 0.9923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3349, grad_fn=<NllLossBackward>)\n","epoch 1944, loss 0.33486342430114746\n","outputs:  tensor([[0.0500, 0.9248],\n","        [0.9545, 0.0638],\n","        [0.9465, 0.0745],\n","        [0.9973, 0.0056],\n","        [0.0062, 0.9923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3348, grad_fn=<NllLossBackward>)\n","epoch 1945, loss 0.33484479784965515\n","outputs:  tensor([[0.0500, 0.9249],\n","        [0.9545, 0.0638],\n","        [0.9466, 0.0745],\n","        [0.9973, 0.0055],\n","        [0.0062, 0.9923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3348, grad_fn=<NllLossBackward>)\n","epoch 1946, loss 0.33482614159584045\n","outputs:  tensor([[0.0500, 0.9249],\n","        [0.9546, 0.0637],\n","        [0.9466, 0.0744],\n","        [0.9973, 0.0055],\n","        [0.0062, 0.9923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3348, grad_fn=<NllLossBackward>)\n","epoch 1947, loss 0.3348076045513153\n","outputs:  tensor([[0.0499, 0.9250],\n","        [0.9546, 0.0637],\n","        [0.9466, 0.0744],\n","        [0.9973, 0.0055],\n","        [0.0062, 0.9923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3348, grad_fn=<NllLossBackward>)\n","epoch 1948, loss 0.3347890377044678\n","outputs:  tensor([[0.0499, 0.9251],\n","        [0.9546, 0.0636],\n","        [0.9467, 0.0743],\n","        [0.9973, 0.0055],\n","        [0.0062, 0.9923]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3348, grad_fn=<NllLossBackward>)\n","epoch 1949, loss 0.33477044105529785\n","outputs:  tensor([[0.0498, 0.9251],\n","        [0.9547, 0.0635],\n","        [0.9467, 0.0743],\n","        [0.9973, 0.0055],\n","        [0.0062, 0.9924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3348, grad_fn=<NllLossBackward>)\n","epoch 1950, loss 0.3347519338130951\n","outputs:  tensor([[0.0498, 0.9252],\n","        [0.9547, 0.0635],\n","        [0.9468, 0.0742],\n","        [0.9973, 0.0055],\n","        [0.0062, 0.9924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3347, grad_fn=<NllLossBackward>)\n","epoch 1951, loss 0.3347334861755371\n","Parameter containing:\n","tensor([[-0.2570, -0.6160,  0.1966],\n","        [-0.9958, -0.7211, -0.0760],\n","        [-1.0087, -0.8819, -0.1243],\n","        [-0.4479, -0.4650, -0.0024]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4965, -0.2888,  0.1612,  0.1244], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8451,  0.7280,  1.1008,  0.1135],\n","        [-0.1764, -0.9387, -0.7757, -0.5583]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3587, -0.5952], requires_grad=True)\n","outputs:  tensor([[0.0498, 0.9252],\n","        [0.9548, 0.0634],\n","        [0.9468, 0.0741],\n","        [0.9973, 0.0055],\n","        [0.0061, 0.9924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3347, grad_fn=<NllLossBackward>)\n","epoch 1952, loss 0.3347150385379791\n","outputs:  tensor([[0.0497, 0.9253],\n","        [0.9548, 0.0634],\n","        [0.9468, 0.0741],\n","        [0.9973, 0.0055],\n","        [0.0061, 0.9924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3347, grad_fn=<NllLossBackward>)\n","epoch 1953, loss 0.33469659090042114\n","outputs:  tensor([[0.0497, 0.9254],\n","        [0.9548, 0.0633],\n","        [0.9469, 0.0740],\n","        [0.9973, 0.0055],\n","        [0.0061, 0.9924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3347, grad_fn=<NllLossBackward>)\n","epoch 1954, loss 0.33467820286750793\n","outputs:  tensor([[0.0497, 0.9254],\n","        [0.9549, 0.0633],\n","        [0.9469, 0.0740],\n","        [0.9973, 0.0055],\n","        [0.0061, 0.9924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3347, grad_fn=<NllLossBackward>)\n","epoch 1955, loss 0.3346598744392395\n","outputs:  tensor([[0.0496, 0.9255],\n","        [0.9549, 0.0632],\n","        [0.9469, 0.0739],\n","        [0.9973, 0.0055],\n","        [0.0061, 0.9924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3346, grad_fn=<NllLossBackward>)\n","epoch 1956, loss 0.3346415162086487\n","outputs:  tensor([[0.0496, 0.9256],\n","        [0.9549, 0.0632],\n","        [0.9470, 0.0739],\n","        [0.9973, 0.0054],\n","        [0.0061, 0.9924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3346, grad_fn=<NllLossBackward>)\n","epoch 1957, loss 0.33462318778038025\n","outputs:  tensor([[0.0495, 0.9256],\n","        [0.9550, 0.0631],\n","        [0.9470, 0.0738],\n","        [0.9973, 0.0054],\n","        [0.0061, 0.9924]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3346, grad_fn=<NllLossBackward>)\n","epoch 1958, loss 0.3346048891544342\n","outputs:  tensor([[0.0495, 0.9257],\n","        [0.9550, 0.0631],\n","        [0.9471, 0.0738],\n","        [0.9973, 0.0054],\n","        [0.0061, 0.9925]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3346, grad_fn=<NllLossBackward>)\n","epoch 1959, loss 0.33458656072616577\n","outputs:  tensor([[0.0495, 0.9258],\n","        [0.9550, 0.0630],\n","        [0.9471, 0.0737],\n","        [0.9973, 0.0054],\n","        [0.0061, 0.9925]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3346, grad_fn=<NllLossBackward>)\n","epoch 1960, loss 0.3345683813095093\n","outputs:  tensor([[0.0494, 0.9258],\n","        [0.9551, 0.0630],\n","        [0.9471, 0.0736],\n","        [0.9973, 0.0054],\n","        [0.0061, 0.9925]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3346, grad_fn=<NllLossBackward>)\n","epoch 1961, loss 0.334550142288208\n","outputs:  tensor([[0.0494, 0.9259],\n","        [0.9551, 0.0629],\n","        [0.9472, 0.0736],\n","        [0.9973, 0.0054],\n","        [0.0061, 0.9925]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3345, grad_fn=<NllLossBackward>)\n","epoch 1962, loss 0.3345319330692291\n","outputs:  tensor([[0.0493, 0.9259],\n","        [0.9551, 0.0629],\n","        [0.9472, 0.0735],\n","        [0.9973, 0.0054],\n","        [0.0061, 0.9925]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3345, grad_fn=<NllLossBackward>)\n","epoch 1963, loss 0.334513783454895\n","outputs:  tensor([[0.0493, 0.9260],\n","        [0.9552, 0.0628],\n","        [0.9472, 0.0735],\n","        [0.9973, 0.0054],\n","        [0.0060, 0.9925]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3345, grad_fn=<NllLossBackward>)\n","epoch 1964, loss 0.3344956338405609\n","outputs:  tensor([[0.0493, 0.9261],\n","        [0.9552, 0.0628],\n","        [0.9473, 0.0734],\n","        [0.9973, 0.0054],\n","        [0.0060, 0.9925]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3345, grad_fn=<NllLossBackward>)\n","epoch 1965, loss 0.3344775140285492\n","outputs:  tensor([[0.0492, 0.9261],\n","        [0.9552, 0.0627],\n","        [0.9473, 0.0734],\n","        [0.9973, 0.0054],\n","        [0.0060, 0.9925]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3345, grad_fn=<NllLossBackward>)\n","epoch 1966, loss 0.33445945382118225\n","outputs:  tensor([[0.0492, 0.9262],\n","        [0.9553, 0.0627],\n","        [0.9474, 0.0733],\n","        [0.9973, 0.0054],\n","        [0.0060, 0.9925]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3344, grad_fn=<NllLossBackward>)\n","epoch 1967, loss 0.3344413638114929\n","outputs:  tensor([[0.0492, 0.9263],\n","        [0.9553, 0.0626],\n","        [0.9474, 0.0733],\n","        [0.9973, 0.0053],\n","        [0.0060, 0.9926]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3344, grad_fn=<NllLossBackward>)\n","epoch 1968, loss 0.33442333340644836\n","outputs:  tensor([[0.0491, 0.9263],\n","        [0.9553, 0.0626],\n","        [0.9474, 0.0732],\n","        [0.9973, 0.0053],\n","        [0.0060, 0.9926]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3344, grad_fn=<NllLossBackward>)\n","epoch 1969, loss 0.3344053328037262\n","outputs:  tensor([[0.0491, 0.9264],\n","        [0.9554, 0.0625],\n","        [0.9475, 0.0731],\n","        [0.9974, 0.0053],\n","        [0.0060, 0.9926]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3344, grad_fn=<NllLossBackward>)\n","epoch 1970, loss 0.3343873620033264\n","outputs:  tensor([[0.0490, 0.9264],\n","        [0.9554, 0.0625],\n","        [0.9475, 0.0731],\n","        [0.9974, 0.0053],\n","        [0.0060, 0.9926]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3344, grad_fn=<NllLossBackward>)\n","epoch 1971, loss 0.33436936140060425\n","outputs:  tensor([[0.0490, 0.9265],\n","        [0.9554, 0.0624],\n","        [0.9475, 0.0730],\n","        [0.9974, 0.0053],\n","        [0.0060, 0.9926]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3344, grad_fn=<NllLossBackward>)\n","epoch 1972, loss 0.33435148000717163\n","outputs:  tensor([[0.0490, 0.9266],\n","        [0.9555, 0.0624],\n","        [0.9476, 0.0730],\n","        [0.9974, 0.0053],\n","        [0.0060, 0.9926]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3343, grad_fn=<NllLossBackward>)\n","epoch 1973, loss 0.33433353900909424\n","outputs:  tensor([[0.0489, 0.9266],\n","        [0.9555, 0.0623],\n","        [0.9476, 0.0729],\n","        [0.9974, 0.0053],\n","        [0.0060, 0.9926]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3343, grad_fn=<NllLossBackward>)\n","epoch 1974, loss 0.33431562781333923\n","outputs:  tensor([[0.0489, 0.9267],\n","        [0.9555, 0.0623],\n","        [0.9477, 0.0729],\n","        [0.9974, 0.0053],\n","        [0.0060, 0.9926]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3343, grad_fn=<NllLossBackward>)\n","epoch 1975, loss 0.3342978358268738\n","outputs:  tensor([[0.0488, 0.9268],\n","        [0.9556, 0.0622],\n","        [0.9477, 0.0728],\n","        [0.9974, 0.0053],\n","        [0.0060, 0.9926]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3343, grad_fn=<NllLossBackward>)\n","epoch 1976, loss 0.33427998423576355\n","outputs:  tensor([[0.0488, 0.9268],\n","        [0.9556, 0.0622],\n","        [0.9477, 0.0728],\n","        [0.9974, 0.0053],\n","        [0.0059, 0.9927]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3343, grad_fn=<NllLossBackward>)\n","epoch 1977, loss 0.3342621922492981\n","outputs:  tensor([[0.0488, 0.9269],\n","        [0.9556, 0.0621],\n","        [0.9478, 0.0727],\n","        [0.9974, 0.0053],\n","        [0.0059, 0.9927]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3342, grad_fn=<NllLossBackward>)\n","epoch 1978, loss 0.33424440026283264\n","outputs:  tensor([[0.0487, 0.9269],\n","        [0.9557, 0.0621],\n","        [0.9478, 0.0726],\n","        [0.9974, 0.0053],\n","        [0.0059, 0.9927]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3342, grad_fn=<NllLossBackward>)\n","epoch 1979, loss 0.3342266082763672\n","outputs:  tensor([[0.0487, 0.9270],\n","        [0.9557, 0.0620],\n","        [0.9478, 0.0726],\n","        [0.9974, 0.0052],\n","        [0.0059, 0.9927]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3342, grad_fn=<NllLossBackward>)\n","epoch 1980, loss 0.3342088758945465\n","outputs:  tensor([[0.0487, 0.9271],\n","        [0.9557, 0.0620],\n","        [0.9479, 0.0725],\n","        [0.9974, 0.0052],\n","        [0.0059, 0.9927]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3342, grad_fn=<NllLossBackward>)\n","epoch 1981, loss 0.3341911733150482\n","outputs:  tensor([[0.0486, 0.9271],\n","        [0.9558, 0.0619],\n","        [0.9479, 0.0725],\n","        [0.9974, 0.0052],\n","        [0.0059, 0.9927]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3342, grad_fn=<NllLossBackward>)\n","epoch 1982, loss 0.3341735303401947\n","outputs:  tensor([[0.0486, 0.9272],\n","        [0.9558, 0.0619],\n","        [0.9479, 0.0724],\n","        [0.9974, 0.0052],\n","        [0.0059, 0.9927]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3342, grad_fn=<NllLossBackward>)\n","epoch 1983, loss 0.3341558575630188\n","outputs:  tensor([[0.0485, 0.9273],\n","        [0.9558, 0.0618],\n","        [0.9480, 0.0724],\n","        [0.9974, 0.0052],\n","        [0.0059, 0.9927]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3341, grad_fn=<NllLossBackward>)\n","epoch 1984, loss 0.3341381549835205\n","outputs:  tensor([[0.0485, 0.9273],\n","        [0.9559, 0.0618],\n","        [0.9480, 0.0723],\n","        [0.9974, 0.0052],\n","        [0.0059, 0.9927]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3341, grad_fn=<NllLossBackward>)\n","epoch 1985, loss 0.33412057161331177\n","outputs:  tensor([[0.0485, 0.9274],\n","        [0.9559, 0.0617],\n","        [0.9481, 0.0723],\n","        [0.9974, 0.0052],\n","        [0.0059, 0.9928]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3341, grad_fn=<NllLossBackward>)\n","epoch 1986, loss 0.3341030180454254\n","outputs:  tensor([[0.0484, 0.9274],\n","        [0.9559, 0.0617],\n","        [0.9481, 0.0722],\n","        [0.9974, 0.0052],\n","        [0.0059, 0.9928]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3341, grad_fn=<NllLossBackward>)\n","epoch 1987, loss 0.33408549427986145\n","outputs:  tensor([[0.0484, 0.9275],\n","        [0.9560, 0.0616],\n","        [0.9481, 0.0722],\n","        [0.9974, 0.0052],\n","        [0.0059, 0.9928]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3341, grad_fn=<NllLossBackward>)\n","epoch 1988, loss 0.3340679407119751\n","outputs:  tensor([[0.0484, 0.9276],\n","        [0.9560, 0.0616],\n","        [0.9482, 0.0721],\n","        [0.9974, 0.0052],\n","        [0.0059, 0.9928]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3341, grad_fn=<NllLossBackward>)\n","epoch 1989, loss 0.33405041694641113\n","outputs:  tensor([[0.0483, 0.9276],\n","        [0.9560, 0.0615],\n","        [0.9482, 0.0721],\n","        [0.9974, 0.0052],\n","        [0.0058, 0.9928]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3340, grad_fn=<NllLossBackward>)\n","epoch 1990, loss 0.33403292298316956\n","outputs:  tensor([[0.0483, 0.9277],\n","        [0.9561, 0.0615],\n","        [0.9482, 0.0720],\n","        [0.9974, 0.0052],\n","        [0.0058, 0.9928]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3340, grad_fn=<NllLossBackward>)\n","epoch 1991, loss 0.33401548862457275\n","outputs:  tensor([[0.0482, 0.9277],\n","        [0.9561, 0.0614],\n","        [0.9483, 0.0719],\n","        [0.9974, 0.0051],\n","        [0.0058, 0.9928]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3340, grad_fn=<NllLossBackward>)\n","epoch 1992, loss 0.33399802446365356\n","outputs:  tensor([[0.0482, 0.9278],\n","        [0.9561, 0.0614],\n","        [0.9483, 0.0719],\n","        [0.9974, 0.0051],\n","        [0.0058, 0.9928]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3340, grad_fn=<NllLossBackward>)\n","epoch 1993, loss 0.33398061990737915\n","outputs:  tensor([[0.0482, 0.9279],\n","        [0.9562, 0.0613],\n","        [0.9483, 0.0718],\n","        [0.9974, 0.0051],\n","        [0.0058, 0.9928]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3340, grad_fn=<NllLossBackward>)\n","epoch 1994, loss 0.3339632451534271\n","outputs:  tensor([[0.0481, 0.9279],\n","        [0.9562, 0.0613],\n","        [0.9484, 0.0718],\n","        [0.9974, 0.0051],\n","        [0.0058, 0.9928]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3339, grad_fn=<NllLossBackward>)\n","epoch 1995, loss 0.3339459002017975\n","outputs:  tensor([[0.0481, 0.9280],\n","        [0.9562, 0.0612],\n","        [0.9484, 0.0717],\n","        [0.9975, 0.0051],\n","        [0.0058, 0.9929]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3339, grad_fn=<NllLossBackward>)\n","epoch 1996, loss 0.33392858505249023\n","outputs:  tensor([[0.0481, 0.9280],\n","        [0.9563, 0.0612],\n","        [0.9484, 0.0717],\n","        [0.9975, 0.0051],\n","        [0.0058, 0.9929]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3339, grad_fn=<NllLossBackward>)\n","epoch 1997, loss 0.3339112401008606\n","outputs:  tensor([[0.0480, 0.9281],\n","        [0.9563, 0.0611],\n","        [0.9485, 0.0716],\n","        [0.9975, 0.0051],\n","        [0.0058, 0.9929]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3339, grad_fn=<NllLossBackward>)\n","epoch 1998, loss 0.33389395475387573\n","outputs:  tensor([[0.0480, 0.9282],\n","        [0.9563, 0.0611],\n","        [0.9485, 0.0716],\n","        [0.9975, 0.0051],\n","        [0.0058, 0.9929]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3339, grad_fn=<NllLossBackward>)\n","epoch 1999, loss 0.33387666940689087\n","outputs:  tensor([[0.0479, 0.9282],\n","        [0.9564, 0.0610],\n","        [0.9486, 0.0715],\n","        [0.9975, 0.0051],\n","        [0.0058, 0.9929]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3339, grad_fn=<NllLossBackward>)\n","epoch 2000, loss 0.3338594436645508\n","outputs:  tensor([[0.0479, 0.9283],\n","        [0.9564, 0.0610],\n","        [0.9486, 0.0715],\n","        [0.9975, 0.0051],\n","        [0.0058, 0.9929]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3338, grad_fn=<NllLossBackward>)\n","epoch 2001, loss 0.3338421881198883\n","Parameter containing:\n","tensor([[-0.2594, -0.6200,  0.1966],\n","        [-1.0003, -0.7287, -0.0760],\n","        [-1.0136, -0.8900, -0.1243],\n","        [-0.4499, -0.4683, -0.0024]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4978, -0.2864,  0.1638,  0.1255], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8486,  0.7326,  1.1065,  0.1164],\n","        [-0.1812, -0.9451, -0.7838, -0.5623]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3599, -0.5968], requires_grad=True)\n","outputs:  tensor([[0.0479, 0.9283],\n","        [0.9564, 0.0609],\n","        [0.9486, 0.0714],\n","        [0.9975, 0.0051],\n","        [0.0058, 0.9929]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3338, grad_fn=<NllLossBackward>)\n","epoch 2002, loss 0.333825021982193\n","outputs:  tensor([[0.0478, 0.9284],\n","        [0.9565, 0.0609],\n","        [0.9487, 0.0714],\n","        [0.9975, 0.0051],\n","        [0.0058, 0.9929]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3338, grad_fn=<NllLossBackward>)\n","epoch 2003, loss 0.33380791544914246\n","outputs:  tensor([[0.0478, 0.9285],\n","        [0.9565, 0.0608],\n","        [0.9487, 0.0713],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9929]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3338, grad_fn=<NllLossBackward>)\n","epoch 2004, loss 0.33379068970680237\n","outputs:  tensor([[0.0478, 0.9285],\n","        [0.9565, 0.0608],\n","        [0.9487, 0.0713],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3338, grad_fn=<NllLossBackward>)\n","epoch 2005, loss 0.3337736129760742\n","outputs:  tensor([[0.0477, 0.9286],\n","        [0.9566, 0.0607],\n","        [0.9488, 0.0712],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3338, grad_fn=<NllLossBackward>)\n","epoch 2006, loss 0.3337565064430237\n","outputs:  tensor([[0.0477, 0.9286],\n","        [0.9566, 0.0607],\n","        [0.9488, 0.0711],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3337, grad_fn=<NllLossBackward>)\n","epoch 2007, loss 0.33373942971229553\n","outputs:  tensor([[0.0477, 0.9287],\n","        [0.9566, 0.0606],\n","        [0.9488, 0.0711],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3337, grad_fn=<NllLossBackward>)\n","epoch 2008, loss 0.33372238278388977\n","outputs:  tensor([[0.0476, 0.9288],\n","        [0.9567, 0.0606],\n","        [0.9489, 0.0710],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3337, grad_fn=<NllLossBackward>)\n","epoch 2009, loss 0.333705335855484\n","outputs:  tensor([[0.0476, 0.9288],\n","        [0.9567, 0.0605],\n","        [0.9489, 0.0710],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3337, grad_fn=<NllLossBackward>)\n","epoch 2010, loss 0.33368831872940063\n","outputs:  tensor([[0.0475, 0.9289],\n","        [0.9567, 0.0605],\n","        [0.9489, 0.0709],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3337, grad_fn=<NllLossBackward>)\n","epoch 2011, loss 0.3336713910102844\n","outputs:  tensor([[0.0475, 0.9289],\n","        [0.9568, 0.0604],\n","        [0.9490, 0.0709],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3337, grad_fn=<NllLossBackward>)\n","epoch 2012, loss 0.3336544334888458\n","outputs:  tensor([[0.0475, 0.9290],\n","        [0.9568, 0.0604],\n","        [0.9490, 0.0708],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3336, grad_fn=<NllLossBackward>)\n","epoch 2013, loss 0.333637535572052\n","outputs:  tensor([[0.0474, 0.9291],\n","        [0.9568, 0.0603],\n","        [0.9491, 0.0708],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9930]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3336, grad_fn=<NllLossBackward>)\n","epoch 2014, loss 0.3336205780506134\n","outputs:  tensor([[0.0474, 0.9291],\n","        [0.9568, 0.0603],\n","        [0.9491, 0.0707],\n","        [0.9975, 0.0050],\n","        [0.0057, 0.9931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3336, grad_fn=<NllLossBackward>)\n","epoch 2015, loss 0.33360376954078674\n","outputs:  tensor([[0.0474, 0.9292],\n","        [0.9569, 0.0602],\n","        [0.9491, 0.0707],\n","        [0.9975, 0.0049],\n","        [0.0057, 0.9931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3336, grad_fn=<NllLossBackward>)\n","epoch 2016, loss 0.33358684182167053\n","outputs:  tensor([[0.0473, 0.9292],\n","        [0.9569, 0.0602],\n","        [0.9492, 0.0706],\n","        [0.9975, 0.0049],\n","        [0.0057, 0.9931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3336, grad_fn=<NllLossBackward>)\n","epoch 2017, loss 0.3335699737071991\n","outputs:  tensor([[0.0473, 0.9293],\n","        [0.9569, 0.0602],\n","        [0.9492, 0.0706],\n","        [0.9975, 0.0049],\n","        [0.0056, 0.9931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3336, grad_fn=<NllLossBackward>)\n","epoch 2018, loss 0.3335531949996948\n","outputs:  tensor([[0.0473, 0.9294],\n","        [0.9570, 0.0601],\n","        [0.9492, 0.0705],\n","        [0.9975, 0.0049],\n","        [0.0056, 0.9931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3335, grad_fn=<NllLossBackward>)\n","epoch 2019, loss 0.33353644609451294\n","outputs:  tensor([[0.0472, 0.9294],\n","        [0.9570, 0.0601],\n","        [0.9493, 0.0705],\n","        [0.9975, 0.0049],\n","        [0.0056, 0.9931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3335, grad_fn=<NllLossBackward>)\n","epoch 2020, loss 0.3335196375846863\n","outputs:  tensor([[0.0472, 0.9295],\n","        [0.9570, 0.0600],\n","        [0.9493, 0.0704],\n","        [0.9975, 0.0049],\n","        [0.0056, 0.9931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3335, grad_fn=<NllLossBackward>)\n","epoch 2021, loss 0.3335029184818268\n","outputs:  tensor([[0.0472, 0.9295],\n","        [0.9571, 0.0600],\n","        [0.9493, 0.0704],\n","        [0.9975, 0.0049],\n","        [0.0056, 0.9931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3335, grad_fn=<NllLossBackward>)\n","epoch 2022, loss 0.3334861695766449\n","outputs:  tensor([[0.0471, 0.9296],\n","        [0.9571, 0.0599],\n","        [0.9494, 0.0703],\n","        [0.9975, 0.0049],\n","        [0.0056, 0.9931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3335, grad_fn=<NllLossBackward>)\n","epoch 2023, loss 0.3334694802761078\n","outputs:  tensor([[0.0471, 0.9297],\n","        [0.9571, 0.0599],\n","        [0.9494, 0.0703],\n","        [0.9976, 0.0049],\n","        [0.0056, 0.9931]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3335, grad_fn=<NllLossBackward>)\n","epoch 2024, loss 0.3334527909755707\n","outputs:  tensor([[0.0470, 0.9297],\n","        [0.9572, 0.0598],\n","        [0.9494, 0.0702],\n","        [0.9976, 0.0049],\n","        [0.0056, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3334, grad_fn=<NllLossBackward>)\n","epoch 2025, loss 0.33343613147735596\n","outputs:  tensor([[0.0470, 0.9298],\n","        [0.9572, 0.0598],\n","        [0.9495, 0.0702],\n","        [0.9976, 0.0049],\n","        [0.0056, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3334, grad_fn=<NllLossBackward>)\n","epoch 2026, loss 0.33341947197914124\n","outputs:  tensor([[0.0470, 0.9298],\n","        [0.9572, 0.0597],\n","        [0.9495, 0.0701],\n","        [0.9976, 0.0049],\n","        [0.0056, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3334, grad_fn=<NllLossBackward>)\n","epoch 2027, loss 0.33340293169021606\n","outputs:  tensor([[0.0469, 0.9299],\n","        [0.9573, 0.0597],\n","        [0.9495, 0.0701],\n","        [0.9976, 0.0049],\n","        [0.0056, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3334, grad_fn=<NllLossBackward>)\n","epoch 2028, loss 0.3333863615989685\n","outputs:  tensor([[0.0469, 0.9299],\n","        [0.9573, 0.0596],\n","        [0.9496, 0.0700],\n","        [0.9976, 0.0048],\n","        [0.0056, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3334, grad_fn=<NllLossBackward>)\n","epoch 2029, loss 0.33336973190307617\n","outputs:  tensor([[0.0469, 0.9300],\n","        [0.9573, 0.0596],\n","        [0.9496, 0.0700],\n","        [0.9976, 0.0048],\n","        [0.0056, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3334, grad_fn=<NllLossBackward>)\n","epoch 2030, loss 0.333353191614151\n","outputs:  tensor([[0.0468, 0.9301],\n","        [0.9574, 0.0595],\n","        [0.9496, 0.0699],\n","        [0.9976, 0.0048],\n","        [0.0056, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3333, grad_fn=<NllLossBackward>)\n","epoch 2031, loss 0.3333367705345154\n","outputs:  tensor([[0.0468, 0.9301],\n","        [0.9574, 0.0595],\n","        [0.9497, 0.0699],\n","        [0.9976, 0.0048],\n","        [0.0055, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3333, grad_fn=<NllLossBackward>)\n","epoch 2032, loss 0.3333202302455902\n","outputs:  tensor([[0.0468, 0.9302],\n","        [0.9574, 0.0594],\n","        [0.9497, 0.0698],\n","        [0.9976, 0.0048],\n","        [0.0055, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3333, grad_fn=<NllLossBackward>)\n","epoch 2033, loss 0.3333037197589874\n","outputs:  tensor([[0.0467, 0.9302],\n","        [0.9574, 0.0594],\n","        [0.9497, 0.0698],\n","        [0.9976, 0.0048],\n","        [0.0055, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3333, grad_fn=<NllLossBackward>)\n","epoch 2034, loss 0.3332873284816742\n","outputs:  tensor([[0.0467, 0.9303],\n","        [0.9575, 0.0593],\n","        [0.9498, 0.0697],\n","        [0.9976, 0.0048],\n","        [0.0055, 0.9932]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3333, grad_fn=<NllLossBackward>)\n","epoch 2035, loss 0.3332709074020386\n","outputs:  tensor([[0.0467, 0.9303],\n","        [0.9575, 0.0593],\n","        [0.9498, 0.0696],\n","        [0.9976, 0.0048],\n","        [0.0055, 0.9933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3333, grad_fn=<NllLossBackward>)\n","epoch 2036, loss 0.33325448632240295\n","outputs:  tensor([[0.0466, 0.9304],\n","        [0.9575, 0.0593],\n","        [0.9498, 0.0696],\n","        [0.9976, 0.0048],\n","        [0.0055, 0.9933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3332, grad_fn=<NllLossBackward>)\n","epoch 2037, loss 0.33323806524276733\n","outputs:  tensor([[0.0466, 0.9305],\n","        [0.9576, 0.0592],\n","        [0.9499, 0.0695],\n","        [0.9976, 0.0048],\n","        [0.0055, 0.9933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3332, grad_fn=<NllLossBackward>)\n","epoch 2038, loss 0.33322176337242126\n","outputs:  tensor([[0.0466, 0.9305],\n","        [0.9576, 0.0592],\n","        [0.9499, 0.0695],\n","        [0.9976, 0.0048],\n","        [0.0055, 0.9933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3332, grad_fn=<NllLossBackward>)\n","epoch 2039, loss 0.3332054615020752\n","outputs:  tensor([[0.0465, 0.9306],\n","        [0.9576, 0.0591],\n","        [0.9500, 0.0694],\n","        [0.9976, 0.0048],\n","        [0.0055, 0.9933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3332, grad_fn=<NllLossBackward>)\n","epoch 2040, loss 0.33318910002708435\n","outputs:  tensor([[0.0465, 0.9306],\n","        [0.9577, 0.0591],\n","        [0.9500, 0.0694],\n","        [0.9976, 0.0048],\n","        [0.0055, 0.9933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3332, grad_fn=<NllLossBackward>)\n","epoch 2041, loss 0.3331727981567383\n","outputs:  tensor([[0.0464, 0.9307],\n","        [0.9577, 0.0590],\n","        [0.9500, 0.0693],\n","        [0.9976, 0.0047],\n","        [0.0055, 0.9933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3332, grad_fn=<NllLossBackward>)\n","epoch 2042, loss 0.333156555891037\n","outputs:  tensor([[0.0464, 0.9307],\n","        [0.9577, 0.0590],\n","        [0.9501, 0.0693],\n","        [0.9976, 0.0047],\n","        [0.0055, 0.9933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3331, grad_fn=<NllLossBackward>)\n","epoch 2043, loss 0.3331403136253357\n","outputs:  tensor([[0.0464, 0.9308],\n","        [0.9578, 0.0589],\n","        [0.9501, 0.0692],\n","        [0.9976, 0.0047],\n","        [0.0055, 0.9933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3331, grad_fn=<NllLossBackward>)\n","epoch 2044, loss 0.3331241309642792\n","outputs:  tensor([[0.0463, 0.9309],\n","        [0.9578, 0.0589],\n","        [0.9501, 0.0692],\n","        [0.9976, 0.0047],\n","        [0.0055, 0.9933]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3331, grad_fn=<NllLossBackward>)\n","epoch 2045, loss 0.3331078886985779\n","outputs:  tensor([[0.0463, 0.9309],\n","        [0.9578, 0.0588],\n","        [0.9502, 0.0691],\n","        [0.9976, 0.0047],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3331, grad_fn=<NllLossBackward>)\n","epoch 2046, loss 0.333091676235199\n","outputs:  tensor([[0.0463, 0.9310],\n","        [0.9579, 0.0588],\n","        [0.9502, 0.0691],\n","        [0.9976, 0.0047],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3331, grad_fn=<NllLossBackward>)\n","epoch 2047, loss 0.3330755829811096\n","outputs:  tensor([[0.0462, 0.9310],\n","        [0.9579, 0.0587],\n","        [0.9502, 0.0690],\n","        [0.9976, 0.0047],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3331, grad_fn=<NllLossBackward>)\n","epoch 2048, loss 0.3330594301223755\n","outputs:  tensor([[0.0462, 0.9311],\n","        [0.9579, 0.0587],\n","        [0.9503, 0.0690],\n","        [0.9976, 0.0047],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3330, grad_fn=<NllLossBackward>)\n","epoch 2049, loss 0.33304327726364136\n","outputs:  tensor([[0.0462, 0.9311],\n","        [0.9579, 0.0587],\n","        [0.9503, 0.0689],\n","        [0.9976, 0.0047],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3330, grad_fn=<NllLossBackward>)\n","epoch 2050, loss 0.333027184009552\n","outputs:  tensor([[0.0461, 0.9312],\n","        [0.9580, 0.0586],\n","        [0.9503, 0.0689],\n","        [0.9976, 0.0047],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3330, grad_fn=<NllLossBackward>)\n","epoch 2051, loss 0.3330111503601074\n","Parameter containing:\n","tensor([[-0.2618, -0.6240,  0.1965],\n","        [-1.0047, -0.7361, -0.0760],\n","        [-1.0183, -0.8979, -0.1244],\n","        [-0.4519, -0.4715, -0.0024]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.4991, -0.2840,  0.1664,  0.1265], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8519,  0.7370,  1.1121,  0.1192],\n","        [-0.1859, -0.9513, -0.7915, -0.5662]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3611, -0.5984], requires_grad=True)\n","outputs:  tensor([[0.0461, 0.9313],\n","        [0.9580, 0.0586],\n","        [0.9504, 0.0688],\n","        [0.9976, 0.0047],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3330, grad_fn=<NllLossBackward>)\n","epoch 2052, loss 0.33299508690834045\n","outputs:  tensor([[0.0461, 0.9313],\n","        [0.9580, 0.0585],\n","        [0.9504, 0.0688],\n","        [0.9977, 0.0047],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3330, grad_fn=<NllLossBackward>)\n","epoch 2053, loss 0.3329790532588959\n","outputs:  tensor([[0.0460, 0.9314],\n","        [0.9581, 0.0585],\n","        [0.9504, 0.0687],\n","        [0.9977, 0.0047],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3330, grad_fn=<NllLossBackward>)\n","epoch 2054, loss 0.33296307921409607\n","outputs:  tensor([[0.0460, 0.9314],\n","        [0.9581, 0.0584],\n","        [0.9505, 0.0687],\n","        [0.9977, 0.0047],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3329, grad_fn=<NllLossBackward>)\n","epoch 2055, loss 0.33294710516929626\n","outputs:  tensor([[0.0460, 0.9315],\n","        [0.9581, 0.0584],\n","        [0.9505, 0.0686],\n","        [0.9977, 0.0046],\n","        [0.0054, 0.9934]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3329, grad_fn=<NllLossBackward>)\n","epoch 2056, loss 0.33293113112449646\n","outputs:  tensor([[0.0459, 0.9315],\n","        [0.9582, 0.0583],\n","        [0.9505, 0.0686],\n","        [0.9977, 0.0046],\n","        [0.0054, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3329, grad_fn=<NllLossBackward>)\n","epoch 2057, loss 0.33291521668434143\n","outputs:  tensor([[0.0459, 0.9316],\n","        [0.9582, 0.0583],\n","        [0.9506, 0.0685],\n","        [0.9977, 0.0046],\n","        [0.0054, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3329, grad_fn=<NllLossBackward>)\n","epoch 2058, loss 0.3328993320465088\n","outputs:  tensor([[0.0459, 0.9316],\n","        [0.9582, 0.0582],\n","        [0.9506, 0.0685],\n","        [0.9977, 0.0046],\n","        [0.0054, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3329, grad_fn=<NllLossBackward>)\n","epoch 2059, loss 0.33288341760635376\n","outputs:  tensor([[0.0458, 0.9317],\n","        [0.9582, 0.0582],\n","        [0.9506, 0.0684],\n","        [0.9977, 0.0046],\n","        [0.0054, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3329, grad_fn=<NllLossBackward>)\n","epoch 2060, loss 0.3328675329685211\n","outputs:  tensor([[0.0458, 0.9318],\n","        [0.9583, 0.0582],\n","        [0.9507, 0.0684],\n","        [0.9977, 0.0046],\n","        [0.0053, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3329, grad_fn=<NllLossBackward>)\n","epoch 2061, loss 0.33285170793533325\n","outputs:  tensor([[0.0458, 0.9318],\n","        [0.9583, 0.0581],\n","        [0.9507, 0.0683],\n","        [0.9977, 0.0046],\n","        [0.0053, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3328, grad_fn=<NllLossBackward>)\n","epoch 2062, loss 0.332835853099823\n","outputs:  tensor([[0.0457, 0.9319],\n","        [0.9583, 0.0581],\n","        [0.9507, 0.0683],\n","        [0.9977, 0.0046],\n","        [0.0053, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3328, grad_fn=<NllLossBackward>)\n","epoch 2063, loss 0.33282002806663513\n","outputs:  tensor([[0.0457, 0.9319],\n","        [0.9584, 0.0580],\n","        [0.9508, 0.0682],\n","        [0.9977, 0.0046],\n","        [0.0053, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3328, grad_fn=<NllLossBackward>)\n","epoch 2064, loss 0.33280426263809204\n","outputs:  tensor([[0.0457, 0.9320],\n","        [0.9584, 0.0580],\n","        [0.9508, 0.0682],\n","        [0.9977, 0.0046],\n","        [0.0053, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3328, grad_fn=<NllLossBackward>)\n","epoch 2065, loss 0.33278846740722656\n","outputs:  tensor([[0.0456, 0.9320],\n","        [0.9584, 0.0579],\n","        [0.9508, 0.0682],\n","        [0.9977, 0.0046],\n","        [0.0053, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3328, grad_fn=<NllLossBackward>)\n","epoch 2066, loss 0.33277279138565063\n","outputs:  tensor([[0.0456, 0.9321],\n","        [0.9585, 0.0579],\n","        [0.9509, 0.0681],\n","        [0.9977, 0.0046],\n","        [0.0053, 0.9935]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3328, grad_fn=<NllLossBackward>)\n","epoch 2067, loss 0.33275699615478516\n","outputs:  tensor([[0.0456, 0.9321],\n","        [0.9585, 0.0578],\n","        [0.9509, 0.0681],\n","        [0.9977, 0.0046],\n","        [0.0053, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3327, grad_fn=<NllLossBackward>)\n","epoch 2068, loss 0.33274132013320923\n","outputs:  tensor([[0.0455, 0.9322],\n","        [0.9585, 0.0578],\n","        [0.9509, 0.0680],\n","        [0.9977, 0.0045],\n","        [0.0053, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3327, grad_fn=<NllLossBackward>)\n","epoch 2069, loss 0.3327256143093109\n","outputs:  tensor([[0.0455, 0.9322],\n","        [0.9585, 0.0577],\n","        [0.9510, 0.0680],\n","        [0.9977, 0.0045],\n","        [0.0053, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3327, grad_fn=<NllLossBackward>)\n","epoch 2070, loss 0.3327099680900574\n","outputs:  tensor([[0.0455, 0.9323],\n","        [0.9586, 0.0577],\n","        [0.9510, 0.0679],\n","        [0.9977, 0.0045],\n","        [0.0053, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3327, grad_fn=<NllLossBackward>)\n","epoch 2071, loss 0.3326943516731262\n","outputs:  tensor([[0.0454, 0.9324],\n","        [0.9586, 0.0577],\n","        [0.9510, 0.0679],\n","        [0.9977, 0.0045],\n","        [0.0053, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3327, grad_fn=<NllLossBackward>)\n","epoch 2072, loss 0.3326787054538727\n","outputs:  tensor([[0.0454, 0.9324],\n","        [0.9586, 0.0576],\n","        [0.9511, 0.0678],\n","        [0.9977, 0.0045],\n","        [0.0053, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3327, grad_fn=<NllLossBackward>)\n","epoch 2073, loss 0.3326631188392639\n","outputs:  tensor([[0.0454, 0.9325],\n","        [0.9587, 0.0576],\n","        [0.9511, 0.0678],\n","        [0.9977, 0.0045],\n","        [0.0053, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3326, grad_fn=<NllLossBackward>)\n","epoch 2074, loss 0.33264756202697754\n","outputs:  tensor([[0.0453, 0.9325],\n","        [0.9587, 0.0575],\n","        [0.9511, 0.0677],\n","        [0.9977, 0.0045],\n","        [0.0053, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3326, grad_fn=<NllLossBackward>)\n","epoch 2075, loss 0.3326319754123688\n","outputs:  tensor([[0.0453, 0.9326],\n","        [0.9587, 0.0575],\n","        [0.9512, 0.0677],\n","        [0.9977, 0.0045],\n","        [0.0052, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3326, grad_fn=<NllLossBackward>)\n","epoch 2076, loss 0.3326164782047272\n","outputs:  tensor([[0.0453, 0.9326],\n","        [0.9588, 0.0574],\n","        [0.9512, 0.0676],\n","        [0.9977, 0.0045],\n","        [0.0052, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3326, grad_fn=<NllLossBackward>)\n","epoch 2077, loss 0.33260098099708557\n","outputs:  tensor([[0.0452, 0.9327],\n","        [0.9588, 0.0574],\n","        [0.9512, 0.0676],\n","        [0.9977, 0.0045],\n","        [0.0052, 0.9936]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3326, grad_fn=<NllLossBackward>)\n","epoch 2078, loss 0.33258548378944397\n","outputs:  tensor([[0.0452, 0.9327],\n","        [0.9588, 0.0573],\n","        [0.9512, 0.0675],\n","        [0.9977, 0.0045],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3326, grad_fn=<NllLossBackward>)\n","epoch 2079, loss 0.33257001638412476\n","outputs:  tensor([[0.0452, 0.9328],\n","        [0.9588, 0.0573],\n","        [0.9513, 0.0675],\n","        [0.9977, 0.0045],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3326, grad_fn=<NllLossBackward>)\n","epoch 2080, loss 0.33255457878112793\n","outputs:  tensor([[0.0451, 0.9328],\n","        [0.9589, 0.0573],\n","        [0.9513, 0.0674],\n","        [0.9977, 0.0045],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3325, grad_fn=<NllLossBackward>)\n","epoch 2081, loss 0.33253905177116394\n","outputs:  tensor([[0.0451, 0.9329],\n","        [0.9589, 0.0572],\n","        [0.9513, 0.0674],\n","        [0.9977, 0.0045],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3325, grad_fn=<NllLossBackward>)\n","epoch 2082, loss 0.3325237035751343\n","outputs:  tensor([[0.0451, 0.9330],\n","        [0.9589, 0.0572],\n","        [0.9514, 0.0673],\n","        [0.9977, 0.0045],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3325, grad_fn=<NllLossBackward>)\n","epoch 2083, loss 0.33250826597213745\n","outputs:  tensor([[0.0450, 0.9330],\n","        [0.9590, 0.0571],\n","        [0.9514, 0.0673],\n","        [0.9978, 0.0044],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3325, grad_fn=<NllLossBackward>)\n","epoch 2084, loss 0.3324929475784302\n","outputs:  tensor([[0.0450, 0.9331],\n","        [0.9590, 0.0571],\n","        [0.9514, 0.0672],\n","        [0.9978, 0.0044],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3325, grad_fn=<NllLossBackward>)\n","epoch 2085, loss 0.3324775695800781\n","outputs:  tensor([[0.0450, 0.9331],\n","        [0.9590, 0.0570],\n","        [0.9515, 0.0672],\n","        [0.9978, 0.0044],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3325, grad_fn=<NllLossBackward>)\n","epoch 2086, loss 0.3324623107910156\n","outputs:  tensor([[0.0449, 0.9332],\n","        [0.9591, 0.0570],\n","        [0.9515, 0.0671],\n","        [0.9978, 0.0044],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3324, grad_fn=<NllLossBackward>)\n","epoch 2087, loss 0.33244696259498596\n","outputs:  tensor([[0.0449, 0.9332],\n","        [0.9591, 0.0570],\n","        [0.9515, 0.0671],\n","        [0.9978, 0.0044],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3324, grad_fn=<NllLossBackward>)\n","epoch 2088, loss 0.3324316442012787\n","outputs:  tensor([[0.0449, 0.9333],\n","        [0.9591, 0.0569],\n","        [0.9516, 0.0670],\n","        [0.9978, 0.0044],\n","        [0.0052, 0.9937]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3324, grad_fn=<NllLossBackward>)\n","epoch 2089, loss 0.3324163854122162\n","outputs:  tensor([[0.0448, 0.9333],\n","        [0.9591, 0.0569],\n","        [0.9516, 0.0670],\n","        [0.9978, 0.0044],\n","        [0.0052, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3324, grad_fn=<NllLossBackward>)\n","epoch 2090, loss 0.33240121603012085\n","outputs:  tensor([[0.0448, 0.9334],\n","        [0.9592, 0.0568],\n","        [0.9516, 0.0669],\n","        [0.9978, 0.0044],\n","        [0.0052, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3324, grad_fn=<NllLossBackward>)\n","epoch 2091, loss 0.33238592743873596\n","outputs:  tensor([[0.0448, 0.9334],\n","        [0.9592, 0.0568],\n","        [0.9517, 0.0669],\n","        [0.9978, 0.0044],\n","        [0.0051, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3324, grad_fn=<NllLossBackward>)\n","epoch 2092, loss 0.33237069845199585\n","outputs:  tensor([[0.0447, 0.9335],\n","        [0.9592, 0.0567],\n","        [0.9517, 0.0668],\n","        [0.9978, 0.0044],\n","        [0.0051, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3324, grad_fn=<NllLossBackward>)\n","epoch 2093, loss 0.3323555588722229\n","outputs:  tensor([[0.0447, 0.9335],\n","        [0.9593, 0.0567],\n","        [0.9517, 0.0668],\n","        [0.9978, 0.0044],\n","        [0.0051, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3323, grad_fn=<NllLossBackward>)\n","epoch 2094, loss 0.33234041929244995\n","outputs:  tensor([[0.0447, 0.9336],\n","        [0.9593, 0.0566],\n","        [0.9518, 0.0668],\n","        [0.9978, 0.0044],\n","        [0.0051, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3323, grad_fn=<NllLossBackward>)\n","epoch 2095, loss 0.332325279712677\n","outputs:  tensor([[0.0446, 0.9337],\n","        [0.9593, 0.0566],\n","        [0.9518, 0.0667],\n","        [0.9978, 0.0044],\n","        [0.0051, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3323, grad_fn=<NllLossBackward>)\n","epoch 2096, loss 0.33231014013290405\n","outputs:  tensor([[0.0446, 0.9337],\n","        [0.9593, 0.0566],\n","        [0.9518, 0.0667],\n","        [0.9978, 0.0044],\n","        [0.0051, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3323, grad_fn=<NllLossBackward>)\n","epoch 2097, loss 0.3322950303554535\n","outputs:  tensor([[0.0446, 0.9338],\n","        [0.9594, 0.0565],\n","        [0.9519, 0.0666],\n","        [0.9978, 0.0044],\n","        [0.0051, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3323, grad_fn=<NllLossBackward>)\n","epoch 2098, loss 0.33227992057800293\n","outputs:  tensor([[0.0445, 0.9338],\n","        [0.9594, 0.0565],\n","        [0.9519, 0.0666],\n","        [0.9978, 0.0043],\n","        [0.0051, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3323, grad_fn=<NllLossBackward>)\n","epoch 2099, loss 0.3322649598121643\n","outputs:  tensor([[0.0445, 0.9339],\n","        [0.9594, 0.0564],\n","        [0.9519, 0.0665],\n","        [0.9978, 0.0043],\n","        [0.0051, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3322, grad_fn=<NllLossBackward>)\n","epoch 2100, loss 0.33224982023239136\n","outputs:  tensor([[0.0445, 0.9339],\n","        [0.9595, 0.0564],\n","        [0.9520, 0.0665],\n","        [0.9978, 0.0043],\n","        [0.0051, 0.9938]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3322, grad_fn=<NllLossBackward>)\n","epoch 2101, loss 0.3322348892688751\n","Parameter containing:\n","tensor([[-0.2640, -0.6278,  0.1964],\n","        [-1.0089, -0.7432, -0.0760],\n","        [-1.0228, -0.9055, -0.1244],\n","        [-0.4537, -0.4747, -0.0024]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5004, -0.2817,  0.1689,  0.1275], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8551,  0.7412,  1.1174,  0.1218],\n","        [-0.1904, -0.9573, -0.7990, -0.5700]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3623, -0.5999], requires_grad=True)\n","outputs:  tensor([[0.0444, 0.9340],\n","        [0.9595, 0.0563],\n","        [0.9520, 0.0664],\n","        [0.9978, 0.0043],\n","        [0.0051, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3322, grad_fn=<NllLossBackward>)\n","epoch 2102, loss 0.33221983909606934\n","outputs:  tensor([[0.0444, 0.9340],\n","        [0.9595, 0.0563],\n","        [0.9520, 0.0664],\n","        [0.9978, 0.0043],\n","        [0.0051, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3322, grad_fn=<NllLossBackward>)\n","epoch 2103, loss 0.3322048783302307\n","outputs:  tensor([[0.0444, 0.9341],\n","        [0.9595, 0.0563],\n","        [0.9521, 0.0663],\n","        [0.9978, 0.0043],\n","        [0.0051, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3322, grad_fn=<NllLossBackward>)\n","epoch 2104, loss 0.3321898877620697\n","outputs:  tensor([[0.0443, 0.9341],\n","        [0.9596, 0.0562],\n","        [0.9521, 0.0663],\n","        [0.9978, 0.0043],\n","        [0.0051, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3322, grad_fn=<NllLossBackward>)\n","epoch 2105, loss 0.33217495679855347\n","outputs:  tensor([[0.0443, 0.9342],\n","        [0.9596, 0.0562],\n","        [0.9521, 0.0662],\n","        [0.9978, 0.0043],\n","        [0.0051, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3322, grad_fn=<NllLossBackward>)\n","epoch 2106, loss 0.33215999603271484\n","outputs:  tensor([[0.0443, 0.9342],\n","        [0.9596, 0.0561],\n","        [0.9521, 0.0662],\n","        [0.9978, 0.0043],\n","        [0.0051, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3321, grad_fn=<NllLossBackward>)\n","epoch 2107, loss 0.3321450650691986\n","outputs:  tensor([[0.0442, 0.9343],\n","        [0.9597, 0.0561],\n","        [0.9522, 0.0661],\n","        [0.9978, 0.0043],\n","        [0.0050, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3321, grad_fn=<NllLossBackward>)\n","epoch 2108, loss 0.33213022351264954\n","outputs:  tensor([[0.0442, 0.9343],\n","        [0.9597, 0.0560],\n","        [0.9522, 0.0661],\n","        [0.9978, 0.0043],\n","        [0.0050, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3321, grad_fn=<NllLossBackward>)\n","epoch 2109, loss 0.33211541175842285\n","outputs:  tensor([[0.0442, 0.9344],\n","        [0.9597, 0.0560],\n","        [0.9522, 0.0660],\n","        [0.9978, 0.0043],\n","        [0.0050, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3321, grad_fn=<NllLossBackward>)\n","epoch 2110, loss 0.3321005702018738\n","outputs:  tensor([[0.0441, 0.9344],\n","        [0.9597, 0.0560],\n","        [0.9523, 0.0660],\n","        [0.9978, 0.0043],\n","        [0.0050, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3321, grad_fn=<NllLossBackward>)\n","epoch 2111, loss 0.3320856988430023\n","outputs:  tensor([[0.0441, 0.9345],\n","        [0.9598, 0.0559],\n","        [0.9523, 0.0660],\n","        [0.9978, 0.0043],\n","        [0.0050, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3321, grad_fn=<NllLossBackward>)\n","epoch 2112, loss 0.332070916891098\n","outputs:  tensor([[0.0441, 0.9345],\n","        [0.9598, 0.0559],\n","        [0.9523, 0.0659],\n","        [0.9978, 0.0043],\n","        [0.0050, 0.9939]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3321, grad_fn=<NllLossBackward>)\n","epoch 2113, loss 0.3320561349391937\n","outputs:  tensor([[0.0441, 0.9346],\n","        [0.9598, 0.0558],\n","        [0.9524, 0.0659],\n","        [0.9978, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n","epoch 2114, loss 0.3320414125919342\n","outputs:  tensor([[0.0440, 0.9346],\n","        [0.9599, 0.0558],\n","        [0.9524, 0.0658],\n","        [0.9978, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n","epoch 2115, loss 0.3320266306400299\n","outputs:  tensor([[0.0440, 0.9347],\n","        [0.9599, 0.0557],\n","        [0.9524, 0.0658],\n","        [0.9978, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n","epoch 2116, loss 0.332011878490448\n","outputs:  tensor([[0.0440, 0.9347],\n","        [0.9599, 0.0557],\n","        [0.9525, 0.0657],\n","        [0.9979, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n","epoch 2117, loss 0.3319971561431885\n","outputs:  tensor([[0.0439, 0.9348],\n","        [0.9599, 0.0557],\n","        [0.9525, 0.0657],\n","        [0.9979, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n","epoch 2118, loss 0.33198246359825134\n","outputs:  tensor([[0.0439, 0.9349],\n","        [0.9600, 0.0556],\n","        [0.9525, 0.0656],\n","        [0.9979, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n","epoch 2119, loss 0.331967830657959\n","outputs:  tensor([[0.0439, 0.9349],\n","        [0.9600, 0.0556],\n","        [0.9526, 0.0656],\n","        [0.9979, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3320, grad_fn=<NllLossBackward>)\n","epoch 2120, loss 0.3319531977176666\n","outputs:  tensor([[0.0438, 0.9350],\n","        [0.9600, 0.0555],\n","        [0.9526, 0.0655],\n","        [0.9979, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3319, grad_fn=<NllLossBackward>)\n","epoch 2121, loss 0.33193856477737427\n","outputs:  tensor([[0.0438, 0.9350],\n","        [0.9601, 0.0555],\n","        [0.9526, 0.0655],\n","        [0.9979, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3319, grad_fn=<NllLossBackward>)\n","epoch 2122, loss 0.3319239616394043\n","outputs:  tensor([[0.0438, 0.9351],\n","        [0.9601, 0.0555],\n","        [0.9526, 0.0654],\n","        [0.9979, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3319, grad_fn=<NllLossBackward>)\n","epoch 2123, loss 0.3319093883037567\n","outputs:  tensor([[0.0437, 0.9351],\n","        [0.9601, 0.0554],\n","        [0.9527, 0.0654],\n","        [0.9979, 0.0042],\n","        [0.0050, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3319, grad_fn=<NllLossBackward>)\n","epoch 2124, loss 0.33189478516578674\n","outputs:  tensor([[0.0437, 0.9352],\n","        [0.9601, 0.0554],\n","        [0.9527, 0.0654],\n","        [0.9979, 0.0042],\n","        [0.0049, 0.9940]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3319, grad_fn=<NllLossBackward>)\n","epoch 2125, loss 0.33188024163246155\n","outputs:  tensor([[0.0437, 0.9352],\n","        [0.9602, 0.0553],\n","        [0.9527, 0.0653],\n","        [0.9979, 0.0042],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3319, grad_fn=<NllLossBackward>)\n","epoch 2126, loss 0.33186569809913635\n","outputs:  tensor([[0.0436, 0.9353],\n","        [0.9602, 0.0553],\n","        [0.9528, 0.0653],\n","        [0.9979, 0.0042],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3319, grad_fn=<NllLossBackward>)\n","epoch 2127, loss 0.33185118436813354\n","outputs:  tensor([[0.0436, 0.9353],\n","        [0.9602, 0.0552],\n","        [0.9528, 0.0652],\n","        [0.9979, 0.0042],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3318, grad_fn=<NllLossBackward>)\n","epoch 2128, loss 0.33183664083480835\n","outputs:  tensor([[0.0436, 0.9354],\n","        [0.9603, 0.0552],\n","        [0.9528, 0.0652],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3318, grad_fn=<NllLossBackward>)\n","epoch 2129, loss 0.3318222165107727\n","outputs:  tensor([[0.0435, 0.9354],\n","        [0.9603, 0.0552],\n","        [0.9529, 0.0651],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3318, grad_fn=<NllLossBackward>)\n","epoch 2130, loss 0.3318077027797699\n","outputs:  tensor([[0.0435, 0.9355],\n","        [0.9603, 0.0551],\n","        [0.9529, 0.0651],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3318, grad_fn=<NllLossBackward>)\n","epoch 2131, loss 0.33179330825805664\n","outputs:  tensor([[0.0435, 0.9355],\n","        [0.9603, 0.0551],\n","        [0.9529, 0.0650],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3318, grad_fn=<NllLossBackward>)\n","epoch 2132, loss 0.3317789137363434\n","outputs:  tensor([[0.0435, 0.9356],\n","        [0.9604, 0.0550],\n","        [0.9530, 0.0650],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3318, grad_fn=<NllLossBackward>)\n","epoch 2133, loss 0.3317645192146301\n","outputs:  tensor([[0.0434, 0.9356],\n","        [0.9604, 0.0550],\n","        [0.9530, 0.0649],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3318, grad_fn=<NllLossBackward>)\n","epoch 2134, loss 0.3317500948905945\n","outputs:  tensor([[0.0434, 0.9357],\n","        [0.9604, 0.0550],\n","        [0.9530, 0.0649],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3317, grad_fn=<NllLossBackward>)\n","epoch 2135, loss 0.3317357897758484\n","outputs:  tensor([[0.0434, 0.9357],\n","        [0.9604, 0.0549],\n","        [0.9530, 0.0649],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3317, grad_fn=<NllLossBackward>)\n","epoch 2136, loss 0.33172139525413513\n","outputs:  tensor([[0.0433, 0.9358],\n","        [0.9605, 0.0549],\n","        [0.9531, 0.0648],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3317, grad_fn=<NllLossBackward>)\n","epoch 2137, loss 0.33170706033706665\n","outputs:  tensor([[0.0433, 0.9358],\n","        [0.9605, 0.0548],\n","        [0.9531, 0.0648],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9941]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3317, grad_fn=<NllLossBackward>)\n","epoch 2138, loss 0.33169275522232056\n","outputs:  tensor([[0.0433, 0.9359],\n","        [0.9605, 0.0548],\n","        [0.9531, 0.0647],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3317, grad_fn=<NllLossBackward>)\n","epoch 2139, loss 0.33167847990989685\n","outputs:  tensor([[0.0432, 0.9359],\n","        [0.9606, 0.0547],\n","        [0.9532, 0.0647],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3317, grad_fn=<NllLossBackward>)\n","epoch 2140, loss 0.33166423439979553\n","outputs:  tensor([[0.0432, 0.9360],\n","        [0.9606, 0.0547],\n","        [0.9532, 0.0646],\n","        [0.9979, 0.0041],\n","        [0.0049, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3316, grad_fn=<NllLossBackward>)\n","epoch 2141, loss 0.33164992928504944\n","outputs:  tensor([[0.0432, 0.9360],\n","        [0.9606, 0.0547],\n","        [0.9532, 0.0646],\n","        [0.9979, 0.0041],\n","        [0.0048, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3316, grad_fn=<NllLossBackward>)\n","epoch 2142, loss 0.3316357135772705\n","outputs:  tensor([[0.0431, 0.9361],\n","        [0.9606, 0.0546],\n","        [0.9533, 0.0645],\n","        [0.9979, 0.0041],\n","        [0.0048, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3316, grad_fn=<NllLossBackward>)\n","epoch 2143, loss 0.3316214978694916\n","outputs:  tensor([[0.0431, 0.9361],\n","        [0.9607, 0.0546],\n","        [0.9533, 0.0645],\n","        [0.9979, 0.0041],\n","        [0.0048, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3316, grad_fn=<NllLossBackward>)\n","epoch 2144, loss 0.33160728216171265\n","outputs:  tensor([[0.0431, 0.9362],\n","        [0.9607, 0.0545],\n","        [0.9533, 0.0644],\n","        [0.9979, 0.0041],\n","        [0.0048, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3316, grad_fn=<NllLossBackward>)\n","epoch 2145, loss 0.3315931260585785\n","outputs:  tensor([[0.0431, 0.9362],\n","        [0.9607, 0.0545],\n","        [0.9533, 0.0644],\n","        [0.9979, 0.0040],\n","        [0.0048, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3316, grad_fn=<NllLossBackward>)\n","epoch 2146, loss 0.33157896995544434\n","outputs:  tensor([[0.0430, 0.9363],\n","        [0.9607, 0.0545],\n","        [0.9534, 0.0644],\n","        [0.9979, 0.0040],\n","        [0.0048, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3316, grad_fn=<NllLossBackward>)\n","epoch 2147, loss 0.33156484365463257\n","outputs:  tensor([[0.0430, 0.9363],\n","        [0.9608, 0.0544],\n","        [0.9534, 0.0643],\n","        [0.9979, 0.0040],\n","        [0.0048, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3316, grad_fn=<NllLossBackward>)\n","epoch 2148, loss 0.3315507471561432\n","outputs:  tensor([[0.0430, 0.9364],\n","        [0.9608, 0.0544],\n","        [0.9534, 0.0643],\n","        [0.9979, 0.0040],\n","        [0.0048, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3315, grad_fn=<NllLossBackward>)\n","epoch 2149, loss 0.3315366506576538\n","outputs:  tensor([[0.0429, 0.9364],\n","        [0.9608, 0.0543],\n","        [0.9535, 0.0642],\n","        [0.9979, 0.0040],\n","        [0.0048, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3315, grad_fn=<NllLossBackward>)\n","epoch 2150, loss 0.33152255415916443\n","outputs:  tensor([[0.0429, 0.9365],\n","        [0.9609, 0.0543],\n","        [0.9535, 0.0642],\n","        [0.9979, 0.0040],\n","        [0.0048, 0.9942]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3315, grad_fn=<NllLossBackward>)\n","epoch 2151, loss 0.33150845766067505\n","Parameter containing:\n","tensor([[-0.2662, -0.6315,  0.1964],\n","        [-1.0130, -0.7500, -0.0760],\n","        [-1.0272, -0.9129, -0.1245],\n","        [-0.4555, -0.4777, -0.0023]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5016, -0.2795,  0.1713,  0.1285], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8583,  0.7453,  1.1226,  0.1244],\n","        [-0.1948, -0.9631, -0.8062, -0.5736]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3634, -0.6014], requires_grad=True)\n","outputs:  tensor([[0.0429, 0.9365],\n","        [0.9609, 0.0543],\n","        [0.9535, 0.0641],\n","        [0.9980, 0.0040],\n","        [0.0048, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3315, grad_fn=<NllLossBackward>)\n","epoch 2152, loss 0.33149439096450806\n","outputs:  tensor([[0.0428, 0.9366],\n","        [0.9609, 0.0542],\n","        [0.9536, 0.0641],\n","        [0.9980, 0.0040],\n","        [0.0048, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3315, grad_fn=<NllLossBackward>)\n","epoch 2153, loss 0.33148035407066345\n","outputs:  tensor([[0.0428, 0.9366],\n","        [0.9609, 0.0542],\n","        [0.9536, 0.0640],\n","        [0.9980, 0.0040],\n","        [0.0048, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3315, grad_fn=<NllLossBackward>)\n","epoch 2154, loss 0.3314663767814636\n","outputs:  tensor([[0.0428, 0.9367],\n","        [0.9610, 0.0541],\n","        [0.9536, 0.0640],\n","        [0.9980, 0.0040],\n","        [0.0048, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3315, grad_fn=<NllLossBackward>)\n","epoch 2155, loss 0.3314524292945862\n","outputs:  tensor([[0.0428, 0.9367],\n","        [0.9610, 0.0541],\n","        [0.9536, 0.0640],\n","        [0.9980, 0.0040],\n","        [0.0048, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n","epoch 2156, loss 0.3314383924007416\n","outputs:  tensor([[0.0427, 0.9368],\n","        [0.9610, 0.0541],\n","        [0.9537, 0.0639],\n","        [0.9980, 0.0040],\n","        [0.0048, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n","epoch 2157, loss 0.3314244747161865\n","outputs:  tensor([[0.0427, 0.9368],\n","        [0.9610, 0.0540],\n","        [0.9537, 0.0639],\n","        [0.9980, 0.0040],\n","        [0.0048, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n","epoch 2158, loss 0.3314105272293091\n","outputs:  tensor([[0.0427, 0.9369],\n","        [0.9611, 0.0540],\n","        [0.9537, 0.0638],\n","        [0.9980, 0.0040],\n","        [0.0048, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n","epoch 2159, loss 0.33139657974243164\n","outputs:  tensor([[0.0426, 0.9369],\n","        [0.9611, 0.0539],\n","        [0.9538, 0.0638],\n","        [0.9980, 0.0040],\n","        [0.0047, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n","epoch 2160, loss 0.33138275146484375\n","outputs:  tensor([[0.0426, 0.9370],\n","        [0.9611, 0.0539],\n","        [0.9538, 0.0637],\n","        [0.9980, 0.0040],\n","        [0.0047, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n","epoch 2161, loss 0.3313688039779663\n","outputs:  tensor([[0.0426, 0.9370],\n","        [0.9612, 0.0539],\n","        [0.9538, 0.0637],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3314, grad_fn=<NllLossBackward>)\n","epoch 2162, loss 0.33135491609573364\n","outputs:  tensor([[0.0425, 0.9371],\n","        [0.9612, 0.0538],\n","        [0.9539, 0.0637],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n","epoch 2163, loss 0.33134108781814575\n","outputs:  tensor([[0.0425, 0.9371],\n","        [0.9612, 0.0538],\n","        [0.9539, 0.0636],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9943]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n","epoch 2164, loss 0.33132725954055786\n","outputs:  tensor([[0.0425, 0.9371],\n","        [0.9612, 0.0537],\n","        [0.9539, 0.0636],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n","epoch 2165, loss 0.33131343126296997\n","outputs:  tensor([[0.0425, 0.9372],\n","        [0.9613, 0.0537],\n","        [0.9539, 0.0635],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n","epoch 2166, loss 0.33129963278770447\n","outputs:  tensor([[0.0424, 0.9372],\n","        [0.9613, 0.0537],\n","        [0.9540, 0.0635],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n","epoch 2167, loss 0.33128586411476135\n","outputs:  tensor([[0.0424, 0.9373],\n","        [0.9613, 0.0536],\n","        [0.9540, 0.0634],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n","epoch 2168, loss 0.3312721252441406\n","outputs:  tensor([[0.0424, 0.9373],\n","        [0.9613, 0.0536],\n","        [0.9540, 0.0634],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3313, grad_fn=<NllLossBackward>)\n","epoch 2169, loss 0.3312583565711975\n","outputs:  tensor([[0.0423, 0.9374],\n","        [0.9614, 0.0535],\n","        [0.9541, 0.0633],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3312, grad_fn=<NllLossBackward>)\n","epoch 2170, loss 0.33124464750289917\n","outputs:  tensor([[0.0423, 0.9374],\n","        [0.9614, 0.0535],\n","        [0.9541, 0.0633],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3312, grad_fn=<NllLossBackward>)\n","epoch 2171, loss 0.33123093843460083\n","outputs:  tensor([[0.0423, 0.9375],\n","        [0.9614, 0.0535],\n","        [0.9541, 0.0633],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3312, grad_fn=<NllLossBackward>)\n","epoch 2172, loss 0.3312172293663025\n","outputs:  tensor([[0.0422, 0.9375],\n","        [0.9614, 0.0534],\n","        [0.9542, 0.0632],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3312, grad_fn=<NllLossBackward>)\n","epoch 2173, loss 0.3312036097049713\n","outputs:  tensor([[0.0422, 0.9376],\n","        [0.9615, 0.0534],\n","        [0.9542, 0.0632],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3312, grad_fn=<NllLossBackward>)\n","epoch 2174, loss 0.33118993043899536\n","outputs:  tensor([[0.0422, 0.9376],\n","        [0.9615, 0.0533],\n","        [0.9542, 0.0631],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3312, grad_fn=<NllLossBackward>)\n","epoch 2175, loss 0.3311762809753418\n","outputs:  tensor([[0.0422, 0.9377],\n","        [0.9615, 0.0533],\n","        [0.9542, 0.0631],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3312, grad_fn=<NllLossBackward>)\n","epoch 2176, loss 0.331162691116333\n","outputs:  tensor([[0.0421, 0.9377],\n","        [0.9616, 0.0533],\n","        [0.9543, 0.0630],\n","        [0.9980, 0.0039],\n","        [0.0047, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3311, grad_fn=<NllLossBackward>)\n","epoch 2177, loss 0.33114904165267944\n","outputs:  tensor([[0.0421, 0.9378],\n","        [0.9616, 0.0532],\n","        [0.9543, 0.0630],\n","        [0.9980, 0.0039],\n","        [0.0046, 0.9944]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3311, grad_fn=<NllLossBackward>)\n","epoch 2178, loss 0.33113548159599304\n","outputs:  tensor([[0.0421, 0.9378],\n","        [0.9616, 0.0532],\n","        [0.9543, 0.0630],\n","        [0.9980, 0.0039],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3311, grad_fn=<NllLossBackward>)\n","epoch 2179, loss 0.3311219811439514\n","outputs:  tensor([[0.0420, 0.9379],\n","        [0.9616, 0.0531],\n","        [0.9544, 0.0629],\n","        [0.9980, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3311, grad_fn=<NllLossBackward>)\n","epoch 2180, loss 0.33110833168029785\n","outputs:  tensor([[0.0420, 0.9379],\n","        [0.9617, 0.0531],\n","        [0.9544, 0.0629],\n","        [0.9980, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3311, grad_fn=<NllLossBackward>)\n","epoch 2181, loss 0.3310948312282562\n","outputs:  tensor([[0.0420, 0.9380],\n","        [0.9617, 0.0531],\n","        [0.9544, 0.0628],\n","        [0.9980, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3311, grad_fn=<NllLossBackward>)\n","epoch 2182, loss 0.3310813307762146\n","outputs:  tensor([[0.0420, 0.9380],\n","        [0.9617, 0.0530],\n","        [0.9544, 0.0628],\n","        [0.9980, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3311, grad_fn=<NllLossBackward>)\n","epoch 2183, loss 0.3310678005218506\n","outputs:  tensor([[0.0419, 0.9381],\n","        [0.9617, 0.0530],\n","        [0.9545, 0.0627],\n","        [0.9980, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3311, grad_fn=<NllLossBackward>)\n","epoch 2184, loss 0.33105435967445374\n","outputs:  tensor([[0.0419, 0.9381],\n","        [0.9618, 0.0529],\n","        [0.9545, 0.0627],\n","        [0.9980, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3310, grad_fn=<NllLossBackward>)\n","epoch 2185, loss 0.3310408592224121\n","outputs:  tensor([[0.0419, 0.9382],\n","        [0.9618, 0.0529],\n","        [0.9545, 0.0627],\n","        [0.9980, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3310, grad_fn=<NllLossBackward>)\n","epoch 2186, loss 0.33102741837501526\n","outputs:  tensor([[0.0418, 0.9382],\n","        [0.9618, 0.0529],\n","        [0.9546, 0.0626],\n","        [0.9980, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3310, grad_fn=<NllLossBackward>)\n","epoch 2187, loss 0.3310139775276184\n","outputs:  tensor([[0.0418, 0.9382],\n","        [0.9618, 0.0528],\n","        [0.9546, 0.0626],\n","        [0.9980, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3310, grad_fn=<NllLossBackward>)\n","epoch 2188, loss 0.3310006260871887\n","outputs:  tensor([[0.0418, 0.9383],\n","        [0.9619, 0.0528],\n","        [0.9546, 0.0625],\n","        [0.9980, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3310, grad_fn=<NllLossBackward>)\n","epoch 2189, loss 0.3309871554374695\n","outputs:  tensor([[0.0417, 0.9383],\n","        [0.9619, 0.0527],\n","        [0.9546, 0.0625],\n","        [0.9981, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3310, grad_fn=<NllLossBackward>)\n","epoch 2190, loss 0.3309738039970398\n","outputs:  tensor([[0.0417, 0.9384],\n","        [0.9619, 0.0527],\n","        [0.9547, 0.0624],\n","        [0.9981, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3310, grad_fn=<NllLossBackward>)\n","epoch 2191, loss 0.3309604525566101\n","outputs:  tensor([[0.0417, 0.9384],\n","        [0.9619, 0.0527],\n","        [0.9547, 0.0624],\n","        [0.9981, 0.0038],\n","        [0.0046, 0.9945]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3309, grad_fn=<NllLossBackward>)\n","epoch 2192, loss 0.3309471011161804\n","outputs:  tensor([[0.0417, 0.9385],\n","        [0.9620, 0.0526],\n","        [0.9547, 0.0624],\n","        [0.9981, 0.0038],\n","        [0.0046, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3309, grad_fn=<NllLossBackward>)\n","epoch 2193, loss 0.33093374967575073\n","outputs:  tensor([[0.0416, 0.9385],\n","        [0.9620, 0.0526],\n","        [0.9548, 0.0623],\n","        [0.9981, 0.0038],\n","        [0.0046, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3309, grad_fn=<NllLossBackward>)\n","epoch 2194, loss 0.3309204578399658\n","outputs:  tensor([[0.0416, 0.9386],\n","        [0.9620, 0.0526],\n","        [0.9548, 0.0623],\n","        [0.9981, 0.0038],\n","        [0.0046, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3309, grad_fn=<NllLossBackward>)\n","epoch 2195, loss 0.3309071958065033\n","outputs:  tensor([[0.0416, 0.9386],\n","        [0.9620, 0.0525],\n","        [0.9548, 0.0622],\n","        [0.9981, 0.0038],\n","        [0.0046, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3309, grad_fn=<NllLossBackward>)\n","epoch 2196, loss 0.3308939039707184\n","outputs:  tensor([[0.0415, 0.9387],\n","        [0.9621, 0.0525],\n","        [0.9548, 0.0622],\n","        [0.9981, 0.0038],\n","        [0.0045, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3309, grad_fn=<NllLossBackward>)\n","epoch 2197, loss 0.3308805823326111\n","outputs:  tensor([[0.0415, 0.9387],\n","        [0.9621, 0.0524],\n","        [0.9549, 0.0621],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3309, grad_fn=<NllLossBackward>)\n","epoch 2198, loss 0.33086737990379333\n","outputs:  tensor([[0.0415, 0.9388],\n","        [0.9621, 0.0524],\n","        [0.9549, 0.0621],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3309, grad_fn=<NllLossBackward>)\n","epoch 2199, loss 0.330854207277298\n","outputs:  tensor([[0.0415, 0.9388],\n","        [0.9622, 0.0524],\n","        [0.9549, 0.0621],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3308, grad_fn=<NllLossBackward>)\n","epoch 2200, loss 0.33084097504615784\n","outputs:  tensor([[0.0414, 0.9389],\n","        [0.9622, 0.0523],\n","        [0.9550, 0.0620],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3308, grad_fn=<NllLossBackward>)\n","epoch 2201, loss 0.3308277726173401\n","Parameter containing:\n","tensor([[-0.2684, -0.6350,  0.1963],\n","        [-1.0169, -0.7567, -0.0760],\n","        [-1.0314, -0.9200, -0.1245],\n","        [-0.4573, -0.4807, -0.0023]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5028, -0.2773,  0.1737,  0.1295], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8613,  0.7493,  1.1276,  0.1269],\n","        [-0.1990, -0.9687, -0.8132, -0.5771]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3645, -0.6028], requires_grad=True)\n","outputs:  tensor([[0.0414, 0.9389],\n","        [0.9622, 0.0523],\n","        [0.9550, 0.0620],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3308, grad_fn=<NllLossBackward>)\n","epoch 2202, loss 0.3308145999908447\n","outputs:  tensor([[0.0414, 0.9389],\n","        [0.9622, 0.0523],\n","        [0.9550, 0.0619],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3308, grad_fn=<NllLossBackward>)\n","epoch 2203, loss 0.33080142736434937\n","outputs:  tensor([[0.0413, 0.9390],\n","        [0.9623, 0.0522],\n","        [0.9550, 0.0619],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3308, grad_fn=<NllLossBackward>)\n","epoch 2204, loss 0.3307883143424988\n","outputs:  tensor([[0.0413, 0.9390],\n","        [0.9623, 0.0522],\n","        [0.9551, 0.0619],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3308, grad_fn=<NllLossBackward>)\n","epoch 2205, loss 0.3307751715183258\n","outputs:  tensor([[0.0413, 0.9391],\n","        [0.9623, 0.0521],\n","        [0.9551, 0.0618],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9946]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3308, grad_fn=<NllLossBackward>)\n","epoch 2206, loss 0.3307620584964752\n","outputs:  tensor([[0.0413, 0.9391],\n","        [0.9623, 0.0521],\n","        [0.9551, 0.0618],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3307, grad_fn=<NllLossBackward>)\n","epoch 2207, loss 0.33074894547462463\n","outputs:  tensor([[0.0412, 0.9392],\n","        [0.9624, 0.0521],\n","        [0.9552, 0.0617],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3307, grad_fn=<NllLossBackward>)\n","epoch 2208, loss 0.33073583245277405\n","outputs:  tensor([[0.0412, 0.9392],\n","        [0.9624, 0.0520],\n","        [0.9552, 0.0617],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3307, grad_fn=<NllLossBackward>)\n","epoch 2209, loss 0.3307228088378906\n","outputs:  tensor([[0.0412, 0.9393],\n","        [0.9624, 0.0520],\n","        [0.9552, 0.0616],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3307, grad_fn=<NllLossBackward>)\n","epoch 2210, loss 0.3307097554206848\n","outputs:  tensor([[0.0411, 0.9393],\n","        [0.9624, 0.0519],\n","        [0.9552, 0.0616],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3307, grad_fn=<NllLossBackward>)\n","epoch 2211, loss 0.3306967616081238\n","outputs:  tensor([[0.0411, 0.9394],\n","        [0.9625, 0.0519],\n","        [0.9553, 0.0616],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3307, grad_fn=<NllLossBackward>)\n","epoch 2212, loss 0.33068376779556274\n","outputs:  tensor([[0.0411, 0.9394],\n","        [0.9625, 0.0519],\n","        [0.9553, 0.0615],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3307, grad_fn=<NllLossBackward>)\n","epoch 2213, loss 0.3306707441806793\n","outputs:  tensor([[0.0411, 0.9395],\n","        [0.9625, 0.0518],\n","        [0.9553, 0.0615],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3307, grad_fn=<NllLossBackward>)\n","epoch 2214, loss 0.33065780997276306\n","outputs:  tensor([[0.0410, 0.9395],\n","        [0.9625, 0.0518],\n","        [0.9554, 0.0614],\n","        [0.9981, 0.0037],\n","        [0.0045, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n","epoch 2215, loss 0.33064478635787964\n","outputs:  tensor([[0.0410, 0.9395],\n","        [0.9626, 0.0518],\n","        [0.9554, 0.0614],\n","        [0.9981, 0.0036],\n","        [0.0045, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n","epoch 2216, loss 0.33063188195228577\n","outputs:  tensor([[0.0410, 0.9396],\n","        [0.9626, 0.0517],\n","        [0.9554, 0.0614],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n","epoch 2217, loss 0.3306189179420471\n","outputs:  tensor([[0.0409, 0.9396],\n","        [0.9626, 0.0517],\n","        [0.9554, 0.0613],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n","epoch 2218, loss 0.33060604333877563\n","outputs:  tensor([[0.0409, 0.9397],\n","        [0.9626, 0.0516],\n","        [0.9555, 0.0613],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n","epoch 2219, loss 0.33059316873550415\n","outputs:  tensor([[0.0409, 0.9397],\n","        [0.9627, 0.0516],\n","        [0.9555, 0.0612],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n","epoch 2220, loss 0.3305802643299103\n","outputs:  tensor([[0.0409, 0.9398],\n","        [0.9627, 0.0516],\n","        [0.9555, 0.0612],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9947]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n","epoch 2221, loss 0.3305674195289612\n","outputs:  tensor([[0.0408, 0.9398],\n","        [0.9627, 0.0515],\n","        [0.9555, 0.0611],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3306, grad_fn=<NllLossBackward>)\n","epoch 2222, loss 0.3305545449256897\n","outputs:  tensor([[0.0408, 0.9399],\n","        [0.9627, 0.0515],\n","        [0.9556, 0.0611],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3305, grad_fn=<NllLossBackward>)\n","epoch 2223, loss 0.3305417001247406\n","outputs:  tensor([[0.0408, 0.9399],\n","        [0.9628, 0.0515],\n","        [0.9556, 0.0611],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3305, grad_fn=<NllLossBackward>)\n","epoch 2224, loss 0.3305288851261139\n","outputs:  tensor([[0.0408, 0.9400],\n","        [0.9628, 0.0514],\n","        [0.9556, 0.0610],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3305, grad_fn=<NllLossBackward>)\n","epoch 2225, loss 0.3305160701274872\n","outputs:  tensor([[0.0407, 0.9400],\n","        [0.9628, 0.0514],\n","        [0.9557, 0.0610],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3305, grad_fn=<NllLossBackward>)\n","epoch 2226, loss 0.33050328493118286\n","outputs:  tensor([[0.0407, 0.9400],\n","        [0.9628, 0.0513],\n","        [0.9557, 0.0609],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3305, grad_fn=<NllLossBackward>)\n","epoch 2227, loss 0.3304905295372009\n","outputs:  tensor([[0.0407, 0.9401],\n","        [0.9629, 0.0513],\n","        [0.9557, 0.0609],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3305, grad_fn=<NllLossBackward>)\n","epoch 2228, loss 0.3304778039455414\n","outputs:  tensor([[0.0406, 0.9401],\n","        [0.9629, 0.0513],\n","        [0.9557, 0.0609],\n","        [0.9981, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3305, grad_fn=<NllLossBackward>)\n","epoch 2229, loss 0.33046507835388184\n","outputs:  tensor([[0.0406, 0.9402],\n","        [0.9629, 0.0512],\n","        [0.9558, 0.0608],\n","        [0.9982, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3305, grad_fn=<NllLossBackward>)\n","epoch 2230, loss 0.3304523229598999\n","outputs:  tensor([[0.0406, 0.9402],\n","        [0.9629, 0.0512],\n","        [0.9558, 0.0608],\n","        [0.9982, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3304, grad_fn=<NllLossBackward>)\n","epoch 2231, loss 0.33043965697288513\n","outputs:  tensor([[0.0406, 0.9403],\n","        [0.9630, 0.0512],\n","        [0.9558, 0.0607],\n","        [0.9982, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3304, grad_fn=<NllLossBackward>)\n","epoch 2232, loss 0.3304269313812256\n","outputs:  tensor([[0.0405, 0.9403],\n","        [0.9630, 0.0511],\n","        [0.9559, 0.0607],\n","        [0.9982, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3304, grad_fn=<NllLossBackward>)\n","epoch 2233, loss 0.3304142355918884\n","outputs:  tensor([[0.0405, 0.9404],\n","        [0.9630, 0.0511],\n","        [0.9559, 0.0607],\n","        [0.9982, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3304, grad_fn=<NllLossBackward>)\n","epoch 2234, loss 0.33040162920951843\n","outputs:  tensor([[0.0405, 0.9404],\n","        [0.9630, 0.0511],\n","        [0.9559, 0.0606],\n","        [0.9982, 0.0036],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3304, grad_fn=<NllLossBackward>)\n","epoch 2235, loss 0.33038896322250366\n","outputs:  tensor([[0.0405, 0.9404],\n","        [0.9631, 0.0510],\n","        [0.9559, 0.0606],\n","        [0.9982, 0.0035],\n","        [0.0044, 0.9948]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3304, grad_fn=<NllLossBackward>)\n","epoch 2236, loss 0.33037638664245605\n","outputs:  tensor([[0.0404, 0.9405],\n","        [0.9631, 0.0510],\n","        [0.9560, 0.0605],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3304, grad_fn=<NllLossBackward>)\n","epoch 2237, loss 0.33036381006240845\n","outputs:  tensor([[0.0404, 0.9405],\n","        [0.9631, 0.0509],\n","        [0.9560, 0.0605],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3304, grad_fn=<NllLossBackward>)\n","epoch 2238, loss 0.33035117387771606\n","outputs:  tensor([[0.0404, 0.9406],\n","        [0.9631, 0.0509],\n","        [0.9560, 0.0605],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3303, grad_fn=<NllLossBackward>)\n","epoch 2239, loss 0.33033856749534607\n","outputs:  tensor([[0.0403, 0.9406],\n","        [0.9632, 0.0509],\n","        [0.9560, 0.0604],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3303, grad_fn=<NllLossBackward>)\n","epoch 2240, loss 0.33032599091529846\n","outputs:  tensor([[0.0403, 0.9407],\n","        [0.9632, 0.0508],\n","        [0.9561, 0.0604],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3303, grad_fn=<NllLossBackward>)\n","epoch 2241, loss 0.33031344413757324\n","outputs:  tensor([[0.0403, 0.9407],\n","        [0.9632, 0.0508],\n","        [0.9561, 0.0603],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3303, grad_fn=<NllLossBackward>)\n","epoch 2242, loss 0.3303009569644928\n","outputs:  tensor([[0.0403, 0.9408],\n","        [0.9632, 0.0508],\n","        [0.9561, 0.0603],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3303, grad_fn=<NllLossBackward>)\n","epoch 2243, loss 0.3302884101867676\n","outputs:  tensor([[0.0402, 0.9408],\n","        [0.9633, 0.0507],\n","        [0.9562, 0.0603],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3303, grad_fn=<NllLossBackward>)\n","epoch 2244, loss 0.33027589321136475\n","outputs:  tensor([[0.0402, 0.9408],\n","        [0.9633, 0.0507],\n","        [0.9562, 0.0602],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3303, grad_fn=<NllLossBackward>)\n","epoch 2245, loss 0.3302633762359619\n","outputs:  tensor([[0.0402, 0.9409],\n","        [0.9633, 0.0507],\n","        [0.9562, 0.0602],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3303, grad_fn=<NllLossBackward>)\n","epoch 2246, loss 0.33025097846984863\n","outputs:  tensor([[0.0402, 0.9409],\n","        [0.9633, 0.0506],\n","        [0.9562, 0.0601],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3302, grad_fn=<NllLossBackward>)\n","epoch 2247, loss 0.3302384912967682\n","outputs:  tensor([[0.0401, 0.9410],\n","        [0.9634, 0.0506],\n","        [0.9563, 0.0601],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3302, grad_fn=<NllLossBackward>)\n","epoch 2248, loss 0.3302261233329773\n","outputs:  tensor([[0.0401, 0.9410],\n","        [0.9634, 0.0505],\n","        [0.9563, 0.0601],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3302, grad_fn=<NllLossBackward>)\n","epoch 2249, loss 0.33021363615989685\n","outputs:  tensor([[0.0401, 0.9411],\n","        [0.9634, 0.0505],\n","        [0.9563, 0.0600],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3302, grad_fn=<NllLossBackward>)\n","epoch 2250, loss 0.33020123839378357\n","outputs:  tensor([[0.0400, 0.9411],\n","        [0.9634, 0.0505],\n","        [0.9563, 0.0600],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9949]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3302, grad_fn=<NllLossBackward>)\n","epoch 2251, loss 0.3301888406276703\n","Parameter containing:\n","tensor([[-0.2704, -0.6385,  0.1963],\n","        [-1.0207, -0.7631, -0.0760],\n","        [-1.0355, -0.9269, -0.1245],\n","        [-0.4590, -0.4835, -0.0023]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5040, -0.2751,  0.1760,  0.1304], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8642,  0.7531,  1.1325,  0.1294],\n","        [-0.2031, -0.9741, -0.8200, -0.5805]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3655, -0.6042], requires_grad=True)\n","outputs:  tensor([[0.0400, 0.9411],\n","        [0.9634, 0.0504],\n","        [0.9564, 0.0599],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3302, grad_fn=<NllLossBackward>)\n","epoch 2252, loss 0.3301764726638794\n","outputs:  tensor([[0.0400, 0.9412],\n","        [0.9635, 0.0504],\n","        [0.9564, 0.0599],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3302, grad_fn=<NllLossBackward>)\n","epoch 2253, loss 0.3301641345024109\n","outputs:  tensor([[0.0400, 0.9412],\n","        [0.9635, 0.0504],\n","        [0.9564, 0.0599],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3302, grad_fn=<NllLossBackward>)\n","epoch 2254, loss 0.3301517963409424\n","outputs:  tensor([[0.0399, 0.9413],\n","        [0.9635, 0.0503],\n","        [0.9564, 0.0598],\n","        [0.9982, 0.0035],\n","        [0.0043, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3301, grad_fn=<NllLossBackward>)\n","epoch 2255, loss 0.3301394581794739\n","outputs:  tensor([[0.0399, 0.9413],\n","        [0.9635, 0.0503],\n","        [0.9565, 0.0598],\n","        [0.9982, 0.0034],\n","        [0.0043, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3301, grad_fn=<NllLossBackward>)\n","epoch 2256, loss 0.330127090215683\n","outputs:  tensor([[0.0399, 0.9414],\n","        [0.9636, 0.0503],\n","        [0.9565, 0.0597],\n","        [0.9982, 0.0034],\n","        [0.0043, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3301, grad_fn=<NllLossBackward>)\n","epoch 2257, loss 0.33011487126350403\n","outputs:  tensor([[0.0399, 0.9414],\n","        [0.9636, 0.0502],\n","        [0.9565, 0.0597],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3301, grad_fn=<NllLossBackward>)\n","epoch 2258, loss 0.3301025331020355\n","outputs:  tensor([[0.0398, 0.9414],\n","        [0.9636, 0.0502],\n","        [0.9566, 0.0597],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3301, grad_fn=<NllLossBackward>)\n","epoch 2259, loss 0.330090194940567\n","outputs:  tensor([[0.0398, 0.9415],\n","        [0.9636, 0.0501],\n","        [0.9566, 0.0596],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3301, grad_fn=<NllLossBackward>)\n","epoch 2260, loss 0.33007797598838806\n","outputs:  tensor([[0.0398, 0.9415],\n","        [0.9637, 0.0501],\n","        [0.9566, 0.0596],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3301, grad_fn=<NllLossBackward>)\n","epoch 2261, loss 0.3300657868385315\n","outputs:  tensor([[0.0397, 0.9416],\n","        [0.9637, 0.0501],\n","        [0.9566, 0.0595],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3301, grad_fn=<NllLossBackward>)\n","epoch 2262, loss 0.3300534784793854\n","outputs:  tensor([[0.0397, 0.9416],\n","        [0.9637, 0.0500],\n","        [0.9567, 0.0595],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n","epoch 2263, loss 0.3300412893295288\n","outputs:  tensor([[0.0397, 0.9417],\n","        [0.9637, 0.0500],\n","        [0.9567, 0.0595],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n","epoch 2264, loss 0.33002910017967224\n","outputs:  tensor([[0.0397, 0.9417],\n","        [0.9638, 0.0500],\n","        [0.9567, 0.0594],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n","epoch 2265, loss 0.3300170302391052\n","outputs:  tensor([[0.0396, 0.9418],\n","        [0.9638, 0.0499],\n","        [0.9567, 0.0594],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n","epoch 2266, loss 0.3300047814846039\n","outputs:  tensor([[0.0396, 0.9418],\n","        [0.9638, 0.0499],\n","        [0.9568, 0.0593],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9950]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n","epoch 2267, loss 0.3299926519393921\n","outputs:  tensor([[0.0396, 0.9418],\n","        [0.9638, 0.0499],\n","        [0.9568, 0.0593],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n","epoch 2268, loss 0.3299805223941803\n","outputs:  tensor([[0.0396, 0.9419],\n","        [0.9639, 0.0498],\n","        [0.9568, 0.0593],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n","epoch 2269, loss 0.3299683928489685\n","outputs:  tensor([[0.0395, 0.9419],\n","        [0.9639, 0.0498],\n","        [0.9568, 0.0592],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3300, grad_fn=<NllLossBackward>)\n","epoch 2270, loss 0.3299562931060791\n","outputs:  tensor([[0.0395, 0.9420],\n","        [0.9639, 0.0498],\n","        [0.9569, 0.0592],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n","epoch 2271, loss 0.3299442231655121\n","outputs:  tensor([[0.0395, 0.9420],\n","        [0.9639, 0.0497],\n","        [0.9569, 0.0592],\n","        [0.9982, 0.0034],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n","epoch 2272, loss 0.3299321234226227\n","outputs:  tensor([[0.0395, 0.9420],\n","        [0.9639, 0.0497],\n","        [0.9569, 0.0591],\n","        [0.9983, 0.0034],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n","epoch 2273, loss 0.32992011308670044\n","outputs:  tensor([[0.0394, 0.9421],\n","        [0.9640, 0.0497],\n","        [0.9570, 0.0591],\n","        [0.9983, 0.0034],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n","epoch 2274, loss 0.3299080431461334\n","outputs:  tensor([[0.0394, 0.9421],\n","        [0.9640, 0.0496],\n","        [0.9570, 0.0590],\n","        [0.9983, 0.0034],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n","epoch 2275, loss 0.3298959732055664\n","outputs:  tensor([[0.0394, 0.9422],\n","        [0.9640, 0.0496],\n","        [0.9570, 0.0590],\n","        [0.9983, 0.0034],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n","epoch 2276, loss 0.32988399267196655\n","outputs:  tensor([[0.0394, 0.9422],\n","        [0.9640, 0.0495],\n","        [0.9570, 0.0590],\n","        [0.9983, 0.0033],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n","epoch 2277, loss 0.3298719525337219\n","outputs:  tensor([[0.0393, 0.9423],\n","        [0.9641, 0.0495],\n","        [0.9571, 0.0589],\n","        [0.9983, 0.0033],\n","        [0.0042, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3299, grad_fn=<NllLossBackward>)\n","epoch 2278, loss 0.32985997200012207\n","outputs:  tensor([[0.0393, 0.9423],\n","        [0.9641, 0.0495],\n","        [0.9571, 0.0589],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3298, grad_fn=<NllLossBackward>)\n","epoch 2279, loss 0.32984796166419983\n","outputs:  tensor([[0.0393, 0.9423],\n","        [0.9641, 0.0494],\n","        [0.9571, 0.0588],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3298, grad_fn=<NllLossBackward>)\n","epoch 2280, loss 0.32983604073524475\n","outputs:  tensor([[0.0392, 0.9424],\n","        [0.9641, 0.0494],\n","        [0.9571, 0.0588],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3298, grad_fn=<NllLossBackward>)\n","epoch 2281, loss 0.3298241198062897\n","outputs:  tensor([[0.0392, 0.9424],\n","        [0.9642, 0.0494],\n","        [0.9572, 0.0588],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3298, grad_fn=<NllLossBackward>)\n","epoch 2282, loss 0.329812228679657\n","outputs:  tensor([[0.0392, 0.9425],\n","        [0.9642, 0.0493],\n","        [0.9572, 0.0587],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9951]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3298, grad_fn=<NllLossBackward>)\n","epoch 2283, loss 0.3298002779483795\n","outputs:  tensor([[0.0392, 0.9425],\n","        [0.9642, 0.0493],\n","        [0.9572, 0.0587],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3298, grad_fn=<NllLossBackward>)\n","epoch 2284, loss 0.32978835701942444\n","outputs:  tensor([[0.0391, 0.9426],\n","        [0.9642, 0.0493],\n","        [0.9572, 0.0587],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3298, grad_fn=<NllLossBackward>)\n","epoch 2285, loss 0.3297765254974365\n","outputs:  tensor([[0.0391, 0.9426],\n","        [0.9643, 0.0492],\n","        [0.9573, 0.0586],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3298, grad_fn=<NllLossBackward>)\n","epoch 2286, loss 0.32976460456848145\n","outputs:  tensor([[0.0391, 0.9426],\n","        [0.9643, 0.0492],\n","        [0.9573, 0.0586],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3298, grad_fn=<NllLossBackward>)\n","epoch 2287, loss 0.32975277304649353\n","outputs:  tensor([[0.0391, 0.9427],\n","        [0.9643, 0.0492],\n","        [0.9573, 0.0585],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n","epoch 2288, loss 0.3297409415245056\n","outputs:  tensor([[0.0390, 0.9427],\n","        [0.9643, 0.0491],\n","        [0.9573, 0.0585],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n","epoch 2289, loss 0.3297290802001953\n","outputs:  tensor([[0.0390, 0.9428],\n","        [0.9643, 0.0491],\n","        [0.9574, 0.0585],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n","epoch 2290, loss 0.3297173082828522\n","outputs:  tensor([[0.0390, 0.9428],\n","        [0.9644, 0.0491],\n","        [0.9574, 0.0584],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n","epoch 2291, loss 0.32970547676086426\n","outputs:  tensor([[0.0390, 0.9428],\n","        [0.9644, 0.0490],\n","        [0.9574, 0.0584],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n","epoch 2292, loss 0.3296937048435211\n","outputs:  tensor([[0.0389, 0.9429],\n","        [0.9644, 0.0490],\n","        [0.9574, 0.0583],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n","epoch 2293, loss 0.329681932926178\n","outputs:  tensor([[0.0389, 0.9429],\n","        [0.9644, 0.0490],\n","        [0.9575, 0.0583],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n","epoch 2294, loss 0.32967013120651245\n","outputs:  tensor([[0.0389, 0.9430],\n","        [0.9645, 0.0489],\n","        [0.9575, 0.0583],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3297, grad_fn=<NllLossBackward>)\n","epoch 2295, loss 0.3296584486961365\n","outputs:  tensor([[0.0389, 0.9430],\n","        [0.9645, 0.0489],\n","        [0.9575, 0.0582],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3296, grad_fn=<NllLossBackward>)\n","epoch 2296, loss 0.32964667677879333\n","outputs:  tensor([[0.0388, 0.9431],\n","        [0.9645, 0.0489],\n","        [0.9575, 0.0582],\n","        [0.9983, 0.0033],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3296, grad_fn=<NllLossBackward>)\n","epoch 2297, loss 0.3296349346637726\n","outputs:  tensor([[0.0388, 0.9431],\n","        [0.9645, 0.0488],\n","        [0.9576, 0.0582],\n","        [0.9983, 0.0032],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3296, grad_fn=<NllLossBackward>)\n","epoch 2298, loss 0.329623281955719\n","outputs:  tensor([[0.0388, 0.9431],\n","        [0.9646, 0.0488],\n","        [0.9576, 0.0581],\n","        [0.9983, 0.0032],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3296, grad_fn=<NllLossBackward>)\n","epoch 2299, loss 0.329611599445343\n","outputs:  tensor([[0.0388, 0.9432],\n","        [0.9646, 0.0488],\n","        [0.9576, 0.0581],\n","        [0.9983, 0.0032],\n","        [0.0041, 0.9952]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3296, grad_fn=<NllLossBackward>)\n","epoch 2300, loss 0.32959994673728943\n","outputs:  tensor([[0.0387, 0.9432],\n","        [0.9646, 0.0487],\n","        [0.9577, 0.0580],\n","        [0.9983, 0.0032],\n","        [0.0041, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3296, grad_fn=<NllLossBackward>)\n","epoch 2301, loss 0.32958829402923584\n","Parameter containing:\n","tensor([[-0.2724, -0.6419,  0.1962],\n","        [-1.0244, -0.7693, -0.0760],\n","        [-1.0395, -0.9336, -0.1246],\n","        [-0.4606, -0.4863, -0.0023]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5052, -0.2730,  0.1783,  0.1313], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8671,  0.7569,  1.1372,  0.1317],\n","        [-0.2071, -0.9793, -0.8265, -0.5838]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3665, -0.6056], requires_grad=True)\n","outputs:  tensor([[0.0387, 0.9433],\n","        [0.9646, 0.0487],\n","        [0.9577, 0.0580],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3296, grad_fn=<NllLossBackward>)\n","epoch 2302, loss 0.32957664132118225\n","outputs:  tensor([[0.0387, 0.9433],\n","        [0.9646, 0.0487],\n","        [0.9577, 0.0580],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3296, grad_fn=<NllLossBackward>)\n","epoch 2303, loss 0.3295650780200958\n","outputs:  tensor([[0.0387, 0.9433],\n","        [0.9647, 0.0486],\n","        [0.9577, 0.0579],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3296, grad_fn=<NllLossBackward>)\n","epoch 2304, loss 0.32955336570739746\n","outputs:  tensor([[0.0386, 0.9434],\n","        [0.9647, 0.0486],\n","        [0.9578, 0.0579],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n","epoch 2305, loss 0.32954180240631104\n","outputs:  tensor([[0.0386, 0.9434],\n","        [0.9647, 0.0485],\n","        [0.9578, 0.0579],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n","epoch 2306, loss 0.3295302391052246\n","outputs:  tensor([[0.0386, 0.9435],\n","        [0.9647, 0.0485],\n","        [0.9578, 0.0578],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n","epoch 2307, loss 0.3295186460018158\n","outputs:  tensor([[0.0386, 0.9435],\n","        [0.9648, 0.0485],\n","        [0.9578, 0.0578],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n","epoch 2308, loss 0.329507052898407\n","outputs:  tensor([[0.0385, 0.9435],\n","        [0.9648, 0.0484],\n","        [0.9579, 0.0577],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n","epoch 2309, loss 0.32949551939964294\n","outputs:  tensor([[0.0385, 0.9436],\n","        [0.9648, 0.0484],\n","        [0.9579, 0.0577],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n","epoch 2310, loss 0.3294840157032013\n","outputs:  tensor([[0.0385, 0.9436],\n","        [0.9648, 0.0484],\n","        [0.9579, 0.0577],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n","epoch 2311, loss 0.32947248220443726\n","outputs:  tensor([[0.0385, 0.9437],\n","        [0.9649, 0.0483],\n","        [0.9579, 0.0576],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3295, grad_fn=<NllLossBackward>)\n","epoch 2312, loss 0.329461008310318\n","outputs:  tensor([[0.0384, 0.9437],\n","        [0.9649, 0.0483],\n","        [0.9580, 0.0576],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3294, grad_fn=<NllLossBackward>)\n","epoch 2313, loss 0.32944950461387634\n","outputs:  tensor([[0.0384, 0.9437],\n","        [0.9649, 0.0483],\n","        [0.9580, 0.0576],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3294, grad_fn=<NllLossBackward>)\n","epoch 2314, loss 0.3294380307197571\n","outputs:  tensor([[0.0384, 0.9438],\n","        [0.9649, 0.0482],\n","        [0.9580, 0.0575],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3294, grad_fn=<NllLossBackward>)\n","epoch 2315, loss 0.3294265866279602\n","outputs:  tensor([[0.0384, 0.9438],\n","        [0.9649, 0.0482],\n","        [0.9580, 0.0575],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3294, grad_fn=<NllLossBackward>)\n","epoch 2316, loss 0.32941511273384094\n","outputs:  tensor([[0.0383, 0.9439],\n","        [0.9650, 0.0482],\n","        [0.9581, 0.0574],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3294, grad_fn=<NllLossBackward>)\n","epoch 2317, loss 0.32940369844436646\n","outputs:  tensor([[0.0383, 0.9439],\n","        [0.9650, 0.0481],\n","        [0.9581, 0.0574],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9953]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3294, grad_fn=<NllLossBackward>)\n","epoch 2318, loss 0.3293922543525696\n","outputs:  tensor([[0.0383, 0.9439],\n","        [0.9650, 0.0481],\n","        [0.9581, 0.0574],\n","        [0.9983, 0.0032],\n","        [0.0040, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3294, grad_fn=<NllLossBackward>)\n","epoch 2319, loss 0.3293808102607727\n","outputs:  tensor([[0.0383, 0.9440],\n","        [0.9650, 0.0481],\n","        [0.9581, 0.0573],\n","        [0.9984, 0.0032],\n","        [0.0040, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3294, grad_fn=<NllLossBackward>)\n","epoch 2320, loss 0.3293694853782654\n","outputs:  tensor([[0.0382, 0.9440],\n","        [0.9651, 0.0480],\n","        [0.9582, 0.0573],\n","        [0.9984, 0.0031],\n","        [0.0040, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3294, grad_fn=<NllLossBackward>)\n","epoch 2321, loss 0.3293581008911133\n","outputs:  tensor([[0.0382, 0.9441],\n","        [0.9651, 0.0480],\n","        [0.9582, 0.0573],\n","        [0.9984, 0.0031],\n","        [0.0040, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3293, grad_fn=<NllLossBackward>)\n","epoch 2322, loss 0.3293466567993164\n","outputs:  tensor([[0.0382, 0.9441],\n","        [0.9651, 0.0480],\n","        [0.9582, 0.0572],\n","        [0.9984, 0.0031],\n","        [0.0040, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3293, grad_fn=<NllLossBackward>)\n","epoch 2323, loss 0.32933536171913147\n","outputs:  tensor([[0.0382, 0.9441],\n","        [0.9651, 0.0479],\n","        [0.9582, 0.0572],\n","        [0.9984, 0.0031],\n","        [0.0040, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3293, grad_fn=<NllLossBackward>)\n","epoch 2324, loss 0.32932406663894653\n","outputs:  tensor([[0.0381, 0.9442],\n","        [0.9651, 0.0479],\n","        [0.9583, 0.0572],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3293, grad_fn=<NllLossBackward>)\n","epoch 2325, loss 0.3293127417564392\n","outputs:  tensor([[0.0381, 0.9442],\n","        [0.9652, 0.0479],\n","        [0.9583, 0.0571],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3293, grad_fn=<NllLossBackward>)\n","epoch 2326, loss 0.3293014168739319\n","outputs:  tensor([[0.0381, 0.9443],\n","        [0.9652, 0.0478],\n","        [0.9583, 0.0571],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3293, grad_fn=<NllLossBackward>)\n","epoch 2327, loss 0.3292900621891022\n","outputs:  tensor([[0.0381, 0.9443],\n","        [0.9652, 0.0478],\n","        [0.9583, 0.0570],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3293, grad_fn=<NllLossBackward>)\n","epoch 2328, loss 0.3292787969112396\n","outputs:  tensor([[0.0380, 0.9443],\n","        [0.9652, 0.0478],\n","        [0.9584, 0.0570],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3293, grad_fn=<NllLossBackward>)\n","epoch 2329, loss 0.32926756143569946\n","outputs:  tensor([[0.0380, 0.9444],\n","        [0.9653, 0.0477],\n","        [0.9584, 0.0570],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3293, grad_fn=<NllLossBackward>)\n","epoch 2330, loss 0.3292562961578369\n","outputs:  tensor([[0.0380, 0.9444],\n","        [0.9653, 0.0477],\n","        [0.9584, 0.0569],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3292, grad_fn=<NllLossBackward>)\n","epoch 2331, loss 0.32924503087997437\n","outputs:  tensor([[0.0380, 0.9445],\n","        [0.9653, 0.0477],\n","        [0.9584, 0.0569],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3292, grad_fn=<NllLossBackward>)\n","epoch 2332, loss 0.3292337954044342\n","outputs:  tensor([[0.0379, 0.9445],\n","        [0.9653, 0.0476],\n","        [0.9585, 0.0569],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3292, grad_fn=<NllLossBackward>)\n","epoch 2333, loss 0.3292226195335388\n","outputs:  tensor([[0.0379, 0.9445],\n","        [0.9653, 0.0476],\n","        [0.9585, 0.0568],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3292, grad_fn=<NllLossBackward>)\n","epoch 2334, loss 0.32921138405799866\n","outputs:  tensor([[0.0379, 0.9446],\n","        [0.9654, 0.0476],\n","        [0.9585, 0.0568],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3292, grad_fn=<NllLossBackward>)\n","epoch 2335, loss 0.32920020818710327\n","outputs:  tensor([[0.0379, 0.9446],\n","        [0.9654, 0.0476],\n","        [0.9585, 0.0568],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9954]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3292, grad_fn=<NllLossBackward>)\n","epoch 2336, loss 0.3291890025138855\n","outputs:  tensor([[0.0378, 0.9447],\n","        [0.9654, 0.0475],\n","        [0.9586, 0.0567],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3292, grad_fn=<NllLossBackward>)\n","epoch 2337, loss 0.3291778862476349\n","outputs:  tensor([[0.0378, 0.9447],\n","        [0.9654, 0.0475],\n","        [0.9586, 0.0567],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3292, grad_fn=<NllLossBackward>)\n","epoch 2338, loss 0.3291667401790619\n","outputs:  tensor([[0.0378, 0.9447],\n","        [0.9655, 0.0475],\n","        [0.9586, 0.0566],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3292, grad_fn=<NllLossBackward>)\n","epoch 2339, loss 0.3291555643081665\n","outputs:  tensor([[0.0378, 0.9448],\n","        [0.9655, 0.0474],\n","        [0.9586, 0.0566],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n","epoch 2340, loss 0.3291444182395935\n","outputs:  tensor([[0.0377, 0.9448],\n","        [0.9655, 0.0474],\n","        [0.9587, 0.0566],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n","epoch 2341, loss 0.32913336157798767\n","outputs:  tensor([[0.0377, 0.9449],\n","        [0.9655, 0.0474],\n","        [0.9587, 0.0565],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n","epoch 2342, loss 0.32912224531173706\n","outputs:  tensor([[0.0377, 0.9449],\n","        [0.9655, 0.0473],\n","        [0.9587, 0.0565],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n","epoch 2343, loss 0.32911115884780884\n","outputs:  tensor([[0.0377, 0.9449],\n","        [0.9656, 0.0473],\n","        [0.9587, 0.0565],\n","        [0.9984, 0.0031],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n","epoch 2344, loss 0.3291001617908478\n","outputs:  tensor([[0.0376, 0.9450],\n","        [0.9656, 0.0473],\n","        [0.9587, 0.0564],\n","        [0.9984, 0.0030],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n","epoch 2345, loss 0.3290889859199524\n","outputs:  tensor([[0.0376, 0.9450],\n","        [0.9656, 0.0472],\n","        [0.9588, 0.0564],\n","        [0.9984, 0.0030],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n","epoch 2346, loss 0.3290780186653137\n","outputs:  tensor([[0.0376, 0.9451],\n","        [0.9656, 0.0472],\n","        [0.9588, 0.0564],\n","        [0.9984, 0.0030],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n","epoch 2347, loss 0.3290669918060303\n","outputs:  tensor([[0.0376, 0.9451],\n","        [0.9657, 0.0472],\n","        [0.9588, 0.0563],\n","        [0.9984, 0.0030],\n","        [0.0039, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3291, grad_fn=<NllLossBackward>)\n","epoch 2348, loss 0.32905593514442444\n","outputs:  tensor([[0.0375, 0.9451],\n","        [0.9657, 0.0471],\n","        [0.9588, 0.0563],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n","epoch 2349, loss 0.329044908285141\n","outputs:  tensor([[0.0375, 0.9452],\n","        [0.9657, 0.0471],\n","        [0.9589, 0.0562],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n","epoch 2350, loss 0.3290339410305023\n","outputs:  tensor([[0.0375, 0.9452],\n","        [0.9657, 0.0471],\n","        [0.9589, 0.0562],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n","epoch 2351, loss 0.32902297377586365\n","Parameter containing:\n","tensor([[-0.2744, -0.6452,  0.1962],\n","        [-1.0279, -0.7753, -0.0760],\n","        [-1.0433, -0.9401, -0.1246],\n","        [-0.4622, -0.4890, -0.0022]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5063, -0.2710,  0.1805,  0.1322], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8699,  0.7605,  1.1418,  0.1340],\n","        [-0.2109, -0.9844, -0.8329, -0.5869]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3675, -0.6069], requires_grad=True)\n","outputs:  tensor([[0.0375, 0.9452],\n","        [0.9657, 0.0470],\n","        [0.9589, 0.0562],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n","epoch 2352, loss 0.3290119767189026\n","outputs:  tensor([[0.0374, 0.9453],\n","        [0.9658, 0.0470],\n","        [0.9589, 0.0561],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n","epoch 2353, loss 0.3290010094642639\n","outputs:  tensor([[0.0374, 0.9453],\n","        [0.9658, 0.0470],\n","        [0.9590, 0.0561],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9955]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n","epoch 2354, loss 0.32899007201194763\n","outputs:  tensor([[0.0374, 0.9454],\n","        [0.9658, 0.0469],\n","        [0.9590, 0.0561],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n","epoch 2355, loss 0.3289791941642761\n","outputs:  tensor([[0.0374, 0.9454],\n","        [0.9658, 0.0469],\n","        [0.9590, 0.0560],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n","epoch 2356, loss 0.32896822690963745\n","outputs:  tensor([[0.0374, 0.9454],\n","        [0.9658, 0.0469],\n","        [0.9590, 0.0560],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3290, grad_fn=<NllLossBackward>)\n","epoch 2357, loss 0.32895734906196594\n","outputs:  tensor([[0.0373, 0.9455],\n","        [0.9659, 0.0468],\n","        [0.9591, 0.0560],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n","epoch 2358, loss 0.32894644141197205\n","outputs:  tensor([[0.0373, 0.9455],\n","        [0.9659, 0.0468],\n","        [0.9591, 0.0559],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n","epoch 2359, loss 0.3289355933666229\n","outputs:  tensor([[0.0373, 0.9456],\n","        [0.9659, 0.0468],\n","        [0.9591, 0.0559],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n","epoch 2360, loss 0.3289247453212738\n","outputs:  tensor([[0.0373, 0.9456],\n","        [0.9659, 0.0467],\n","        [0.9591, 0.0559],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n","epoch 2361, loss 0.32891392707824707\n","outputs:  tensor([[0.0372, 0.9456],\n","        [0.9660, 0.0467],\n","        [0.9592, 0.0558],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n","epoch 2362, loss 0.3289030194282532\n","outputs:  tensor([[0.0372, 0.9457],\n","        [0.9660, 0.0467],\n","        [0.9592, 0.0558],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n","epoch 2363, loss 0.32889217138290405\n","outputs:  tensor([[0.0372, 0.9457],\n","        [0.9660, 0.0466],\n","        [0.9592, 0.0558],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n","epoch 2364, loss 0.3288813829421997\n","outputs:  tensor([[0.0372, 0.9457],\n","        [0.9660, 0.0466],\n","        [0.9592, 0.0557],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n","epoch 2365, loss 0.32887059450149536\n","outputs:  tensor([[0.0371, 0.9458],\n","        [0.9660, 0.0466],\n","        [0.9593, 0.0557],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3289, grad_fn=<NllLossBackward>)\n","epoch 2366, loss 0.3288598656654358\n","outputs:  tensor([[0.0371, 0.9458],\n","        [0.9661, 0.0466],\n","        [0.9593, 0.0556],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n","epoch 2367, loss 0.32884910702705383\n","outputs:  tensor([[0.0371, 0.9459],\n","        [0.9661, 0.0465],\n","        [0.9593, 0.0556],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n","epoch 2368, loss 0.3288382887840271\n","outputs:  tensor([[0.0371, 0.9459],\n","        [0.9661, 0.0465],\n","        [0.9593, 0.0556],\n","        [0.9984, 0.0030],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n","epoch 2369, loss 0.32882755994796753\n","outputs:  tensor([[0.0370, 0.9459],\n","        [0.9661, 0.0465],\n","        [0.9594, 0.0555],\n","        [0.9984, 0.0029],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n","epoch 2370, loss 0.32881680130958557\n","outputs:  tensor([[0.0370, 0.9460],\n","        [0.9661, 0.0464],\n","        [0.9594, 0.0555],\n","        [0.9984, 0.0029],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n","epoch 2371, loss 0.328806072473526\n","outputs:  tensor([[0.0370, 0.9460],\n","        [0.9662, 0.0464],\n","        [0.9594, 0.0555],\n","        [0.9985, 0.0029],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n","epoch 2372, loss 0.3287954330444336\n","outputs:  tensor([[0.0370, 0.9461],\n","        [0.9662, 0.0464],\n","        [0.9594, 0.0554],\n","        [0.9985, 0.0029],\n","        [0.0038, 0.9956]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n","epoch 2373, loss 0.32878461480140686\n","outputs:  tensor([[0.0370, 0.9461],\n","        [0.9662, 0.0463],\n","        [0.9594, 0.0554],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n","epoch 2374, loss 0.32877397537231445\n","outputs:  tensor([[0.0369, 0.9461],\n","        [0.9662, 0.0463],\n","        [0.9595, 0.0554],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n","epoch 2375, loss 0.32876333594322205\n","outputs:  tensor([[0.0369, 0.9462],\n","        [0.9663, 0.0463],\n","        [0.9595, 0.0553],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3288, grad_fn=<NllLossBackward>)\n","epoch 2376, loss 0.32875266671180725\n","outputs:  tensor([[0.0369, 0.9462],\n","        [0.9663, 0.0462],\n","        [0.9595, 0.0553],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n","epoch 2377, loss 0.32874196767807007\n","outputs:  tensor([[0.0369, 0.9462],\n","        [0.9663, 0.0462],\n","        [0.9595, 0.0553],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n","epoch 2378, loss 0.32873135805130005\n","outputs:  tensor([[0.0368, 0.9463],\n","        [0.9663, 0.0462],\n","        [0.9596, 0.0552],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n","epoch 2379, loss 0.32872074842453003\n","outputs:  tensor([[0.0368, 0.9463],\n","        [0.9663, 0.0461],\n","        [0.9596, 0.0552],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n","epoch 2380, loss 0.32871013879776\n","outputs:  tensor([[0.0368, 0.9464],\n","        [0.9664, 0.0461],\n","        [0.9596, 0.0552],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n","epoch 2381, loss 0.3286994993686676\n","outputs:  tensor([[0.0368, 0.9464],\n","        [0.9664, 0.0461],\n","        [0.9596, 0.0551],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n","epoch 2382, loss 0.32868894934654236\n","outputs:  tensor([[0.0367, 0.9464],\n","        [0.9664, 0.0461],\n","        [0.9597, 0.0551],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n","epoch 2383, loss 0.32867833971977234\n","outputs:  tensor([[0.0367, 0.9465],\n","        [0.9664, 0.0460],\n","        [0.9597, 0.0551],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n","epoch 2384, loss 0.32866787910461426\n","outputs:  tensor([[0.0367, 0.9465],\n","        [0.9664, 0.0460],\n","        [0.9597, 0.0550],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3287, grad_fn=<NllLossBackward>)\n","epoch 2385, loss 0.32865726947784424\n","outputs:  tensor([[0.0367, 0.9465],\n","        [0.9665, 0.0460],\n","        [0.9597, 0.0550],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n","epoch 2386, loss 0.328646719455719\n","outputs:  tensor([[0.0366, 0.9466],\n","        [0.9665, 0.0459],\n","        [0.9598, 0.0550],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n","epoch 2387, loss 0.32863616943359375\n","outputs:  tensor([[0.0366, 0.9466],\n","        [0.9665, 0.0459],\n","        [0.9598, 0.0549],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n","epoch 2388, loss 0.32862570881843567\n","outputs:  tensor([[0.0366, 0.9466],\n","        [0.9665, 0.0459],\n","        [0.9598, 0.0549],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n","epoch 2389, loss 0.3286151885986328\n","outputs:  tensor([[0.0366, 0.9467],\n","        [0.9665, 0.0458],\n","        [0.9598, 0.0548],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n","epoch 2390, loss 0.32860463857650757\n","outputs:  tensor([[0.0366, 0.9467],\n","        [0.9666, 0.0458],\n","        [0.9598, 0.0548],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n","epoch 2391, loss 0.32859423756599426\n","outputs:  tensor([[0.0365, 0.9468],\n","        [0.9666, 0.0458],\n","        [0.9599, 0.0548],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n","epoch 2392, loss 0.3285837173461914\n","outputs:  tensor([[0.0365, 0.9468],\n","        [0.9666, 0.0457],\n","        [0.9599, 0.0547],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9957]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n","epoch 2393, loss 0.3285732865333557\n","outputs:  tensor([[0.0365, 0.9468],\n","        [0.9666, 0.0457],\n","        [0.9599, 0.0547],\n","        [0.9985, 0.0029],\n","        [0.0037, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n","epoch 2394, loss 0.3285629153251648\n","outputs:  tensor([[0.0365, 0.9469],\n","        [0.9667, 0.0457],\n","        [0.9599, 0.0547],\n","        [0.9985, 0.0028],\n","        [0.0037, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3286, grad_fn=<NllLossBackward>)\n","epoch 2395, loss 0.3285524249076843\n","outputs:  tensor([[0.0364, 0.9469],\n","        [0.9667, 0.0457],\n","        [0.9600, 0.0546],\n","        [0.9985, 0.0028],\n","        [0.0037, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3285, grad_fn=<NllLossBackward>)\n","epoch 2396, loss 0.328542023897171\n","outputs:  tensor([[0.0364, 0.9469],\n","        [0.9667, 0.0456],\n","        [0.9600, 0.0546],\n","        [0.9985, 0.0028],\n","        [0.0037, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3285, grad_fn=<NllLossBackward>)\n","epoch 2397, loss 0.32853156328201294\n","outputs:  tensor([[0.0364, 0.9470],\n","        [0.9667, 0.0456],\n","        [0.9600, 0.0546],\n","        [0.9985, 0.0028],\n","        [0.0037, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3285, grad_fn=<NllLossBackward>)\n","epoch 2398, loss 0.328521192073822\n","outputs:  tensor([[0.0364, 0.9470],\n","        [0.9667, 0.0456],\n","        [0.9600, 0.0545],\n","        [0.9985, 0.0028],\n","        [0.0037, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3285, grad_fn=<NllLossBackward>)\n","epoch 2399, loss 0.3285108208656311\n","outputs:  tensor([[0.0364, 0.9471],\n","        [0.9668, 0.0455],\n","        [0.9601, 0.0545],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3285, grad_fn=<NllLossBackward>)\n","epoch 2400, loss 0.3285004496574402\n","outputs:  tensor([[0.0363, 0.9471],\n","        [0.9668, 0.0455],\n","        [0.9601, 0.0545],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3285, grad_fn=<NllLossBackward>)\n","epoch 2401, loss 0.32849010825157166\n","Parameter containing:\n","tensor([[-0.2763, -0.6484,  0.1961],\n","        [-1.0314, -0.7812, -0.0760],\n","        [-1.0470, -0.9465, -0.1246],\n","        [-0.4637, -0.4916, -0.0022]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5074, -0.2690,  0.1827,  0.1331], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8726,  0.7641,  1.1462,  0.1362],\n","        [-0.2147, -0.9893, -0.8390, -0.5900]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3685, -0.6081], requires_grad=True)\n","outputs:  tensor([[0.0363, 0.9471],\n","        [0.9668, 0.0455],\n","        [0.9601, 0.0544],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3285, grad_fn=<NllLossBackward>)\n","epoch 2402, loss 0.3284797668457031\n","outputs:  tensor([[0.0363, 0.9472],\n","        [0.9668, 0.0454],\n","        [0.9601, 0.0544],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3285, grad_fn=<NllLossBackward>)\n","epoch 2403, loss 0.3284694254398346\n","outputs:  tensor([[0.0363, 0.9472],\n","        [0.9668, 0.0454],\n","        [0.9601, 0.0544],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3285, grad_fn=<NllLossBackward>)\n","epoch 2404, loss 0.32845911383628845\n","outputs:  tensor([[0.0362, 0.9472],\n","        [0.9669, 0.0454],\n","        [0.9602, 0.0543],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n","epoch 2405, loss 0.3284488320350647\n","outputs:  tensor([[0.0362, 0.9473],\n","        [0.9669, 0.0453],\n","        [0.9602, 0.0543],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n","epoch 2406, loss 0.32843852043151855\n","outputs:  tensor([[0.0362, 0.9473],\n","        [0.9669, 0.0453],\n","        [0.9602, 0.0543],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n","epoch 2407, loss 0.3284282088279724\n","outputs:  tensor([[0.0362, 0.9473],\n","        [0.9669, 0.0453],\n","        [0.9602, 0.0542],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n","epoch 2408, loss 0.32841798663139343\n","outputs:  tensor([[0.0361, 0.9474],\n","        [0.9669, 0.0453],\n","        [0.9603, 0.0542],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n","epoch 2409, loss 0.3284077048301697\n","outputs:  tensor([[0.0361, 0.9474],\n","        [0.9670, 0.0452],\n","        [0.9603, 0.0542],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n","epoch 2410, loss 0.3283974528312683\n","outputs:  tensor([[0.0361, 0.9475],\n","        [0.9670, 0.0452],\n","        [0.9603, 0.0541],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n","epoch 2411, loss 0.32838720083236694\n","outputs:  tensor([[0.0361, 0.9475],\n","        [0.9670, 0.0452],\n","        [0.9603, 0.0541],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n","epoch 2412, loss 0.32837700843811035\n","outputs:  tensor([[0.0361, 0.9475],\n","        [0.9670, 0.0451],\n","        [0.9604, 0.0541],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9958]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n","epoch 2413, loss 0.328366756439209\n","outputs:  tensor([[0.0360, 0.9476],\n","        [0.9670, 0.0451],\n","        [0.9604, 0.0540],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3284, grad_fn=<NllLossBackward>)\n","epoch 2414, loss 0.3283565640449524\n","outputs:  tensor([[0.0360, 0.9476],\n","        [0.9671, 0.0451],\n","        [0.9604, 0.0540],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n","epoch 2415, loss 0.3283463418483734\n","outputs:  tensor([[0.0360, 0.9476],\n","        [0.9671, 0.0450],\n","        [0.9604, 0.0540],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n","epoch 2416, loss 0.328336238861084\n","outputs:  tensor([[0.0360, 0.9477],\n","        [0.9671, 0.0450],\n","        [0.9604, 0.0539],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n","epoch 2417, loss 0.3283260464668274\n","outputs:  tensor([[0.0359, 0.9477],\n","        [0.9671, 0.0450],\n","        [0.9605, 0.0539],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n","epoch 2418, loss 0.3283159136772156\n","outputs:  tensor([[0.0359, 0.9477],\n","        [0.9671, 0.0450],\n","        [0.9605, 0.0539],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n","epoch 2419, loss 0.32830578088760376\n","outputs:  tensor([[0.0359, 0.9478],\n","        [0.9672, 0.0449],\n","        [0.9605, 0.0538],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n","epoch 2420, loss 0.32829558849334717\n","outputs:  tensor([[0.0359, 0.9478],\n","        [0.9672, 0.0449],\n","        [0.9605, 0.0538],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n","epoch 2421, loss 0.32828545570373535\n","outputs:  tensor([[0.0359, 0.9478],\n","        [0.9672, 0.0449],\n","        [0.9606, 0.0538],\n","        [0.9985, 0.0028],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n","epoch 2422, loss 0.3282753825187683\n","outputs:  tensor([[0.0358, 0.9479],\n","        [0.9672, 0.0448],\n","        [0.9606, 0.0537],\n","        [0.9985, 0.0027],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n","epoch 2423, loss 0.3282652795314789\n","outputs:  tensor([[0.0358, 0.9479],\n","        [0.9672, 0.0448],\n","        [0.9606, 0.0537],\n","        [0.9985, 0.0027],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3283, grad_fn=<NllLossBackward>)\n","epoch 2424, loss 0.32825523614883423\n","outputs:  tensor([[0.0358, 0.9480],\n","        [0.9673, 0.0448],\n","        [0.9606, 0.0537],\n","        [0.9985, 0.0027],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n","epoch 2425, loss 0.3282451033592224\n","outputs:  tensor([[0.0358, 0.9480],\n","        [0.9673, 0.0447],\n","        [0.9606, 0.0536],\n","        [0.9985, 0.0027],\n","        [0.0036, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n","epoch 2426, loss 0.32823503017425537\n","outputs:  tensor([[0.0357, 0.9480],\n","        [0.9673, 0.0447],\n","        [0.9607, 0.0536],\n","        [0.9985, 0.0027],\n","        [0.0035, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n","epoch 2427, loss 0.3282249867916107\n","outputs:  tensor([[0.0357, 0.9481],\n","        [0.9673, 0.0447],\n","        [0.9607, 0.0536],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n","epoch 2428, loss 0.3282150328159332\n","outputs:  tensor([[0.0357, 0.9481],\n","        [0.9673, 0.0447],\n","        [0.9607, 0.0535],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n","epoch 2429, loss 0.3282049298286438\n","outputs:  tensor([[0.0357, 0.9481],\n","        [0.9674, 0.0446],\n","        [0.9607, 0.0535],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n","epoch 2430, loss 0.32819491624832153\n","outputs:  tensor([[0.0357, 0.9482],\n","        [0.9674, 0.0446],\n","        [0.9608, 0.0535],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n","epoch 2431, loss 0.32818490266799927\n","outputs:  tensor([[0.0356, 0.9482],\n","        [0.9674, 0.0446],\n","        [0.9608, 0.0534],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n","epoch 2432, loss 0.3281749188899994\n","outputs:  tensor([[0.0356, 0.9482],\n","        [0.9674, 0.0445],\n","        [0.9608, 0.0534],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n","epoch 2433, loss 0.3281649649143219\n","outputs:  tensor([[0.0356, 0.9483],\n","        [0.9674, 0.0445],\n","        [0.9608, 0.0534],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9959]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3282, grad_fn=<NllLossBackward>)\n","epoch 2434, loss 0.32815495133399963\n","outputs:  tensor([[0.0356, 0.9483],\n","        [0.9675, 0.0445],\n","        [0.9608, 0.0533],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n","epoch 2435, loss 0.32814499735832214\n","outputs:  tensor([[0.0355, 0.9483],\n","        [0.9675, 0.0445],\n","        [0.9609, 0.0533],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n","epoch 2436, loss 0.32813504338264465\n","outputs:  tensor([[0.0355, 0.9484],\n","        [0.9675, 0.0444],\n","        [0.9609, 0.0533],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n","epoch 2437, loss 0.32812508940696716\n","outputs:  tensor([[0.0355, 0.9484],\n","        [0.9675, 0.0444],\n","        [0.9609, 0.0532],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n","epoch 2438, loss 0.32811519503593445\n","outputs:  tensor([[0.0355, 0.9484],\n","        [0.9675, 0.0444],\n","        [0.9609, 0.0532],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n","epoch 2439, loss 0.32810527086257935\n","outputs:  tensor([[0.0355, 0.9485],\n","        [0.9676, 0.0443],\n","        [0.9610, 0.0532],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n","epoch 2440, loss 0.3280954360961914\n","outputs:  tensor([[0.0354, 0.9485],\n","        [0.9676, 0.0443],\n","        [0.9610, 0.0531],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n","epoch 2441, loss 0.3280854821205139\n","outputs:  tensor([[0.0354, 0.9486],\n","        [0.9676, 0.0443],\n","        [0.9610, 0.0531],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n","epoch 2442, loss 0.328075647354126\n","outputs:  tensor([[0.0354, 0.9486],\n","        [0.9676, 0.0442],\n","        [0.9610, 0.0531],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n","epoch 2443, loss 0.3280657231807709\n","outputs:  tensor([[0.0354, 0.9486],\n","        [0.9676, 0.0442],\n","        [0.9610, 0.0531],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3281, grad_fn=<NllLossBackward>)\n","epoch 2444, loss 0.3280559182167053\n","outputs:  tensor([[0.0353, 0.9487],\n","        [0.9677, 0.0442],\n","        [0.9611, 0.0530],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3280, grad_fn=<NllLossBackward>)\n","epoch 2445, loss 0.328046053647995\n","outputs:  tensor([[0.0353, 0.9487],\n","        [0.9677, 0.0442],\n","        [0.9611, 0.0530],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3280, grad_fn=<NllLossBackward>)\n","epoch 2446, loss 0.32803621888160706\n","outputs:  tensor([[0.0353, 0.9487],\n","        [0.9677, 0.0441],\n","        [0.9611, 0.0530],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3280, grad_fn=<NllLossBackward>)\n","epoch 2447, loss 0.3280263841152191\n","outputs:  tensor([[0.0353, 0.9488],\n","        [0.9677, 0.0441],\n","        [0.9611, 0.0529],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3280, grad_fn=<NllLossBackward>)\n","epoch 2448, loss 0.32801657915115356\n","outputs:  tensor([[0.0353, 0.9488],\n","        [0.9677, 0.0441],\n","        [0.9612, 0.0529],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3280, grad_fn=<NllLossBackward>)\n","epoch 2449, loss 0.3280068039894104\n","outputs:  tensor([[0.0352, 0.9488],\n","        [0.9678, 0.0440],\n","        [0.9612, 0.0529],\n","        [0.9986, 0.0027],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3280, grad_fn=<NllLossBackward>)\n","epoch 2450, loss 0.32799696922302246\n","outputs:  tensor([[0.0352, 0.9489],\n","        [0.9678, 0.0440],\n","        [0.9612, 0.0528],\n","        [0.9986, 0.0026],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3280, grad_fn=<NllLossBackward>)\n","epoch 2451, loss 0.3279872238636017\n","Parameter containing:\n","tensor([[-0.2781, -0.6515,  0.1961],\n","        [-1.0347, -0.7869, -0.0760],\n","        [-1.0506, -0.9526, -0.1246],\n","        [-0.4652, -0.4941, -0.0022]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5085, -0.2671,  0.1848,  0.1339], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8752,  0.7675,  1.1506,  0.1384],\n","        [-0.2183, -0.9941, -0.8450, -0.5930]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3695, -0.6093], requires_grad=True)\n","outputs:  tensor([[0.0352, 0.9489],\n","        [0.9678, 0.0440],\n","        [0.9612, 0.0528],\n","        [0.9986, 0.0026],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3280, grad_fn=<NllLossBackward>)\n","epoch 2452, loss 0.3279774487018585\n","outputs:  tensor([[0.0352, 0.9489],\n","        [0.9678, 0.0440],\n","        [0.9612, 0.0528],\n","        [0.9986, 0.0026],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3280, grad_fn=<NllLossBackward>)\n","epoch 2453, loss 0.32796764373779297\n","outputs:  tensor([[0.0352, 0.9490],\n","        [0.9678, 0.0439],\n","        [0.9613, 0.0527],\n","        [0.9986, 0.0026],\n","        [0.0035, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3280, grad_fn=<NllLossBackward>)\n","epoch 2454, loss 0.3279579281806946\n","outputs:  tensor([[0.0351, 0.9490],\n","        [0.9679, 0.0439],\n","        [0.9613, 0.0527],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2455, loss 0.3279482126235962\n","outputs:  tensor([[0.0351, 0.9490],\n","        [0.9679, 0.0439],\n","        [0.9613, 0.0527],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9960]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2456, loss 0.3279384672641754\n","outputs:  tensor([[0.0351, 0.9491],\n","        [0.9679, 0.0438],\n","        [0.9613, 0.0526],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2457, loss 0.32792872190475464\n","outputs:  tensor([[0.0351, 0.9491],\n","        [0.9679, 0.0438],\n","        [0.9614, 0.0526],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2458, loss 0.32791900634765625\n","outputs:  tensor([[0.0350, 0.9491],\n","        [0.9679, 0.0438],\n","        [0.9614, 0.0526],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2459, loss 0.327909380197525\n","outputs:  tensor([[0.0350, 0.9492],\n","        [0.9680, 0.0438],\n","        [0.9614, 0.0525],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2460, loss 0.327899694442749\n","outputs:  tensor([[0.0350, 0.9492],\n","        [0.9680, 0.0437],\n","        [0.9614, 0.0525],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2461, loss 0.3278900384902954\n","outputs:  tensor([[0.0350, 0.9492],\n","        [0.9680, 0.0437],\n","        [0.9614, 0.0525],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2462, loss 0.32788029313087463\n","outputs:  tensor([[0.0350, 0.9493],\n","        [0.9680, 0.0437],\n","        [0.9615, 0.0524],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2463, loss 0.3278706967830658\n","outputs:  tensor([[0.0349, 0.9493],\n","        [0.9680, 0.0436],\n","        [0.9615, 0.0524],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2464, loss 0.3278610110282898\n","outputs:  tensor([[0.0349, 0.9493],\n","        [0.9681, 0.0436],\n","        [0.9615, 0.0524],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3279, grad_fn=<NllLossBackward>)\n","epoch 2465, loss 0.32785144448280334\n","outputs:  tensor([[0.0349, 0.9494],\n","        [0.9681, 0.0436],\n","        [0.9615, 0.0523],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n","epoch 2466, loss 0.3278418183326721\n","outputs:  tensor([[0.0349, 0.9494],\n","        [0.9681, 0.0436],\n","        [0.9615, 0.0523],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n","epoch 2467, loss 0.3278322219848633\n","outputs:  tensor([[0.0349, 0.9494],\n","        [0.9681, 0.0435],\n","        [0.9616, 0.0523],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n","epoch 2468, loss 0.32782259583473206\n","outputs:  tensor([[0.0348, 0.9495],\n","        [0.9681, 0.0435],\n","        [0.9616, 0.0523],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n","epoch 2469, loss 0.3278130292892456\n","outputs:  tensor([[0.0348, 0.9495],\n","        [0.9681, 0.0435],\n","        [0.9616, 0.0522],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n","epoch 2470, loss 0.32780346274375916\n","outputs:  tensor([[0.0348, 0.9495],\n","        [0.9682, 0.0434],\n","        [0.9616, 0.0522],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n","epoch 2471, loss 0.3277938961982727\n","outputs:  tensor([[0.0348, 0.9496],\n","        [0.9682, 0.0434],\n","        [0.9617, 0.0522],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n","epoch 2472, loss 0.32778435945510864\n","outputs:  tensor([[0.0348, 0.9496],\n","        [0.9682, 0.0434],\n","        [0.9617, 0.0521],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n","epoch 2473, loss 0.3277748227119446\n","outputs:  tensor([[0.0347, 0.9496],\n","        [0.9682, 0.0434],\n","        [0.9617, 0.0521],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n","epoch 2474, loss 0.3277652859687805\n","outputs:  tensor([[0.0347, 0.9497],\n","        [0.9682, 0.0433],\n","        [0.9617, 0.0521],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3278, grad_fn=<NllLossBackward>)\n","epoch 2475, loss 0.32775574922561646\n","outputs:  tensor([[0.0347, 0.9497],\n","        [0.9683, 0.0433],\n","        [0.9617, 0.0520],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2476, loss 0.32774630188941956\n","outputs:  tensor([[0.0347, 0.9497],\n","        [0.9683, 0.0433],\n","        [0.9618, 0.0520],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2477, loss 0.3277367651462555\n","outputs:  tensor([[0.0346, 0.9498],\n","        [0.9683, 0.0433],\n","        [0.9618, 0.0520],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2478, loss 0.3277272880077362\n","outputs:  tensor([[0.0346, 0.9498],\n","        [0.9683, 0.0432],\n","        [0.9618, 0.0519],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9961]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2479, loss 0.32771775126457214\n","outputs:  tensor([[0.0346, 0.9498],\n","        [0.9683, 0.0432],\n","        [0.9618, 0.0519],\n","        [0.9986, 0.0026],\n","        [0.0034, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2480, loss 0.32770833373069763\n","outputs:  tensor([[0.0346, 0.9499],\n","        [0.9684, 0.0432],\n","        [0.9618, 0.0519],\n","        [0.9986, 0.0025],\n","        [0.0034, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2481, loss 0.32769888639450073\n","outputs:  tensor([[0.0346, 0.9499],\n","        [0.9684, 0.0431],\n","        [0.9619, 0.0518],\n","        [0.9986, 0.0025],\n","        [0.0034, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2482, loss 0.32768943905830383\n","outputs:  tensor([[0.0345, 0.9499],\n","        [0.9684, 0.0431],\n","        [0.9619, 0.0518],\n","        [0.9986, 0.0025],\n","        [0.0034, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2483, loss 0.32767999172210693\n","outputs:  tensor([[0.0345, 0.9500],\n","        [0.9684, 0.0431],\n","        [0.9619, 0.0518],\n","        [0.9986, 0.0025],\n","        [0.0034, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2484, loss 0.3276705741882324\n","outputs:  tensor([[0.0345, 0.9500],\n","        [0.9684, 0.0431],\n","        [0.9619, 0.0518],\n","        [0.9986, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2485, loss 0.3276611268520355\n","outputs:  tensor([[0.0345, 0.9500],\n","        [0.9685, 0.0430],\n","        [0.9620, 0.0517],\n","        [0.9986, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3277, grad_fn=<NllLossBackward>)\n","epoch 2486, loss 0.3276517391204834\n","outputs:  tensor([[0.0345, 0.9501],\n","        [0.9685, 0.0430],\n","        [0.9620, 0.0517],\n","        [0.9986, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n","epoch 2487, loss 0.3276422917842865\n","outputs:  tensor([[0.0344, 0.9501],\n","        [0.9685, 0.0430],\n","        [0.9620, 0.0517],\n","        [0.9986, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n","epoch 2488, loss 0.3276329040527344\n","outputs:  tensor([[0.0344, 0.9501],\n","        [0.9685, 0.0429],\n","        [0.9620, 0.0516],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n","epoch 2489, loss 0.3276236057281494\n","outputs:  tensor([[0.0344, 0.9502],\n","        [0.9685, 0.0429],\n","        [0.9620, 0.0516],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n","epoch 2490, loss 0.3276142477989197\n","outputs:  tensor([[0.0344, 0.9502],\n","        [0.9685, 0.0429],\n","        [0.9621, 0.0516],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n","epoch 2491, loss 0.32760486006736755\n","outputs:  tensor([[0.0344, 0.9502],\n","        [0.9686, 0.0429],\n","        [0.9621, 0.0515],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n","epoch 2492, loss 0.3275955319404602\n","outputs:  tensor([[0.0343, 0.9503],\n","        [0.9686, 0.0428],\n","        [0.9621, 0.0515],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n","epoch 2493, loss 0.32758623361587524\n","outputs:  tensor([[0.0343, 0.9503],\n","        [0.9686, 0.0428],\n","        [0.9621, 0.0515],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n","epoch 2494, loss 0.3275768756866455\n","outputs:  tensor([[0.0343, 0.9503],\n","        [0.9686, 0.0428],\n","        [0.9621, 0.0514],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n","epoch 2495, loss 0.32756751775741577\n","outputs:  tensor([[0.0343, 0.9504],\n","        [0.9686, 0.0428],\n","        [0.9622, 0.0514],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3276, grad_fn=<NllLossBackward>)\n","epoch 2496, loss 0.3275582790374756\n","outputs:  tensor([[0.0343, 0.9504],\n","        [0.9687, 0.0427],\n","        [0.9622, 0.0514],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2497, loss 0.3275489807128906\n","outputs:  tensor([[0.0342, 0.9504],\n","        [0.9687, 0.0427],\n","        [0.9622, 0.0514],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2498, loss 0.32753974199295044\n","outputs:  tensor([[0.0342, 0.9505],\n","        [0.9687, 0.0427],\n","        [0.9622, 0.0513],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2499, loss 0.32753047347068787\n","outputs:  tensor([[0.0342, 0.9505],\n","        [0.9687, 0.0426],\n","        [0.9622, 0.0513],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2500, loss 0.3275212049484253\n","outputs:  tensor([[0.0342, 0.9505],\n","        [0.9687, 0.0426],\n","        [0.9623, 0.0513],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2501, loss 0.3275119364261627\n","Parameter containing:\n","tensor([[-0.2799, -0.6545,  0.1960],\n","        [-1.0380, -0.7924, -0.0760],\n","        [-1.0541, -0.9586, -0.1247],\n","        [-0.4666, -0.4966, -0.0022]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5096, -0.2652,  0.1869,  0.1348], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8778,  0.7709,  1.1548,  0.1405],\n","        [-0.2218, -0.9987, -0.8508, -0.5959]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3704, -0.6105], requires_grad=True)\n","outputs:  tensor([[0.0341, 0.9506],\n","        [0.9688, 0.0426],\n","        [0.9623, 0.0512],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9962]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2502, loss 0.32750266790390015\n","outputs:  tensor([[0.0341, 0.9506],\n","        [0.9688, 0.0426],\n","        [0.9623, 0.0512],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2503, loss 0.32749348878860474\n","outputs:  tensor([[0.0341, 0.9506],\n","        [0.9688, 0.0425],\n","        [0.9623, 0.0512],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2504, loss 0.32748425006866455\n","outputs:  tensor([[0.0341, 0.9507],\n","        [0.9688, 0.0425],\n","        [0.9624, 0.0511],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2505, loss 0.32747507095336914\n","outputs:  tensor([[0.0341, 0.9507],\n","        [0.9688, 0.0425],\n","        [0.9624, 0.0511],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2506, loss 0.32746583223342896\n","outputs:  tensor([[0.0340, 0.9507],\n","        [0.9688, 0.0424],\n","        [0.9624, 0.0511],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3275, grad_fn=<NllLossBackward>)\n","epoch 2507, loss 0.3274567127227783\n","outputs:  tensor([[0.0340, 0.9508],\n","        [0.9689, 0.0424],\n","        [0.9624, 0.0510],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2508, loss 0.32744747400283813\n","outputs:  tensor([[0.0340, 0.9508],\n","        [0.9689, 0.0424],\n","        [0.9624, 0.0510],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2509, loss 0.3274383246898651\n","outputs:  tensor([[0.0340, 0.9508],\n","        [0.9689, 0.0424],\n","        [0.9625, 0.0510],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2510, loss 0.3274291455745697\n","outputs:  tensor([[0.0340, 0.9509],\n","        [0.9689, 0.0423],\n","        [0.9625, 0.0510],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2511, loss 0.32742005586624146\n","outputs:  tensor([[0.0339, 0.9509],\n","        [0.9689, 0.0423],\n","        [0.9625, 0.0509],\n","        [0.9987, 0.0025],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2512, loss 0.32741090655326843\n","outputs:  tensor([[0.0339, 0.9509],\n","        [0.9690, 0.0423],\n","        [0.9625, 0.0509],\n","        [0.9987, 0.0024],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2513, loss 0.3274018168449402\n","outputs:  tensor([[0.0339, 0.9510],\n","        [0.9690, 0.0423],\n","        [0.9625, 0.0509],\n","        [0.9987, 0.0024],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2514, loss 0.32739266753196716\n","outputs:  tensor([[0.0339, 0.9510],\n","        [0.9690, 0.0422],\n","        [0.9626, 0.0508],\n","        [0.9987, 0.0024],\n","        [0.0033, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2515, loss 0.3273835778236389\n","outputs:  tensor([[0.0339, 0.9510],\n","        [0.9690, 0.0422],\n","        [0.9626, 0.0508],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2516, loss 0.3273744285106659\n","outputs:  tensor([[0.0338, 0.9511],\n","        [0.9690, 0.0422],\n","        [0.9626, 0.0508],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2517, loss 0.32736533880233765\n","outputs:  tensor([[0.0338, 0.9511],\n","        [0.9690, 0.0422],\n","        [0.9626, 0.0507],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3274, grad_fn=<NllLossBackward>)\n","epoch 2518, loss 0.3273562788963318\n","outputs:  tensor([[0.0338, 0.9511],\n","        [0.9691, 0.0421],\n","        [0.9626, 0.0507],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2519, loss 0.32734718918800354\n","outputs:  tensor([[0.0338, 0.9512],\n","        [0.9691, 0.0421],\n","        [0.9627, 0.0507],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2520, loss 0.32733815908432007\n","outputs:  tensor([[0.0338, 0.9512],\n","        [0.9691, 0.0421],\n","        [0.9627, 0.0507],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2521, loss 0.3273290991783142\n","outputs:  tensor([[0.0337, 0.9512],\n","        [0.9691, 0.0420],\n","        [0.9627, 0.0506],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2522, loss 0.3273200988769531\n","outputs:  tensor([[0.0337, 0.9513],\n","        [0.9691, 0.0420],\n","        [0.9627, 0.0506],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2523, loss 0.32731103897094727\n","outputs:  tensor([[0.0337, 0.9513],\n","        [0.9692, 0.0420],\n","        [0.9627, 0.0506],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2524, loss 0.3273020386695862\n","outputs:  tensor([[0.0337, 0.9513],\n","        [0.9692, 0.0420],\n","        [0.9628, 0.0505],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2525, loss 0.3272930383682251\n","outputs:  tensor([[0.0337, 0.9513],\n","        [0.9692, 0.0419],\n","        [0.9628, 0.0505],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2526, loss 0.327284038066864\n","outputs:  tensor([[0.0336, 0.9514],\n","        [0.9692, 0.0419],\n","        [0.9628, 0.0505],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9963]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2527, loss 0.3272750973701477\n","outputs:  tensor([[0.0336, 0.9514],\n","        [0.9692, 0.0419],\n","        [0.9628, 0.0504],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2528, loss 0.32726606726646423\n","outputs:  tensor([[0.0336, 0.9514],\n","        [0.9692, 0.0419],\n","        [0.9628, 0.0504],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3273, grad_fn=<NllLossBackward>)\n","epoch 2529, loss 0.32725706696510315\n","outputs:  tensor([[0.0336, 0.9515],\n","        [0.9693, 0.0418],\n","        [0.9629, 0.0504],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2530, loss 0.32724815607070923\n","outputs:  tensor([[0.0336, 0.9515],\n","        [0.9693, 0.0418],\n","        [0.9629, 0.0504],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2531, loss 0.32723918557167053\n","outputs:  tensor([[0.0335, 0.9515],\n","        [0.9693, 0.0418],\n","        [0.9629, 0.0503],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2532, loss 0.3272302746772766\n","outputs:  tensor([[0.0335, 0.9516],\n","        [0.9693, 0.0418],\n","        [0.9629, 0.0503],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2533, loss 0.3272213339805603\n","outputs:  tensor([[0.0335, 0.9516],\n","        [0.9693, 0.0417],\n","        [0.9629, 0.0503],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2534, loss 0.32721251249313354\n","outputs:  tensor([[0.0335, 0.9516],\n","        [0.9694, 0.0417],\n","        [0.9630, 0.0502],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2535, loss 0.32720351219177246\n","outputs:  tensor([[0.0335, 0.9517],\n","        [0.9694, 0.0417],\n","        [0.9630, 0.0502],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2536, loss 0.32719460129737854\n","outputs:  tensor([[0.0334, 0.9517],\n","        [0.9694, 0.0416],\n","        [0.9630, 0.0502],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2537, loss 0.3271856904029846\n","outputs:  tensor([[0.0334, 0.9517],\n","        [0.9694, 0.0416],\n","        [0.9630, 0.0501],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2538, loss 0.32717689871788025\n","outputs:  tensor([[0.0334, 0.9518],\n","        [0.9694, 0.0416],\n","        [0.9630, 0.0501],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2539, loss 0.32716798782348633\n","outputs:  tensor([[0.0334, 0.9518],\n","        [0.9694, 0.0416],\n","        [0.9631, 0.0501],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2540, loss 0.3271591067314148\n","outputs:  tensor([[0.0334, 0.9518],\n","        [0.9695, 0.0415],\n","        [0.9631, 0.0501],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3272, grad_fn=<NllLossBackward>)\n","epoch 2541, loss 0.32715028524398804\n","outputs:  tensor([[0.0333, 0.9519],\n","        [0.9695, 0.0415],\n","        [0.9631, 0.0500],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2542, loss 0.3271414637565613\n","outputs:  tensor([[0.0333, 0.9519],\n","        [0.9695, 0.0415],\n","        [0.9631, 0.0500],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2543, loss 0.32713261246681213\n","outputs:  tensor([[0.0333, 0.9519],\n","        [0.9695, 0.0415],\n","        [0.9631, 0.0500],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2544, loss 0.3271237313747406\n","outputs:  tensor([[0.0333, 0.9519],\n","        [0.9695, 0.0414],\n","        [0.9632, 0.0499],\n","        [0.9987, 0.0024],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2545, loss 0.3271149694919586\n","outputs:  tensor([[0.0333, 0.9520],\n","        [0.9696, 0.0414],\n","        [0.9632, 0.0499],\n","        [0.9987, 0.0023],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2546, loss 0.32710614800453186\n","outputs:  tensor([[0.0333, 0.9520],\n","        [0.9696, 0.0414],\n","        [0.9632, 0.0499],\n","        [0.9987, 0.0023],\n","        [0.0032, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2547, loss 0.3270973563194275\n","outputs:  tensor([[0.0332, 0.9520],\n","        [0.9696, 0.0414],\n","        [0.9632, 0.0499],\n","        [0.9987, 0.0023],\n","        [0.0031, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2548, loss 0.3270885646343231\n","outputs:  tensor([[0.0332, 0.9521],\n","        [0.9696, 0.0413],\n","        [0.9632, 0.0498],\n","        [0.9987, 0.0023],\n","        [0.0031, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2549, loss 0.3270798325538635\n","outputs:  tensor([[0.0332, 0.9521],\n","        [0.9696, 0.0413],\n","        [0.9633, 0.0498],\n","        [0.9987, 0.0023],\n","        [0.0031, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2550, loss 0.32707104086875916\n","outputs:  tensor([[0.0332, 0.9521],\n","        [0.9696, 0.0413],\n","        [0.9633, 0.0498],\n","        [0.9987, 0.0023],\n","        [0.0031, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2551, loss 0.3270622789859772\n","Parameter containing:\n","tensor([[-0.2816, -0.6575,  0.1960],\n","        [-1.0411, -0.7977, -0.0760],\n","        [-1.0576, -0.9644, -0.1247],\n","        [-0.4681, -0.4990, -0.0021]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5106, -0.2633,  0.1889,  0.1356], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8803,  0.7742,  1.1589,  0.1426],\n","        [-0.2252, -1.0032, -0.8564, -0.5987]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3713, -0.6117], requires_grad=True)\n","outputs:  tensor([[0.0332, 0.9522],\n","        [0.9697, 0.0413],\n","        [0.9633, 0.0497],\n","        [0.9987, 0.0023],\n","        [0.0031, 0.9964]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3271, grad_fn=<NllLossBackward>)\n","epoch 2552, loss 0.3270534873008728\n","outputs:  tensor([[0.0331, 0.9522],\n","        [0.9697, 0.0412],\n","        [0.9633, 0.0497],\n","        [0.9987, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2553, loss 0.327044814825058\n","outputs:  tensor([[0.0331, 0.9522],\n","        [0.9697, 0.0412],\n","        [0.9633, 0.0497],\n","        [0.9987, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2554, loss 0.3270360827445984\n","outputs:  tensor([[0.0331, 0.9523],\n","        [0.9697, 0.0412],\n","        [0.9634, 0.0497],\n","        [0.9987, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2555, loss 0.3270273804664612\n","outputs:  tensor([[0.0331, 0.9523],\n","        [0.9697, 0.0412],\n","        [0.9634, 0.0496],\n","        [0.9987, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2556, loss 0.3270186483860016\n","outputs:  tensor([[0.0331, 0.9523],\n","        [0.9697, 0.0411],\n","        [0.9634, 0.0496],\n","        [0.9987, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2557, loss 0.327009916305542\n","outputs:  tensor([[0.0330, 0.9523],\n","        [0.9698, 0.0411],\n","        [0.9634, 0.0496],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2558, loss 0.32700127363204956\n","outputs:  tensor([[0.0330, 0.9524],\n","        [0.9698, 0.0411],\n","        [0.9634, 0.0495],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2559, loss 0.32699260115623474\n","outputs:  tensor([[0.0330, 0.9524],\n","        [0.9698, 0.0410],\n","        [0.9635, 0.0495],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2560, loss 0.3269839286804199\n","outputs:  tensor([[0.0330, 0.9524],\n","        [0.9698, 0.0410],\n","        [0.9635, 0.0495],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2561, loss 0.3269752562046051\n","outputs:  tensor([[0.0330, 0.9525],\n","        [0.9698, 0.0410],\n","        [0.9635, 0.0495],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2562, loss 0.3269665837287903\n","outputs:  tensor([[0.0329, 0.9525],\n","        [0.9699, 0.0410],\n","        [0.9635, 0.0494],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3270, grad_fn=<NllLossBackward>)\n","epoch 2563, loss 0.326958030462265\n","outputs:  tensor([[0.0329, 0.9525],\n","        [0.9699, 0.0409],\n","        [0.9635, 0.0494],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2564, loss 0.3269492983818054\n","outputs:  tensor([[0.0329, 0.9526],\n","        [0.9699, 0.0409],\n","        [0.9636, 0.0494],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2565, loss 0.32694071531295776\n","outputs:  tensor([[0.0329, 0.9526],\n","        [0.9699, 0.0409],\n","        [0.9636, 0.0493],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2566, loss 0.32693207263946533\n","outputs:  tensor([[0.0329, 0.9526],\n","        [0.9699, 0.0409],\n","        [0.9636, 0.0493],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2567, loss 0.32692351937294006\n","outputs:  tensor([[0.0328, 0.9527],\n","        [0.9699, 0.0408],\n","        [0.9636, 0.0493],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2568, loss 0.3269149363040924\n","outputs:  tensor([[0.0328, 0.9527],\n","        [0.9700, 0.0408],\n","        [0.9636, 0.0492],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2569, loss 0.32690635323524475\n","outputs:  tensor([[0.0328, 0.9527],\n","        [0.9700, 0.0408],\n","        [0.9637, 0.0492],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2570, loss 0.3268977701663971\n","outputs:  tensor([[0.0328, 0.9527],\n","        [0.9700, 0.0408],\n","        [0.9637, 0.0492],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2571, loss 0.32688915729522705\n","outputs:  tensor([[0.0328, 0.9528],\n","        [0.9700, 0.0407],\n","        [0.9637, 0.0492],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2572, loss 0.32688063383102417\n","outputs:  tensor([[0.0328, 0.9528],\n","        [0.9700, 0.0407],\n","        [0.9637, 0.0491],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2573, loss 0.3268720209598541\n","outputs:  tensor([[0.0327, 0.9528],\n","        [0.9700, 0.0407],\n","        [0.9637, 0.0491],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2574, loss 0.32686352729797363\n","outputs:  tensor([[0.0327, 0.9529],\n","        [0.9701, 0.0407],\n","        [0.9638, 0.0491],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3269, grad_fn=<NllLossBackward>)\n","epoch 2575, loss 0.3268550634384155\n","outputs:  tensor([[0.0327, 0.9529],\n","        [0.9701, 0.0406],\n","        [0.9638, 0.0491],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2576, loss 0.32684651017189026\n","outputs:  tensor([[0.0327, 0.9529],\n","        [0.9701, 0.0406],\n","        [0.9638, 0.0490],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2577, loss 0.3268379271030426\n","outputs:  tensor([[0.0327, 0.9530],\n","        [0.9701, 0.0406],\n","        [0.9638, 0.0490],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2578, loss 0.3268294930458069\n","outputs:  tensor([[0.0326, 0.9530],\n","        [0.9701, 0.0406],\n","        [0.9638, 0.0490],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9965]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2579, loss 0.326820969581604\n","outputs:  tensor([[0.0326, 0.9530],\n","        [0.9701, 0.0405],\n","        [0.9639, 0.0489],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2580, loss 0.3268124461174011\n","outputs:  tensor([[0.0326, 0.9530],\n","        [0.9702, 0.0405],\n","        [0.9639, 0.0489],\n","        [0.9988, 0.0023],\n","        [0.0031, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2581, loss 0.3268040418624878\n","outputs:  tensor([[0.0326, 0.9531],\n","        [0.9702, 0.0405],\n","        [0.9639, 0.0489],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2582, loss 0.3267955183982849\n","outputs:  tensor([[0.0326, 0.9531],\n","        [0.9702, 0.0405],\n","        [0.9639, 0.0489],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2583, loss 0.3267870843410492\n","outputs:  tensor([[0.0325, 0.9531],\n","        [0.9702, 0.0404],\n","        [0.9639, 0.0488],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2584, loss 0.32677868008613586\n","outputs:  tensor([[0.0325, 0.9532],\n","        [0.9702, 0.0404],\n","        [0.9640, 0.0488],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2585, loss 0.32677018642425537\n","outputs:  tensor([[0.0325, 0.9532],\n","        [0.9702, 0.0404],\n","        [0.9640, 0.0488],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2586, loss 0.32676178216934204\n","outputs:  tensor([[0.0325, 0.9532],\n","        [0.9703, 0.0404],\n","        [0.9640, 0.0487],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3268, grad_fn=<NllLossBackward>)\n","epoch 2587, loss 0.32675331830978394\n","outputs:  tensor([[0.0325, 0.9533],\n","        [0.9703, 0.0403],\n","        [0.9640, 0.0487],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2588, loss 0.3267448842525482\n","outputs:  tensor([[0.0324, 0.9533],\n","        [0.9703, 0.0403],\n","        [0.9640, 0.0487],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2589, loss 0.3267365097999573\n","outputs:  tensor([[0.0324, 0.9533],\n","        [0.9703, 0.0403],\n","        [0.9641, 0.0487],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2590, loss 0.32672813534736633\n","outputs:  tensor([[0.0324, 0.9533],\n","        [0.9703, 0.0403],\n","        [0.9641, 0.0486],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2591, loss 0.3267197012901306\n","outputs:  tensor([[0.0324, 0.9534],\n","        [0.9703, 0.0402],\n","        [0.9641, 0.0486],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2592, loss 0.32671135663986206\n","outputs:  tensor([[0.0324, 0.9534],\n","        [0.9704, 0.0402],\n","        [0.9641, 0.0486],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2593, loss 0.3267030119895935\n","outputs:  tensor([[0.0324, 0.9534],\n","        [0.9704, 0.0402],\n","        [0.9641, 0.0485],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2594, loss 0.32669463753700256\n","outputs:  tensor([[0.0323, 0.9535],\n","        [0.9704, 0.0402],\n","        [0.9641, 0.0485],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2595, loss 0.3266862630844116\n","outputs:  tensor([[0.0323, 0.9535],\n","        [0.9704, 0.0401],\n","        [0.9642, 0.0485],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2596, loss 0.32667797803878784\n","outputs:  tensor([[0.0323, 0.9535],\n","        [0.9704, 0.0401],\n","        [0.9642, 0.0485],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2597, loss 0.3266696333885193\n","outputs:  tensor([[0.0323, 0.9535],\n","        [0.9705, 0.0401],\n","        [0.9642, 0.0484],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2598, loss 0.32666128873825073\n","outputs:  tensor([[0.0323, 0.9536],\n","        [0.9705, 0.0401],\n","        [0.9642, 0.0484],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3267, grad_fn=<NllLossBackward>)\n","epoch 2599, loss 0.32665297389030457\n","outputs:  tensor([[0.0322, 0.9536],\n","        [0.9705, 0.0400],\n","        [0.9642, 0.0484],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2600, loss 0.326644629240036\n","outputs:  tensor([[0.0322, 0.9536],\n","        [0.9705, 0.0400],\n","        [0.9643, 0.0483],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2601, loss 0.3266363739967346\n","Parameter containing:\n","tensor([[-0.2833, -0.6604,  0.1960],\n","        [-1.0441, -0.8030, -0.0760],\n","        [-1.0609, -0.9701, -0.1247],\n","        [-0.4694, -0.5013, -0.0021]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5117, -0.2615,  0.1909,  0.1364], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8827,  0.7774,  1.1630,  0.1445],\n","        [-0.2285, -1.0076, -0.8619, -0.6014]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3721, -0.6128], requires_grad=True)\n","outputs:  tensor([[0.0322, 0.9537],\n","        [0.9705, 0.0400],\n","        [0.9643, 0.0483],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2602, loss 0.32662805914878845\n","outputs:  tensor([[0.0322, 0.9537],\n","        [0.9705, 0.0400],\n","        [0.9643, 0.0483],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2603, loss 0.3266197741031647\n","outputs:  tensor([[0.0322, 0.9537],\n","        [0.9706, 0.0399],\n","        [0.9643, 0.0483],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2604, loss 0.32661154866218567\n","outputs:  tensor([[0.0322, 0.9538],\n","        [0.9706, 0.0399],\n","        [0.9643, 0.0482],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2605, loss 0.3266032934188843\n","outputs:  tensor([[0.0321, 0.9538],\n","        [0.9706, 0.0399],\n","        [0.9644, 0.0482],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9966]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2606, loss 0.3265950083732605\n","outputs:  tensor([[0.0321, 0.9538],\n","        [0.9706, 0.0399],\n","        [0.9644, 0.0482],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2607, loss 0.3265867829322815\n","outputs:  tensor([[0.0321, 0.9538],\n","        [0.9706, 0.0398],\n","        [0.9644, 0.0482],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2608, loss 0.3265785276889801\n","outputs:  tensor([[0.0321, 0.9539],\n","        [0.9706, 0.0398],\n","        [0.9644, 0.0481],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2609, loss 0.3265703320503235\n","outputs:  tensor([[0.0321, 0.9539],\n","        [0.9707, 0.0398],\n","        [0.9644, 0.0481],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2610, loss 0.3265621066093445\n","outputs:  tensor([[0.0320, 0.9539],\n","        [0.9707, 0.0398],\n","        [0.9644, 0.0481],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3266, grad_fn=<NllLossBackward>)\n","epoch 2611, loss 0.32655391097068787\n","outputs:  tensor([[0.0320, 0.9540],\n","        [0.9707, 0.0397],\n","        [0.9645, 0.0480],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2612, loss 0.326545774936676\n","outputs:  tensor([[0.0320, 0.9540],\n","        [0.9707, 0.0397],\n","        [0.9645, 0.0480],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2613, loss 0.32653748989105225\n","outputs:  tensor([[0.0320, 0.9540],\n","        [0.9707, 0.0397],\n","        [0.9645, 0.0480],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2614, loss 0.326529324054718\n","outputs:  tensor([[0.0320, 0.9540],\n","        [0.9707, 0.0397],\n","        [0.9645, 0.0480],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2615, loss 0.326521098613739\n","outputs:  tensor([[0.0320, 0.9541],\n","        [0.9708, 0.0396],\n","        [0.9645, 0.0479],\n","        [0.9988, 0.0022],\n","        [0.0030, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2616, loss 0.3265129625797272\n","outputs:  tensor([[0.0319, 0.9541],\n","        [0.9708, 0.0396],\n","        [0.9646, 0.0479],\n","        [0.9988, 0.0022],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2617, loss 0.32650479674339294\n","outputs:  tensor([[0.0319, 0.9541],\n","        [0.9708, 0.0396],\n","        [0.9646, 0.0479],\n","        [0.9988, 0.0022],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2618, loss 0.3264966607093811\n","outputs:  tensor([[0.0319, 0.9542],\n","        [0.9708, 0.0396],\n","        [0.9646, 0.0479],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2619, loss 0.3264884948730469\n","outputs:  tensor([[0.0319, 0.9542],\n","        [0.9708, 0.0396],\n","        [0.9646, 0.0478],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2620, loss 0.32648032903671265\n","outputs:  tensor([[0.0319, 0.9542],\n","        [0.9708, 0.0395],\n","        [0.9646, 0.0478],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2621, loss 0.3264722228050232\n","outputs:  tensor([[0.0318, 0.9542],\n","        [0.9709, 0.0395],\n","        [0.9647, 0.0478],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2622, loss 0.32646411657333374\n","outputs:  tensor([[0.0318, 0.9543],\n","        [0.9709, 0.0395],\n","        [0.9647, 0.0477],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3265, grad_fn=<NllLossBackward>)\n","epoch 2623, loss 0.32645612955093384\n","outputs:  tensor([[0.0318, 0.9543],\n","        [0.9709, 0.0395],\n","        [0.9647, 0.0477],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2624, loss 0.3264479637145996\n","outputs:  tensor([[0.0318, 0.9543],\n","        [0.9709, 0.0394],\n","        [0.9647, 0.0477],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2625, loss 0.32643991708755493\n","outputs:  tensor([[0.0318, 0.9544],\n","        [0.9709, 0.0394],\n","        [0.9647, 0.0477],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2626, loss 0.3264318108558655\n","outputs:  tensor([[0.0318, 0.9544],\n","        [0.9709, 0.0394],\n","        [0.9647, 0.0476],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2627, loss 0.326423704624176\n","outputs:  tensor([[0.0317, 0.9544],\n","        [0.9710, 0.0394],\n","        [0.9648, 0.0476],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2628, loss 0.32641562819480896\n","outputs:  tensor([[0.0317, 0.9544],\n","        [0.9710, 0.0393],\n","        [0.9648, 0.0476],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2629, loss 0.32640761137008667\n","outputs:  tensor([[0.0317, 0.9545],\n","        [0.9710, 0.0393],\n","        [0.9648, 0.0476],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2630, loss 0.3263995051383972\n","outputs:  tensor([[0.0317, 0.9545],\n","        [0.9710, 0.0393],\n","        [0.9648, 0.0475],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2631, loss 0.3263915181159973\n","outputs:  tensor([[0.0317, 0.9545],\n","        [0.9710, 0.0393],\n","        [0.9648, 0.0475],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2632, loss 0.326383501291275\n","outputs:  tensor([[0.0316, 0.9546],\n","        [0.9710, 0.0392],\n","        [0.9649, 0.0475],\n","        [0.9988, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2633, loss 0.32637542486190796\n","outputs:  tensor([[0.0316, 0.9546],\n","        [0.9710, 0.0392],\n","        [0.9649, 0.0474],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2634, loss 0.3263673782348633\n","outputs:  tensor([[0.0316, 0.9546],\n","        [0.9711, 0.0392],\n","        [0.9649, 0.0474],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9967]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2635, loss 0.3263593912124634\n","outputs:  tensor([[0.0316, 0.9546],\n","        [0.9711, 0.0392],\n","        [0.9649, 0.0474],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3264, grad_fn=<NllLossBackward>)\n","epoch 2636, loss 0.32635143399238586\n","outputs:  tensor([[0.0316, 0.9547],\n","        [0.9711, 0.0391],\n","        [0.9649, 0.0474],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2637, loss 0.3263433873653412\n","outputs:  tensor([[0.0316, 0.9547],\n","        [0.9711, 0.0391],\n","        [0.9650, 0.0473],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2638, loss 0.32633548974990845\n","outputs:  tensor([[0.0315, 0.9547],\n","        [0.9711, 0.0391],\n","        [0.9650, 0.0473],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2639, loss 0.32632747292518616\n","outputs:  tensor([[0.0315, 0.9548],\n","        [0.9711, 0.0391],\n","        [0.9650, 0.0473],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2640, loss 0.32631951570510864\n","outputs:  tensor([[0.0315, 0.9548],\n","        [0.9712, 0.0390],\n","        [0.9650, 0.0473],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2641, loss 0.32631155848503113\n","outputs:  tensor([[0.0315, 0.9548],\n","        [0.9712, 0.0390],\n","        [0.9650, 0.0472],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2642, loss 0.326303631067276\n","outputs:  tensor([[0.0315, 0.9548],\n","        [0.9712, 0.0390],\n","        [0.9650, 0.0472],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2643, loss 0.3262957036495209\n","outputs:  tensor([[0.0314, 0.9549],\n","        [0.9712, 0.0390],\n","        [0.9651, 0.0472],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2644, loss 0.32628774642944336\n","outputs:  tensor([[0.0314, 0.9549],\n","        [0.9712, 0.0390],\n","        [0.9651, 0.0472],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2645, loss 0.32627981901168823\n","outputs:  tensor([[0.0314, 0.9549],\n","        [0.9712, 0.0389],\n","        [0.9651, 0.0471],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2646, loss 0.3262719213962555\n","outputs:  tensor([[0.0314, 0.9550],\n","        [0.9713, 0.0389],\n","        [0.9651, 0.0471],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2647, loss 0.32626402378082275\n","outputs:  tensor([[0.0314, 0.9550],\n","        [0.9713, 0.0389],\n","        [0.9651, 0.0471],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3263, grad_fn=<NllLossBackward>)\n","epoch 2648, loss 0.32625612616539\n","outputs:  tensor([[0.0314, 0.9550],\n","        [0.9713, 0.0389],\n","        [0.9652, 0.0471],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2649, loss 0.3262482285499573\n","outputs:  tensor([[0.0313, 0.9550],\n","        [0.9713, 0.0388],\n","        [0.9652, 0.0470],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2650, loss 0.3262403607368469\n","outputs:  tensor([[0.0313, 0.9551],\n","        [0.9713, 0.0388],\n","        [0.9652, 0.0470],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2651, loss 0.3262324929237366\n","Parameter containing:\n","tensor([[-0.2849, -0.6632,  0.1959],\n","        [-1.0471, -0.8080, -0.0759],\n","        [-1.0641, -0.9756, -0.1247],\n","        [-0.4708, -0.5036, -0.0021]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5127, -0.2598,  0.1928,  0.1372], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8851,  0.7805,  1.1669,  0.1465],\n","        [-0.2318, -1.0119, -0.8672, -0.6040]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3730, -0.6139], requires_grad=True)\n","outputs:  tensor([[0.0313, 0.9551],\n","        [0.9713, 0.0388],\n","        [0.9652, 0.0470],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2652, loss 0.3262246251106262\n","outputs:  tensor([[0.0313, 0.9551],\n","        [0.9714, 0.0388],\n","        [0.9652, 0.0469],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2653, loss 0.32621675729751587\n","outputs:  tensor([[0.0313, 0.9551],\n","        [0.9714, 0.0387],\n","        [0.9652, 0.0469],\n","        [0.9989, 0.0021],\n","        [0.0029, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2654, loss 0.3262088894844055\n","outputs:  tensor([[0.0313, 0.9552],\n","        [0.9714, 0.0387],\n","        [0.9653, 0.0469],\n","        [0.9989, 0.0021],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2655, loss 0.32620105147361755\n","outputs:  tensor([[0.0312, 0.9552],\n","        [0.9714, 0.0387],\n","        [0.9653, 0.0469],\n","        [0.9989, 0.0021],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2656, loss 0.326193243265152\n","outputs:  tensor([[0.0312, 0.9552],\n","        [0.9714, 0.0387],\n","        [0.9653, 0.0468],\n","        [0.9989, 0.0021],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2657, loss 0.326185405254364\n","outputs:  tensor([[0.0312, 0.9553],\n","        [0.9714, 0.0386],\n","        [0.9653, 0.0468],\n","        [0.9989, 0.0021],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2658, loss 0.3261776268482208\n","outputs:  tensor([[0.0312, 0.9553],\n","        [0.9715, 0.0386],\n","        [0.9653, 0.0468],\n","        [0.9989, 0.0021],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2659, loss 0.32616981863975525\n","outputs:  tensor([[0.0312, 0.9553],\n","        [0.9715, 0.0386],\n","        [0.9654, 0.0468],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2660, loss 0.32616204023361206\n","outputs:  tensor([[0.0312, 0.9553],\n","        [0.9715, 0.0386],\n","        [0.9654, 0.0467],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3262, grad_fn=<NllLossBackward>)\n","epoch 2661, loss 0.3261542320251465\n","outputs:  tensor([[0.0311, 0.9554],\n","        [0.9715, 0.0386],\n","        [0.9654, 0.0467],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2662, loss 0.32614636421203613\n","outputs:  tensor([[0.0311, 0.9554],\n","        [0.9715, 0.0385],\n","        [0.9654, 0.0467],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2663, loss 0.3261386752128601\n","outputs:  tensor([[0.0311, 0.9554],\n","        [0.9715, 0.0385],\n","        [0.9654, 0.0467],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2664, loss 0.32613086700439453\n","outputs:  tensor([[0.0311, 0.9554],\n","        [0.9715, 0.0385],\n","        [0.9654, 0.0466],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9968]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2665, loss 0.32612308859825134\n","outputs:  tensor([[0.0311, 0.9555],\n","        [0.9716, 0.0385],\n","        [0.9655, 0.0466],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2666, loss 0.32611536979675293\n","outputs:  tensor([[0.0310, 0.9555],\n","        [0.9716, 0.0384],\n","        [0.9655, 0.0466],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2667, loss 0.3261076509952545\n","outputs:  tensor([[0.0310, 0.9555],\n","        [0.9716, 0.0384],\n","        [0.9655, 0.0466],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2668, loss 0.32609984278678894\n","outputs:  tensor([[0.0310, 0.9556],\n","        [0.9716, 0.0384],\n","        [0.9655, 0.0465],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2669, loss 0.3260921537876129\n","outputs:  tensor([[0.0310, 0.9556],\n","        [0.9716, 0.0384],\n","        [0.9655, 0.0465],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2670, loss 0.3260844051837921\n","outputs:  tensor([[0.0310, 0.9556],\n","        [0.9716, 0.0383],\n","        [0.9655, 0.0465],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2671, loss 0.3260767459869385\n","outputs:  tensor([[0.0310, 0.9556],\n","        [0.9717, 0.0383],\n","        [0.9656, 0.0464],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2672, loss 0.32606905698776245\n","outputs:  tensor([[0.0309, 0.9557],\n","        [0.9717, 0.0383],\n","        [0.9656, 0.0464],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2673, loss 0.32606133818626404\n","outputs:  tensor([[0.0309, 0.9557],\n","        [0.9717, 0.0383],\n","        [0.9656, 0.0464],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3261, grad_fn=<NllLossBackward>)\n","epoch 2674, loss 0.326053649187088\n","outputs:  tensor([[0.0309, 0.9557],\n","        [0.9717, 0.0383],\n","        [0.9656, 0.0464],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2675, loss 0.3260459303855896\n","outputs:  tensor([[0.0309, 0.9557],\n","        [0.9717, 0.0382],\n","        [0.9656, 0.0463],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2676, loss 0.3260382413864136\n","outputs:  tensor([[0.0309, 0.9558],\n","        [0.9717, 0.0382],\n","        [0.9657, 0.0463],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2677, loss 0.3260306417942047\n","outputs:  tensor([[0.0309, 0.9558],\n","        [0.9718, 0.0382],\n","        [0.9657, 0.0463],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2678, loss 0.3260229527950287\n","outputs:  tensor([[0.0308, 0.9558],\n","        [0.9718, 0.0382],\n","        [0.9657, 0.0463],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2679, loss 0.32601532340049744\n","outputs:  tensor([[0.0308, 0.9559],\n","        [0.9718, 0.0381],\n","        [0.9657, 0.0462],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2680, loss 0.3260077238082886\n","outputs:  tensor([[0.0308, 0.9559],\n","        [0.9718, 0.0381],\n","        [0.9657, 0.0462],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2681, loss 0.32600006461143494\n","outputs:  tensor([[0.0308, 0.9559],\n","        [0.9718, 0.0381],\n","        [0.9657, 0.0462],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2682, loss 0.3259924352169037\n","outputs:  tensor([[0.0308, 0.9559],\n","        [0.9718, 0.0381],\n","        [0.9658, 0.0462],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2683, loss 0.32598477602005005\n","outputs:  tensor([[0.0308, 0.9560],\n","        [0.9718, 0.0381],\n","        [0.9658, 0.0461],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2684, loss 0.3259771764278412\n","outputs:  tensor([[0.0307, 0.9560],\n","        [0.9719, 0.0380],\n","        [0.9658, 0.0461],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2685, loss 0.3259696066379547\n","outputs:  tensor([[0.0307, 0.9560],\n","        [0.9719, 0.0380],\n","        [0.9658, 0.0461],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2686, loss 0.32596200704574585\n","outputs:  tensor([[0.0307, 0.9560],\n","        [0.9719, 0.0380],\n","        [0.9658, 0.0461],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3260, grad_fn=<NllLossBackward>)\n","epoch 2687, loss 0.3259543776512146\n","outputs:  tensor([[0.0307, 0.9561],\n","        [0.9719, 0.0380],\n","        [0.9658, 0.0460],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2688, loss 0.3259468674659729\n","outputs:  tensor([[0.0307, 0.9561],\n","        [0.9719, 0.0379],\n","        [0.9659, 0.0460],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2689, loss 0.32593926787376404\n","outputs:  tensor([[0.0307, 0.9561],\n","        [0.9719, 0.0379],\n","        [0.9659, 0.0460],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2690, loss 0.32593172788619995\n","outputs:  tensor([[0.0306, 0.9562],\n","        [0.9720, 0.0379],\n","        [0.9659, 0.0460],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2691, loss 0.3259241580963135\n","outputs:  tensor([[0.0306, 0.9562],\n","        [0.9720, 0.0379],\n","        [0.9659, 0.0459],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2692, loss 0.3259166479110718\n","outputs:  tensor([[0.0306, 0.9562],\n","        [0.9720, 0.0378],\n","        [0.9659, 0.0459],\n","        [0.9989, 0.0020],\n","        [0.0028, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2693, loss 0.3259090781211853\n","outputs:  tensor([[0.0306, 0.9562],\n","        [0.9720, 0.0378],\n","        [0.9660, 0.0459],\n","        [0.9989, 0.0020],\n","        [0.0027, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2694, loss 0.3259015381336212\n","outputs:  tensor([[0.0306, 0.9563],\n","        [0.9720, 0.0378],\n","        [0.9660, 0.0459],\n","        [0.9989, 0.0020],\n","        [0.0027, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2695, loss 0.32589396834373474\n","outputs:  tensor([[0.0306, 0.9563],\n","        [0.9720, 0.0378],\n","        [0.9660, 0.0458],\n","        [0.9989, 0.0020],\n","        [0.0027, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2696, loss 0.32588648796081543\n","outputs:  tensor([[0.0305, 0.9563],\n","        [0.9720, 0.0378],\n","        [0.9660, 0.0458],\n","        [0.9989, 0.0020],\n","        [0.0027, 0.9969]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2697, loss 0.3258790075778961\n","outputs:  tensor([[0.0305, 0.9563],\n","        [0.9721, 0.0377],\n","        [0.9660, 0.0458],\n","        [0.9989, 0.0020],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2698, loss 0.3258714973926544\n","outputs:  tensor([[0.0305, 0.9564],\n","        [0.9721, 0.0377],\n","        [0.9660, 0.0458],\n","        [0.9989, 0.0020],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2699, loss 0.3258640170097351\n","outputs:  tensor([[0.0305, 0.9564],\n","        [0.9721, 0.0377],\n","        [0.9661, 0.0457],\n","        [0.9989, 0.0020],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3259, grad_fn=<NllLossBackward>)\n","epoch 2700, loss 0.3258565068244934\n","outputs:  tensor([[0.0305, 0.9564],\n","        [0.9721, 0.0377],\n","        [0.9661, 0.0457],\n","        [0.9989, 0.0020],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2701, loss 0.3258490562438965\n","Parameter containing:\n","tensor([[-0.2865, -0.6660,  0.1959],\n","        [-1.0500, -0.8130, -0.0759],\n","        [-1.0672, -0.9810, -0.1247],\n","        [-0.4720, -0.5058, -0.0021]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5137, -0.2580,  0.1947,  0.1379], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8874,  0.7835,  1.1707,  0.1484],\n","        [-0.2349, -1.0160, -0.8724, -0.6066]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3738, -0.6150], requires_grad=True)\n","outputs:  tensor([[0.0305, 0.9564],\n","        [0.9721, 0.0376],\n","        [0.9661, 0.0457],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2702, loss 0.3258415758609772\n","outputs:  tensor([[0.0304, 0.9565],\n","        [0.9721, 0.0376],\n","        [0.9661, 0.0457],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2703, loss 0.32583412528038025\n","outputs:  tensor([[0.0304, 0.9565],\n","        [0.9722, 0.0376],\n","        [0.9661, 0.0456],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2704, loss 0.32582664489746094\n","outputs:  tensor([[0.0304, 0.9565],\n","        [0.9722, 0.0376],\n","        [0.9661, 0.0456],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2705, loss 0.32581913471221924\n","outputs:  tensor([[0.0304, 0.9565],\n","        [0.9722, 0.0376],\n","        [0.9662, 0.0456],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2706, loss 0.3258117437362671\n","outputs:  tensor([[0.0304, 0.9566],\n","        [0.9722, 0.0375],\n","        [0.9662, 0.0456],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2707, loss 0.32580429315567017\n","outputs:  tensor([[0.0304, 0.9566],\n","        [0.9722, 0.0375],\n","        [0.9662, 0.0455],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2708, loss 0.3257969319820404\n","outputs:  tensor([[0.0303, 0.9566],\n","        [0.9722, 0.0375],\n","        [0.9662, 0.0455],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2709, loss 0.32578951120376587\n","outputs:  tensor([[0.0303, 0.9567],\n","        [0.9722, 0.0375],\n","        [0.9662, 0.0455],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2710, loss 0.3257821202278137\n","outputs:  tensor([[0.0303, 0.9567],\n","        [0.9723, 0.0374],\n","        [0.9662, 0.0455],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2711, loss 0.3257746994495392\n","outputs:  tensor([[0.0303, 0.9567],\n","        [0.9723, 0.0374],\n","        [0.9663, 0.0454],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2712, loss 0.32576727867126465\n","outputs:  tensor([[0.0303, 0.9567],\n","        [0.9723, 0.0374],\n","        [0.9663, 0.0454],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2713, loss 0.3257599472999573\n","outputs:  tensor([[0.0303, 0.9568],\n","        [0.9723, 0.0374],\n","        [0.9663, 0.0454],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3258, grad_fn=<NllLossBackward>)\n","epoch 2714, loss 0.3257525563240051\n","outputs:  tensor([[0.0302, 0.9568],\n","        [0.9723, 0.0374],\n","        [0.9663, 0.0454],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2715, loss 0.325745165348053\n","outputs:  tensor([[0.0302, 0.9568],\n","        [0.9723, 0.0373],\n","        [0.9663, 0.0453],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2716, loss 0.32573777437210083\n","outputs:  tensor([[0.0302, 0.9568],\n","        [0.9723, 0.0373],\n","        [0.9663, 0.0453],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2717, loss 0.32573044300079346\n","outputs:  tensor([[0.0302, 0.9569],\n","        [0.9724, 0.0373],\n","        [0.9664, 0.0453],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2718, loss 0.3257231116294861\n","outputs:  tensor([[0.0302, 0.9569],\n","        [0.9724, 0.0373],\n","        [0.9664, 0.0453],\n","        [0.9989, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2719, loss 0.32571572065353394\n","outputs:  tensor([[0.0302, 0.9569],\n","        [0.9724, 0.0372],\n","        [0.9664, 0.0452],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2720, loss 0.32570841908454895\n","outputs:  tensor([[0.0301, 0.9569],\n","        [0.9724, 0.0372],\n","        [0.9664, 0.0452],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2721, loss 0.3257010877132416\n","outputs:  tensor([[0.0301, 0.9570],\n","        [0.9724, 0.0372],\n","        [0.9664, 0.0452],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2722, loss 0.3256937563419342\n","outputs:  tensor([[0.0301, 0.9570],\n","        [0.9724, 0.0372],\n","        [0.9665, 0.0452],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2723, loss 0.3256864547729492\n","outputs:  tensor([[0.0301, 0.9570],\n","        [0.9725, 0.0372],\n","        [0.9665, 0.0451],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2724, loss 0.32567912340164185\n","outputs:  tensor([[0.0301, 0.9570],\n","        [0.9725, 0.0371],\n","        [0.9665, 0.0451],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2725, loss 0.32567185163497925\n","outputs:  tensor([[0.0301, 0.9571],\n","        [0.9725, 0.0371],\n","        [0.9665, 0.0451],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2726, loss 0.32566457986831665\n","outputs:  tensor([[0.0300, 0.9571],\n","        [0.9725, 0.0371],\n","        [0.9665, 0.0451],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2727, loss 0.32565730810165405\n","outputs:  tensor([[0.0300, 0.9571],\n","        [0.9725, 0.0371],\n","        [0.9665, 0.0450],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3257, grad_fn=<NllLossBackward>)\n","epoch 2728, loss 0.32565003633499146\n","outputs:  tensor([[0.0300, 0.9571],\n","        [0.9725, 0.0371],\n","        [0.9666, 0.0450],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2729, loss 0.32564273476600647\n","outputs:  tensor([[0.0300, 0.9572],\n","        [0.9725, 0.0370],\n","        [0.9666, 0.0450],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9970]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2730, loss 0.3256354331970215\n","outputs:  tensor([[0.0300, 0.9572],\n","        [0.9726, 0.0370],\n","        [0.9666, 0.0450],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2731, loss 0.32562825083732605\n","outputs:  tensor([[0.0300, 0.9572],\n","        [0.9726, 0.0370],\n","        [0.9666, 0.0449],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2732, loss 0.32562094926834106\n","outputs:  tensor([[0.0299, 0.9572],\n","        [0.9726, 0.0370],\n","        [0.9666, 0.0449],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2733, loss 0.32561370730400085\n","outputs:  tensor([[0.0299, 0.9573],\n","        [0.9726, 0.0369],\n","        [0.9666, 0.0449],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2734, loss 0.32560649514198303\n","outputs:  tensor([[0.0299, 0.9573],\n","        [0.9726, 0.0369],\n","        [0.9667, 0.0449],\n","        [0.9990, 0.0019],\n","        [0.0027, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2735, loss 0.3255992829799652\n","outputs:  tensor([[0.0299, 0.9573],\n","        [0.9726, 0.0369],\n","        [0.9667, 0.0448],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2736, loss 0.3255921006202698\n","outputs:  tensor([[0.0299, 0.9574],\n","        [0.9726, 0.0369],\n","        [0.9667, 0.0448],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2737, loss 0.3255847990512848\n","outputs:  tensor([[0.0299, 0.9574],\n","        [0.9727, 0.0369],\n","        [0.9667, 0.0448],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2738, loss 0.32557764649391174\n","outputs:  tensor([[0.0298, 0.9574],\n","        [0.9727, 0.0368],\n","        [0.9667, 0.0448],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2739, loss 0.3255704343318939\n","outputs:  tensor([[0.0298, 0.9574],\n","        [0.9727, 0.0368],\n","        [0.9667, 0.0447],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2740, loss 0.3255632817745209\n","outputs:  tensor([[0.0298, 0.9575],\n","        [0.9727, 0.0368],\n","        [0.9668, 0.0447],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3256, grad_fn=<NllLossBackward>)\n","epoch 2741, loss 0.32555609941482544\n","outputs:  tensor([[0.0298, 0.9575],\n","        [0.9727, 0.0368],\n","        [0.9668, 0.0447],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2742, loss 0.3255489468574524\n","outputs:  tensor([[0.0298, 0.9575],\n","        [0.9727, 0.0367],\n","        [0.9668, 0.0447],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2743, loss 0.32554173469543457\n","outputs:  tensor([[0.0298, 0.9575],\n","        [0.9728, 0.0367],\n","        [0.9668, 0.0446],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2744, loss 0.3255345821380615\n","outputs:  tensor([[0.0297, 0.9576],\n","        [0.9728, 0.0367],\n","        [0.9668, 0.0446],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2745, loss 0.32552745938301086\n","outputs:  tensor([[0.0297, 0.9576],\n","        [0.9728, 0.0367],\n","        [0.9668, 0.0446],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2746, loss 0.32552027702331543\n","outputs:  tensor([[0.0297, 0.9576],\n","        [0.9728, 0.0367],\n","        [0.9669, 0.0446],\n","        [0.9990, 0.0019],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2747, loss 0.32551315426826477\n","outputs:  tensor([[0.0297, 0.9576],\n","        [0.9728, 0.0366],\n","        [0.9669, 0.0446],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2748, loss 0.3255060315132141\n","outputs:  tensor([[0.0297, 0.9577],\n","        [0.9728, 0.0366],\n","        [0.9669, 0.0445],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2749, loss 0.32549887895584106\n","outputs:  tensor([[0.0297, 0.9577],\n","        [0.9728, 0.0366],\n","        [0.9669, 0.0445],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2750, loss 0.3254917562007904\n","outputs:  tensor([[0.0297, 0.9577],\n","        [0.9729, 0.0366],\n","        [0.9669, 0.0445],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2751, loss 0.32548466324806213\n","Parameter containing:\n","tensor([[-0.2881, -0.6686,  0.1959],\n","        [-1.0528, -0.8178, -0.0759],\n","        [-1.0703, -0.9862, -0.1247],\n","        [-0.4733, -0.5080, -0.0021]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5146, -0.2564,  0.1965,  0.1387], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8896,  0.7865,  1.1744,  0.1502],\n","        [-0.2380, -1.0200, -0.8775, -0.6091]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3746, -0.6160], requires_grad=True)\n","outputs:  tensor([[0.0296, 0.9577],\n","        [0.9729, 0.0366],\n","        [0.9669, 0.0445],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2752, loss 0.32547757029533386\n","outputs:  tensor([[0.0296, 0.9578],\n","        [0.9729, 0.0365],\n","        [0.9670, 0.0444],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2753, loss 0.325470507144928\n","outputs:  tensor([[0.0296, 0.9578],\n","        [0.9729, 0.0365],\n","        [0.9670, 0.0444],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2754, loss 0.3254634141921997\n","outputs:  tensor([[0.0296, 0.9578],\n","        [0.9729, 0.0365],\n","        [0.9670, 0.0444],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3255, grad_fn=<NllLossBackward>)\n","epoch 2755, loss 0.32545632123947144\n","outputs:  tensor([[0.0296, 0.9578],\n","        [0.9729, 0.0365],\n","        [0.9670, 0.0444],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2756, loss 0.32544922828674316\n","outputs:  tensor([[0.0296, 0.9579],\n","        [0.9729, 0.0365],\n","        [0.9670, 0.0443],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2757, loss 0.3254421651363373\n","outputs:  tensor([[0.0295, 0.9579],\n","        [0.9730, 0.0364],\n","        [0.9670, 0.0443],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2758, loss 0.3254351019859314\n","outputs:  tensor([[0.0295, 0.9579],\n","        [0.9730, 0.0364],\n","        [0.9671, 0.0443],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2759, loss 0.3254280686378479\n","outputs:  tensor([[0.0295, 0.9579],\n","        [0.9730, 0.0364],\n","        [0.9671, 0.0443],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2760, loss 0.3254210352897644\n","outputs:  tensor([[0.0295, 0.9580],\n","        [0.9730, 0.0364],\n","        [0.9671, 0.0442],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2761, loss 0.3254140019416809\n","outputs:  tensor([[0.0295, 0.9580],\n","        [0.9730, 0.0363],\n","        [0.9671, 0.0442],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2762, loss 0.3254069685935974\n","outputs:  tensor([[0.0295, 0.9580],\n","        [0.9730, 0.0363],\n","        [0.9671, 0.0442],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2763, loss 0.3253999352455139\n","outputs:  tensor([[0.0294, 0.9580],\n","        [0.9730, 0.0363],\n","        [0.9671, 0.0442],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2764, loss 0.3253929615020752\n","outputs:  tensor([[0.0294, 0.9581],\n","        [0.9731, 0.0363],\n","        [0.9672, 0.0441],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9971]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2765, loss 0.3253858685493469\n","outputs:  tensor([[0.0294, 0.9581],\n","        [0.9731, 0.0363],\n","        [0.9672, 0.0441],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2766, loss 0.3253788948059082\n","outputs:  tensor([[0.0294, 0.9581],\n","        [0.9731, 0.0362],\n","        [0.9672, 0.0441],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2767, loss 0.3253718614578247\n","outputs:  tensor([[0.0294, 0.9581],\n","        [0.9731, 0.0362],\n","        [0.9672, 0.0441],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2768, loss 0.3253648579120636\n","outputs:  tensor([[0.0294, 0.9582],\n","        [0.9731, 0.0362],\n","        [0.9672, 0.0440],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2769, loss 0.3253578543663025\n","outputs:  tensor([[0.0294, 0.9582],\n","        [0.9731, 0.0362],\n","        [0.9672, 0.0440],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3254, grad_fn=<NllLossBackward>)\n","epoch 2770, loss 0.32535091042518616\n","outputs:  tensor([[0.0293, 0.9582],\n","        [0.9731, 0.0362],\n","        [0.9673, 0.0440],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2771, loss 0.3253439962863922\n","outputs:  tensor([[0.0293, 0.9582],\n","        [0.9732, 0.0361],\n","        [0.9673, 0.0440],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2772, loss 0.3253369927406311\n","outputs:  tensor([[0.0293, 0.9583],\n","        [0.9732, 0.0361],\n","        [0.9673, 0.0440],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2773, loss 0.32533007860183716\n","outputs:  tensor([[0.0293, 0.9583],\n","        [0.9732, 0.0361],\n","        [0.9673, 0.0439],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2774, loss 0.3253231644630432\n","outputs:  tensor([[0.0293, 0.9583],\n","        [0.9732, 0.0361],\n","        [0.9673, 0.0439],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2775, loss 0.3253161609172821\n","outputs:  tensor([[0.0293, 0.9583],\n","        [0.9732, 0.0361],\n","        [0.9673, 0.0439],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2776, loss 0.32530921697616577\n","outputs:  tensor([[0.0292, 0.9583],\n","        [0.9732, 0.0360],\n","        [0.9673, 0.0439],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2777, loss 0.3253023028373718\n","outputs:  tensor([[0.0292, 0.9584],\n","        [0.9732, 0.0360],\n","        [0.9674, 0.0438],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2778, loss 0.3252953588962555\n","outputs:  tensor([[0.0292, 0.9584],\n","        [0.9733, 0.0360],\n","        [0.9674, 0.0438],\n","        [0.9990, 0.0018],\n","        [0.0026, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2779, loss 0.32528847455978394\n","outputs:  tensor([[0.0292, 0.9584],\n","        [0.9733, 0.0360],\n","        [0.9674, 0.0438],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2780, loss 0.32528156042099\n","outputs:  tensor([[0.0292, 0.9584],\n","        [0.9733, 0.0360],\n","        [0.9674, 0.0438],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2781, loss 0.32527467608451843\n","outputs:  tensor([[0.0292, 0.9585],\n","        [0.9733, 0.0359],\n","        [0.9674, 0.0437],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2782, loss 0.3252677619457245\n","outputs:  tensor([[0.0291, 0.9585],\n","        [0.9733, 0.0359],\n","        [0.9674, 0.0437],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2783, loss 0.32526081800460815\n","outputs:  tensor([[0.0291, 0.9585],\n","        [0.9733, 0.0359],\n","        [0.9675, 0.0437],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3253, grad_fn=<NllLossBackward>)\n","epoch 2784, loss 0.32525402307510376\n","outputs:  tensor([[0.0291, 0.9585],\n","        [0.9733, 0.0359],\n","        [0.9675, 0.0437],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2785, loss 0.3252471387386322\n","outputs:  tensor([[0.0291, 0.9586],\n","        [0.9734, 0.0358],\n","        [0.9675, 0.0436],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2786, loss 0.32524028420448303\n","outputs:  tensor([[0.0291, 0.9586],\n","        [0.9734, 0.0358],\n","        [0.9675, 0.0436],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2787, loss 0.3252333998680115\n","outputs:  tensor([[0.0291, 0.9586],\n","        [0.9734, 0.0358],\n","        [0.9675, 0.0436],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2788, loss 0.3252265453338623\n","outputs:  tensor([[0.0291, 0.9586],\n","        [0.9734, 0.0358],\n","        [0.9675, 0.0436],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2789, loss 0.3252197206020355\n","outputs:  tensor([[0.0290, 0.9587],\n","        [0.9734, 0.0358],\n","        [0.9676, 0.0436],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2790, loss 0.32521289587020874\n","outputs:  tensor([[0.0290, 0.9587],\n","        [0.9734, 0.0357],\n","        [0.9676, 0.0435],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2791, loss 0.32520604133605957\n","outputs:  tensor([[0.0290, 0.9587],\n","        [0.9734, 0.0357],\n","        [0.9676, 0.0435],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2792, loss 0.3251992166042328\n","outputs:  tensor([[0.0290, 0.9587],\n","        [0.9735, 0.0357],\n","        [0.9676, 0.0435],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2793, loss 0.3251923620700836\n","outputs:  tensor([[0.0290, 0.9588],\n","        [0.9735, 0.0357],\n","        [0.9676, 0.0435],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2794, loss 0.325185626745224\n","outputs:  tensor([[0.0290, 0.9588],\n","        [0.9735, 0.0357],\n","        [0.9676, 0.0434],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2795, loss 0.32517871260643005\n","outputs:  tensor([[0.0289, 0.9588],\n","        [0.9735, 0.0356],\n","        [0.9677, 0.0434],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2796, loss 0.32517194747924805\n","outputs:  tensor([[0.0289, 0.9588],\n","        [0.9735, 0.0356],\n","        [0.9677, 0.0434],\n","        [0.9990, 0.0018],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2797, loss 0.32516518235206604\n","outputs:  tensor([[0.0289, 0.9589],\n","        [0.9735, 0.0356],\n","        [0.9677, 0.0434],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2798, loss 0.32515841722488403\n","outputs:  tensor([[0.0289, 0.9589],\n","        [0.9735, 0.0356],\n","        [0.9677, 0.0433],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3252, grad_fn=<NllLossBackward>)\n","epoch 2799, loss 0.32515159249305725\n","outputs:  tensor([[0.0289, 0.9589],\n","        [0.9736, 0.0356],\n","        [0.9677, 0.0433],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2800, loss 0.32514482736587524\n","outputs:  tensor([[0.0289, 0.9589],\n","        [0.9736, 0.0355],\n","        [0.9677, 0.0433],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9972]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2801, loss 0.32513803243637085\n","Parameter containing:\n","tensor([[-0.2896, -0.6713,  0.1959],\n","        [-1.0555, -0.8225, -0.0759],\n","        [-1.0733, -0.9913, -0.1248],\n","        [-0.4745, -0.5101, -0.0020]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5156, -0.2547,  0.1983,  0.1394], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8918,  0.7894,  1.1780,  0.1520],\n","        [-0.2410, -1.0240, -0.8824, -0.6116]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3754, -0.6170], requires_grad=True)\n","outputs:  tensor([[0.0289, 0.9590],\n","        [0.9736, 0.0355],\n","        [0.9677, 0.0433],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2802, loss 0.3251313269138336\n","outputs:  tensor([[0.0288, 0.9590],\n","        [0.9736, 0.0355],\n","        [0.9678, 0.0433],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2803, loss 0.3251245617866516\n","outputs:  tensor([[0.0288, 0.9590],\n","        [0.9736, 0.0355],\n","        [0.9678, 0.0432],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2804, loss 0.32511788606643677\n","outputs:  tensor([[0.0288, 0.9590],\n","        [0.9736, 0.0355],\n","        [0.9678, 0.0432],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2805, loss 0.3251110315322876\n","outputs:  tensor([[0.0288, 0.9590],\n","        [0.9736, 0.0354],\n","        [0.9678, 0.0432],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2806, loss 0.32510435581207275\n","outputs:  tensor([[0.0288, 0.9591],\n","        [0.9737, 0.0354],\n","        [0.9678, 0.0432],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2807, loss 0.32509759068489075\n","outputs:  tensor([[0.0288, 0.9591],\n","        [0.9737, 0.0354],\n","        [0.9678, 0.0431],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2808, loss 0.32509082555770874\n","outputs:  tensor([[0.0288, 0.9591],\n","        [0.9737, 0.0354],\n","        [0.9679, 0.0431],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2809, loss 0.32508420944213867\n","outputs:  tensor([[0.0287, 0.9591],\n","        [0.9737, 0.0354],\n","        [0.9679, 0.0431],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2810, loss 0.32507747411727905\n","outputs:  tensor([[0.0287, 0.9592],\n","        [0.9737, 0.0353],\n","        [0.9679, 0.0431],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2811, loss 0.3250707685947418\n","outputs:  tensor([[0.0287, 0.9592],\n","        [0.9737, 0.0353],\n","        [0.9679, 0.0431],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2812, loss 0.325064092874527\n","outputs:  tensor([[0.0287, 0.9592],\n","        [0.9737, 0.0353],\n","        [0.9679, 0.0430],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2813, loss 0.3250574469566345\n","outputs:  tensor([[0.0287, 0.9592],\n","        [0.9737, 0.0353],\n","        [0.9679, 0.0430],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3251, grad_fn=<NllLossBackward>)\n","epoch 2814, loss 0.3250507116317749\n","outputs:  tensor([[0.0287, 0.9593],\n","        [0.9738, 0.0353],\n","        [0.9680, 0.0430],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2815, loss 0.32504409551620483\n","outputs:  tensor([[0.0286, 0.9593],\n","        [0.9738, 0.0352],\n","        [0.9680, 0.0430],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2816, loss 0.3250373899936676\n","outputs:  tensor([[0.0286, 0.9593],\n","        [0.9738, 0.0352],\n","        [0.9680, 0.0429],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2817, loss 0.32503071427345276\n","outputs:  tensor([[0.0286, 0.9593],\n","        [0.9738, 0.0352],\n","        [0.9680, 0.0429],\n","        [0.9990, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2818, loss 0.3250240683555603\n","outputs:  tensor([[0.0286, 0.9594],\n","        [0.9738, 0.0352],\n","        [0.9680, 0.0429],\n","        [0.9991, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2819, loss 0.32501739263534546\n","outputs:  tensor([[0.0286, 0.9594],\n","        [0.9738, 0.0352],\n","        [0.9680, 0.0429],\n","        [0.9991, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2820, loss 0.3250107765197754\n","outputs:  tensor([[0.0286, 0.9594],\n","        [0.9738, 0.0351],\n","        [0.9680, 0.0428],\n","        [0.9991, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2821, loss 0.3250041604042053\n","outputs:  tensor([[0.0286, 0.9594],\n","        [0.9739, 0.0351],\n","        [0.9681, 0.0428],\n","        [0.9991, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2822, loss 0.3249974548816681\n","outputs:  tensor([[0.0285, 0.9595],\n","        [0.9739, 0.0351],\n","        [0.9681, 0.0428],\n","        [0.9991, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2823, loss 0.324990838766098\n","outputs:  tensor([[0.0285, 0.9595],\n","        [0.9739, 0.0351],\n","        [0.9681, 0.0428],\n","        [0.9991, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2824, loss 0.32498425245285034\n","outputs:  tensor([[0.0285, 0.9595],\n","        [0.9739, 0.0351],\n","        [0.9681, 0.0428],\n","        [0.9991, 0.0017],\n","        [0.0025, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2825, loss 0.32497766613960266\n","outputs:  tensor([[0.0285, 0.9595],\n","        [0.9739, 0.0350],\n","        [0.9681, 0.0427],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2826, loss 0.3249710500240326\n","outputs:  tensor([[0.0285, 0.9595],\n","        [0.9739, 0.0350],\n","        [0.9681, 0.0427],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2827, loss 0.3249644637107849\n","outputs:  tensor([[0.0285, 0.9596],\n","        [0.9739, 0.0350],\n","        [0.9682, 0.0427],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2828, loss 0.3249579071998596\n","outputs:  tensor([[0.0285, 0.9596],\n","        [0.9740, 0.0350],\n","        [0.9682, 0.0427],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3250, grad_fn=<NllLossBackward>)\n","epoch 2829, loss 0.32495126128196716\n","outputs:  tensor([[0.0284, 0.9596],\n","        [0.9740, 0.0350],\n","        [0.9682, 0.0426],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2830, loss 0.32494470477104187\n","outputs:  tensor([[0.0284, 0.9596],\n","        [0.9740, 0.0349],\n","        [0.9682, 0.0426],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2831, loss 0.3249381482601166\n","outputs:  tensor([[0.0284, 0.9597],\n","        [0.9740, 0.0349],\n","        [0.9682, 0.0426],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2832, loss 0.3249315917491913\n","outputs:  tensor([[0.0284, 0.9597],\n","        [0.9740, 0.0349],\n","        [0.9682, 0.0426],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2833, loss 0.3249250054359436\n","outputs:  tensor([[0.0284, 0.9597],\n","        [0.9740, 0.0349],\n","        [0.9682, 0.0426],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2834, loss 0.3249184489250183\n","outputs:  tensor([[0.0284, 0.9597],\n","        [0.9740, 0.0349],\n","        [0.9683, 0.0425],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2835, loss 0.3249119222164154\n","outputs:  tensor([[0.0283, 0.9598],\n","        [0.9740, 0.0348],\n","        [0.9683, 0.0425],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2836, loss 0.3249053359031677\n","outputs:  tensor([[0.0283, 0.9598],\n","        [0.9741, 0.0348],\n","        [0.9683, 0.0425],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2837, loss 0.3248988687992096\n","outputs:  tensor([[0.0283, 0.9598],\n","        [0.9741, 0.0348],\n","        [0.9683, 0.0425],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2838, loss 0.3248923420906067\n","outputs:  tensor([[0.0283, 0.9598],\n","        [0.9741, 0.0348],\n","        [0.9683, 0.0424],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2839, loss 0.3248858153820038\n","outputs:  tensor([[0.0283, 0.9598],\n","        [0.9741, 0.0348],\n","        [0.9683, 0.0424],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9973]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2840, loss 0.32487931847572327\n","outputs:  tensor([[0.0283, 0.9599],\n","        [0.9741, 0.0347],\n","        [0.9684, 0.0424],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2841, loss 0.32487279176712036\n","outputs:  tensor([[0.0283, 0.9599],\n","        [0.9741, 0.0347],\n","        [0.9684, 0.0424],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2842, loss 0.3248663544654846\n","outputs:  tensor([[0.0282, 0.9599],\n","        [0.9741, 0.0347],\n","        [0.9684, 0.0424],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2843, loss 0.32485976815223694\n","outputs:  tensor([[0.0282, 0.9599],\n","        [0.9742, 0.0347],\n","        [0.9684, 0.0423],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3249, grad_fn=<NllLossBackward>)\n","epoch 2844, loss 0.3248533308506012\n","outputs:  tensor([[0.0282, 0.9600],\n","        [0.9742, 0.0347],\n","        [0.9684, 0.0423],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2845, loss 0.3248468041419983\n","outputs:  tensor([[0.0282, 0.9600],\n","        [0.9742, 0.0346],\n","        [0.9684, 0.0423],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2846, loss 0.3248403072357178\n","outputs:  tensor([[0.0282, 0.9600],\n","        [0.9742, 0.0346],\n","        [0.9684, 0.0423],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2847, loss 0.32483381032943726\n","outputs:  tensor([[0.0282, 0.9600],\n","        [0.9742, 0.0346],\n","        [0.9685, 0.0422],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2848, loss 0.3248273730278015\n","outputs:  tensor([[0.0282, 0.9601],\n","        [0.9742, 0.0346],\n","        [0.9685, 0.0422],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2849, loss 0.32482093572616577\n","outputs:  tensor([[0.0281, 0.9601],\n","        [0.9742, 0.0346],\n","        [0.9685, 0.0422],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2850, loss 0.32481449842453003\n","outputs:  tensor([[0.0281, 0.9601],\n","        [0.9742, 0.0346],\n","        [0.9685, 0.0422],\n","        [0.9991, 0.0017],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2851, loss 0.3248080611228943\n","Parameter containing:\n","tensor([[-0.2911, -0.6738,  0.1958],\n","        [-1.0582, -0.8271, -0.0759],\n","        [-1.0762, -0.9963, -0.1248],\n","        [-0.4757, -0.5122, -0.0020]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5165, -0.2531,  0.2001,  0.1402], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8940,  0.7922,  1.1816,  0.1538],\n","        [-0.2439, -1.0278, -0.8872, -0.6139]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3762, -0.6180], requires_grad=True)\n","outputs:  tensor([[0.0281, 0.9601],\n","        [0.9743, 0.0345],\n","        [0.9685, 0.0422],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2852, loss 0.32480159401893616\n","outputs:  tensor([[0.0281, 0.9601],\n","        [0.9743, 0.0345],\n","        [0.9685, 0.0421],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2853, loss 0.3247951567173004\n","outputs:  tensor([[0.0281, 0.9602],\n","        [0.9743, 0.0345],\n","        [0.9686, 0.0421],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2854, loss 0.32478874921798706\n","outputs:  tensor([[0.0281, 0.9602],\n","        [0.9743, 0.0345],\n","        [0.9686, 0.0421],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2855, loss 0.3247823119163513\n","outputs:  tensor([[0.0281, 0.9602],\n","        [0.9743, 0.0345],\n","        [0.9686, 0.0421],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2856, loss 0.32477593421936035\n","outputs:  tensor([[0.0280, 0.9602],\n","        [0.9743, 0.0344],\n","        [0.9686, 0.0420],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2857, loss 0.3247695565223694\n","outputs:  tensor([[0.0280, 0.9603],\n","        [0.9743, 0.0344],\n","        [0.9686, 0.0420],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2858, loss 0.32476311922073364\n","outputs:  tensor([[0.0280, 0.9603],\n","        [0.9744, 0.0344],\n","        [0.9686, 0.0420],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2859, loss 0.3247567117214203\n","outputs:  tensor([[0.0280, 0.9603],\n","        [0.9744, 0.0344],\n","        [0.9686, 0.0420],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3248, grad_fn=<NllLossBackward>)\n","epoch 2860, loss 0.3247503638267517\n","outputs:  tensor([[0.0280, 0.9603],\n","        [0.9744, 0.0344],\n","        [0.9687, 0.0420],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2861, loss 0.32474398612976074\n","outputs:  tensor([[0.0280, 0.9603],\n","        [0.9744, 0.0343],\n","        [0.9687, 0.0419],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2862, loss 0.324737548828125\n","outputs:  tensor([[0.0280, 0.9604],\n","        [0.9744, 0.0343],\n","        [0.9687, 0.0419],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2863, loss 0.3247312009334564\n","outputs:  tensor([[0.0279, 0.9604],\n","        [0.9744, 0.0343],\n","        [0.9687, 0.0419],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2864, loss 0.32472482323646545\n","outputs:  tensor([[0.0279, 0.9604],\n","        [0.9744, 0.0343],\n","        [0.9687, 0.0419],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2865, loss 0.3247184753417969\n","outputs:  tensor([[0.0279, 0.9604],\n","        [0.9744, 0.0343],\n","        [0.9687, 0.0419],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2866, loss 0.3247120976448059\n","outputs:  tensor([[0.0279, 0.9605],\n","        [0.9745, 0.0342],\n","        [0.9688, 0.0418],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2867, loss 0.3247057795524597\n","outputs:  tensor([[0.0279, 0.9605],\n","        [0.9745, 0.0342],\n","        [0.9688, 0.0418],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2868, loss 0.32469940185546875\n","outputs:  tensor([[0.0279, 0.9605],\n","        [0.9745, 0.0342],\n","        [0.9688, 0.0418],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2869, loss 0.32469308376312256\n","outputs:  tensor([[0.0279, 0.9605],\n","        [0.9745, 0.0342],\n","        [0.9688, 0.0418],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2870, loss 0.324686735868454\n","outputs:  tensor([[0.0278, 0.9605],\n","        [0.9745, 0.0342],\n","        [0.9688, 0.0417],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2871, loss 0.3246804177761078\n","outputs:  tensor([[0.0278, 0.9606],\n","        [0.9745, 0.0341],\n","        [0.9688, 0.0417],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2872, loss 0.32467418909072876\n","outputs:  tensor([[0.0278, 0.9606],\n","        [0.9745, 0.0341],\n","        [0.9688, 0.0417],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2873, loss 0.3246678411960602\n","outputs:  tensor([[0.0278, 0.9606],\n","        [0.9746, 0.0341],\n","        [0.9689, 0.0417],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2874, loss 0.3246614933013916\n","outputs:  tensor([[0.0278, 0.9606],\n","        [0.9746, 0.0341],\n","        [0.9689, 0.0417],\n","        [0.9991, 0.0016],\n","        [0.0024, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3247, grad_fn=<NllLossBackward>)\n","epoch 2875, loss 0.3246552050113678\n","outputs:  tensor([[0.0278, 0.9607],\n","        [0.9746, 0.0341],\n","        [0.9689, 0.0416],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2876, loss 0.3246489465236664\n","outputs:  tensor([[0.0278, 0.9607],\n","        [0.9746, 0.0341],\n","        [0.9689, 0.0416],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2877, loss 0.3246426582336426\n","outputs:  tensor([[0.0277, 0.9607],\n","        [0.9746, 0.0340],\n","        [0.9689, 0.0416],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2878, loss 0.3246363401412964\n","outputs:  tensor([[0.0277, 0.9607],\n","        [0.9746, 0.0340],\n","        [0.9689, 0.0416],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2879, loss 0.32463008165359497\n","outputs:  tensor([[0.0277, 0.9607],\n","        [0.9746, 0.0340],\n","        [0.9689, 0.0416],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9974]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2880, loss 0.3246237635612488\n","outputs:  tensor([[0.0277, 0.9608],\n","        [0.9746, 0.0340],\n","        [0.9690, 0.0415],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2881, loss 0.32461753487586975\n","outputs:  tensor([[0.0277, 0.9608],\n","        [0.9747, 0.0340],\n","        [0.9690, 0.0415],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2882, loss 0.32461127638816833\n","outputs:  tensor([[0.0277, 0.9608],\n","        [0.9747, 0.0339],\n","        [0.9690, 0.0415],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2883, loss 0.32460498809814453\n","outputs:  tensor([[0.0277, 0.9608],\n","        [0.9747, 0.0339],\n","        [0.9690, 0.0415],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2884, loss 0.32459884881973267\n","outputs:  tensor([[0.0276, 0.9609],\n","        [0.9747, 0.0339],\n","        [0.9690, 0.0414],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2885, loss 0.3245925307273865\n","outputs:  tensor([[0.0276, 0.9609],\n","        [0.9747, 0.0339],\n","        [0.9690, 0.0414],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2886, loss 0.32458633184432983\n","outputs:  tensor([[0.0276, 0.9609],\n","        [0.9747, 0.0339],\n","        [0.9690, 0.0414],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2887, loss 0.3245801031589508\n","outputs:  tensor([[0.0276, 0.9609],\n","        [0.9747, 0.0338],\n","        [0.9691, 0.0414],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2888, loss 0.3245738446712494\n","outputs:  tensor([[0.0276, 0.9609],\n","        [0.9747, 0.0338],\n","        [0.9691, 0.0414],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2889, loss 0.32456764578819275\n","outputs:  tensor([[0.0276, 0.9610],\n","        [0.9748, 0.0338],\n","        [0.9691, 0.0413],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2890, loss 0.3245614171028137\n","outputs:  tensor([[0.0276, 0.9610],\n","        [0.9748, 0.0338],\n","        [0.9691, 0.0413],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3246, grad_fn=<NllLossBackward>)\n","epoch 2891, loss 0.32455530762672424\n","outputs:  tensor([[0.0275, 0.9610],\n","        [0.9748, 0.0338],\n","        [0.9691, 0.0413],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2892, loss 0.32454901933670044\n","outputs:  tensor([[0.0275, 0.9610],\n","        [0.9748, 0.0338],\n","        [0.9691, 0.0413],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2893, loss 0.3245428502559662\n","outputs:  tensor([[0.0275, 0.9611],\n","        [0.9748, 0.0337],\n","        [0.9692, 0.0413],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2894, loss 0.32453665137290955\n","outputs:  tensor([[0.0275, 0.9611],\n","        [0.9748, 0.0337],\n","        [0.9692, 0.0412],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2895, loss 0.3245305120944977\n","outputs:  tensor([[0.0275, 0.9611],\n","        [0.9748, 0.0337],\n","        [0.9692, 0.0412],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2896, loss 0.3245243430137634\n","outputs:  tensor([[0.0275, 0.9611],\n","        [0.9748, 0.0337],\n","        [0.9692, 0.0412],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2897, loss 0.3245181441307068\n","outputs:  tensor([[0.0275, 0.9611],\n","        [0.9749, 0.0337],\n","        [0.9692, 0.0412],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2898, loss 0.32451197504997253\n","outputs:  tensor([[0.0274, 0.9612],\n","        [0.9749, 0.0336],\n","        [0.9692, 0.0411],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2899, loss 0.3245058059692383\n","outputs:  tensor([[0.0274, 0.9612],\n","        [0.9749, 0.0336],\n","        [0.9692, 0.0411],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2900, loss 0.3244996964931488\n","outputs:  tensor([[0.0274, 0.9612],\n","        [0.9749, 0.0336],\n","        [0.9693, 0.0411],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2901, loss 0.32449355721473694\n","Parameter containing:\n","tensor([[-0.2926, -0.6763,  0.1958],\n","        [-1.0608, -0.8315, -0.0759],\n","        [-1.0790, -1.0012, -0.1248],\n","        [-0.4769, -0.5142, -0.0020]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5174, -0.2515,  0.2019,  0.1409], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8961,  0.7950,  1.1851,  0.1555],\n","        [-0.2467, -1.0316, -0.8919, -0.6162]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3769, -0.6190], requires_grad=True)\n","outputs:  tensor([[0.0274, 0.9612],\n","        [0.9749, 0.0336],\n","        [0.9693, 0.0411],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2902, loss 0.3244872987270355\n","outputs:  tensor([[0.0274, 0.9613],\n","        [0.9749, 0.0336],\n","        [0.9693, 0.0411],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2903, loss 0.3244812488555908\n","outputs:  tensor([[0.0274, 0.9613],\n","        [0.9749, 0.0335],\n","        [0.9693, 0.0410],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2904, loss 0.32447513937950134\n","outputs:  tensor([[0.0274, 0.9613],\n","        [0.9750, 0.0335],\n","        [0.9693, 0.0410],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2905, loss 0.3244690001010895\n","outputs:  tensor([[0.0273, 0.9613],\n","        [0.9750, 0.0335],\n","        [0.9693, 0.0410],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2906, loss 0.324462890625\n","outputs:  tensor([[0.0273, 0.9613],\n","        [0.9750, 0.0335],\n","        [0.9693, 0.0410],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2907, loss 0.3244567811489105\n","outputs:  tensor([[0.0273, 0.9614],\n","        [0.9750, 0.0335],\n","        [0.9694, 0.0410],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3245, grad_fn=<NllLossBackward>)\n","epoch 2908, loss 0.32445067167282104\n","outputs:  tensor([[0.0273, 0.9614],\n","        [0.9750, 0.0335],\n","        [0.9694, 0.0409],\n","        [0.9991, 0.0016],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2909, loss 0.32444459199905396\n","outputs:  tensor([[0.0273, 0.9614],\n","        [0.9750, 0.0334],\n","        [0.9694, 0.0409],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2910, loss 0.3244384825229645\n","outputs:  tensor([[0.0273, 0.9614],\n","        [0.9750, 0.0334],\n","        [0.9694, 0.0409],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2911, loss 0.324432373046875\n","outputs:  tensor([[0.0273, 0.9614],\n","        [0.9750, 0.0334],\n","        [0.9694, 0.0409],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2912, loss 0.3244263231754303\n","outputs:  tensor([[0.0273, 0.9615],\n","        [0.9751, 0.0334],\n","        [0.9694, 0.0409],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2913, loss 0.3244202136993408\n","outputs:  tensor([[0.0272, 0.9615],\n","        [0.9751, 0.0334],\n","        [0.9694, 0.0408],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2914, loss 0.3244141638278961\n","outputs:  tensor([[0.0272, 0.9615],\n","        [0.9751, 0.0333],\n","        [0.9695, 0.0408],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2915, loss 0.3244081139564514\n","outputs:  tensor([[0.0272, 0.9615],\n","        [0.9751, 0.0333],\n","        [0.9695, 0.0408],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2916, loss 0.3244020342826843\n","outputs:  tensor([[0.0272, 0.9616],\n","        [0.9751, 0.0333],\n","        [0.9695, 0.0408],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2917, loss 0.3243959844112396\n","outputs:  tensor([[0.0272, 0.9616],\n","        [0.9751, 0.0333],\n","        [0.9695, 0.0408],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2918, loss 0.3243899643421173\n","outputs:  tensor([[0.0272, 0.9616],\n","        [0.9751, 0.0333],\n","        [0.9695, 0.0407],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2919, loss 0.32438385486602783\n","outputs:  tensor([[0.0272, 0.9616],\n","        [0.9751, 0.0333],\n","        [0.9695, 0.0407],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2920, loss 0.3243778944015503\n","outputs:  tensor([[0.0271, 0.9616],\n","        [0.9752, 0.0332],\n","        [0.9695, 0.0407],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2921, loss 0.3243718147277832\n","outputs:  tensor([[0.0271, 0.9617],\n","        [0.9752, 0.0332],\n","        [0.9696, 0.0407],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2922, loss 0.3243657946586609\n","outputs:  tensor([[0.0271, 0.9617],\n","        [0.9752, 0.0332],\n","        [0.9696, 0.0406],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9975]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2923, loss 0.32435980439186096\n","outputs:  tensor([[0.0271, 0.9617],\n","        [0.9752, 0.0332],\n","        [0.9696, 0.0406],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3244, grad_fn=<NllLossBackward>)\n","epoch 2924, loss 0.32435378432273865\n","outputs:  tensor([[0.0271, 0.9617],\n","        [0.9752, 0.0332],\n","        [0.9696, 0.0406],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2925, loss 0.32434767484664917\n","outputs:  tensor([[0.0271, 0.9617],\n","        [0.9752, 0.0331],\n","        [0.9696, 0.0406],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2926, loss 0.32434171438217163\n","outputs:  tensor([[0.0271, 0.9618],\n","        [0.9752, 0.0331],\n","        [0.9696, 0.0406],\n","        [0.9991, 0.0015],\n","        [0.0023, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2927, loss 0.3243357241153717\n","outputs:  tensor([[0.0270, 0.9618],\n","        [0.9752, 0.0331],\n","        [0.9696, 0.0405],\n","        [0.9991, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2928, loss 0.32432979345321655\n","outputs:  tensor([[0.0270, 0.9618],\n","        [0.9753, 0.0331],\n","        [0.9697, 0.0405],\n","        [0.9991, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2929, loss 0.3243238031864166\n","outputs:  tensor([[0.0270, 0.9618],\n","        [0.9753, 0.0331],\n","        [0.9697, 0.0405],\n","        [0.9991, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2930, loss 0.3243177831172943\n","outputs:  tensor([[0.0270, 0.9618],\n","        [0.9753, 0.0331],\n","        [0.9697, 0.0405],\n","        [0.9991, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2931, loss 0.3243117928504944\n","outputs:  tensor([[0.0270, 0.9619],\n","        [0.9753, 0.0330],\n","        [0.9697, 0.0405],\n","        [0.9991, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2932, loss 0.32430586218833923\n","outputs:  tensor([[0.0270, 0.9619],\n","        [0.9753, 0.0330],\n","        [0.9697, 0.0404],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2933, loss 0.3242998719215393\n","outputs:  tensor([[0.0270, 0.9619],\n","        [0.9753, 0.0330],\n","        [0.9697, 0.0404],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2934, loss 0.32429394125938416\n","outputs:  tensor([[0.0270, 0.9619],\n","        [0.9753, 0.0330],\n","        [0.9697, 0.0404],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2935, loss 0.3242879807949066\n","outputs:  tensor([[0.0269, 0.9620],\n","        [0.9753, 0.0330],\n","        [0.9698, 0.0404],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2936, loss 0.3242820203304291\n","outputs:  tensor([[0.0269, 0.9620],\n","        [0.9754, 0.0330],\n","        [0.9698, 0.0404],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2937, loss 0.32427605986595154\n","outputs:  tensor([[0.0269, 0.9620],\n","        [0.9754, 0.0329],\n","        [0.9698, 0.0403],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2938, loss 0.32427018880844116\n","outputs:  tensor([[0.0269, 0.9620],\n","        [0.9754, 0.0329],\n","        [0.9698, 0.0403],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2939, loss 0.3242642283439636\n","outputs:  tensor([[0.0269, 0.9620],\n","        [0.9754, 0.0329],\n","        [0.9698, 0.0403],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2940, loss 0.32425835728645325\n","outputs:  tensor([[0.0269, 0.9621],\n","        [0.9754, 0.0329],\n","        [0.9698, 0.0403],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3243, grad_fn=<NllLossBackward>)\n","epoch 2941, loss 0.3242523670196533\n","outputs:  tensor([[0.0269, 0.9621],\n","        [0.9754, 0.0329],\n","        [0.9698, 0.0403],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2942, loss 0.32424646615982056\n","outputs:  tensor([[0.0268, 0.9621],\n","        [0.9754, 0.0328],\n","        [0.9699, 0.0402],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2943, loss 0.3242405951023102\n","outputs:  tensor([[0.0268, 0.9621],\n","        [0.9754, 0.0328],\n","        [0.9699, 0.0402],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2944, loss 0.32423466444015503\n","outputs:  tensor([[0.0268, 0.9621],\n","        [0.9755, 0.0328],\n","        [0.9699, 0.0402],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2945, loss 0.32422876358032227\n","outputs:  tensor([[0.0268, 0.9622],\n","        [0.9755, 0.0328],\n","        [0.9699, 0.0402],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2946, loss 0.3242228925228119\n","outputs:  tensor([[0.0268, 0.9622],\n","        [0.9755, 0.0328],\n","        [0.9699, 0.0402],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2947, loss 0.3242169916629791\n","outputs:  tensor([[0.0268, 0.9622],\n","        [0.9755, 0.0328],\n","        [0.9699, 0.0401],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2948, loss 0.32421112060546875\n","outputs:  tensor([[0.0268, 0.9622],\n","        [0.9755, 0.0327],\n","        [0.9699, 0.0401],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2949, loss 0.3242052495479584\n","outputs:  tensor([[0.0268, 0.9622],\n","        [0.9755, 0.0327],\n","        [0.9700, 0.0401],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2950, loss 0.324199378490448\n","outputs:  tensor([[0.0267, 0.9623],\n","        [0.9755, 0.0327],\n","        [0.9700, 0.0401],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2951, loss 0.32419353723526\n","Parameter containing:\n","tensor([[-0.2940, -0.6788,  0.1958],\n","        [-1.0633, -0.8359, -0.0759],\n","        [-1.0817, -1.0060, -0.1248],\n","        [-0.4780, -0.5162, -0.0020]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5183, -0.2499,  0.2036,  0.1416], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.8981,  0.7977,  1.1885,  0.1572],\n","        [-0.2495, -1.0352, -0.8964, -0.6185]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3776, -0.6199], requires_grad=True)\n","outputs:  tensor([[0.0267, 0.9623],\n","        [0.9755, 0.0327],\n","        [0.9700, 0.0401],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2952, loss 0.32418766617774963\n","outputs:  tensor([[0.0267, 0.9623],\n","        [0.9755, 0.0327],\n","        [0.9700, 0.0400],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2953, loss 0.32418182492256165\n","outputs:  tensor([[0.0267, 0.9623],\n","        [0.9756, 0.0326],\n","        [0.9700, 0.0400],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2954, loss 0.32417595386505127\n","outputs:  tensor([[0.0267, 0.9624],\n","        [0.9756, 0.0326],\n","        [0.9700, 0.0400],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2955, loss 0.3241701126098633\n","outputs:  tensor([[0.0267, 0.9624],\n","        [0.9756, 0.0326],\n","        [0.9700, 0.0400],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2956, loss 0.3241642415523529\n","outputs:  tensor([[0.0267, 0.9624],\n","        [0.9756, 0.0326],\n","        [0.9701, 0.0400],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2957, loss 0.3241584300994873\n","outputs:  tensor([[0.0266, 0.9624],\n","        [0.9756, 0.0326],\n","        [0.9701, 0.0399],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3242, grad_fn=<NllLossBackward>)\n","epoch 2958, loss 0.3241526186466217\n","outputs:  tensor([[0.0266, 0.9624],\n","        [0.9756, 0.0326],\n","        [0.9701, 0.0399],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2959, loss 0.3241468071937561\n","outputs:  tensor([[0.0266, 0.9625],\n","        [0.9756, 0.0325],\n","        [0.9701, 0.0399],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2960, loss 0.3241409659385681\n","outputs:  tensor([[0.0266, 0.9625],\n","        [0.9756, 0.0325],\n","        [0.9701, 0.0399],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2961, loss 0.3241351246833801\n","outputs:  tensor([[0.0266, 0.9625],\n","        [0.9757, 0.0325],\n","        [0.9701, 0.0399],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2962, loss 0.3241293728351593\n","outputs:  tensor([[0.0266, 0.9625],\n","        [0.9757, 0.0325],\n","        [0.9701, 0.0398],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2963, loss 0.3241235315799713\n","outputs:  tensor([[0.0266, 0.9625],\n","        [0.9757, 0.0325],\n","        [0.9701, 0.0398],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2964, loss 0.3241177499294281\n","outputs:  tensor([[0.0266, 0.9626],\n","        [0.9757, 0.0325],\n","        [0.9702, 0.0398],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2965, loss 0.3241119384765625\n","outputs:  tensor([[0.0265, 0.9626],\n","        [0.9757, 0.0324],\n","        [0.9702, 0.0398],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2966, loss 0.3241061568260193\n","outputs:  tensor([[0.0265, 0.9626],\n","        [0.9757, 0.0324],\n","        [0.9702, 0.0398],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2967, loss 0.32410040497779846\n","outputs:  tensor([[0.0265, 0.9626],\n","        [0.9757, 0.0324],\n","        [0.9702, 0.0397],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2968, loss 0.32409459352493286\n","outputs:  tensor([[0.0265, 0.9626],\n","        [0.9757, 0.0324],\n","        [0.9702, 0.0397],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9976]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2969, loss 0.3240888714790344\n","outputs:  tensor([[0.0265, 0.9627],\n","        [0.9758, 0.0324],\n","        [0.9702, 0.0397],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2970, loss 0.3240830898284912\n","outputs:  tensor([[0.0265, 0.9627],\n","        [0.9758, 0.0324],\n","        [0.9702, 0.0397],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2971, loss 0.3240773677825928\n","outputs:  tensor([[0.0265, 0.9627],\n","        [0.9758, 0.0323],\n","        [0.9703, 0.0397],\n","        [0.9992, 0.0015],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2972, loss 0.32407164573669434\n","outputs:  tensor([[0.0264, 0.9627],\n","        [0.9758, 0.0323],\n","        [0.9703, 0.0396],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2973, loss 0.32406583428382874\n","outputs:  tensor([[0.0264, 0.9627],\n","        [0.9758, 0.0323],\n","        [0.9703, 0.0396],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2974, loss 0.3240601122379303\n","outputs:  tensor([[0.0264, 0.9628],\n","        [0.9758, 0.0323],\n","        [0.9703, 0.0396],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3241, grad_fn=<NllLossBackward>)\n","epoch 2975, loss 0.3240543603897095\n","outputs:  tensor([[0.0264, 0.9628],\n","        [0.9758, 0.0323],\n","        [0.9703, 0.0396],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2976, loss 0.3240486681461334\n","outputs:  tensor([[0.0264, 0.9628],\n","        [0.9758, 0.0322],\n","        [0.9703, 0.0396],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2977, loss 0.324042946100235\n","outputs:  tensor([[0.0264, 0.9628],\n","        [0.9759, 0.0322],\n","        [0.9703, 0.0395],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2978, loss 0.32403722405433655\n","outputs:  tensor([[0.0264, 0.9628],\n","        [0.9759, 0.0322],\n","        [0.9704, 0.0395],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2979, loss 0.32403144240379333\n","outputs:  tensor([[0.0264, 0.9629],\n","        [0.9759, 0.0322],\n","        [0.9704, 0.0395],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2980, loss 0.3240257799625397\n","outputs:  tensor([[0.0263, 0.9629],\n","        [0.9759, 0.0322],\n","        [0.9704, 0.0395],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2981, loss 0.32402005791664124\n","outputs:  tensor([[0.0263, 0.9629],\n","        [0.9759, 0.0322],\n","        [0.9704, 0.0395],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2982, loss 0.3240143358707428\n","outputs:  tensor([[0.0263, 0.9629],\n","        [0.9759, 0.0321],\n","        [0.9704, 0.0394],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2983, loss 0.32400864362716675\n","outputs:  tensor([[0.0263, 0.9629],\n","        [0.9759, 0.0321],\n","        [0.9704, 0.0394],\n","        [0.9992, 0.0014],\n","        [0.0022, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2984, loss 0.3240029513835907\n","outputs:  tensor([[0.0263, 0.9630],\n","        [0.9759, 0.0321],\n","        [0.9704, 0.0394],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2985, loss 0.32399728894233704\n","outputs:  tensor([[0.0263, 0.9630],\n","        [0.9759, 0.0321],\n","        [0.9704, 0.0394],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2986, loss 0.32399165630340576\n","outputs:  tensor([[0.0263, 0.9630],\n","        [0.9760, 0.0321],\n","        [0.9705, 0.0394],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2987, loss 0.3239859640598297\n","outputs:  tensor([[0.0263, 0.9630],\n","        [0.9760, 0.0321],\n","        [0.9705, 0.0393],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2988, loss 0.32398030161857605\n","outputs:  tensor([[0.0262, 0.9630],\n","        [0.9760, 0.0320],\n","        [0.9705, 0.0393],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2989, loss 0.323974609375\n","outputs:  tensor([[0.0262, 0.9631],\n","        [0.9760, 0.0320],\n","        [0.9705, 0.0393],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2990, loss 0.3239689767360687\n","outputs:  tensor([[0.0262, 0.9631],\n","        [0.9760, 0.0320],\n","        [0.9705, 0.0393],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2991, loss 0.32396331429481506\n","outputs:  tensor([[0.0262, 0.9631],\n","        [0.9760, 0.0320],\n","        [0.9705, 0.0393],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2992, loss 0.3239576816558838\n","outputs:  tensor([[0.0262, 0.9631],\n","        [0.9760, 0.0320],\n","        [0.9705, 0.0392],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3240, grad_fn=<NllLossBackward>)\n","epoch 2993, loss 0.3239520490169525\n","outputs:  tensor([[0.0262, 0.9631],\n","        [0.9760, 0.0320],\n","        [0.9706, 0.0392],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 2994, loss 0.3239463269710541\n","outputs:  tensor([[0.0262, 0.9632],\n","        [0.9761, 0.0319],\n","        [0.9706, 0.0392],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 2995, loss 0.3239407539367676\n","outputs:  tensor([[0.0262, 0.9632],\n","        [0.9761, 0.0319],\n","        [0.9706, 0.0392],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 2996, loss 0.3239351212978363\n","outputs:  tensor([[0.0261, 0.9632],\n","        [0.9761, 0.0319],\n","        [0.9706, 0.0392],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 2997, loss 0.32392945885658264\n","outputs:  tensor([[0.0261, 0.9632],\n","        [0.9761, 0.0319],\n","        [0.9706, 0.0391],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 2998, loss 0.32392388582229614\n","outputs:  tensor([[0.0261, 0.9632],\n","        [0.9761, 0.0319],\n","        [0.9706, 0.0391],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 2999, loss 0.32391828298568726\n","outputs:  tensor([[0.0261, 0.9633],\n","        [0.9761, 0.0319],\n","        [0.9706, 0.0391],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3000, loss 0.32391268014907837\n","outputs:  tensor([[0.0261, 0.9633],\n","        [0.9761, 0.0318],\n","        [0.9707, 0.0391],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3001, loss 0.3239070773124695\n","Parameter containing:\n","tensor([[-0.2954, -0.6812,  0.1958],\n","        [-1.0658, -0.8402, -0.0759],\n","        [-1.0844, -1.0106, -0.1248],\n","        [-0.4792, -0.5181, -0.0020]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5191, -0.2484,  0.2052,  0.1422], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9001,  0.8003,  1.1918,  0.1588],\n","        [-0.2522, -1.0388, -0.9009, -0.6207]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3784, -0.6208], requires_grad=True)\n","outputs:  tensor([[0.0261, 0.9633],\n","        [0.9761, 0.0318],\n","        [0.9707, 0.0391],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3002, loss 0.3239014446735382\n","outputs:  tensor([[0.0261, 0.9633],\n","        [0.9761, 0.0318],\n","        [0.9707, 0.0391],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3003, loss 0.3238958716392517\n","outputs:  tensor([[0.0260, 0.9633],\n","        [0.9762, 0.0318],\n","        [0.9707, 0.0390],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3004, loss 0.3238902986049652\n","outputs:  tensor([[0.0260, 0.9634],\n","        [0.9762, 0.0318],\n","        [0.9707, 0.0390],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3005, loss 0.32388466596603394\n","outputs:  tensor([[0.0260, 0.9634],\n","        [0.9762, 0.0318],\n","        [0.9707, 0.0390],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3006, loss 0.32387909293174744\n","outputs:  tensor([[0.0260, 0.9634],\n","        [0.9762, 0.0317],\n","        [0.9707, 0.0390],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3007, loss 0.32387351989746094\n","outputs:  tensor([[0.0260, 0.9634],\n","        [0.9762, 0.0317],\n","        [0.9707, 0.0390],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3008, loss 0.3238679766654968\n","outputs:  tensor([[0.0260, 0.9634],\n","        [0.9762, 0.0317],\n","        [0.9708, 0.0389],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3009, loss 0.3238624334335327\n","outputs:  tensor([[0.0260, 0.9635],\n","        [0.9762, 0.0317],\n","        [0.9708, 0.0389],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3010, loss 0.3238568603992462\n","outputs:  tensor([[0.0260, 0.9635],\n","        [0.9762, 0.0317],\n","        [0.9708, 0.0389],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3239, grad_fn=<NllLossBackward>)\n","epoch 3011, loss 0.3238513469696045\n","outputs:  tensor([[0.0259, 0.9635],\n","        [0.9763, 0.0317],\n","        [0.9708, 0.0389],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3012, loss 0.3238457441329956\n","outputs:  tensor([[0.0259, 0.9635],\n","        [0.9763, 0.0316],\n","        [0.9708, 0.0389],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3013, loss 0.32384026050567627\n","outputs:  tensor([[0.0259, 0.9635],\n","        [0.9763, 0.0316],\n","        [0.9708, 0.0388],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3014, loss 0.32383471727371216\n","outputs:  tensor([[0.0259, 0.9636],\n","        [0.9763, 0.0316],\n","        [0.9708, 0.0388],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3015, loss 0.32382917404174805\n","outputs:  tensor([[0.0259, 0.9636],\n","        [0.9763, 0.0316],\n","        [0.9709, 0.0388],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3016, loss 0.32382363080978394\n","outputs:  tensor([[0.0259, 0.9636],\n","        [0.9763, 0.0316],\n","        [0.9709, 0.0388],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9977]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3017, loss 0.3238181471824646\n","outputs:  tensor([[0.0259, 0.9636],\n","        [0.9763, 0.0316],\n","        [0.9709, 0.0388],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3018, loss 0.3238125741481781\n","outputs:  tensor([[0.0259, 0.9636],\n","        [0.9763, 0.0315],\n","        [0.9709, 0.0387],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3019, loss 0.32380709052085876\n","outputs:  tensor([[0.0258, 0.9637],\n","        [0.9763, 0.0315],\n","        [0.9709, 0.0387],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3020, loss 0.32380157709121704\n","outputs:  tensor([[0.0258, 0.9637],\n","        [0.9764, 0.0315],\n","        [0.9709, 0.0387],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3021, loss 0.3237960934638977\n","outputs:  tensor([[0.0258, 0.9637],\n","        [0.9764, 0.0315],\n","        [0.9709, 0.0387],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3022, loss 0.32379060983657837\n","outputs:  tensor([[0.0258, 0.9637],\n","        [0.9764, 0.0315],\n","        [0.9709, 0.0387],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3023, loss 0.32378512620925903\n","outputs:  tensor([[0.0258, 0.9637],\n","        [0.9764, 0.0315],\n","        [0.9710, 0.0387],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3024, loss 0.3237796127796173\n","outputs:  tensor([[0.0258, 0.9637],\n","        [0.9764, 0.0314],\n","        [0.9710, 0.0386],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3025, loss 0.32377415895462036\n","outputs:  tensor([[0.0258, 0.9638],\n","        [0.9764, 0.0314],\n","        [0.9710, 0.0386],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3026, loss 0.323768675327301\n","outputs:  tensor([[0.0258, 0.9638],\n","        [0.9764, 0.0314],\n","        [0.9710, 0.0386],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3027, loss 0.3237631916999817\n","outputs:  tensor([[0.0257, 0.9638],\n","        [0.9764, 0.0314],\n","        [0.9710, 0.0386],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3028, loss 0.32375770807266235\n","outputs:  tensor([[0.0257, 0.9638],\n","        [0.9764, 0.0314],\n","        [0.9710, 0.0386],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3238, grad_fn=<NllLossBackward>)\n","epoch 3029, loss 0.3237523138523102\n","outputs:  tensor([[0.0257, 0.9638],\n","        [0.9765, 0.0314],\n","        [0.9710, 0.0385],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3030, loss 0.32374686002731323\n","outputs:  tensor([[0.0257, 0.9639],\n","        [0.9765, 0.0313],\n","        [0.9710, 0.0385],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3031, loss 0.3237413465976715\n","outputs:  tensor([[0.0257, 0.9639],\n","        [0.9765, 0.0313],\n","        [0.9711, 0.0385],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3032, loss 0.32373589277267456\n","outputs:  tensor([[0.0257, 0.9639],\n","        [0.9765, 0.0313],\n","        [0.9711, 0.0385],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3033, loss 0.32373046875\n","outputs:  tensor([[0.0257, 0.9639],\n","        [0.9765, 0.0313],\n","        [0.9711, 0.0385],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3034, loss 0.32372504472732544\n","outputs:  tensor([[0.0257, 0.9639],\n","        [0.9765, 0.0313],\n","        [0.9711, 0.0384],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3035, loss 0.32371965050697327\n","outputs:  tensor([[0.0256, 0.9640],\n","        [0.9765, 0.0313],\n","        [0.9711, 0.0384],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3036, loss 0.32371416687965393\n","outputs:  tensor([[0.0256, 0.9640],\n","        [0.9765, 0.0312],\n","        [0.9711, 0.0384],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3037, loss 0.32370877265930176\n","outputs:  tensor([[0.0256, 0.9640],\n","        [0.9765, 0.0312],\n","        [0.9711, 0.0384],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3038, loss 0.3237033188343048\n","outputs:  tensor([[0.0256, 0.9640],\n","        [0.9766, 0.0312],\n","        [0.9712, 0.0384],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3039, loss 0.32369789481163025\n","outputs:  tensor([[0.0256, 0.9640],\n","        [0.9766, 0.0312],\n","        [0.9712, 0.0384],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3040, loss 0.3236925005912781\n","outputs:  tensor([[0.0256, 0.9641],\n","        [0.9766, 0.0312],\n","        [0.9712, 0.0383],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3041, loss 0.3236871361732483\n","outputs:  tensor([[0.0256, 0.9641],\n","        [0.9766, 0.0312],\n","        [0.9712, 0.0383],\n","        [0.9992, 0.0014],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3042, loss 0.32368168234825134\n","outputs:  tensor([[0.0256, 0.9641],\n","        [0.9766, 0.0311],\n","        [0.9712, 0.0383],\n","        [0.9992, 0.0013],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3043, loss 0.32367634773254395\n","outputs:  tensor([[0.0255, 0.9641],\n","        [0.9766, 0.0311],\n","        [0.9712, 0.0383],\n","        [0.9992, 0.0013],\n","        [0.0021, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3044, loss 0.3236709535121918\n","outputs:  tensor([[0.0255, 0.9641],\n","        [0.9766, 0.0311],\n","        [0.9712, 0.0383],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3045, loss 0.3236655592918396\n","outputs:  tensor([[0.0255, 0.9642],\n","        [0.9766, 0.0311],\n","        [0.9712, 0.0382],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3046, loss 0.32366013526916504\n","outputs:  tensor([[0.0255, 0.9642],\n","        [0.9767, 0.0311],\n","        [0.9713, 0.0382],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3237, grad_fn=<NllLossBackward>)\n","epoch 3047, loss 0.32365480065345764\n","outputs:  tensor([[0.0255, 0.9642],\n","        [0.9767, 0.0311],\n","        [0.9713, 0.0382],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3048, loss 0.32364946603775024\n","outputs:  tensor([[0.0255, 0.9642],\n","        [0.9767, 0.0310],\n","        [0.9713, 0.0382],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3049, loss 0.3236440122127533\n","outputs:  tensor([[0.0255, 0.9642],\n","        [0.9767, 0.0310],\n","        [0.9713, 0.0382],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3050, loss 0.3236387073993683\n","outputs:  tensor([[0.0255, 0.9642],\n","        [0.9767, 0.0310],\n","        [0.9713, 0.0381],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3051, loss 0.3236333727836609\n","Parameter containing:\n","tensor([[-0.2968, -0.6835,  0.1957],\n","        [-1.0682, -0.8443, -0.0758],\n","        [-1.0871, -1.0152, -0.1248],\n","        [-0.4802, -0.5200, -0.0019]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5200, -0.2469,  0.2069,  0.1429], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9021,  0.8029,  1.1950,  0.1604],\n","        [-0.2549, -1.0423, -0.9052, -0.6229]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3791, -0.6217], requires_grad=True)\n","outputs:  tensor([[0.0255, 0.9643],\n","        [0.9767, 0.0310],\n","        [0.9713, 0.0381],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3052, loss 0.3236280083656311\n","outputs:  tensor([[0.0254, 0.9643],\n","        [0.9767, 0.0310],\n","        [0.9713, 0.0381],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3053, loss 0.3236226439476013\n","outputs:  tensor([[0.0254, 0.9643],\n","        [0.9767, 0.0310],\n","        [0.9713, 0.0381],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3054, loss 0.3236173391342163\n","outputs:  tensor([[0.0254, 0.9643],\n","        [0.9767, 0.0309],\n","        [0.9714, 0.0381],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3055, loss 0.3236120045185089\n","outputs:  tensor([[0.0254, 0.9643],\n","        [0.9768, 0.0309],\n","        [0.9714, 0.0381],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3056, loss 0.3236066401004791\n","outputs:  tensor([[0.0254, 0.9644],\n","        [0.9768, 0.0309],\n","        [0.9714, 0.0380],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3057, loss 0.3236013352870941\n","outputs:  tensor([[0.0254, 0.9644],\n","        [0.9768, 0.0309],\n","        [0.9714, 0.0380],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3058, loss 0.3235960006713867\n","outputs:  tensor([[0.0254, 0.9644],\n","        [0.9768, 0.0309],\n","        [0.9714, 0.0380],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3059, loss 0.3235906660556793\n","outputs:  tensor([[0.0254, 0.9644],\n","        [0.9768, 0.0309],\n","        [0.9714, 0.0380],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3060, loss 0.3235854208469391\n","outputs:  tensor([[0.0253, 0.9644],\n","        [0.9768, 0.0309],\n","        [0.9714, 0.0380],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3061, loss 0.3235800862312317\n","outputs:  tensor([[0.0253, 0.9645],\n","        [0.9768, 0.0308],\n","        [0.9715, 0.0379],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3062, loss 0.3235747218132019\n","outputs:  tensor([[0.0253, 0.9645],\n","        [0.9768, 0.0308],\n","        [0.9715, 0.0379],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3063, loss 0.32356947660446167\n","outputs:  tensor([[0.0253, 0.9645],\n","        [0.9768, 0.0308],\n","        [0.9715, 0.0379],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3064, loss 0.32356420159339905\n","outputs:  tensor([[0.0253, 0.9645],\n","        [0.9769, 0.0308],\n","        [0.9715, 0.0379],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3065, loss 0.32355889678001404\n","outputs:  tensor([[0.0253, 0.9645],\n","        [0.9769, 0.0308],\n","        [0.9715, 0.0379],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3236, grad_fn=<NllLossBackward>)\n","epoch 3066, loss 0.3235536217689514\n","outputs:  tensor([[0.0253, 0.9645],\n","        [0.9769, 0.0308],\n","        [0.9715, 0.0379],\n","        [0.9992, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3067, loss 0.3235483467578888\n","outputs:  tensor([[0.0253, 0.9646],\n","        [0.9769, 0.0307],\n","        [0.9715, 0.0378],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3068, loss 0.3235430419445038\n","outputs:  tensor([[0.0252, 0.9646],\n","        [0.9769, 0.0307],\n","        [0.9715, 0.0378],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9978]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3069, loss 0.32353776693344116\n","outputs:  tensor([[0.0252, 0.9646],\n","        [0.9769, 0.0307],\n","        [0.9716, 0.0378],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3070, loss 0.3235325217247009\n","outputs:  tensor([[0.0252, 0.9646],\n","        [0.9769, 0.0307],\n","        [0.9716, 0.0378],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3071, loss 0.3235272765159607\n","outputs:  tensor([[0.0252, 0.9646],\n","        [0.9769, 0.0307],\n","        [0.9716, 0.0378],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3072, loss 0.32352200150489807\n","outputs:  tensor([[0.0252, 0.9647],\n","        [0.9769, 0.0307],\n","        [0.9716, 0.0377],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3073, loss 0.3235167860984802\n","outputs:  tensor([[0.0252, 0.9647],\n","        [0.9770, 0.0306],\n","        [0.9716, 0.0377],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3074, loss 0.3235115110874176\n","outputs:  tensor([[0.0252, 0.9647],\n","        [0.9770, 0.0306],\n","        [0.9716, 0.0377],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3075, loss 0.32350626587867737\n","outputs:  tensor([[0.0252, 0.9647],\n","        [0.9770, 0.0306],\n","        [0.9716, 0.0377],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3076, loss 0.3235010504722595\n","outputs:  tensor([[0.0252, 0.9647],\n","        [0.9770, 0.0306],\n","        [0.9716, 0.0377],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3077, loss 0.3234958052635193\n","outputs:  tensor([[0.0251, 0.9648],\n","        [0.9770, 0.0306],\n","        [0.9717, 0.0377],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3078, loss 0.32349061965942383\n","outputs:  tensor([[0.0251, 0.9648],\n","        [0.9770, 0.0306],\n","        [0.9717, 0.0376],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3079, loss 0.3234853744506836\n","outputs:  tensor([[0.0251, 0.9648],\n","        [0.9770, 0.0306],\n","        [0.9717, 0.0376],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3080, loss 0.32348015904426575\n","outputs:  tensor([[0.0251, 0.9648],\n","        [0.9770, 0.0305],\n","        [0.9717, 0.0376],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3081, loss 0.3234749138355255\n","outputs:  tensor([[0.0251, 0.9648],\n","        [0.9770, 0.0305],\n","        [0.9717, 0.0376],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3082, loss 0.32346975803375244\n","outputs:  tensor([[0.0251, 0.9648],\n","        [0.9771, 0.0305],\n","        [0.9717, 0.0376],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3083, loss 0.3234645128250122\n","outputs:  tensor([[0.0251, 0.9649],\n","        [0.9771, 0.0305],\n","        [0.9717, 0.0375],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3084, loss 0.32345932722091675\n","outputs:  tensor([[0.0251, 0.9649],\n","        [0.9771, 0.0305],\n","        [0.9717, 0.0375],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3235, grad_fn=<NllLossBackward>)\n","epoch 3085, loss 0.3234541416168213\n","outputs:  tensor([[0.0250, 0.9649],\n","        [0.9771, 0.0305],\n","        [0.9718, 0.0375],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3086, loss 0.32344895601272583\n","outputs:  tensor([[0.0250, 0.9649],\n","        [0.9771, 0.0304],\n","        [0.9718, 0.0375],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3087, loss 0.3234437108039856\n","outputs:  tensor([[0.0250, 0.9649],\n","        [0.9771, 0.0304],\n","        [0.9718, 0.0375],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3088, loss 0.3234385550022125\n","outputs:  tensor([[0.0250, 0.9650],\n","        [0.9771, 0.0304],\n","        [0.9718, 0.0375],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3089, loss 0.3234333395957947\n","outputs:  tensor([[0.0250, 0.9650],\n","        [0.9771, 0.0304],\n","        [0.9718, 0.0374],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3090, loss 0.323428213596344\n","outputs:  tensor([[0.0250, 0.9650],\n","        [0.9771, 0.0304],\n","        [0.9718, 0.0374],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3091, loss 0.3234230577945709\n","outputs:  tensor([[0.0250, 0.9650],\n","        [0.9771, 0.0304],\n","        [0.9718, 0.0374],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3092, loss 0.32341790199279785\n","outputs:  tensor([[0.0250, 0.9650],\n","        [0.9772, 0.0303],\n","        [0.9718, 0.0374],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3093, loss 0.3234127163887024\n","outputs:  tensor([[0.0249, 0.9650],\n","        [0.9772, 0.0303],\n","        [0.9719, 0.0374],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3094, loss 0.32340750098228455\n","outputs:  tensor([[0.0249, 0.9651],\n","        [0.9772, 0.0303],\n","        [0.9719, 0.0373],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3095, loss 0.32340243458747864\n","outputs:  tensor([[0.0249, 0.9651],\n","        [0.9772, 0.0303],\n","        [0.9719, 0.0373],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3096, loss 0.32339727878570557\n","outputs:  tensor([[0.0249, 0.9651],\n","        [0.9772, 0.0303],\n","        [0.9719, 0.0373],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3097, loss 0.3233921527862549\n","outputs:  tensor([[0.0249, 0.9651],\n","        [0.9772, 0.0303],\n","        [0.9719, 0.0373],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3098, loss 0.3233869671821594\n","outputs:  tensor([[0.0249, 0.9651],\n","        [0.9772, 0.0303],\n","        [0.9719, 0.0373],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3099, loss 0.3233819007873535\n","outputs:  tensor([[0.0249, 0.9652],\n","        [0.9772, 0.0302],\n","        [0.9719, 0.0373],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3100, loss 0.32337674498558044\n","outputs:  tensor([[0.0249, 0.9652],\n","        [0.9772, 0.0302],\n","        [0.9719, 0.0372],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3101, loss 0.32337161898612976\n","Parameter containing:\n","tensor([[-0.2981, -0.6858,  0.1957],\n","        [-1.0705, -0.8484, -0.0758],\n","        [-1.0897, -1.0196, -0.1248],\n","        [-0.4813, -0.5218, -0.0019]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5208, -0.2455,  0.2085,  0.1436], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9040,  0.8054,  1.1982,  0.1620],\n","        [-0.2574, -1.0457, -0.9095, -0.6250]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3797, -0.6226], requires_grad=True)\n","outputs:  tensor([[0.0249, 0.9652],\n","        [0.9773, 0.0302],\n","        [0.9720, 0.0372],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3102, loss 0.3233664631843567\n","outputs:  tensor([[0.0248, 0.9652],\n","        [0.9773, 0.0302],\n","        [0.9720, 0.0372],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3103, loss 0.3233613967895508\n","outputs:  tensor([[0.0248, 0.9652],\n","        [0.9773, 0.0302],\n","        [0.9720, 0.0372],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3104, loss 0.3233562409877777\n","outputs:  tensor([[0.0248, 0.9652],\n","        [0.9773, 0.0302],\n","        [0.9720, 0.0372],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3234, grad_fn=<NllLossBackward>)\n","epoch 3105, loss 0.3233511447906494\n","outputs:  tensor([[0.0248, 0.9653],\n","        [0.9773, 0.0301],\n","        [0.9720, 0.0372],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3106, loss 0.3233460485935211\n","outputs:  tensor([[0.0248, 0.9653],\n","        [0.9773, 0.0301],\n","        [0.9720, 0.0371],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3107, loss 0.3233409821987152\n","outputs:  tensor([[0.0248, 0.9653],\n","        [0.9773, 0.0301],\n","        [0.9720, 0.0371],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3108, loss 0.3233358860015869\n","outputs:  tensor([[0.0248, 0.9653],\n","        [0.9773, 0.0301],\n","        [0.9720, 0.0371],\n","        [0.9993, 0.0013],\n","        [0.0020, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3109, loss 0.3233307898044586\n","outputs:  tensor([[0.0248, 0.9653],\n","        [0.9773, 0.0301],\n","        [0.9721, 0.0371],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3110, loss 0.3233257234096527\n","outputs:  tensor([[0.0248, 0.9654],\n","        [0.9774, 0.0301],\n","        [0.9721, 0.0371],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3111, loss 0.3233206570148468\n","outputs:  tensor([[0.0247, 0.9654],\n","        [0.9774, 0.0301],\n","        [0.9721, 0.0370],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3112, loss 0.3233155608177185\n","outputs:  tensor([[0.0247, 0.9654],\n","        [0.9774, 0.0300],\n","        [0.9721, 0.0370],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3113, loss 0.3233104944229126\n","outputs:  tensor([[0.0247, 0.9654],\n","        [0.9774, 0.0300],\n","        [0.9721, 0.0370],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3114, loss 0.3233054280281067\n","outputs:  tensor([[0.0247, 0.9654],\n","        [0.9774, 0.0300],\n","        [0.9721, 0.0370],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3115, loss 0.32330039143562317\n","outputs:  tensor([[0.0247, 0.9654],\n","        [0.9774, 0.0300],\n","        [0.9721, 0.0370],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3116, loss 0.3232952952384949\n","outputs:  tensor([[0.0247, 0.9655],\n","        [0.9774, 0.0300],\n","        [0.9721, 0.0370],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3117, loss 0.32329031825065613\n","outputs:  tensor([[0.0247, 0.9655],\n","        [0.9774, 0.0300],\n","        [0.9722, 0.0369],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3118, loss 0.32328522205352783\n","outputs:  tensor([[0.0247, 0.9655],\n","        [0.9774, 0.0299],\n","        [0.9722, 0.0369],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3119, loss 0.3232801854610443\n","outputs:  tensor([[0.0246, 0.9655],\n","        [0.9774, 0.0299],\n","        [0.9722, 0.0369],\n","        [0.9993, 0.0013],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3120, loss 0.3232751488685608\n","outputs:  tensor([[0.0246, 0.9655],\n","        [0.9775, 0.0299],\n","        [0.9722, 0.0369],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3121, loss 0.32327014207839966\n","outputs:  tensor([[0.0246, 0.9655],\n","        [0.9775, 0.0299],\n","        [0.9722, 0.0369],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3122, loss 0.3232651352882385\n","outputs:  tensor([[0.0246, 0.9656],\n","        [0.9775, 0.0299],\n","        [0.9722, 0.0369],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3123, loss 0.32326000928878784\n","outputs:  tensor([[0.0246, 0.9656],\n","        [0.9775, 0.0299],\n","        [0.9722, 0.0368],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9979]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3233, grad_fn=<NllLossBackward>)\n","epoch 3124, loss 0.3232550621032715\n","outputs:  tensor([[0.0246, 0.9656],\n","        [0.9775, 0.0299],\n","        [0.9722, 0.0368],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3125, loss 0.3232499957084656\n","outputs:  tensor([[0.0246, 0.9656],\n","        [0.9775, 0.0298],\n","        [0.9722, 0.0368],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3126, loss 0.32324498891830444\n","outputs:  tensor([[0.0246, 0.9656],\n","        [0.9775, 0.0298],\n","        [0.9723, 0.0368],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3127, loss 0.3232399821281433\n","outputs:  tensor([[0.0246, 0.9657],\n","        [0.9775, 0.0298],\n","        [0.9723, 0.0368],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3128, loss 0.3232349753379822\n","outputs:  tensor([[0.0245, 0.9657],\n","        [0.9775, 0.0298],\n","        [0.9723, 0.0367],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3129, loss 0.32322999835014343\n","outputs:  tensor([[0.0245, 0.9657],\n","        [0.9776, 0.0298],\n","        [0.9723, 0.0367],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3130, loss 0.3232250213623047\n","outputs:  tensor([[0.0245, 0.9657],\n","        [0.9776, 0.0298],\n","        [0.9723, 0.0367],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3131, loss 0.3232199549674988\n","outputs:  tensor([[0.0245, 0.9657],\n","        [0.9776, 0.0297],\n","        [0.9723, 0.0367],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3132, loss 0.3232150375843048\n","outputs:  tensor([[0.0245, 0.9657],\n","        [0.9776, 0.0297],\n","        [0.9723, 0.0367],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3133, loss 0.32321006059646606\n","outputs:  tensor([[0.0245, 0.9658],\n","        [0.9776, 0.0297],\n","        [0.9723, 0.0367],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3134, loss 0.32320502400398254\n","outputs:  tensor([[0.0245, 0.9658],\n","        [0.9776, 0.0297],\n","        [0.9724, 0.0366],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3135, loss 0.3232000768184662\n","outputs:  tensor([[0.0245, 0.9658],\n","        [0.9776, 0.0297],\n","        [0.9724, 0.0366],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3136, loss 0.32319512963294983\n","outputs:  tensor([[0.0245, 0.9658],\n","        [0.9776, 0.0297],\n","        [0.9724, 0.0366],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3137, loss 0.3231901526451111\n","outputs:  tensor([[0.0244, 0.9658],\n","        [0.9776, 0.0297],\n","        [0.9724, 0.0366],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3138, loss 0.3231852054595947\n","outputs:  tensor([[0.0244, 0.9658],\n","        [0.9776, 0.0296],\n","        [0.9724, 0.0366],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3139, loss 0.32318025827407837\n","outputs:  tensor([[0.0244, 0.9659],\n","        [0.9777, 0.0296],\n","        [0.9724, 0.0366],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3140, loss 0.3231752812862396\n","outputs:  tensor([[0.0244, 0.9659],\n","        [0.9777, 0.0296],\n","        [0.9724, 0.0365],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3141, loss 0.32317033410072327\n","outputs:  tensor([[0.0244, 0.9659],\n","        [0.9777, 0.0296],\n","        [0.9724, 0.0365],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3142, loss 0.3231653571128845\n","outputs:  tensor([[0.0244, 0.9659],\n","        [0.9777, 0.0296],\n","        [0.9725, 0.0365],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3143, loss 0.3231604993343353\n","outputs:  tensor([[0.0244, 0.9659],\n","        [0.9777, 0.0296],\n","        [0.9725, 0.0365],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3144, loss 0.32315555214881897\n","outputs:  tensor([[0.0244, 0.9660],\n","        [0.9777, 0.0296],\n","        [0.9725, 0.0365],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3232, grad_fn=<NllLossBackward>)\n","epoch 3145, loss 0.3231505751609802\n","outputs:  tensor([[0.0243, 0.9660],\n","        [0.9777, 0.0295],\n","        [0.9725, 0.0365],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3146, loss 0.32314568758010864\n","outputs:  tensor([[0.0243, 0.9660],\n","        [0.9777, 0.0295],\n","        [0.9725, 0.0364],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3147, loss 0.3231407403945923\n","outputs:  tensor([[0.0243, 0.9660],\n","        [0.9777, 0.0295],\n","        [0.9725, 0.0364],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3148, loss 0.3231357932090759\n","outputs:  tensor([[0.0243, 0.9660],\n","        [0.9778, 0.0295],\n","        [0.9725, 0.0364],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3149, loss 0.32313090562820435\n","outputs:  tensor([[0.0243, 0.9660],\n","        [0.9778, 0.0295],\n","        [0.9725, 0.0364],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3150, loss 0.32312601804733276\n","outputs:  tensor([[0.0243, 0.9661],\n","        [0.9778, 0.0295],\n","        [0.9725, 0.0364],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3151, loss 0.3231211006641388\n","Parameter containing:\n","tensor([[-0.2994, -0.6881,  0.1957],\n","        [-1.0728, -0.8524, -0.0758],\n","        [-1.0922, -1.0240, -0.1248],\n","        [-0.4823, -0.5236, -0.0019]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5217, -0.2440,  0.2101,  0.1442], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9059,  0.8079,  1.2014,  0.1635],\n","        [-0.2600, -1.0490, -0.9136, -0.6270]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3804, -0.6235], requires_grad=True)\n","outputs:  tensor([[0.0243, 0.9661],\n","        [0.9778, 0.0295],\n","        [0.9726, 0.0364],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3152, loss 0.3231162130832672\n","outputs:  tensor([[0.0243, 0.9661],\n","        [0.9778, 0.0294],\n","        [0.9726, 0.0363],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3153, loss 0.323111355304718\n","outputs:  tensor([[0.0243, 0.9661],\n","        [0.9778, 0.0294],\n","        [0.9726, 0.0363],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3154, loss 0.3231063783168793\n","outputs:  tensor([[0.0242, 0.9661],\n","        [0.9778, 0.0294],\n","        [0.9726, 0.0363],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3155, loss 0.3231015205383301\n","outputs:  tensor([[0.0242, 0.9661],\n","        [0.9778, 0.0294],\n","        [0.9726, 0.0363],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3156, loss 0.3230966627597809\n","outputs:  tensor([[0.0242, 0.9662],\n","        [0.9778, 0.0294],\n","        [0.9726, 0.0363],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3157, loss 0.3230918049812317\n","outputs:  tensor([[0.0242, 0.9662],\n","        [0.9778, 0.0294],\n","        [0.9726, 0.0363],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3158, loss 0.3230868875980377\n","outputs:  tensor([[0.0242, 0.9662],\n","        [0.9779, 0.0293],\n","        [0.9726, 0.0362],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3159, loss 0.3230820298194885\n","outputs:  tensor([[0.0242, 0.9662],\n","        [0.9779, 0.0293],\n","        [0.9727, 0.0362],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3160, loss 0.32307714223861694\n","outputs:  tensor([[0.0242, 0.9662],\n","        [0.9779, 0.0293],\n","        [0.9727, 0.0362],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3161, loss 0.32307225465774536\n","outputs:  tensor([[0.0242, 0.9662],\n","        [0.9779, 0.0293],\n","        [0.9727, 0.0362],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3162, loss 0.32306742668151855\n","outputs:  tensor([[0.0242, 0.9663],\n","        [0.9779, 0.0293],\n","        [0.9727, 0.0362],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3163, loss 0.32306256890296936\n","outputs:  tensor([[0.0241, 0.9663],\n","        [0.9779, 0.0293],\n","        [0.9727, 0.0361],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3164, loss 0.32305771112442017\n","outputs:  tensor([[0.0241, 0.9663],\n","        [0.9779, 0.0293],\n","        [0.9727, 0.0361],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3231, grad_fn=<NllLossBackward>)\n","epoch 3165, loss 0.32305285334587097\n","outputs:  tensor([[0.0241, 0.9663],\n","        [0.9779, 0.0292],\n","        [0.9727, 0.0361],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3166, loss 0.32304805517196655\n","outputs:  tensor([[0.0241, 0.9663],\n","        [0.9779, 0.0292],\n","        [0.9727, 0.0361],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3167, loss 0.32304316759109497\n","outputs:  tensor([[0.0241, 0.9663],\n","        [0.9779, 0.0292],\n","        [0.9728, 0.0361],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3168, loss 0.32303839921951294\n","outputs:  tensor([[0.0241, 0.9664],\n","        [0.9780, 0.0292],\n","        [0.9728, 0.0361],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3169, loss 0.32303354144096375\n","outputs:  tensor([[0.0241, 0.9664],\n","        [0.9780, 0.0292],\n","        [0.9728, 0.0360],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3170, loss 0.32302871346473694\n","outputs:  tensor([[0.0241, 0.9664],\n","        [0.9780, 0.0292],\n","        [0.9728, 0.0360],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3171, loss 0.32302388548851013\n","outputs:  tensor([[0.0241, 0.9664],\n","        [0.9780, 0.0292],\n","        [0.9728, 0.0360],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3172, loss 0.32301902770996094\n","outputs:  tensor([[0.0240, 0.9664],\n","        [0.9780, 0.0291],\n","        [0.9728, 0.0360],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3173, loss 0.3230143189430237\n","outputs:  tensor([[0.0240, 0.9664],\n","        [0.9780, 0.0291],\n","        [0.9728, 0.0360],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3174, loss 0.3230094909667969\n","outputs:  tensor([[0.0240, 0.9665],\n","        [0.9780, 0.0291],\n","        [0.9728, 0.0360],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3175, loss 0.32300472259521484\n","outputs:  tensor([[0.0240, 0.9665],\n","        [0.9780, 0.0291],\n","        [0.9728, 0.0359],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3176, loss 0.32299986481666565\n","outputs:  tensor([[0.0240, 0.9665],\n","        [0.9780, 0.0291],\n","        [0.9729, 0.0359],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3177, loss 0.3229950964450836\n","outputs:  tensor([[0.0240, 0.9665],\n","        [0.9781, 0.0291],\n","        [0.9729, 0.0359],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3178, loss 0.3229903280735016\n","outputs:  tensor([[0.0240, 0.9665],\n","        [0.9781, 0.0291],\n","        [0.9729, 0.0359],\n","        [0.9993, 0.0012],\n","        [0.0019, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3179, loss 0.3229854702949524\n","outputs:  tensor([[0.0240, 0.9666],\n","        [0.9781, 0.0290],\n","        [0.9729, 0.0359],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3180, loss 0.32298070192337036\n","outputs:  tensor([[0.0240, 0.9666],\n","        [0.9781, 0.0290],\n","        [0.9729, 0.0359],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3181, loss 0.3229759633541107\n","outputs:  tensor([[0.0240, 0.9666],\n","        [0.9781, 0.0290],\n","        [0.9729, 0.0358],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3182, loss 0.3229711353778839\n","outputs:  tensor([[0.0239, 0.9666],\n","        [0.9781, 0.0290],\n","        [0.9729, 0.0358],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3183, loss 0.32296639680862427\n","outputs:  tensor([[0.0239, 0.9666],\n","        [0.9781, 0.0290],\n","        [0.9729, 0.0358],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9980]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3184, loss 0.32296159863471985\n","outputs:  tensor([[0.0239, 0.9666],\n","        [0.9781, 0.0290],\n","        [0.9729, 0.0358],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3185, loss 0.3229568600654602\n","outputs:  tensor([[0.0239, 0.9667],\n","        [0.9781, 0.0290],\n","        [0.9730, 0.0358],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3230, grad_fn=<NllLossBackward>)\n","epoch 3186, loss 0.3229520916938782\n","outputs:  tensor([[0.0239, 0.9667],\n","        [0.9781, 0.0289],\n","        [0.9730, 0.0358],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3187, loss 0.32294729351997375\n","outputs:  tensor([[0.0239, 0.9667],\n","        [0.9782, 0.0289],\n","        [0.9730, 0.0357],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3188, loss 0.3229426145553589\n","outputs:  tensor([[0.0239, 0.9667],\n","        [0.9782, 0.0289],\n","        [0.9730, 0.0357],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3189, loss 0.32293787598609924\n","outputs:  tensor([[0.0239, 0.9667],\n","        [0.9782, 0.0289],\n","        [0.9730, 0.0357],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3190, loss 0.3229331076145172\n","outputs:  tensor([[0.0239, 0.9667],\n","        [0.9782, 0.0289],\n","        [0.9730, 0.0357],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3191, loss 0.3229283392429352\n","outputs:  tensor([[0.0238, 0.9668],\n","        [0.9782, 0.0289],\n","        [0.9730, 0.0357],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3192, loss 0.32292360067367554\n","outputs:  tensor([[0.0238, 0.9668],\n","        [0.9782, 0.0289],\n","        [0.9730, 0.0357],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3193, loss 0.3229188919067383\n","outputs:  tensor([[0.0238, 0.9668],\n","        [0.9782, 0.0288],\n","        [0.9731, 0.0356],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3194, loss 0.32291412353515625\n","outputs:  tensor([[0.0238, 0.9668],\n","        [0.9782, 0.0288],\n","        [0.9731, 0.0356],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3195, loss 0.3229094445705414\n","outputs:  tensor([[0.0238, 0.9668],\n","        [0.9782, 0.0288],\n","        [0.9731, 0.0356],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3196, loss 0.32290467619895935\n","outputs:  tensor([[0.0238, 0.9668],\n","        [0.9782, 0.0288],\n","        [0.9731, 0.0356],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3197, loss 0.3228999972343445\n","outputs:  tensor([[0.0238, 0.9669],\n","        [0.9783, 0.0288],\n","        [0.9731, 0.0356],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3198, loss 0.3228952884674072\n","outputs:  tensor([[0.0238, 0.9669],\n","        [0.9783, 0.0288],\n","        [0.9731, 0.0356],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3199, loss 0.32289057970046997\n","outputs:  tensor([[0.0238, 0.9669],\n","        [0.9783, 0.0288],\n","        [0.9731, 0.0356],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3200, loss 0.3228859007358551\n","outputs:  tensor([[0.0237, 0.9669],\n","        [0.9783, 0.0287],\n","        [0.9731, 0.0355],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3201, loss 0.32288116216659546\n","Parameter containing:\n","tensor([[-0.3007, -0.6903,  0.1957],\n","        [-1.0751, -0.8563, -0.0758],\n","        [-1.0946, -1.0282, -0.1248],\n","        [-0.4834, -0.5254, -0.0019]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5225, -0.2426,  0.2116,  0.1448], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9078,  0.8104,  1.2044,  0.1650],\n","        [-0.2624, -1.0523, -0.9177, -0.6290]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3811, -0.6243], requires_grad=True)\n","outputs:  tensor([[0.0237, 0.9669],\n","        [0.9783, 0.0287],\n","        [0.9731, 0.0355],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3202, loss 0.3228764832019806\n","outputs:  tensor([[0.0237, 0.9669],\n","        [0.9783, 0.0287],\n","        [0.9732, 0.0355],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3203, loss 0.32287177443504333\n","outputs:  tensor([[0.0237, 0.9670],\n","        [0.9783, 0.0287],\n","        [0.9732, 0.0355],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3204, loss 0.32286715507507324\n","outputs:  tensor([[0.0237, 0.9670],\n","        [0.9783, 0.0287],\n","        [0.9732, 0.0355],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3205, loss 0.322862446308136\n","outputs:  tensor([[0.0237, 0.9670],\n","        [0.9783, 0.0287],\n","        [0.9732, 0.0355],\n","        [0.9993, 0.0012],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3206, loss 0.32285773754119873\n","outputs:  tensor([[0.0237, 0.9670],\n","        [0.9783, 0.0287],\n","        [0.9732, 0.0354],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3229, grad_fn=<NllLossBackward>)\n","epoch 3207, loss 0.32285308837890625\n","outputs:  tensor([[0.0237, 0.9670],\n","        [0.9784, 0.0286],\n","        [0.9732, 0.0354],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3208, loss 0.3228484094142914\n","outputs:  tensor([[0.0237, 0.9670],\n","        [0.9784, 0.0286],\n","        [0.9732, 0.0354],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3209, loss 0.3228437006473541\n","outputs:  tensor([[0.0236, 0.9671],\n","        [0.9784, 0.0286],\n","        [0.9732, 0.0354],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3210, loss 0.32283908128738403\n","outputs:  tensor([[0.0236, 0.9671],\n","        [0.9784, 0.0286],\n","        [0.9732, 0.0354],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3211, loss 0.32283440232276917\n","outputs:  tensor([[0.0236, 0.9671],\n","        [0.9784, 0.0286],\n","        [0.9733, 0.0354],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3212, loss 0.3228297829627991\n","outputs:  tensor([[0.0236, 0.9671],\n","        [0.9784, 0.0286],\n","        [0.9733, 0.0353],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3213, loss 0.3228251039981842\n","outputs:  tensor([[0.0236, 0.9671],\n","        [0.9784, 0.0286],\n","        [0.9733, 0.0353],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3214, loss 0.32282042503356934\n","outputs:  tensor([[0.0236, 0.9671],\n","        [0.9784, 0.0285],\n","        [0.9733, 0.0353],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3215, loss 0.32281580567359924\n","outputs:  tensor([[0.0236, 0.9671],\n","        [0.9784, 0.0285],\n","        [0.9733, 0.0353],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3216, loss 0.32281121611595154\n","outputs:  tensor([[0.0236, 0.9672],\n","        [0.9784, 0.0285],\n","        [0.9733, 0.0353],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3217, loss 0.32280653715133667\n","outputs:  tensor([[0.0236, 0.9672],\n","        [0.9784, 0.0285],\n","        [0.9733, 0.0353],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3218, loss 0.3228019177913666\n","outputs:  tensor([[0.0236, 0.9672],\n","        [0.9785, 0.0285],\n","        [0.9733, 0.0352],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3219, loss 0.3227972388267517\n","outputs:  tensor([[0.0235, 0.9672],\n","        [0.9785, 0.0285],\n","        [0.9734, 0.0352],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3220, loss 0.322792649269104\n","outputs:  tensor([[0.0235, 0.9672],\n","        [0.9785, 0.0285],\n","        [0.9734, 0.0352],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3221, loss 0.3227880001068115\n","outputs:  tensor([[0.0235, 0.9672],\n","        [0.9785, 0.0284],\n","        [0.9734, 0.0352],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3222, loss 0.3227834105491638\n","outputs:  tensor([[0.0235, 0.9673],\n","        [0.9785, 0.0284],\n","        [0.9734, 0.0352],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3223, loss 0.3227787911891937\n","outputs:  tensor([[0.0235, 0.9673],\n","        [0.9785, 0.0284],\n","        [0.9734, 0.0352],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3224, loss 0.322774201631546\n","outputs:  tensor([[0.0235, 0.9673],\n","        [0.9785, 0.0284],\n","        [0.9734, 0.0351],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3225, loss 0.32276955246925354\n","outputs:  tensor([[0.0235, 0.9673],\n","        [0.9785, 0.0284],\n","        [0.9734, 0.0351],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3226, loss 0.3227650225162506\n","outputs:  tensor([[0.0235, 0.9673],\n","        [0.9785, 0.0284],\n","        [0.9734, 0.0351],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3227, loss 0.3227604031562805\n","outputs:  tensor([[0.0235, 0.9673],\n","        [0.9785, 0.0284],\n","        [0.9734, 0.0351],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3228, loss 0.3227558135986328\n","outputs:  tensor([[0.0234, 0.9674],\n","        [0.9786, 0.0283],\n","        [0.9735, 0.0351],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3228, grad_fn=<NllLossBackward>)\n","epoch 3229, loss 0.3227511942386627\n","outputs:  tensor([[0.0234, 0.9674],\n","        [0.9786, 0.0283],\n","        [0.9735, 0.0351],\n","        [0.9993, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3230, loss 0.322746604681015\n","outputs:  tensor([[0.0234, 0.9674],\n","        [0.9786, 0.0283],\n","        [0.9735, 0.0350],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3231, loss 0.3227420449256897\n","outputs:  tensor([[0.0234, 0.9674],\n","        [0.9786, 0.0283],\n","        [0.9735, 0.0350],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3232, loss 0.322737455368042\n","outputs:  tensor([[0.0234, 0.9674],\n","        [0.9786, 0.0283],\n","        [0.9735, 0.0350],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3233, loss 0.32273292541503906\n","outputs:  tensor([[0.0234, 0.9674],\n","        [0.9786, 0.0283],\n","        [0.9735, 0.0350],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3234, loss 0.32272833585739136\n","outputs:  tensor([[0.0234, 0.9675],\n","        [0.9786, 0.0283],\n","        [0.9735, 0.0350],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3235, loss 0.32272371649742126\n","outputs:  tensor([[0.0234, 0.9675],\n","        [0.9786, 0.0282],\n","        [0.9735, 0.0350],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3236, loss 0.32271918654441833\n","outputs:  tensor([[0.0234, 0.9675],\n","        [0.9786, 0.0282],\n","        [0.9735, 0.0350],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3237, loss 0.322714626789093\n","outputs:  tensor([[0.0234, 0.9675],\n","        [0.9786, 0.0282],\n","        [0.9736, 0.0349],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3238, loss 0.3227100968360901\n","outputs:  tensor([[0.0233, 0.9675],\n","        [0.9787, 0.0282],\n","        [0.9736, 0.0349],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3239, loss 0.3227055072784424\n","outputs:  tensor([[0.0233, 0.9675],\n","        [0.9787, 0.0282],\n","        [0.9736, 0.0349],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3240, loss 0.32270094752311707\n","outputs:  tensor([[0.0233, 0.9676],\n","        [0.9787, 0.0282],\n","        [0.9736, 0.0349],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3241, loss 0.3226964473724365\n","outputs:  tensor([[0.0233, 0.9676],\n","        [0.9787, 0.0282],\n","        [0.9736, 0.0349],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3242, loss 0.3226918876171112\n","outputs:  tensor([[0.0233, 0.9676],\n","        [0.9787, 0.0282],\n","        [0.9736, 0.0349],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3243, loss 0.32268738746643066\n","outputs:  tensor([[0.0233, 0.9676],\n","        [0.9787, 0.0281],\n","        [0.9736, 0.0348],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3244, loss 0.32268285751342773\n","outputs:  tensor([[0.0233, 0.9676],\n","        [0.9787, 0.0281],\n","        [0.9736, 0.0348],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3245, loss 0.3226783275604248\n","outputs:  tensor([[0.0233, 0.9676],\n","        [0.9787, 0.0281],\n","        [0.9736, 0.0348],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3246, loss 0.3226737678050995\n","outputs:  tensor([[0.0233, 0.9676],\n","        [0.9787, 0.0281],\n","        [0.9737, 0.0348],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3247, loss 0.32266920804977417\n","outputs:  tensor([[0.0232, 0.9677],\n","        [0.9787, 0.0281],\n","        [0.9737, 0.0348],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9981]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3248, loss 0.3226647675037384\n","outputs:  tensor([[0.0232, 0.9677],\n","        [0.9787, 0.0281],\n","        [0.9737, 0.0348],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3249, loss 0.32266026735305786\n","outputs:  tensor([[0.0232, 0.9677],\n","        [0.9788, 0.0281],\n","        [0.9737, 0.0347],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3250, loss 0.32265567779541016\n","outputs:  tensor([[0.0232, 0.9677],\n","        [0.9788, 0.0280],\n","        [0.9737, 0.0347],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3227, grad_fn=<NllLossBackward>)\n","epoch 3251, loss 0.3226512372493744\n","Parameter containing:\n","tensor([[-0.3019, -0.6924,  0.1957],\n","        [-1.0773, -0.8601, -0.0758],\n","        [-1.0970, -1.0324, -0.1248],\n","        [-0.4844, -0.5271, -0.0019]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5233, -0.2412,  0.2132,  0.1455], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9096,  0.8127,  1.2074,  0.1665],\n","        [-0.2649, -1.0555, -0.9217, -0.6310]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3817, -0.6251], requires_grad=True)\n","outputs:  tensor([[0.0232, 0.9677],\n","        [0.9788, 0.0280],\n","        [0.9737, 0.0347],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3252, loss 0.32264670729637146\n","outputs:  tensor([[0.0232, 0.9677],\n","        [0.9788, 0.0280],\n","        [0.9737, 0.0347],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3253, loss 0.3226422369480133\n","outputs:  tensor([[0.0232, 0.9678],\n","        [0.9788, 0.0280],\n","        [0.9737, 0.0347],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3254, loss 0.32263773679733276\n","outputs:  tensor([[0.0232, 0.9678],\n","        [0.9788, 0.0280],\n","        [0.9737, 0.0347],\n","        [0.9994, 0.0011],\n","        [0.0018, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3255, loss 0.32263320684432983\n","outputs:  tensor([[0.0232, 0.9678],\n","        [0.9788, 0.0280],\n","        [0.9738, 0.0347],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3256, loss 0.32262879610061646\n","outputs:  tensor([[0.0232, 0.9678],\n","        [0.9788, 0.0280],\n","        [0.9738, 0.0346],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3257, loss 0.3226242661476135\n","outputs:  tensor([[0.0231, 0.9678],\n","        [0.9788, 0.0279],\n","        [0.9738, 0.0346],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3258, loss 0.322619765996933\n","outputs:  tensor([[0.0231, 0.9678],\n","        [0.9788, 0.0279],\n","        [0.9738, 0.0346],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3259, loss 0.32261529564857483\n","outputs:  tensor([[0.0231, 0.9679],\n","        [0.9789, 0.0279],\n","        [0.9738, 0.0346],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3260, loss 0.3226107954978943\n","outputs:  tensor([[0.0231, 0.9679],\n","        [0.9789, 0.0279],\n","        [0.9738, 0.0346],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3261, loss 0.3226063847541809\n","outputs:  tensor([[0.0231, 0.9679],\n","        [0.9789, 0.0279],\n","        [0.9738, 0.0346],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3262, loss 0.322601854801178\n","outputs:  tensor([[0.0231, 0.9679],\n","        [0.9789, 0.0279],\n","        [0.9738, 0.0345],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3263, loss 0.3225974440574646\n","outputs:  tensor([[0.0231, 0.9679],\n","        [0.9789, 0.0279],\n","        [0.9738, 0.0345],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3264, loss 0.3225930333137512\n","outputs:  tensor([[0.0231, 0.9679],\n","        [0.9789, 0.0279],\n","        [0.9739, 0.0345],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3265, loss 0.3225885033607483\n","outputs:  tensor([[0.0231, 0.9679],\n","        [0.9789, 0.0278],\n","        [0.9739, 0.0345],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3266, loss 0.3225840628147125\n","outputs:  tensor([[0.0231, 0.9680],\n","        [0.9789, 0.0278],\n","        [0.9739, 0.0345],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3267, loss 0.32257965207099915\n","outputs:  tensor([[0.0230, 0.9680],\n","        [0.9789, 0.0278],\n","        [0.9739, 0.0345],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3268, loss 0.322575181722641\n","outputs:  tensor([[0.0230, 0.9680],\n","        [0.9789, 0.0278],\n","        [0.9739, 0.0345],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3269, loss 0.3225707411766052\n","outputs:  tensor([[0.0230, 0.9680],\n","        [0.9789, 0.0278],\n","        [0.9739, 0.0344],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3270, loss 0.32256633043289185\n","outputs:  tensor([[0.0230, 0.9680],\n","        [0.9790, 0.0278],\n","        [0.9739, 0.0344],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3271, loss 0.3225618898868561\n","outputs:  tensor([[0.0230, 0.9680],\n","        [0.9790, 0.0278],\n","        [0.9739, 0.0344],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3272, loss 0.3225574493408203\n","outputs:  tensor([[0.0230, 0.9681],\n","        [0.9790, 0.0277],\n","        [0.9739, 0.0344],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3226, grad_fn=<NllLossBackward>)\n","epoch 3273, loss 0.32255300879478455\n","outputs:  tensor([[0.0230, 0.9681],\n","        [0.9790, 0.0277],\n","        [0.9739, 0.0344],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3274, loss 0.32254862785339355\n","outputs:  tensor([[0.0230, 0.9681],\n","        [0.9790, 0.0277],\n","        [0.9740, 0.0344],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3275, loss 0.3225441873073578\n","outputs:  tensor([[0.0230, 0.9681],\n","        [0.9790, 0.0277],\n","        [0.9740, 0.0343],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3276, loss 0.3225398063659668\n","outputs:  tensor([[0.0229, 0.9681],\n","        [0.9790, 0.0277],\n","        [0.9740, 0.0343],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3277, loss 0.32253533601760864\n","outputs:  tensor([[0.0229, 0.9681],\n","        [0.9790, 0.0277],\n","        [0.9740, 0.0343],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3278, loss 0.32253098487854004\n","outputs:  tensor([[0.0229, 0.9682],\n","        [0.9790, 0.0277],\n","        [0.9740, 0.0343],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3279, loss 0.3225265443325043\n","outputs:  tensor([[0.0229, 0.9682],\n","        [0.9790, 0.0277],\n","        [0.9740, 0.0343],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3280, loss 0.32252222299575806\n","outputs:  tensor([[0.0229, 0.9682],\n","        [0.9791, 0.0276],\n","        [0.9740, 0.0343],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3281, loss 0.3225177228450775\n","outputs:  tensor([[0.0229, 0.9682],\n","        [0.9791, 0.0276],\n","        [0.9740, 0.0342],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3282, loss 0.3225134015083313\n","outputs:  tensor([[0.0229, 0.9682],\n","        [0.9791, 0.0276],\n","        [0.9740, 0.0342],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3283, loss 0.3225089907646179\n","outputs:  tensor([[0.0229, 0.9682],\n","        [0.9791, 0.0276],\n","        [0.9741, 0.0342],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3284, loss 0.3225046992301941\n","outputs:  tensor([[0.0229, 0.9682],\n","        [0.9791, 0.0276],\n","        [0.9741, 0.0342],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3285, loss 0.32250022888183594\n","outputs:  tensor([[0.0229, 0.9683],\n","        [0.9791, 0.0276],\n","        [0.9741, 0.0342],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3286, loss 0.32249587774276733\n","outputs:  tensor([[0.0228, 0.9683],\n","        [0.9791, 0.0276],\n","        [0.9741, 0.0342],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3287, loss 0.32249146699905396\n","outputs:  tensor([[0.0228, 0.9683],\n","        [0.9791, 0.0275],\n","        [0.9741, 0.0342],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3288, loss 0.32248714566230774\n","outputs:  tensor([[0.0228, 0.9683],\n","        [0.9791, 0.0275],\n","        [0.9741, 0.0341],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3289, loss 0.32248276472091675\n","outputs:  tensor([[0.0228, 0.9683],\n","        [0.9791, 0.0275],\n","        [0.9741, 0.0341],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3290, loss 0.32247835397720337\n","outputs:  tensor([[0.0228, 0.9683],\n","        [0.9791, 0.0275],\n","        [0.9741, 0.0341],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3291, loss 0.32247403264045715\n","outputs:  tensor([[0.0228, 0.9684],\n","        [0.9792, 0.0275],\n","        [0.9741, 0.0341],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3292, loss 0.32246968150138855\n","outputs:  tensor([[0.0228, 0.9684],\n","        [0.9792, 0.0275],\n","        [0.9742, 0.0341],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3293, loss 0.32246536016464233\n","outputs:  tensor([[0.0228, 0.9684],\n","        [0.9792, 0.0275],\n","        [0.9742, 0.0341],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3294, loss 0.32246097922325134\n","outputs:  tensor([[0.0228, 0.9684],\n","        [0.9792, 0.0275],\n","        [0.9742, 0.0341],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3295, loss 0.3224566578865051\n","outputs:  tensor([[0.0228, 0.9684],\n","        [0.9792, 0.0274],\n","        [0.9742, 0.0340],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3225, grad_fn=<NllLossBackward>)\n","epoch 3296, loss 0.3224523067474365\n","outputs:  tensor([[0.0227, 0.9684],\n","        [0.9792, 0.0274],\n","        [0.9742, 0.0340],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3297, loss 0.3224480152130127\n","outputs:  tensor([[0.0227, 0.9684],\n","        [0.9792, 0.0274],\n","        [0.9742, 0.0340],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3298, loss 0.3224436342716217\n","outputs:  tensor([[0.0227, 0.9685],\n","        [0.9792, 0.0274],\n","        [0.9742, 0.0340],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3299, loss 0.3224392831325531\n","outputs:  tensor([[0.0227, 0.9685],\n","        [0.9792, 0.0274],\n","        [0.9742, 0.0340],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3300, loss 0.3224349617958069\n","outputs:  tensor([[0.0227, 0.9685],\n","        [0.9792, 0.0274],\n","        [0.9742, 0.0340],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3301, loss 0.32243067026138306\n","Parameter containing:\n","tensor([[-0.3031, -0.6946,  0.1957],\n","        [-1.0794, -0.8638, -0.0758],\n","        [-1.0994, -1.0365, -0.1248],\n","        [-0.4853, -0.5288, -0.0018]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5241, -0.2399,  0.2146,  0.1461], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9114,  0.8151,  1.2103,  0.1680],\n","        [-0.2672, -1.0586, -0.9256, -0.6329]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3823, -0.6259], requires_grad=True)\n","outputs:  tensor([[0.0227, 0.9685],\n","        [0.9792, 0.0274],\n","        [0.9743, 0.0339],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3302, loss 0.32242631912231445\n","outputs:  tensor([[0.0227, 0.9685],\n","        [0.9793, 0.0273],\n","        [0.9743, 0.0339],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3303, loss 0.3224220275878906\n","outputs:  tensor([[0.0227, 0.9685],\n","        [0.9793, 0.0273],\n","        [0.9743, 0.0339],\n","        [0.9994, 0.0011],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3304, loss 0.32241764664649963\n","outputs:  tensor([[0.0227, 0.9686],\n","        [0.9793, 0.0273],\n","        [0.9743, 0.0339],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3305, loss 0.32241344451904297\n","outputs:  tensor([[0.0227, 0.9686],\n","        [0.9793, 0.0273],\n","        [0.9743, 0.0339],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3306, loss 0.32240909337997437\n","outputs:  tensor([[0.0226, 0.9686],\n","        [0.9793, 0.0273],\n","        [0.9743, 0.0339],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3307, loss 0.32240480184555054\n","outputs:  tensor([[0.0226, 0.9686],\n","        [0.9793, 0.0273],\n","        [0.9743, 0.0339],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3308, loss 0.3224005103111267\n","outputs:  tensor([[0.0226, 0.9686],\n","        [0.9793, 0.0273],\n","        [0.9743, 0.0338],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3309, loss 0.3223962187767029\n","outputs:  tensor([[0.0226, 0.9686],\n","        [0.9793, 0.0273],\n","        [0.9743, 0.0338],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3310, loss 0.32239192724227905\n","outputs:  tensor([[0.0226, 0.9686],\n","        [0.9793, 0.0272],\n","        [0.9743, 0.0338],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3311, loss 0.32238760590553284\n","outputs:  tensor([[0.0226, 0.9687],\n","        [0.9793, 0.0272],\n","        [0.9744, 0.0338],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3312, loss 0.3223833441734314\n","outputs:  tensor([[0.0226, 0.9687],\n","        [0.9793, 0.0272],\n","        [0.9744, 0.0338],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3313, loss 0.32237905263900757\n","outputs:  tensor([[0.0226, 0.9687],\n","        [0.9794, 0.0272],\n","        [0.9744, 0.0338],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3314, loss 0.32237476110458374\n","outputs:  tensor([[0.0226, 0.9687],\n","        [0.9794, 0.0272],\n","        [0.9744, 0.0337],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3315, loss 0.3223704695701599\n","outputs:  tensor([[0.0226, 0.9687],\n","        [0.9794, 0.0272],\n","        [0.9744, 0.0337],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3316, loss 0.32236623764038086\n","outputs:  tensor([[0.0225, 0.9687],\n","        [0.9794, 0.0272],\n","        [0.9744, 0.0337],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9982]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3317, loss 0.32236194610595703\n","outputs:  tensor([[0.0225, 0.9687],\n","        [0.9794, 0.0272],\n","        [0.9744, 0.0337],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3318, loss 0.3223576545715332\n","outputs:  tensor([[0.0225, 0.9688],\n","        [0.9794, 0.0271],\n","        [0.9744, 0.0337],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3224, grad_fn=<NllLossBackward>)\n","epoch 3319, loss 0.32235342264175415\n","outputs:  tensor([[0.0225, 0.9688],\n","        [0.9794, 0.0271],\n","        [0.9744, 0.0337],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3320, loss 0.3223491609096527\n","outputs:  tensor([[0.0225, 0.9688],\n","        [0.9794, 0.0271],\n","        [0.9745, 0.0337],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3321, loss 0.32234492897987366\n","outputs:  tensor([[0.0225, 0.9688],\n","        [0.9794, 0.0271],\n","        [0.9745, 0.0336],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3322, loss 0.3223406672477722\n","outputs:  tensor([[0.0225, 0.9688],\n","        [0.9794, 0.0271],\n","        [0.9745, 0.0336],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3323, loss 0.3223363757133484\n","outputs:  tensor([[0.0225, 0.9688],\n","        [0.9794, 0.0271],\n","        [0.9745, 0.0336],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3324, loss 0.3223322033882141\n","outputs:  tensor([[0.0225, 0.9689],\n","        [0.9795, 0.0271],\n","        [0.9745, 0.0336],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3325, loss 0.32232794165611267\n","outputs:  tensor([[0.0225, 0.9689],\n","        [0.9795, 0.0270],\n","        [0.9745, 0.0336],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3326, loss 0.3223237097263336\n","outputs:  tensor([[0.0225, 0.9689],\n","        [0.9795, 0.0270],\n","        [0.9745, 0.0336],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3327, loss 0.3223194479942322\n","outputs:  tensor([[0.0224, 0.9689],\n","        [0.9795, 0.0270],\n","        [0.9745, 0.0336],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3328, loss 0.3223152160644531\n","outputs:  tensor([[0.0224, 0.9689],\n","        [0.9795, 0.0270],\n","        [0.9745, 0.0335],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3329, loss 0.32231107354164124\n","outputs:  tensor([[0.0224, 0.9689],\n","        [0.9795, 0.0270],\n","        [0.9745, 0.0335],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3330, loss 0.3223068118095398\n","outputs:  tensor([[0.0224, 0.9689],\n","        [0.9795, 0.0270],\n","        [0.9746, 0.0335],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3331, loss 0.32230255007743835\n","outputs:  tensor([[0.0224, 0.9690],\n","        [0.9795, 0.0270],\n","        [0.9746, 0.0335],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3332, loss 0.3222983181476593\n","outputs:  tensor([[0.0224, 0.9690],\n","        [0.9795, 0.0270],\n","        [0.9746, 0.0335],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3333, loss 0.3222941756248474\n","outputs:  tensor([[0.0224, 0.9690],\n","        [0.9795, 0.0269],\n","        [0.9746, 0.0335],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3334, loss 0.32228994369506836\n","outputs:  tensor([[0.0224, 0.9690],\n","        [0.9795, 0.0269],\n","        [0.9746, 0.0335],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3335, loss 0.3222857117652893\n","outputs:  tensor([[0.0224, 0.9690],\n","        [0.9796, 0.0269],\n","        [0.9746, 0.0334],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3336, loss 0.32228153944015503\n","outputs:  tensor([[0.0224, 0.9690],\n","        [0.9796, 0.0269],\n","        [0.9746, 0.0334],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3337, loss 0.32227733731269836\n","outputs:  tensor([[0.0223, 0.9690],\n","        [0.9796, 0.0269],\n","        [0.9746, 0.0334],\n","        [0.9994, 0.0010],\n","        [0.0017, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3338, loss 0.3222731351852417\n","outputs:  tensor([[0.0223, 0.9691],\n","        [0.9796, 0.0269],\n","        [0.9746, 0.0334],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3339, loss 0.32226890325546265\n","outputs:  tensor([[0.0223, 0.9691],\n","        [0.9796, 0.0269],\n","        [0.9746, 0.0334],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3340, loss 0.32226476073265076\n","outputs:  tensor([[0.0223, 0.9691],\n","        [0.9796, 0.0269],\n","        [0.9747, 0.0334],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3341, loss 0.3222605884075165\n","outputs:  tensor([[0.0223, 0.9691],\n","        [0.9796, 0.0268],\n","        [0.9747, 0.0333],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3342, loss 0.3222564160823822\n","outputs:  tensor([[0.0223, 0.9691],\n","        [0.9796, 0.0268],\n","        [0.9747, 0.0333],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3223, grad_fn=<NllLossBackward>)\n","epoch 3343, loss 0.32225221395492554\n","outputs:  tensor([[0.0223, 0.9691],\n","        [0.9796, 0.0268],\n","        [0.9747, 0.0333],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3344, loss 0.32224804162979126\n","outputs:  tensor([[0.0223, 0.9691],\n","        [0.9796, 0.0268],\n","        [0.9747, 0.0333],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3345, loss 0.322243869304657\n","outputs:  tensor([[0.0223, 0.9692],\n","        [0.9796, 0.0268],\n","        [0.9747, 0.0333],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3346, loss 0.3222397267818451\n","outputs:  tensor([[0.0223, 0.9692],\n","        [0.9797, 0.0268],\n","        [0.9747, 0.0333],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3347, loss 0.32223549485206604\n","outputs:  tensor([[0.0222, 0.9692],\n","        [0.9797, 0.0268],\n","        [0.9747, 0.0333],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3348, loss 0.3222314417362213\n","outputs:  tensor([[0.0222, 0.9692],\n","        [0.9797, 0.0268],\n","        [0.9747, 0.0332],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3349, loss 0.32222723960876465\n","outputs:  tensor([[0.0222, 0.9692],\n","        [0.9797, 0.0267],\n","        [0.9748, 0.0332],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3350, loss 0.322223037481308\n","outputs:  tensor([[0.0222, 0.9692],\n","        [0.9797, 0.0267],\n","        [0.9748, 0.0332],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3351, loss 0.32221895456314087\n","Parameter containing:\n","tensor([[-0.3043, -0.6966,  0.1956],\n","        [-1.0815, -0.8675, -0.0758],\n","        [-1.1017, -1.0405, -0.1248],\n","        [-0.4863, -0.5305, -0.0018]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5248, -0.2386,  0.2161,  0.1467], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9131,  0.8174,  1.2132,  0.1694],\n","        [-0.2695, -1.0616, -0.9294, -0.6348]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3830, -0.6267], requires_grad=True)\n","outputs:  tensor([[0.0222, 0.9693],\n","        [0.9797, 0.0267],\n","        [0.9748, 0.0332],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3352, loss 0.3222147524356842\n","outputs:  tensor([[0.0222, 0.9693],\n","        [0.9797, 0.0267],\n","        [0.9748, 0.0332],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3353, loss 0.3222106397151947\n","outputs:  tensor([[0.0222, 0.9693],\n","        [0.9797, 0.0267],\n","        [0.9748, 0.0332],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3354, loss 0.3222064971923828\n","outputs:  tensor([[0.0222, 0.9693],\n","        [0.9797, 0.0267],\n","        [0.9748, 0.0332],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3355, loss 0.3222023546695709\n","outputs:  tensor([[0.0222, 0.9693],\n","        [0.9797, 0.0267],\n","        [0.9748, 0.0331],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3356, loss 0.32219821214675903\n","outputs:  tensor([[0.0222, 0.9693],\n","        [0.9797, 0.0267],\n","        [0.9748, 0.0331],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3357, loss 0.32219406962394714\n","outputs:  tensor([[0.0222, 0.9693],\n","        [0.9798, 0.0266],\n","        [0.9748, 0.0331],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3358, loss 0.32218995690345764\n","outputs:  tensor([[0.0221, 0.9694],\n","        [0.9798, 0.0266],\n","        [0.9748, 0.0331],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3359, loss 0.32218581438064575\n","outputs:  tensor([[0.0221, 0.9694],\n","        [0.9798, 0.0266],\n","        [0.9749, 0.0331],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3360, loss 0.32218167185783386\n","outputs:  tensor([[0.0221, 0.9694],\n","        [0.9798, 0.0266],\n","        [0.9749, 0.0331],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3361, loss 0.3221776485443115\n","outputs:  tensor([[0.0221, 0.9694],\n","        [0.9798, 0.0266],\n","        [0.9749, 0.0331],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3362, loss 0.32217347621917725\n","outputs:  tensor([[0.0221, 0.9694],\n","        [0.9798, 0.0266],\n","        [0.9749, 0.0330],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3363, loss 0.32216936349868774\n","outputs:  tensor([[0.0221, 0.9694],\n","        [0.9798, 0.0266],\n","        [0.9749, 0.0330],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3364, loss 0.32216525077819824\n","outputs:  tensor([[0.0221, 0.9694],\n","        [0.9798, 0.0266],\n","        [0.9749, 0.0330],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3365, loss 0.32216113805770874\n","outputs:  tensor([[0.0221, 0.9695],\n","        [0.9798, 0.0265],\n","        [0.9749, 0.0330],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3366, loss 0.322157084941864\n","outputs:  tensor([[0.0221, 0.9695],\n","        [0.9798, 0.0265],\n","        [0.9749, 0.0330],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3222, grad_fn=<NllLossBackward>)\n","epoch 3367, loss 0.3221529722213745\n","outputs:  tensor([[0.0221, 0.9695],\n","        [0.9798, 0.0265],\n","        [0.9749, 0.0330],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3368, loss 0.322148859500885\n","outputs:  tensor([[0.0220, 0.9695],\n","        [0.9798, 0.0265],\n","        [0.9749, 0.0330],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3369, loss 0.3221447765827179\n","outputs:  tensor([[0.0220, 0.9695],\n","        [0.9799, 0.0265],\n","        [0.9750, 0.0329],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3370, loss 0.322140634059906\n","outputs:  tensor([[0.0220, 0.9695],\n","        [0.9799, 0.0265],\n","        [0.9750, 0.0329],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3371, loss 0.32213664054870605\n","outputs:  tensor([[0.0220, 0.9695],\n","        [0.9799, 0.0265],\n","        [0.9750, 0.0329],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3372, loss 0.32213252782821655\n","outputs:  tensor([[0.0220, 0.9696],\n","        [0.9799, 0.0265],\n","        [0.9750, 0.0329],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3373, loss 0.3221284747123718\n","outputs:  tensor([[0.0220, 0.9696],\n","        [0.9799, 0.0264],\n","        [0.9750, 0.0329],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3374, loss 0.32212433218955994\n","outputs:  tensor([[0.0220, 0.9696],\n","        [0.9799, 0.0264],\n","        [0.9750, 0.0329],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3375, loss 0.32212033867836\n","outputs:  tensor([[0.0220, 0.9696],\n","        [0.9799, 0.0264],\n","        [0.9750, 0.0329],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3376, loss 0.3221162259578705\n","outputs:  tensor([[0.0220, 0.9696],\n","        [0.9799, 0.0264],\n","        [0.9750, 0.0328],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3377, loss 0.32211217284202576\n","outputs:  tensor([[0.0220, 0.9696],\n","        [0.9799, 0.0264],\n","        [0.9750, 0.0328],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3378, loss 0.32210811972618103\n","outputs:  tensor([[0.0220, 0.9696],\n","        [0.9799, 0.0264],\n","        [0.9750, 0.0328],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3379, loss 0.3221040368080139\n","outputs:  tensor([[0.0219, 0.9697],\n","        [0.9799, 0.0264],\n","        [0.9751, 0.0328],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3380, loss 0.3221000134944916\n","outputs:  tensor([[0.0219, 0.9697],\n","        [0.9800, 0.0264],\n","        [0.9751, 0.0328],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3381, loss 0.3220958709716797\n","outputs:  tensor([[0.0219, 0.9697],\n","        [0.9800, 0.0263],\n","        [0.9751, 0.0328],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3382, loss 0.3220919072628021\n","outputs:  tensor([[0.0219, 0.9697],\n","        [0.9800, 0.0263],\n","        [0.9751, 0.0328],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3383, loss 0.3220878839492798\n","outputs:  tensor([[0.0219, 0.9697],\n","        [0.9800, 0.0263],\n","        [0.9751, 0.0327],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3384, loss 0.32208380103111267\n","outputs:  tensor([[0.0219, 0.9697],\n","        [0.9800, 0.0263],\n","        [0.9751, 0.0327],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3385, loss 0.3220798075199127\n","outputs:  tensor([[0.0219, 0.9697],\n","        [0.9800, 0.0263],\n","        [0.9751, 0.0327],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3386, loss 0.3220757246017456\n","outputs:  tensor([[0.0219, 0.9698],\n","        [0.9800, 0.0263],\n","        [0.9751, 0.0327],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3387, loss 0.32207173109054565\n","outputs:  tensor([[0.0219, 0.9698],\n","        [0.9800, 0.0263],\n","        [0.9751, 0.0327],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3388, loss 0.3220676779747009\n","outputs:  tensor([[0.0219, 0.9698],\n","        [0.9800, 0.0263],\n","        [0.9751, 0.0327],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3389, loss 0.3220636248588562\n","outputs:  tensor([[0.0219, 0.9698],\n","        [0.9800, 0.0262],\n","        [0.9752, 0.0327],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3390, loss 0.3220595717430115\n","outputs:  tensor([[0.0218, 0.9698],\n","        [0.9800, 0.0262],\n","        [0.9752, 0.0326],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3391, loss 0.3220556378364563\n","outputs:  tensor([[0.0218, 0.9698],\n","        [0.9800, 0.0262],\n","        [0.9752, 0.0326],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3221, grad_fn=<NllLossBackward>)\n","epoch 3392, loss 0.3220515847206116\n","outputs:  tensor([[0.0218, 0.9698],\n","        [0.9801, 0.0262],\n","        [0.9752, 0.0326],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9983]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3393, loss 0.3220475912094116\n","outputs:  tensor([[0.0218, 0.9699],\n","        [0.9801, 0.0262],\n","        [0.9752, 0.0326],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3394, loss 0.32204359769821167\n","outputs:  tensor([[0.0218, 0.9699],\n","        [0.9801, 0.0262],\n","        [0.9752, 0.0326],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3395, loss 0.32203954458236694\n","outputs:  tensor([[0.0218, 0.9699],\n","        [0.9801, 0.0262],\n","        [0.9752, 0.0326],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3396, loss 0.3220355808734894\n","outputs:  tensor([[0.0218, 0.9699],\n","        [0.9801, 0.0262],\n","        [0.9752, 0.0326],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3397, loss 0.32203158736228943\n","outputs:  tensor([[0.0218, 0.9699],\n","        [0.9801, 0.0261],\n","        [0.9752, 0.0325],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3398, loss 0.3220275342464447\n","outputs:  tensor([[0.0218, 0.9699],\n","        [0.9801, 0.0261],\n","        [0.9752, 0.0325],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3399, loss 0.32202354073524475\n","outputs:  tensor([[0.0218, 0.9699],\n","        [0.9801, 0.0261],\n","        [0.9753, 0.0325],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3400, loss 0.3220195174217224\n","outputs:  tensor([[0.0217, 0.9700],\n","        [0.9801, 0.0261],\n","        [0.9753, 0.0325],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3401, loss 0.32201552391052246\n","Parameter containing:\n","tensor([[-0.3055, -0.6987,  0.1956],\n","        [-1.0836, -0.8710, -0.0757],\n","        [-1.1040, -1.0445, -0.1248],\n","        [-0.4872, -0.5321, -0.0018]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5256, -0.2373,  0.2176,  0.1473], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9148,  0.8196,  1.2160,  0.1708],\n","        [-0.2718, -1.0646, -0.9331, -0.6366]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3836, -0.6275], requires_grad=True)\n","outputs:  tensor([[0.0217, 0.9700],\n","        [0.9801, 0.0261],\n","        [0.9753, 0.0325],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3402, loss 0.3220115602016449\n","outputs:  tensor([[0.0217, 0.9700],\n","        [0.9801, 0.0261],\n","        [0.9753, 0.0325],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3403, loss 0.32200759649276733\n","outputs:  tensor([[0.0217, 0.9700],\n","        [0.9801, 0.0261],\n","        [0.9753, 0.0325],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3404, loss 0.3220036029815674\n","outputs:  tensor([[0.0217, 0.9700],\n","        [0.9802, 0.0261],\n","        [0.9753, 0.0324],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3405, loss 0.3219996392726898\n","outputs:  tensor([[0.0217, 0.9700],\n","        [0.9802, 0.0261],\n","        [0.9753, 0.0324],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3406, loss 0.32199567556381226\n","outputs:  tensor([[0.0217, 0.9700],\n","        [0.9802, 0.0260],\n","        [0.9753, 0.0324],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3407, loss 0.3219917416572571\n","outputs:  tensor([[0.0217, 0.9701],\n","        [0.9802, 0.0260],\n","        [0.9753, 0.0324],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3408, loss 0.32198771834373474\n","outputs:  tensor([[0.0217, 0.9701],\n","        [0.9802, 0.0260],\n","        [0.9753, 0.0324],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3409, loss 0.32198381423950195\n","outputs:  tensor([[0.0217, 0.9701],\n","        [0.9802, 0.0260],\n","        [0.9754, 0.0324],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3410, loss 0.321979820728302\n","outputs:  tensor([[0.0217, 0.9701],\n","        [0.9802, 0.0260],\n","        [0.9754, 0.0324],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3411, loss 0.32197585701942444\n","outputs:  tensor([[0.0216, 0.9701],\n","        [0.9802, 0.0260],\n","        [0.9754, 0.0323],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3412, loss 0.3219718933105469\n","outputs:  tensor([[0.0216, 0.9701],\n","        [0.9802, 0.0260],\n","        [0.9754, 0.0323],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3413, loss 0.3219680190086365\n","outputs:  tensor([[0.0216, 0.9701],\n","        [0.9802, 0.0260],\n","        [0.9754, 0.0323],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3414, loss 0.3219640254974365\n","outputs:  tensor([[0.0216, 0.9701],\n","        [0.9802, 0.0259],\n","        [0.9754, 0.0323],\n","        [0.9994, 0.0010],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3415, loss 0.32196006178855896\n","outputs:  tensor([[0.0216, 0.9702],\n","        [0.9803, 0.0259],\n","        [0.9754, 0.0323],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3416, loss 0.3219560980796814\n","outputs:  tensor([[0.0216, 0.9702],\n","        [0.9803, 0.0259],\n","        [0.9754, 0.0323],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3220, grad_fn=<NllLossBackward>)\n","epoch 3417, loss 0.3219521939754486\n","outputs:  tensor([[0.0216, 0.9702],\n","        [0.9803, 0.0259],\n","        [0.9754, 0.0323],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3418, loss 0.32194826006889343\n","outputs:  tensor([[0.0216, 0.9702],\n","        [0.9803, 0.0259],\n","        [0.9754, 0.0323],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3419, loss 0.32194429636001587\n","outputs:  tensor([[0.0216, 0.9702],\n","        [0.9803, 0.0259],\n","        [0.9755, 0.0322],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3420, loss 0.3219403922557831\n","outputs:  tensor([[0.0216, 0.9702],\n","        [0.9803, 0.0259],\n","        [0.9755, 0.0322],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3421, loss 0.3219364285469055\n","outputs:  tensor([[0.0216, 0.9702],\n","        [0.9803, 0.0259],\n","        [0.9755, 0.0322],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3422, loss 0.3219325542449951\n","outputs:  tensor([[0.0215, 0.9703],\n","        [0.9803, 0.0258],\n","        [0.9755, 0.0322],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3423, loss 0.32192862033843994\n","outputs:  tensor([[0.0215, 0.9703],\n","        [0.9803, 0.0258],\n","        [0.9755, 0.0322],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3424, loss 0.32192474603652954\n","outputs:  tensor([[0.0215, 0.9703],\n","        [0.9803, 0.0258],\n","        [0.9755, 0.0322],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3425, loss 0.32192081212997437\n","outputs:  tensor([[0.0215, 0.9703],\n","        [0.9803, 0.0258],\n","        [0.9755, 0.0322],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3426, loss 0.32191693782806396\n","outputs:  tensor([[0.0215, 0.9703],\n","        [0.9803, 0.0258],\n","        [0.9755, 0.0321],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3427, loss 0.321912944316864\n","outputs:  tensor([[0.0215, 0.9703],\n","        [0.9804, 0.0258],\n","        [0.9755, 0.0321],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3428, loss 0.3219091296195984\n","outputs:  tensor([[0.0215, 0.9703],\n","        [0.9804, 0.0258],\n","        [0.9755, 0.0321],\n","        [0.9994, 0.0009],\n","        [0.0016, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3429, loss 0.3219051957130432\n","outputs:  tensor([[0.0215, 0.9704],\n","        [0.9804, 0.0258],\n","        [0.9756, 0.0321],\n","        [0.9994, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3430, loss 0.32190126180648804\n","outputs:  tensor([[0.0215, 0.9704],\n","        [0.9804, 0.0258],\n","        [0.9756, 0.0321],\n","        [0.9994, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3431, loss 0.3218974173069\n","outputs:  tensor([[0.0215, 0.9704],\n","        [0.9804, 0.0257],\n","        [0.9756, 0.0321],\n","        [0.9994, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3432, loss 0.32189351320266724\n","outputs:  tensor([[0.0215, 0.9704],\n","        [0.9804, 0.0257],\n","        [0.9756, 0.0321],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3433, loss 0.32188957929611206\n","outputs:  tensor([[0.0214, 0.9704],\n","        [0.9804, 0.0257],\n","        [0.9756, 0.0320],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3434, loss 0.32188573479652405\n","outputs:  tensor([[0.0214, 0.9704],\n","        [0.9804, 0.0257],\n","        [0.9756, 0.0320],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3435, loss 0.32188186049461365\n","outputs:  tensor([[0.0214, 0.9704],\n","        [0.9804, 0.0257],\n","        [0.9756, 0.0320],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3436, loss 0.32187795639038086\n","outputs:  tensor([[0.0214, 0.9705],\n","        [0.9804, 0.0257],\n","        [0.9756, 0.0320],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3437, loss 0.32187408208847046\n","outputs:  tensor([[0.0214, 0.9705],\n","        [0.9804, 0.0257],\n","        [0.9756, 0.0320],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3438, loss 0.32187017798423767\n","outputs:  tensor([[0.0214, 0.9705],\n","        [0.9804, 0.0257],\n","        [0.9756, 0.0320],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3439, loss 0.32186636328697205\n","outputs:  tensor([[0.0214, 0.9705],\n","        [0.9805, 0.0256],\n","        [0.9756, 0.0320],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3440, loss 0.32186245918273926\n","outputs:  tensor([[0.0214, 0.9705],\n","        [0.9805, 0.0256],\n","        [0.9757, 0.0319],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3441, loss 0.32185858488082886\n","outputs:  tensor([[0.0214, 0.9705],\n","        [0.9805, 0.0256],\n","        [0.9757, 0.0319],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3442, loss 0.32185477018356323\n","outputs:  tensor([[0.0214, 0.9705],\n","        [0.9805, 0.0256],\n","        [0.9757, 0.0319],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3219, grad_fn=<NllLossBackward>)\n","epoch 3443, loss 0.3218509554862976\n","outputs:  tensor([[0.0214, 0.9705],\n","        [0.9805, 0.0256],\n","        [0.9757, 0.0319],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3444, loss 0.3218470811843872\n","outputs:  tensor([[0.0214, 0.9706],\n","        [0.9805, 0.0256],\n","        [0.9757, 0.0319],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3445, loss 0.3218432068824768\n","outputs:  tensor([[0.0213, 0.9706],\n","        [0.9805, 0.0256],\n","        [0.9757, 0.0319],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3446, loss 0.3218393325805664\n","outputs:  tensor([[0.0213, 0.9706],\n","        [0.9805, 0.0256],\n","        [0.9757, 0.0319],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3447, loss 0.321835458278656\n","outputs:  tensor([[0.0213, 0.9706],\n","        [0.9805, 0.0256],\n","        [0.9757, 0.0319],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3448, loss 0.32183167338371277\n","outputs:  tensor([[0.0213, 0.9706],\n","        [0.9805, 0.0255],\n","        [0.9757, 0.0318],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3449, loss 0.32182779908180237\n","outputs:  tensor([[0.0213, 0.9706],\n","        [0.9805, 0.0255],\n","        [0.9757, 0.0318],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3450, loss 0.32182398438453674\n","outputs:  tensor([[0.0213, 0.9706],\n","        [0.9805, 0.0255],\n","        [0.9758, 0.0318],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3451, loss 0.32182011008262634\n","Parameter containing:\n","tensor([[-0.3067, -0.7007,  0.1956],\n","        [-1.0856, -0.8745, -0.0757],\n","        [-1.1062, -1.0483, -0.1248],\n","        [-0.4881, -0.5337, -0.0018]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5263, -0.2360,  0.2190,  0.1478], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9165,  0.8218,  1.2188,  0.1721],\n","        [-0.2740, -1.0676, -0.9368, -0.6384]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3841, -0.6282], requires_grad=True)\n","outputs:  tensor([[0.0213, 0.9707],\n","        [0.9806, 0.0255],\n","        [0.9758, 0.0318],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3452, loss 0.3218163549900055\n","outputs:  tensor([[0.0213, 0.9707],\n","        [0.9806, 0.0255],\n","        [0.9758, 0.0318],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3453, loss 0.3218124508857727\n","outputs:  tensor([[0.0213, 0.9707],\n","        [0.9806, 0.0255],\n","        [0.9758, 0.0318],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3454, loss 0.3218086361885071\n","outputs:  tensor([[0.0213, 0.9707],\n","        [0.9806, 0.0255],\n","        [0.9758, 0.0318],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3455, loss 0.32180482149124146\n","outputs:  tensor([[0.0213, 0.9707],\n","        [0.9806, 0.0255],\n","        [0.9758, 0.0317],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3456, loss 0.32180100679397583\n","outputs:  tensor([[0.0212, 0.9707],\n","        [0.9806, 0.0255],\n","        [0.9758, 0.0317],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3457, loss 0.3217971920967102\n","outputs:  tensor([[0.0212, 0.9707],\n","        [0.9806, 0.0254],\n","        [0.9758, 0.0317],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3458, loss 0.3217933773994446\n","outputs:  tensor([[0.0212, 0.9708],\n","        [0.9806, 0.0254],\n","        [0.9758, 0.0317],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3459, loss 0.32178956270217896\n","outputs:  tensor([[0.0212, 0.9708],\n","        [0.9806, 0.0254],\n","        [0.9758, 0.0317],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3460, loss 0.3217857778072357\n","outputs:  tensor([[0.0212, 0.9708],\n","        [0.9806, 0.0254],\n","        [0.9758, 0.0317],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3461, loss 0.3217819631099701\n","outputs:  tensor([[0.0212, 0.9708],\n","        [0.9806, 0.0254],\n","        [0.9759, 0.0317],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3462, loss 0.32177814841270447\n","outputs:  tensor([[0.0212, 0.9708],\n","        [0.9806, 0.0254],\n","        [0.9759, 0.0317],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3463, loss 0.32177433371543884\n","outputs:  tensor([[0.0212, 0.9708],\n","        [0.9806, 0.0254],\n","        [0.9759, 0.0316],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3464, loss 0.321770578622818\n","outputs:  tensor([[0.0212, 0.9708],\n","        [0.9807, 0.0254],\n","        [0.9759, 0.0316],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3465, loss 0.32176676392555237\n","outputs:  tensor([[0.0212, 0.9708],\n","        [0.9807, 0.0253],\n","        [0.9759, 0.0316],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3466, loss 0.32176297903060913\n","outputs:  tensor([[0.0212, 0.9709],\n","        [0.9807, 0.0253],\n","        [0.9759, 0.0316],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3467, loss 0.3217592239379883\n","outputs:  tensor([[0.0211, 0.9709],\n","        [0.9807, 0.0253],\n","        [0.9759, 0.0316],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3468, loss 0.32175540924072266\n","outputs:  tensor([[0.0211, 0.9709],\n","        [0.9807, 0.0253],\n","        [0.9759, 0.0316],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3218, grad_fn=<NllLossBackward>)\n","epoch 3469, loss 0.32175159454345703\n","outputs:  tensor([[0.0211, 0.9709],\n","        [0.9807, 0.0253],\n","        [0.9759, 0.0316],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3470, loss 0.32174786925315857\n","outputs:  tensor([[0.0211, 0.9709],\n","        [0.9807, 0.0253],\n","        [0.9759, 0.0315],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3471, loss 0.32174405455589294\n","outputs:  tensor([[0.0211, 0.9709],\n","        [0.9807, 0.0253],\n","        [0.9760, 0.0315],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3472, loss 0.3217402994632721\n","outputs:  tensor([[0.0211, 0.9709],\n","        [0.9807, 0.0253],\n","        [0.9760, 0.0315],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3473, loss 0.32173648476600647\n","outputs:  tensor([[0.0211, 0.9710],\n","        [0.9807, 0.0253],\n","        [0.9760, 0.0315],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3474, loss 0.3217327892780304\n","outputs:  tensor([[0.0211, 0.9710],\n","        [0.9807, 0.0252],\n","        [0.9760, 0.0315],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9984]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3475, loss 0.32172900438308716\n","outputs:  tensor([[0.0211, 0.9710],\n","        [0.9807, 0.0252],\n","        [0.9760, 0.0315],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3476, loss 0.3217252492904663\n","outputs:  tensor([[0.0211, 0.9710],\n","        [0.9808, 0.0252],\n","        [0.9760, 0.0315],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3477, loss 0.32172149419784546\n","outputs:  tensor([[0.0211, 0.9710],\n","        [0.9808, 0.0252],\n","        [0.9760, 0.0315],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3478, loss 0.321717768907547\n","outputs:  tensor([[0.0211, 0.9710],\n","        [0.9808, 0.0252],\n","        [0.9760, 0.0314],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3479, loss 0.32171398401260376\n","outputs:  tensor([[0.0210, 0.9710],\n","        [0.9808, 0.0252],\n","        [0.9760, 0.0314],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3480, loss 0.3217102289199829\n","outputs:  tensor([[0.0210, 0.9710],\n","        [0.9808, 0.0252],\n","        [0.9760, 0.0314],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3481, loss 0.32170650362968445\n","outputs:  tensor([[0.0210, 0.9711],\n","        [0.9808, 0.0252],\n","        [0.9760, 0.0314],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3482, loss 0.3217027485370636\n","outputs:  tensor([[0.0210, 0.9711],\n","        [0.9808, 0.0252],\n","        [0.9761, 0.0314],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3483, loss 0.32169899344444275\n","outputs:  tensor([[0.0210, 0.9711],\n","        [0.9808, 0.0251],\n","        [0.9761, 0.0314],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3484, loss 0.3216952681541443\n","outputs:  tensor([[0.0210, 0.9711],\n","        [0.9808, 0.0251],\n","        [0.9761, 0.0314],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3485, loss 0.3216915726661682\n","outputs:  tensor([[0.0210, 0.9711],\n","        [0.9808, 0.0251],\n","        [0.9761, 0.0313],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3486, loss 0.3216877579689026\n","outputs:  tensor([[0.0210, 0.9711],\n","        [0.9808, 0.0251],\n","        [0.9761, 0.0313],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3487, loss 0.3216840624809265\n","outputs:  tensor([[0.0210, 0.9711],\n","        [0.9808, 0.0251],\n","        [0.9761, 0.0313],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3488, loss 0.32168036699295044\n","outputs:  tensor([[0.0210, 0.9711],\n","        [0.9809, 0.0251],\n","        [0.9761, 0.0313],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3489, loss 0.32167667150497437\n","outputs:  tensor([[0.0210, 0.9712],\n","        [0.9809, 0.0251],\n","        [0.9761, 0.0313],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3490, loss 0.32167288661003113\n","outputs:  tensor([[0.0209, 0.9712],\n","        [0.9809, 0.0251],\n","        [0.9761, 0.0313],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3491, loss 0.32166916131973267\n","outputs:  tensor([[0.0209, 0.9712],\n","        [0.9809, 0.0250],\n","        [0.9761, 0.0313],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3492, loss 0.32166552543640137\n","outputs:  tensor([[0.0209, 0.9712],\n","        [0.9809, 0.0250],\n","        [0.9761, 0.0313],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3493, loss 0.3216618001461029\n","outputs:  tensor([[0.0209, 0.9712],\n","        [0.9809, 0.0250],\n","        [0.9762, 0.0312],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3494, loss 0.32165807485580444\n","outputs:  tensor([[0.0209, 0.9712],\n","        [0.9809, 0.0250],\n","        [0.9762, 0.0312],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3495, loss 0.32165437936782837\n","outputs:  tensor([[0.0209, 0.9712],\n","        [0.9809, 0.0250],\n","        [0.9762, 0.0312],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3217, grad_fn=<NllLossBackward>)\n","epoch 3496, loss 0.3216506540775299\n","outputs:  tensor([[0.0209, 0.9713],\n","        [0.9809, 0.0250],\n","        [0.9762, 0.0312],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3497, loss 0.32164692878723145\n","outputs:  tensor([[0.0209, 0.9713],\n","        [0.9809, 0.0250],\n","        [0.9762, 0.0312],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3498, loss 0.32164326310157776\n","outputs:  tensor([[0.0209, 0.9713],\n","        [0.9809, 0.0250],\n","        [0.9762, 0.0312],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3499, loss 0.3216395974159241\n","outputs:  tensor([[0.0209, 0.9713],\n","        [0.9809, 0.0250],\n","        [0.9762, 0.0312],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3500, loss 0.3216358721256256\n","outputs:  tensor([[0.0209, 0.9713],\n","        [0.9809, 0.0249],\n","        [0.9762, 0.0311],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3501, loss 0.3216322064399719\n","Parameter containing:\n","tensor([[-0.3078, -0.7027,  0.1956],\n","        [-1.0875, -0.8780, -0.0757],\n","        [-1.1084, -1.0521, -0.1248],\n","        [-0.4890, -0.5353, -0.0018]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5271, -0.2347,  0.2204,  0.1484], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9182,  0.8240,  1.2215,  0.1735],\n","        [-0.2762, -1.0704, -0.9403, -0.6402]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3847, -0.6289], requires_grad=True)\n","outputs:  tensor([[0.0209, 0.9713],\n","        [0.9810, 0.0249],\n","        [0.9762, 0.0311],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3502, loss 0.32162851095199585\n","outputs:  tensor([[0.0208, 0.9713],\n","        [0.9810, 0.0249],\n","        [0.9762, 0.0311],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3503, loss 0.32162484526634216\n","outputs:  tensor([[0.0208, 0.9713],\n","        [0.9810, 0.0249],\n","        [0.9763, 0.0311],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3504, loss 0.3216211199760437\n","outputs:  tensor([[0.0208, 0.9714],\n","        [0.9810, 0.0249],\n","        [0.9763, 0.0311],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3505, loss 0.32161745429039\n","outputs:  tensor([[0.0208, 0.9714],\n","        [0.9810, 0.0249],\n","        [0.9763, 0.0311],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3506, loss 0.32161378860473633\n","outputs:  tensor([[0.0208, 0.9714],\n","        [0.9810, 0.0249],\n","        [0.9763, 0.0311],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3507, loss 0.32161012291908264\n","outputs:  tensor([[0.0208, 0.9714],\n","        [0.9810, 0.0249],\n","        [0.9763, 0.0311],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3508, loss 0.32160645723342896\n","outputs:  tensor([[0.0208, 0.9714],\n","        [0.9810, 0.0249],\n","        [0.9763, 0.0310],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3509, loss 0.3216027617454529\n","outputs:  tensor([[0.0208, 0.9714],\n","        [0.9810, 0.0248],\n","        [0.9763, 0.0310],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3510, loss 0.3215990662574768\n","outputs:  tensor([[0.0208, 0.9714],\n","        [0.9810, 0.0248],\n","        [0.9763, 0.0310],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3511, loss 0.3215954899787903\n","outputs:  tensor([[0.0208, 0.9714],\n","        [0.9810, 0.0248],\n","        [0.9763, 0.0310],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3512, loss 0.3215917944908142\n","outputs:  tensor([[0.0208, 0.9715],\n","        [0.9810, 0.0248],\n","        [0.9763, 0.0310],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3513, loss 0.3215881586074829\n","outputs:  tensor([[0.0207, 0.9715],\n","        [0.9810, 0.0248],\n","        [0.9763, 0.0310],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3514, loss 0.32158446311950684\n","outputs:  tensor([[0.0207, 0.9715],\n","        [0.9811, 0.0248],\n","        [0.9764, 0.0310],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3515, loss 0.3215808868408203\n","outputs:  tensor([[0.0207, 0.9715],\n","        [0.9811, 0.0248],\n","        [0.9764, 0.0310],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3516, loss 0.321577250957489\n","outputs:  tensor([[0.0207, 0.9715],\n","        [0.9811, 0.0248],\n","        [0.9764, 0.0309],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3517, loss 0.3215735852718353\n","outputs:  tensor([[0.0207, 0.9715],\n","        [0.9811, 0.0248],\n","        [0.9764, 0.0309],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3518, loss 0.32156988978385925\n","outputs:  tensor([[0.0207, 0.9715],\n","        [0.9811, 0.0247],\n","        [0.9764, 0.0309],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3519, loss 0.32156631350517273\n","outputs:  tensor([[0.0207, 0.9715],\n","        [0.9811, 0.0247],\n","        [0.9764, 0.0309],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3520, loss 0.32156264781951904\n","outputs:  tensor([[0.0207, 0.9716],\n","        [0.9811, 0.0247],\n","        [0.9764, 0.0309],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3521, loss 0.32155904173851013\n","outputs:  tensor([[0.0207, 0.9716],\n","        [0.9811, 0.0247],\n","        [0.9764, 0.0309],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3522, loss 0.32155540585517883\n","outputs:  tensor([[0.0207, 0.9716],\n","        [0.9811, 0.0247],\n","        [0.9764, 0.0309],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3216, grad_fn=<NllLossBackward>)\n","epoch 3523, loss 0.32155174016952515\n","outputs:  tensor([[0.0207, 0.9716],\n","        [0.9811, 0.0247],\n","        [0.9764, 0.0309],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3524, loss 0.32154813408851624\n","outputs:  tensor([[0.0207, 0.9716],\n","        [0.9811, 0.0247],\n","        [0.9764, 0.0308],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3525, loss 0.3215445578098297\n","outputs:  tensor([[0.0206, 0.9716],\n","        [0.9811, 0.0247],\n","        [0.9765, 0.0308],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3526, loss 0.321540892124176\n","outputs:  tensor([[0.0206, 0.9716],\n","        [0.9811, 0.0247],\n","        [0.9765, 0.0308],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3527, loss 0.3215372562408447\n","outputs:  tensor([[0.0206, 0.9717],\n","        [0.9812, 0.0246],\n","        [0.9765, 0.0308],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3528, loss 0.3215336799621582\n","outputs:  tensor([[0.0206, 0.9717],\n","        [0.9812, 0.0246],\n","        [0.9765, 0.0308],\n","        [0.9995, 0.0009],\n","        [0.0015, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3529, loss 0.3215300440788269\n","outputs:  tensor([[0.0206, 0.9717],\n","        [0.9812, 0.0246],\n","        [0.9765, 0.0308],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3530, loss 0.321526437997818\n","outputs:  tensor([[0.0206, 0.9717],\n","        [0.9812, 0.0246],\n","        [0.9765, 0.0308],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3531, loss 0.32152286171913147\n","outputs:  tensor([[0.0206, 0.9717],\n","        [0.9812, 0.0246],\n","        [0.9765, 0.0307],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3532, loss 0.32151922583580017\n","outputs:  tensor([[0.0206, 0.9717],\n","        [0.9812, 0.0246],\n","        [0.9765, 0.0307],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3533, loss 0.32151564955711365\n","outputs:  tensor([[0.0206, 0.9717],\n","        [0.9812, 0.0246],\n","        [0.9765, 0.0307],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3534, loss 0.3215120732784271\n","outputs:  tensor([[0.0206, 0.9717],\n","        [0.9812, 0.0246],\n","        [0.9765, 0.0307],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3535, loss 0.3215084671974182\n","outputs:  tensor([[0.0206, 0.9718],\n","        [0.9812, 0.0246],\n","        [0.9765, 0.0307],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3536, loss 0.3215048313140869\n","outputs:  tensor([[0.0206, 0.9718],\n","        [0.9812, 0.0246],\n","        [0.9766, 0.0307],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3537, loss 0.3215012550354004\n","outputs:  tensor([[0.0205, 0.9718],\n","        [0.9812, 0.0245],\n","        [0.9766, 0.0307],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3538, loss 0.32149773836135864\n","outputs:  tensor([[0.0205, 0.9718],\n","        [0.9812, 0.0245],\n","        [0.9766, 0.0307],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3539, loss 0.3214941620826721\n","outputs:  tensor([[0.0205, 0.9718],\n","        [0.9813, 0.0245],\n","        [0.9766, 0.0306],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3540, loss 0.3214905261993408\n","outputs:  tensor([[0.0205, 0.9718],\n","        [0.9813, 0.0245],\n","        [0.9766, 0.0306],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3541, loss 0.3214869499206543\n","outputs:  tensor([[0.0205, 0.9718],\n","        [0.9813, 0.0245],\n","        [0.9766, 0.0306],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3542, loss 0.3214833736419678\n","outputs:  tensor([[0.0205, 0.9718],\n","        [0.9813, 0.0245],\n","        [0.9766, 0.0306],\n","        [0.9995, 0.0009],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3543, loss 0.32147979736328125\n","outputs:  tensor([[0.0205, 0.9719],\n","        [0.9813, 0.0245],\n","        [0.9766, 0.0306],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3544, loss 0.3214762210845947\n","outputs:  tensor([[0.0205, 0.9719],\n","        [0.9813, 0.0245],\n","        [0.9766, 0.0306],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3545, loss 0.3214726448059082\n","outputs:  tensor([[0.0205, 0.9719],\n","        [0.9813, 0.0245],\n","        [0.9766, 0.0306],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3546, loss 0.32146912813186646\n","outputs:  tensor([[0.0205, 0.9719],\n","        [0.9813, 0.0244],\n","        [0.9766, 0.0306],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3547, loss 0.32146555185317993\n","outputs:  tensor([[0.0205, 0.9719],\n","        [0.9813, 0.0244],\n","        [0.9766, 0.0305],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3548, loss 0.3214620053768158\n","outputs:  tensor([[0.0205, 0.9719],\n","        [0.9813, 0.0244],\n","        [0.9767, 0.0305],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3549, loss 0.3214583992958069\n","outputs:  tensor([[0.0204, 0.9719],\n","        [0.9813, 0.0244],\n","        [0.9767, 0.0305],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3550, loss 0.3214549124240875\n","outputs:  tensor([[0.0204, 0.9719],\n","        [0.9813, 0.0244],\n","        [0.9767, 0.0305],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3215, grad_fn=<NllLossBackward>)\n","epoch 3551, loss 0.3214513063430786\n","Parameter containing:\n","tensor([[-0.3089, -0.7046,  0.1956],\n","        [-1.0895, -0.8814, -0.0757],\n","        [-1.1105, -1.0558, -0.1248],\n","        [-0.4899, -0.5368, -0.0018]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5278, -0.2335,  0.2217,  0.1490], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9198,  0.8262,  1.2242,  0.1748],\n","        [-0.2783, -1.0732, -0.9439, -0.6419]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3853, -0.6297], requires_grad=True)\n","outputs:  tensor([[0.0204, 0.9720],\n","        [0.9813, 0.0244],\n","        [0.9767, 0.0305],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3552, loss 0.3214477300643921\n","outputs:  tensor([[0.0204, 0.9720],\n","        [0.9813, 0.0244],\n","        [0.9767, 0.0305],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3553, loss 0.32144421339035034\n","outputs:  tensor([[0.0204, 0.9720],\n","        [0.9814, 0.0244],\n","        [0.9767, 0.0305],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3554, loss 0.3214406371116638\n","outputs:  tensor([[0.0204, 0.9720],\n","        [0.9814, 0.0244],\n","        [0.9767, 0.0305],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3555, loss 0.32143715023994446\n","outputs:  tensor([[0.0204, 0.9720],\n","        [0.9814, 0.0243],\n","        [0.9767, 0.0304],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3556, loss 0.3214336335659027\n","outputs:  tensor([[0.0204, 0.9720],\n","        [0.9814, 0.0243],\n","        [0.9767, 0.0304],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3557, loss 0.3214300870895386\n","outputs:  tensor([[0.0204, 0.9720],\n","        [0.9814, 0.0243],\n","        [0.9767, 0.0304],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3558, loss 0.3214265704154968\n","outputs:  tensor([[0.0204, 0.9720],\n","        [0.9814, 0.0243],\n","        [0.9767, 0.0304],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3559, loss 0.3214230239391327\n","outputs:  tensor([[0.0204, 0.9721],\n","        [0.9814, 0.0243],\n","        [0.9768, 0.0304],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3560, loss 0.32141950726509094\n","outputs:  tensor([[0.0204, 0.9721],\n","        [0.9814, 0.0243],\n","        [0.9768, 0.0304],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3561, loss 0.3214159607887268\n","outputs:  tensor([[0.0203, 0.9721],\n","        [0.9814, 0.0243],\n","        [0.9768, 0.0304],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3562, loss 0.32141247391700745\n","outputs:  tensor([[0.0203, 0.9721],\n","        [0.9814, 0.0243],\n","        [0.9768, 0.0304],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3563, loss 0.3214089274406433\n","outputs:  tensor([[0.0203, 0.9721],\n","        [0.9814, 0.0243],\n","        [0.9768, 0.0303],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3564, loss 0.32140541076660156\n","outputs:  tensor([[0.0203, 0.9721],\n","        [0.9814, 0.0242],\n","        [0.9768, 0.0303],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3565, loss 0.3214018940925598\n","outputs:  tensor([[0.0203, 0.9721],\n","        [0.9814, 0.0242],\n","        [0.9768, 0.0303],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9985]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3566, loss 0.32139840722084045\n","outputs:  tensor([[0.0203, 0.9721],\n","        [0.9815, 0.0242],\n","        [0.9768, 0.0303],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3567, loss 0.3213948607444763\n","outputs:  tensor([[0.0203, 0.9722],\n","        [0.9815, 0.0242],\n","        [0.9768, 0.0303],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3568, loss 0.32139140367507935\n","outputs:  tensor([[0.0203, 0.9722],\n","        [0.9815, 0.0242],\n","        [0.9768, 0.0303],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3569, loss 0.32138791680336\n","outputs:  tensor([[0.0203, 0.9722],\n","        [0.9815, 0.0242],\n","        [0.9768, 0.0303],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3570, loss 0.32138437032699585\n","outputs:  tensor([[0.0203, 0.9722],\n","        [0.9815, 0.0242],\n","        [0.9769, 0.0303],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3571, loss 0.3213808536529541\n","outputs:  tensor([[0.0203, 0.9722],\n","        [0.9815, 0.0242],\n","        [0.9769, 0.0302],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3572, loss 0.3213774263858795\n","outputs:  tensor([[0.0203, 0.9722],\n","        [0.9815, 0.0242],\n","        [0.9769, 0.0302],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3573, loss 0.3213738799095154\n","outputs:  tensor([[0.0203, 0.9722],\n","        [0.9815, 0.0242],\n","        [0.9769, 0.0302],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3574, loss 0.3213704228401184\n","outputs:  tensor([[0.0202, 0.9722],\n","        [0.9815, 0.0241],\n","        [0.9769, 0.0302],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3575, loss 0.32136693596839905\n","outputs:  tensor([[0.0202, 0.9723],\n","        [0.9815, 0.0241],\n","        [0.9769, 0.0302],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3576, loss 0.3213633894920349\n","outputs:  tensor([[0.0202, 0.9723],\n","        [0.9815, 0.0241],\n","        [0.9769, 0.0302],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3577, loss 0.3213600218296051\n","outputs:  tensor([[0.0202, 0.9723],\n","        [0.9815, 0.0241],\n","        [0.9769, 0.0302],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3578, loss 0.32135647535324097\n","outputs:  tensor([[0.0202, 0.9723],\n","        [0.9815, 0.0241],\n","        [0.9769, 0.0302],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3214, grad_fn=<NllLossBackward>)\n","epoch 3579, loss 0.321353018283844\n","outputs:  tensor([[0.0202, 0.9723],\n","        [0.9816, 0.0241],\n","        [0.9769, 0.0301],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3580, loss 0.32134953141212463\n","outputs:  tensor([[0.0202, 0.9723],\n","        [0.9816, 0.0241],\n","        [0.9769, 0.0301],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3581, loss 0.32134610414505005\n","outputs:  tensor([[0.0202, 0.9723],\n","        [0.9816, 0.0241],\n","        [0.9769, 0.0301],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3582, loss 0.3213425576686859\n","outputs:  tensor([[0.0202, 0.9723],\n","        [0.9816, 0.0241],\n","        [0.9770, 0.0301],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3583, loss 0.3213391602039337\n","outputs:  tensor([[0.0202, 0.9723],\n","        [0.9816, 0.0240],\n","        [0.9770, 0.0301],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3584, loss 0.32133567333221436\n","outputs:  tensor([[0.0202, 0.9724],\n","        [0.9816, 0.0240],\n","        [0.9770, 0.0301],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3585, loss 0.32133227586746216\n","outputs:  tensor([[0.0202, 0.9724],\n","        [0.9816, 0.0240],\n","        [0.9770, 0.0301],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3586, loss 0.3213287591934204\n","outputs:  tensor([[0.0201, 0.9724],\n","        [0.9816, 0.0240],\n","        [0.9770, 0.0301],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3587, loss 0.32132527232170105\n","outputs:  tensor([[0.0201, 0.9724],\n","        [0.9816, 0.0240],\n","        [0.9770, 0.0300],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3588, loss 0.32132184505462646\n","outputs:  tensor([[0.0201, 0.9724],\n","        [0.9816, 0.0240],\n","        [0.9770, 0.0300],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3589, loss 0.3213183283805847\n","outputs:  tensor([[0.0201, 0.9724],\n","        [0.9816, 0.0240],\n","        [0.9770, 0.0300],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3590, loss 0.3213149309158325\n","outputs:  tensor([[0.0201, 0.9724],\n","        [0.9816, 0.0240],\n","        [0.9770, 0.0300],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3591, loss 0.32131150364875793\n","outputs:  tensor([[0.0201, 0.9724],\n","        [0.9816, 0.0240],\n","        [0.9770, 0.0300],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3592, loss 0.32130807638168335\n","outputs:  tensor([[0.0201, 0.9725],\n","        [0.9817, 0.0240],\n","        [0.9770, 0.0300],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3593, loss 0.3213046193122864\n","outputs:  tensor([[0.0201, 0.9725],\n","        [0.9817, 0.0239],\n","        [0.9771, 0.0300],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3594, loss 0.3213012218475342\n","outputs:  tensor([[0.0201, 0.9725],\n","        [0.9817, 0.0239],\n","        [0.9771, 0.0300],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3595, loss 0.32129770517349243\n","outputs:  tensor([[0.0201, 0.9725],\n","        [0.9817, 0.0239],\n","        [0.9771, 0.0300],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3596, loss 0.32129430770874023\n","outputs:  tensor([[0.0201, 0.9725],\n","        [0.9817, 0.0239],\n","        [0.9771, 0.0299],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3597, loss 0.3212908208370209\n","outputs:  tensor([[0.0201, 0.9725],\n","        [0.9817, 0.0239],\n","        [0.9771, 0.0299],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3598, loss 0.32128745317459106\n","outputs:  tensor([[0.0201, 0.9725],\n","        [0.9817, 0.0239],\n","        [0.9771, 0.0299],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3599, loss 0.3212839961051941\n","outputs:  tensor([[0.0200, 0.9725],\n","        [0.9817, 0.0239],\n","        [0.9771, 0.0299],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3600, loss 0.3212805986404419\n","outputs:  tensor([[0.0200, 0.9726],\n","        [0.9817, 0.0239],\n","        [0.9771, 0.0299],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3601, loss 0.3212771713733673\n","Parameter containing:\n","tensor([[-0.3100, -0.7065,  0.1956],\n","        [-1.0914, -0.8847, -0.0757],\n","        [-1.1126, -1.0594, -0.1248],\n","        [-0.4908, -0.5383, -0.0017]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5285, -0.2323,  0.2231,  0.1495], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9214,  0.8282,  1.2268,  0.1761],\n","        [-0.2804, -1.0760, -0.9473, -0.6436]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3858, -0.6304], requires_grad=True)\n","outputs:  tensor([[0.0200, 0.9726],\n","        [0.9817, 0.0239],\n","        [0.9771, 0.0299],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3602, loss 0.3212737739086151\n","outputs:  tensor([[0.0200, 0.9726],\n","        [0.9817, 0.0238],\n","        [0.9771, 0.0299],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3603, loss 0.3212704062461853\n","outputs:  tensor([[0.0200, 0.9726],\n","        [0.9817, 0.0238],\n","        [0.9771, 0.0299],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3604, loss 0.32126694917678833\n","outputs:  tensor([[0.0200, 0.9726],\n","        [0.9817, 0.0238],\n","        [0.9771, 0.0298],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3605, loss 0.32126355171203613\n","outputs:  tensor([[0.0200, 0.9726],\n","        [0.9817, 0.0238],\n","        [0.9772, 0.0298],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3606, loss 0.32126012444496155\n","outputs:  tensor([[0.0200, 0.9726],\n","        [0.9818, 0.0238],\n","        [0.9772, 0.0298],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3607, loss 0.32125672698020935\n","outputs:  tensor([[0.0200, 0.9726],\n","        [0.9818, 0.0238],\n","        [0.9772, 0.0298],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3213, grad_fn=<NllLossBackward>)\n","epoch 3608, loss 0.32125329971313477\n","outputs:  tensor([[0.0200, 0.9726],\n","        [0.9818, 0.0238],\n","        [0.9772, 0.0298],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3609, loss 0.32124996185302734\n","outputs:  tensor([[0.0200, 0.9727],\n","        [0.9818, 0.0238],\n","        [0.9772, 0.0298],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3610, loss 0.321246474981308\n","outputs:  tensor([[0.0200, 0.9727],\n","        [0.9818, 0.0238],\n","        [0.9772, 0.0298],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3611, loss 0.32124313712120056\n","outputs:  tensor([[0.0199, 0.9727],\n","        [0.9818, 0.0238],\n","        [0.9772, 0.0298],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3612, loss 0.321239709854126\n","outputs:  tensor([[0.0199, 0.9727],\n","        [0.9818, 0.0237],\n","        [0.9772, 0.0297],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3613, loss 0.3212363123893738\n","outputs:  tensor([[0.0199, 0.9727],\n","        [0.9818, 0.0237],\n","        [0.9772, 0.0297],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3614, loss 0.32123297452926636\n","outputs:  tensor([[0.0199, 0.9727],\n","        [0.9818, 0.0237],\n","        [0.9772, 0.0297],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3615, loss 0.32122960686683655\n","outputs:  tensor([[0.0199, 0.9727],\n","        [0.9818, 0.0237],\n","        [0.9772, 0.0297],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3616, loss 0.32122620940208435\n","outputs:  tensor([[0.0199, 0.9727],\n","        [0.9818, 0.0237],\n","        [0.9773, 0.0297],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3617, loss 0.32122284173965454\n","outputs:  tensor([[0.0199, 0.9728],\n","        [0.9818, 0.0237],\n","        [0.9773, 0.0297],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3618, loss 0.32121944427490234\n","outputs:  tensor([[0.0199, 0.9728],\n","        [0.9818, 0.0237],\n","        [0.9773, 0.0297],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3619, loss 0.32121601700782776\n","outputs:  tensor([[0.0199, 0.9728],\n","        [0.9818, 0.0237],\n","        [0.9773, 0.0297],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3620, loss 0.32121267914772034\n","outputs:  tensor([[0.0199, 0.9728],\n","        [0.9819, 0.0237],\n","        [0.9773, 0.0296],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3621, loss 0.3212093412876129\n","outputs:  tensor([[0.0199, 0.9728],\n","        [0.9819, 0.0237],\n","        [0.9773, 0.0296],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3622, loss 0.3212059438228607\n","outputs:  tensor([[0.0199, 0.9728],\n","        [0.9819, 0.0236],\n","        [0.9773, 0.0296],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3623, loss 0.3212025761604309\n","outputs:  tensor([[0.0199, 0.9728],\n","        [0.9819, 0.0236],\n","        [0.9773, 0.0296],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3624, loss 0.3211992383003235\n","outputs:  tensor([[0.0198, 0.9728],\n","        [0.9819, 0.0236],\n","        [0.9773, 0.0296],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3625, loss 0.3211958408355713\n","outputs:  tensor([[0.0198, 0.9729],\n","        [0.9819, 0.0236],\n","        [0.9773, 0.0296],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3626, loss 0.32119253277778625\n","outputs:  tensor([[0.0198, 0.9729],\n","        [0.9819, 0.0236],\n","        [0.9773, 0.0296],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3627, loss 0.32118919491767883\n","outputs:  tensor([[0.0198, 0.9729],\n","        [0.9819, 0.0236],\n","        [0.9773, 0.0296],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3628, loss 0.3211858570575714\n","outputs:  tensor([[0.0198, 0.9729],\n","        [0.9819, 0.0236],\n","        [0.9774, 0.0296],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3629, loss 0.3211824297904968\n","outputs:  tensor([[0.0198, 0.9729],\n","        [0.9819, 0.0236],\n","        [0.9774, 0.0295],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3630, loss 0.32117918133735657\n","outputs:  tensor([[0.0198, 0.9729],\n","        [0.9819, 0.0236],\n","        [0.9774, 0.0295],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3631, loss 0.32117581367492676\n","outputs:  tensor([[0.0198, 0.9729],\n","        [0.9819, 0.0236],\n","        [0.9774, 0.0295],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3632, loss 0.32117244601249695\n","outputs:  tensor([[0.0198, 0.9729],\n","        [0.9819, 0.0235],\n","        [0.9774, 0.0295],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3633, loss 0.3211691081523895\n","outputs:  tensor([[0.0198, 0.9729],\n","        [0.9820, 0.0235],\n","        [0.9774, 0.0295],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3634, loss 0.3211657404899597\n","outputs:  tensor([[0.0198, 0.9730],\n","        [0.9820, 0.0235],\n","        [0.9774, 0.0295],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3635, loss 0.3211624026298523\n","outputs:  tensor([[0.0198, 0.9730],\n","        [0.9820, 0.0235],\n","        [0.9774, 0.0295],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3636, loss 0.32115912437438965\n","outputs:  tensor([[0.0198, 0.9730],\n","        [0.9820, 0.0235],\n","        [0.9774, 0.0295],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3637, loss 0.32115575671195984\n","outputs:  tensor([[0.0197, 0.9730],\n","        [0.9820, 0.0235],\n","        [0.9774, 0.0294],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3212, grad_fn=<NllLossBackward>)\n","epoch 3638, loss 0.32115238904953003\n","outputs:  tensor([[0.0197, 0.9730],\n","        [0.9820, 0.0235],\n","        [0.9774, 0.0294],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3639, loss 0.32114917039871216\n","outputs:  tensor([[0.0197, 0.9730],\n","        [0.9820, 0.0235],\n","        [0.9774, 0.0294],\n","        [0.9995, 0.0008],\n","        [0.0014, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3640, loss 0.32114580273628235\n","outputs:  tensor([[0.0197, 0.9730],\n","        [0.9820, 0.0235],\n","        [0.9775, 0.0294],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3641, loss 0.3211424946784973\n","outputs:  tensor([[0.0197, 0.9730],\n","        [0.9820, 0.0234],\n","        [0.9775, 0.0294],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3642, loss 0.3211391568183899\n","outputs:  tensor([[0.0197, 0.9731],\n","        [0.9820, 0.0234],\n","        [0.9775, 0.0294],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3643, loss 0.32113581895828247\n","outputs:  tensor([[0.0197, 0.9731],\n","        [0.9820, 0.0234],\n","        [0.9775, 0.0294],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3644, loss 0.3211325407028198\n","outputs:  tensor([[0.0197, 0.9731],\n","        [0.9820, 0.0234],\n","        [0.9775, 0.0294],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3645, loss 0.3211292028427124\n","outputs:  tensor([[0.0197, 0.9731],\n","        [0.9820, 0.0234],\n","        [0.9775, 0.0294],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3646, loss 0.32112589478492737\n","outputs:  tensor([[0.0197, 0.9731],\n","        [0.9820, 0.0234],\n","        [0.9775, 0.0293],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3647, loss 0.32112258672714233\n","outputs:  tensor([[0.0197, 0.9731],\n","        [0.9821, 0.0234],\n","        [0.9775, 0.0293],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3648, loss 0.3211193084716797\n","outputs:  tensor([[0.0197, 0.9731],\n","        [0.9821, 0.0234],\n","        [0.9775, 0.0293],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3649, loss 0.32111603021621704\n","outputs:  tensor([[0.0197, 0.9731],\n","        [0.9821, 0.0234],\n","        [0.9775, 0.0293],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3650, loss 0.321112722158432\n","outputs:  tensor([[0.0196, 0.9731],\n","        [0.9821, 0.0234],\n","        [0.9775, 0.0293],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3651, loss 0.3211093842983246\n","Parameter containing:\n","tensor([[-0.3111, -0.7084,  0.1956],\n","        [-1.0932, -0.8879, -0.0757],\n","        [-1.1146, -1.0630, -0.1248],\n","        [-0.4916, -0.5398, -0.0017]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5292, -0.2311,  0.2244,  0.1501], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9229,  0.8303,  1.2294,  0.1773],\n","        [-0.2825, -1.0787, -0.9507, -0.6453]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3864, -0.6311], requires_grad=True)\n","outputs:  tensor([[0.0196, 0.9732],\n","        [0.9821, 0.0233],\n","        [0.9775, 0.0293],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3652, loss 0.3211061358451843\n","outputs:  tensor([[0.0196, 0.9732],\n","        [0.9821, 0.0233],\n","        [0.9776, 0.0293],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3653, loss 0.3211028575897217\n","outputs:  tensor([[0.0196, 0.9732],\n","        [0.9821, 0.0233],\n","        [0.9776, 0.0293],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3654, loss 0.32109951972961426\n","outputs:  tensor([[0.0196, 0.9732],\n","        [0.9821, 0.0233],\n","        [0.9776, 0.0292],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3655, loss 0.3210962414741516\n","outputs:  tensor([[0.0196, 0.9732],\n","        [0.9821, 0.0233],\n","        [0.9776, 0.0292],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3656, loss 0.32109299302101135\n","outputs:  tensor([[0.0196, 0.9732],\n","        [0.9821, 0.0233],\n","        [0.9776, 0.0292],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3657, loss 0.3210896849632263\n","outputs:  tensor([[0.0196, 0.9732],\n","        [0.9821, 0.0233],\n","        [0.9776, 0.0292],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3658, loss 0.32108640670776367\n","outputs:  tensor([[0.0196, 0.9732],\n","        [0.9821, 0.0233],\n","        [0.9776, 0.0292],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3659, loss 0.3210831582546234\n","outputs:  tensor([[0.0196, 0.9732],\n","        [0.9821, 0.0233],\n","        [0.9776, 0.0292],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3660, loss 0.32107987999916077\n","outputs:  tensor([[0.0196, 0.9733],\n","        [0.9821, 0.0233],\n","        [0.9776, 0.0292],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3661, loss 0.32107657194137573\n","outputs:  tensor([[0.0196, 0.9733],\n","        [0.9822, 0.0232],\n","        [0.9776, 0.0292],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3662, loss 0.32107335329055786\n","outputs:  tensor([[0.0196, 0.9733],\n","        [0.9822, 0.0232],\n","        [0.9776, 0.0292],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3663, loss 0.3210700452327728\n","outputs:  tensor([[0.0195, 0.9733],\n","        [0.9822, 0.0232],\n","        [0.9776, 0.0291],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3664, loss 0.32106679677963257\n","outputs:  tensor([[0.0195, 0.9733],\n","        [0.9822, 0.0232],\n","        [0.9777, 0.0291],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3665, loss 0.3210635185241699\n","outputs:  tensor([[0.0195, 0.9733],\n","        [0.9822, 0.0232],\n","        [0.9777, 0.0291],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9986]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3666, loss 0.32106027007102966\n","outputs:  tensor([[0.0195, 0.9733],\n","        [0.9822, 0.0232],\n","        [0.9777, 0.0291],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3667, loss 0.3210570812225342\n","outputs:  tensor([[0.0195, 0.9733],\n","        [0.9822, 0.0232],\n","        [0.9777, 0.0291],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3668, loss 0.32105380296707153\n","outputs:  tensor([[0.0195, 0.9734],\n","        [0.9822, 0.0232],\n","        [0.9777, 0.0291],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3211, grad_fn=<NllLossBackward>)\n","epoch 3669, loss 0.3210505247116089\n","outputs:  tensor([[0.0195, 0.9734],\n","        [0.9822, 0.0232],\n","        [0.9777, 0.0291],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3670, loss 0.32104724645614624\n","outputs:  tensor([[0.0195, 0.9734],\n","        [0.9822, 0.0232],\n","        [0.9777, 0.0291],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3671, loss 0.32104402780532837\n","outputs:  tensor([[0.0195, 0.9734],\n","        [0.9822, 0.0231],\n","        [0.9777, 0.0290],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3672, loss 0.3210408091545105\n","outputs:  tensor([[0.0195, 0.9734],\n","        [0.9822, 0.0231],\n","        [0.9777, 0.0290],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3673, loss 0.32103750109672546\n","outputs:  tensor([[0.0195, 0.9734],\n","        [0.9822, 0.0231],\n","        [0.9777, 0.0290],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3674, loss 0.3210342526435852\n","outputs:  tensor([[0.0195, 0.9734],\n","        [0.9822, 0.0231],\n","        [0.9777, 0.0290],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3675, loss 0.32103103399276733\n","outputs:  tensor([[0.0195, 0.9734],\n","        [0.9822, 0.0231],\n","        [0.9777, 0.0290],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3676, loss 0.3210277855396271\n","outputs:  tensor([[0.0194, 0.9734],\n","        [0.9823, 0.0231],\n","        [0.9778, 0.0290],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3677, loss 0.3210245966911316\n","outputs:  tensor([[0.0194, 0.9735],\n","        [0.9823, 0.0231],\n","        [0.9778, 0.0290],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3678, loss 0.32102134823799133\n","outputs:  tensor([[0.0194, 0.9735],\n","        [0.9823, 0.0231],\n","        [0.9778, 0.0290],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3679, loss 0.32101815938949585\n","outputs:  tensor([[0.0194, 0.9735],\n","        [0.9823, 0.0231],\n","        [0.9778, 0.0290],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3680, loss 0.3210149109363556\n","outputs:  tensor([[0.0194, 0.9735],\n","        [0.9823, 0.0231],\n","        [0.9778, 0.0289],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3681, loss 0.32101166248321533\n","outputs:  tensor([[0.0194, 0.9735],\n","        [0.9823, 0.0231],\n","        [0.9778, 0.0289],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3682, loss 0.32100844383239746\n","outputs:  tensor([[0.0194, 0.9735],\n","        [0.9823, 0.0230],\n","        [0.9778, 0.0289],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3683, loss 0.321005254983902\n","outputs:  tensor([[0.0194, 0.9735],\n","        [0.9823, 0.0230],\n","        [0.9778, 0.0289],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3684, loss 0.32100197672843933\n","outputs:  tensor([[0.0194, 0.9735],\n","        [0.9823, 0.0230],\n","        [0.9778, 0.0289],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3685, loss 0.3209988474845886\n","outputs:  tensor([[0.0194, 0.9735],\n","        [0.9823, 0.0230],\n","        [0.9778, 0.0289],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3686, loss 0.32099562883377075\n","outputs:  tensor([[0.0194, 0.9736],\n","        [0.9823, 0.0230],\n","        [0.9778, 0.0289],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3687, loss 0.3209924101829529\n","outputs:  tensor([[0.0194, 0.9736],\n","        [0.9823, 0.0230],\n","        [0.9778, 0.0289],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3688, loss 0.320989191532135\n","outputs:  tensor([[0.0194, 0.9736],\n","        [0.9823, 0.0230],\n","        [0.9779, 0.0289],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3689, loss 0.32098597288131714\n","outputs:  tensor([[0.0193, 0.9736],\n","        [0.9823, 0.0230],\n","        [0.9779, 0.0288],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3690, loss 0.32098278403282166\n","outputs:  tensor([[0.0193, 0.9736],\n","        [0.9824, 0.0230],\n","        [0.9779, 0.0288],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3691, loss 0.3209795653820038\n","outputs:  tensor([[0.0193, 0.9736],\n","        [0.9824, 0.0230],\n","        [0.9779, 0.0288],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3692, loss 0.3209763765335083\n","outputs:  tensor([[0.0193, 0.9736],\n","        [0.9824, 0.0229],\n","        [0.9779, 0.0288],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3693, loss 0.32097315788269043\n","outputs:  tensor([[0.0193, 0.9736],\n","        [0.9824, 0.0229],\n","        [0.9779, 0.0288],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3694, loss 0.32096996903419495\n","outputs:  tensor([[0.0193, 0.9736],\n","        [0.9824, 0.0229],\n","        [0.9779, 0.0288],\n","        [0.9995, 0.0008],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3695, loss 0.32096678018569946\n","outputs:  tensor([[0.0193, 0.9737],\n","        [0.9824, 0.0229],\n","        [0.9779, 0.0288],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3696, loss 0.32096362113952637\n","outputs:  tensor([[0.0193, 0.9737],\n","        [0.9824, 0.0229],\n","        [0.9779, 0.0288],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3697, loss 0.3209603726863861\n","outputs:  tensor([[0.0193, 0.9737],\n","        [0.9824, 0.0229],\n","        [0.9779, 0.0288],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3698, loss 0.3209572732448578\n","outputs:  tensor([[0.0193, 0.9737],\n","        [0.9824, 0.0229],\n","        [0.9779, 0.0287],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3699, loss 0.3209540843963623\n","outputs:  tensor([[0.0193, 0.9737],\n","        [0.9824, 0.0229],\n","        [0.9779, 0.0287],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3210, grad_fn=<NllLossBackward>)\n","epoch 3700, loss 0.32095083594322205\n","outputs:  tensor([[0.0193, 0.9737],\n","        [0.9824, 0.0229],\n","        [0.9779, 0.0287],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3701, loss 0.32094770669937134\n","Parameter containing:\n","tensor([[-0.3121, -0.7102,  0.1956],\n","        [-1.0951, -0.8911, -0.0756],\n","        [-1.1166, -1.0665, -0.1248],\n","        [-0.4924, -0.5413, -0.0017]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5299, -0.2299,  0.2257,  0.1506], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9245,  0.8323,  1.2319,  0.1786],\n","        [-0.2845, -1.0814, -0.9540, -0.6469]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3869, -0.6317], requires_grad=True)\n","outputs:  tensor([[0.0193, 0.9737],\n","        [0.9824, 0.0229],\n","        [0.9780, 0.0287],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3702, loss 0.32094448804855347\n","outputs:  tensor([[0.0192, 0.9737],\n","        [0.9824, 0.0228],\n","        [0.9780, 0.0287],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3703, loss 0.32094135880470276\n","outputs:  tensor([[0.0192, 0.9737],\n","        [0.9824, 0.0228],\n","        [0.9780, 0.0287],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3704, loss 0.3209381699562073\n","outputs:  tensor([[0.0192, 0.9738],\n","        [0.9825, 0.0228],\n","        [0.9780, 0.0287],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3705, loss 0.3209350109100342\n","outputs:  tensor([[0.0192, 0.9738],\n","        [0.9825, 0.0228],\n","        [0.9780, 0.0287],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3706, loss 0.3209318518638611\n","outputs:  tensor([[0.0192, 0.9738],\n","        [0.9825, 0.0228],\n","        [0.9780, 0.0286],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3707, loss 0.3209287226200104\n","outputs:  tensor([[0.0192, 0.9738],\n","        [0.9825, 0.0228],\n","        [0.9780, 0.0286],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3708, loss 0.3209255337715149\n","outputs:  tensor([[0.0192, 0.9738],\n","        [0.9825, 0.0228],\n","        [0.9780, 0.0286],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3709, loss 0.320922315120697\n","outputs:  tensor([[0.0192, 0.9738],\n","        [0.9825, 0.0228],\n","        [0.9780, 0.0286],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3710, loss 0.3209192156791687\n","outputs:  tensor([[0.0192, 0.9738],\n","        [0.9825, 0.0228],\n","        [0.9780, 0.0286],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3711, loss 0.3209160268306732\n","outputs:  tensor([[0.0192, 0.9738],\n","        [0.9825, 0.0228],\n","        [0.9780, 0.0286],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3712, loss 0.3209128975868225\n","outputs:  tensor([[0.0192, 0.9738],\n","        [0.9825, 0.0228],\n","        [0.9780, 0.0286],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3713, loss 0.3209097385406494\n","outputs:  tensor([[0.0192, 0.9739],\n","        [0.9825, 0.0227],\n","        [0.9781, 0.0286],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3714, loss 0.3209065794944763\n","outputs:  tensor([[0.0192, 0.9739],\n","        [0.9825, 0.0227],\n","        [0.9781, 0.0286],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3715, loss 0.3209034502506256\n","outputs:  tensor([[0.0192, 0.9739],\n","        [0.9825, 0.0227],\n","        [0.9781, 0.0285],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3716, loss 0.3209003508090973\n","outputs:  tensor([[0.0191, 0.9739],\n","        [0.9825, 0.0227],\n","        [0.9781, 0.0285],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3717, loss 0.3208971619606018\n","outputs:  tensor([[0.0191, 0.9739],\n","        [0.9825, 0.0227],\n","        [0.9781, 0.0285],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3718, loss 0.3208940327167511\n","outputs:  tensor([[0.0191, 0.9739],\n","        [0.9825, 0.0227],\n","        [0.9781, 0.0285],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3719, loss 0.3208909332752228\n","outputs:  tensor([[0.0191, 0.9739],\n","        [0.9826, 0.0227],\n","        [0.9781, 0.0285],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3720, loss 0.3208877444267273\n","outputs:  tensor([[0.0191, 0.9739],\n","        [0.9826, 0.0227],\n","        [0.9781, 0.0285],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3721, loss 0.320884644985199\n","outputs:  tensor([[0.0191, 0.9739],\n","        [0.9826, 0.0227],\n","        [0.9781, 0.0285],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3722, loss 0.3208814859390259\n","outputs:  tensor([[0.0191, 0.9740],\n","        [0.9826, 0.0227],\n","        [0.9781, 0.0285],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3723, loss 0.32087838649749756\n","outputs:  tensor([[0.0191, 0.9740],\n","        [0.9826, 0.0226],\n","        [0.9781, 0.0285],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3724, loss 0.32087528705596924\n","outputs:  tensor([[0.0191, 0.9740],\n","        [0.9826, 0.0226],\n","        [0.9781, 0.0284],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3725, loss 0.32087212800979614\n","outputs:  tensor([[0.0191, 0.9740],\n","        [0.9826, 0.0226],\n","        [0.9781, 0.0284],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3726, loss 0.3208690285682678\n","outputs:  tensor([[0.0191, 0.9740],\n","        [0.9826, 0.0226],\n","        [0.9782, 0.0284],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3727, loss 0.3208658695220947\n","outputs:  tensor([[0.0191, 0.9740],\n","        [0.9826, 0.0226],\n","        [0.9782, 0.0284],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3728, loss 0.3208627700805664\n","outputs:  tensor([[0.0191, 0.9740],\n","        [0.9826, 0.0226],\n","        [0.9782, 0.0284],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3729, loss 0.3208596706390381\n","outputs:  tensor([[0.0191, 0.9740],\n","        [0.9826, 0.0226],\n","        [0.9782, 0.0284],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3730, loss 0.320856511592865\n","outputs:  tensor([[0.0190, 0.9740],\n","        [0.9826, 0.0226],\n","        [0.9782, 0.0284],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3731, loss 0.32085341215133667\n","outputs:  tensor([[0.0190, 0.9741],\n","        [0.9826, 0.0226],\n","        [0.9782, 0.0284],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3209, grad_fn=<NllLossBackward>)\n","epoch 3732, loss 0.32085034251213074\n","outputs:  tensor([[0.0190, 0.9741],\n","        [0.9826, 0.0226],\n","        [0.9782, 0.0284],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3733, loss 0.32084721326828003\n","outputs:  tensor([[0.0190, 0.9741],\n","        [0.9826, 0.0226],\n","        [0.9782, 0.0283],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3734, loss 0.3208441138267517\n","outputs:  tensor([[0.0190, 0.9741],\n","        [0.9827, 0.0225],\n","        [0.9782, 0.0283],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3735, loss 0.320840984582901\n","outputs:  tensor([[0.0190, 0.9741],\n","        [0.9827, 0.0225],\n","        [0.9782, 0.0283],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3736, loss 0.32083794474601746\n","outputs:  tensor([[0.0190, 0.9741],\n","        [0.9827, 0.0225],\n","        [0.9782, 0.0283],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3737, loss 0.32083481550216675\n","outputs:  tensor([[0.0190, 0.9741],\n","        [0.9827, 0.0225],\n","        [0.9782, 0.0283],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3738, loss 0.3208317756652832\n","outputs:  tensor([[0.0190, 0.9741],\n","        [0.9827, 0.0225],\n","        [0.9783, 0.0283],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3739, loss 0.3208286464214325\n","outputs:  tensor([[0.0190, 0.9741],\n","        [0.9827, 0.0225],\n","        [0.9783, 0.0283],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3740, loss 0.32082557678222656\n","outputs:  tensor([[0.0190, 0.9742],\n","        [0.9827, 0.0225],\n","        [0.9783, 0.0283],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3741, loss 0.32082247734069824\n","outputs:  tensor([[0.0190, 0.9742],\n","        [0.9827, 0.0225],\n","        [0.9783, 0.0283],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3742, loss 0.3208193778991699\n","outputs:  tensor([[0.0190, 0.9742],\n","        [0.9827, 0.0225],\n","        [0.9783, 0.0282],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3743, loss 0.3208163380622864\n","outputs:  tensor([[0.0189, 0.9742],\n","        [0.9827, 0.0225],\n","        [0.9783, 0.0282],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3744, loss 0.32081323862075806\n","outputs:  tensor([[0.0189, 0.9742],\n","        [0.9827, 0.0224],\n","        [0.9783, 0.0282],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3745, loss 0.32081013917922974\n","outputs:  tensor([[0.0189, 0.9742],\n","        [0.9827, 0.0224],\n","        [0.9783, 0.0282],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3746, loss 0.3208070695400238\n","outputs:  tensor([[0.0189, 0.9742],\n","        [0.9827, 0.0224],\n","        [0.9783, 0.0282],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3747, loss 0.3208039700984955\n","outputs:  tensor([[0.0189, 0.9742],\n","        [0.9827, 0.0224],\n","        [0.9783, 0.0282],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3748, loss 0.32080093026161194\n","outputs:  tensor([[0.0189, 0.9742],\n","        [0.9827, 0.0224],\n","        [0.9783, 0.0282],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3749, loss 0.320797860622406\n","outputs:  tensor([[0.0189, 0.9742],\n","        [0.9828, 0.0224],\n","        [0.9783, 0.0282],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3750, loss 0.3207947611808777\n","outputs:  tensor([[0.0189, 0.9743],\n","        [0.9828, 0.0224],\n","        [0.9783, 0.0282],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3751, loss 0.3207917809486389\n","Parameter containing:\n","tensor([[-0.3132, -0.7120,  0.1955],\n","        [-1.0968, -0.8942, -0.0756],\n","        [-1.1186, -1.0700, -0.1248],\n","        [-0.4933, -0.5427, -0.0017]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5306, -0.2287,  0.2270,  0.1511], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9260,  0.8343,  1.2344,  0.1798],\n","        [-0.2865, -1.0840, -0.9572, -0.6485]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3875, -0.6324], requires_grad=True)\n","outputs:  tensor([[0.0189, 0.9743],\n","        [0.9828, 0.0224],\n","        [0.9784, 0.0281],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3752, loss 0.3207886815071106\n","outputs:  tensor([[0.0189, 0.9743],\n","        [0.9828, 0.0224],\n","        [0.9784, 0.0281],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3753, loss 0.32078561186790466\n","outputs:  tensor([[0.0189, 0.9743],\n","        [0.9828, 0.0224],\n","        [0.9784, 0.0281],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3754, loss 0.32078251242637634\n","outputs:  tensor([[0.0189, 0.9743],\n","        [0.9828, 0.0224],\n","        [0.9784, 0.0281],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3755, loss 0.3207794725894928\n","outputs:  tensor([[0.0189, 0.9743],\n","        [0.9828, 0.0223],\n","        [0.9784, 0.0281],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3756, loss 0.32077640295028687\n","outputs:  tensor([[0.0189, 0.9743],\n","        [0.9828, 0.0223],\n","        [0.9784, 0.0281],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3757, loss 0.3207733631134033\n","outputs:  tensor([[0.0188, 0.9743],\n","        [0.9828, 0.0223],\n","        [0.9784, 0.0281],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3758, loss 0.3207703232765198\n","outputs:  tensor([[0.0188, 0.9743],\n","        [0.9828, 0.0223],\n","        [0.9784, 0.0281],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3759, loss 0.32076725363731384\n","outputs:  tensor([[0.0188, 0.9744],\n","        [0.9828, 0.0223],\n","        [0.9784, 0.0281],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3760, loss 0.3207642138004303\n","outputs:  tensor([[0.0188, 0.9744],\n","        [0.9828, 0.0223],\n","        [0.9784, 0.0281],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3761, loss 0.32076114416122437\n","outputs:  tensor([[0.0188, 0.9744],\n","        [0.9828, 0.0223],\n","        [0.9784, 0.0280],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3762, loss 0.3207581043243408\n","outputs:  tensor([[0.0188, 0.9744],\n","        [0.9828, 0.0223],\n","        [0.9784, 0.0280],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3763, loss 0.32075509428977966\n","outputs:  tensor([[0.0188, 0.9744],\n","        [0.9828, 0.0223],\n","        [0.9784, 0.0280],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3208, grad_fn=<NllLossBackward>)\n","epoch 3764, loss 0.3207520842552185\n","outputs:  tensor([[0.0188, 0.9744],\n","        [0.9829, 0.0223],\n","        [0.9785, 0.0280],\n","        [0.9996, 0.0007],\n","        [0.0013, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3765, loss 0.32074904441833496\n","outputs:  tensor([[0.0188, 0.9744],\n","        [0.9829, 0.0223],\n","        [0.9785, 0.0280],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3766, loss 0.32074594497680664\n","outputs:  tensor([[0.0188, 0.9744],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0280],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3767, loss 0.32074302434921265\n","outputs:  tensor([[0.0188, 0.9744],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0280],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3768, loss 0.3207399249076843\n","outputs:  tensor([[0.0188, 0.9745],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0280],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3769, loss 0.3207368850708008\n","outputs:  tensor([[0.0188, 0.9745],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0280],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3770, loss 0.3207339346408844\n","outputs:  tensor([[0.0188, 0.9745],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0279],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3771, loss 0.32073086500167847\n","outputs:  tensor([[0.0187, 0.9745],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0279],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3772, loss 0.3207278251647949\n","outputs:  tensor([[0.0187, 0.9745],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0279],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3773, loss 0.32072481513023376\n","outputs:  tensor([[0.0187, 0.9745],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0279],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3774, loss 0.320721834897995\n","outputs:  tensor([[0.0187, 0.9745],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0279],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3775, loss 0.3207188546657562\n","outputs:  tensor([[0.0187, 0.9745],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0279],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3776, loss 0.3207158148288727\n","outputs:  tensor([[0.0187, 0.9745],\n","        [0.9829, 0.0222],\n","        [0.9785, 0.0279],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9987]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3777, loss 0.3207128047943115\n","outputs:  tensor([[0.0187, 0.9745],\n","        [0.9829, 0.0221],\n","        [0.9786, 0.0279],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3778, loss 0.32070979475975037\n","outputs:  tensor([[0.0187, 0.9746],\n","        [0.9829, 0.0221],\n","        [0.9786, 0.0279],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3779, loss 0.3207067847251892\n","outputs:  tensor([[0.0187, 0.9746],\n","        [0.9830, 0.0221],\n","        [0.9786, 0.0278],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3780, loss 0.32070380449295044\n","outputs:  tensor([[0.0187, 0.9746],\n","        [0.9830, 0.0221],\n","        [0.9786, 0.0278],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3781, loss 0.3207007944583893\n","outputs:  tensor([[0.0187, 0.9746],\n","        [0.9830, 0.0221],\n","        [0.9786, 0.0278],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3782, loss 0.32069775462150574\n","outputs:  tensor([[0.0187, 0.9746],\n","        [0.9830, 0.0221],\n","        [0.9786, 0.0278],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3783, loss 0.32069480419158936\n","outputs:  tensor([[0.0187, 0.9746],\n","        [0.9830, 0.0221],\n","        [0.9786, 0.0278],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3784, loss 0.320691853761673\n","outputs:  tensor([[0.0187, 0.9746],\n","        [0.9830, 0.0221],\n","        [0.9786, 0.0278],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3785, loss 0.32068878412246704\n","outputs:  tensor([[0.0187, 0.9746],\n","        [0.9830, 0.0221],\n","        [0.9786, 0.0278],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3786, loss 0.32068586349487305\n","outputs:  tensor([[0.0186, 0.9746],\n","        [0.9830, 0.0221],\n","        [0.9786, 0.0278],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3787, loss 0.3206828236579895\n","outputs:  tensor([[0.0186, 0.9747],\n","        [0.9830, 0.0220],\n","        [0.9786, 0.0278],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3788, loss 0.32067984342575073\n","outputs:  tensor([[0.0186, 0.9747],\n","        [0.9830, 0.0220],\n","        [0.9786, 0.0277],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3789, loss 0.3206768035888672\n","outputs:  tensor([[0.0186, 0.9747],\n","        [0.9830, 0.0220],\n","        [0.9786, 0.0277],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3790, loss 0.3206738829612732\n","outputs:  tensor([[0.0186, 0.9747],\n","        [0.9830, 0.0220],\n","        [0.9787, 0.0277],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3791, loss 0.32067087292671204\n","outputs:  tensor([[0.0186, 0.9747],\n","        [0.9830, 0.0220],\n","        [0.9787, 0.0277],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3792, loss 0.32066789269447327\n","outputs:  tensor([[0.0186, 0.9747],\n","        [0.9830, 0.0220],\n","        [0.9787, 0.0277],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3793, loss 0.3206649422645569\n","outputs:  tensor([[0.0186, 0.9747],\n","        [0.9830, 0.0220],\n","        [0.9787, 0.0277],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3794, loss 0.3206619620323181\n","outputs:  tensor([[0.0186, 0.9747],\n","        [0.9830, 0.0220],\n","        [0.9787, 0.0277],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3795, loss 0.32065901160240173\n","outputs:  tensor([[0.0186, 0.9747],\n","        [0.9831, 0.0220],\n","        [0.9787, 0.0277],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3796, loss 0.3206560015678406\n","outputs:  tensor([[0.0186, 0.9747],\n","        [0.9831, 0.0220],\n","        [0.9787, 0.0277],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3797, loss 0.3206530511379242\n","outputs:  tensor([[0.0186, 0.9748],\n","        [0.9831, 0.0220],\n","        [0.9787, 0.0277],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3207, grad_fn=<NllLossBackward>)\n","epoch 3798, loss 0.3206501305103302\n","outputs:  tensor([[0.0186, 0.9748],\n","        [0.9831, 0.0220],\n","        [0.9787, 0.0276],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3799, loss 0.32064715027809143\n","outputs:  tensor([[0.0186, 0.9748],\n","        [0.9831, 0.0219],\n","        [0.9787, 0.0276],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3800, loss 0.32064419984817505\n","outputs:  tensor([[0.0185, 0.9748],\n","        [0.9831, 0.0219],\n","        [0.9787, 0.0276],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3801, loss 0.3206412196159363\n","Parameter containing:\n","tensor([[-0.3142, -0.7138,  0.1955],\n","        [-1.0986, -0.8973, -0.0756],\n","        [-1.1205, -1.0734, -0.1248],\n","        [-0.4941, -0.5441, -0.0017]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5312, -0.2276,  0.2283,  0.1516], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9275,  0.8363,  1.2369,  0.1810],\n","        [-0.2884, -1.0865, -0.9604, -0.6501]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3880, -0.6330], requires_grad=True)\n","outputs:  tensor([[0.0185, 0.9748],\n","        [0.9831, 0.0219],\n","        [0.9787, 0.0276],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3802, loss 0.3206382393836975\n","outputs:  tensor([[0.0185, 0.9748],\n","        [0.9831, 0.0219],\n","        [0.9787, 0.0276],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3803, loss 0.3206353187561035\n","outputs:  tensor([[0.0185, 0.9748],\n","        [0.9831, 0.0219],\n","        [0.9788, 0.0276],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3804, loss 0.32063236832618713\n","outputs:  tensor([[0.0185, 0.9748],\n","        [0.9831, 0.0219],\n","        [0.9788, 0.0276],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3805, loss 0.32062941789627075\n","outputs:  tensor([[0.0185, 0.9748],\n","        [0.9831, 0.0219],\n","        [0.9788, 0.0276],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3806, loss 0.320626437664032\n","outputs:  tensor([[0.0185, 0.9749],\n","        [0.9831, 0.0219],\n","        [0.9788, 0.0276],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3807, loss 0.3206235468387604\n","outputs:  tensor([[0.0185, 0.9749],\n","        [0.9831, 0.0219],\n","        [0.9788, 0.0275],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3808, loss 0.3206205368041992\n","outputs:  tensor([[0.0185, 0.9749],\n","        [0.9831, 0.0219],\n","        [0.9788, 0.0275],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3809, loss 0.32061758637428284\n","outputs:  tensor([[0.0185, 0.9749],\n","        [0.9831, 0.0219],\n","        [0.9788, 0.0275],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3810, loss 0.32061466574668884\n","outputs:  tensor([[0.0185, 0.9749],\n","        [0.9832, 0.0218],\n","        [0.9788, 0.0275],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3811, loss 0.32061177492141724\n","outputs:  tensor([[0.0185, 0.9749],\n","        [0.9832, 0.0218],\n","        [0.9788, 0.0275],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3812, loss 0.32060879468917847\n","outputs:  tensor([[0.0185, 0.9749],\n","        [0.9832, 0.0218],\n","        [0.9788, 0.0275],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3813, loss 0.3206058442592621\n","outputs:  tensor([[0.0185, 0.9749],\n","        [0.9832, 0.0218],\n","        [0.9788, 0.0275],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3814, loss 0.32060298323631287\n","outputs:  tensor([[0.0184, 0.9749],\n","        [0.9832, 0.0218],\n","        [0.9788, 0.0275],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3815, loss 0.3205999732017517\n","outputs:  tensor([[0.0184, 0.9749],\n","        [0.9832, 0.0218],\n","        [0.9788, 0.0275],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3816, loss 0.3205970823764801\n","outputs:  tensor([[0.0184, 0.9750],\n","        [0.9832, 0.0218],\n","        [0.9788, 0.0275],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3817, loss 0.3205941617488861\n","outputs:  tensor([[0.0184, 0.9750],\n","        [0.9832, 0.0218],\n","        [0.9789, 0.0274],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3818, loss 0.3205912113189697\n","outputs:  tensor([[0.0184, 0.9750],\n","        [0.9832, 0.0218],\n","        [0.9789, 0.0274],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3819, loss 0.3205883502960205\n","outputs:  tensor([[0.0184, 0.9750],\n","        [0.9832, 0.0218],\n","        [0.9789, 0.0274],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3820, loss 0.3205854296684265\n","outputs:  tensor([[0.0184, 0.9750],\n","        [0.9832, 0.0218],\n","        [0.9789, 0.0274],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3821, loss 0.32058247923851013\n","outputs:  tensor([[0.0184, 0.9750],\n","        [0.9832, 0.0217],\n","        [0.9789, 0.0274],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3822, loss 0.3205795884132385\n","outputs:  tensor([[0.0184, 0.9750],\n","        [0.9832, 0.0217],\n","        [0.9789, 0.0274],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3823, loss 0.32057660818099976\n","outputs:  tensor([[0.0184, 0.9750],\n","        [0.9832, 0.0217],\n","        [0.9789, 0.0274],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3824, loss 0.32057374715805054\n","outputs:  tensor([[0.0184, 0.9750],\n","        [0.9832, 0.0217],\n","        [0.9789, 0.0274],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3825, loss 0.32057079672813416\n","outputs:  tensor([[0.0184, 0.9750],\n","        [0.9832, 0.0217],\n","        [0.9789, 0.0274],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3826, loss 0.32056790590286255\n","outputs:  tensor([[0.0184, 0.9751],\n","        [0.9833, 0.0217],\n","        [0.9789, 0.0273],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3827, loss 0.32056504487991333\n","outputs:  tensor([[0.0184, 0.9751],\n","        [0.9833, 0.0217],\n","        [0.9789, 0.0273],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3828, loss 0.32056212425231934\n","outputs:  tensor([[0.0184, 0.9751],\n","        [0.9833, 0.0217],\n","        [0.9789, 0.0273],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3829, loss 0.32055920362472534\n","outputs:  tensor([[0.0183, 0.9751],\n","        [0.9833, 0.0217],\n","        [0.9789, 0.0273],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3830, loss 0.32055628299713135\n","outputs:  tensor([[0.0183, 0.9751],\n","        [0.9833, 0.0217],\n","        [0.9790, 0.0273],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3831, loss 0.3205534517765045\n","outputs:  tensor([[0.0183, 0.9751],\n","        [0.9833, 0.0217],\n","        [0.9790, 0.0273],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3206, grad_fn=<NllLossBackward>)\n","epoch 3832, loss 0.3205505311489105\n","outputs:  tensor([[0.0183, 0.9751],\n","        [0.9833, 0.0216],\n","        [0.9790, 0.0273],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3833, loss 0.32054761052131653\n","outputs:  tensor([[0.0183, 0.9751],\n","        [0.9833, 0.0216],\n","        [0.9790, 0.0273],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3834, loss 0.3205447793006897\n","outputs:  tensor([[0.0183, 0.9751],\n","        [0.9833, 0.0216],\n","        [0.9790, 0.0273],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3835, loss 0.3205418586730957\n","outputs:  tensor([[0.0183, 0.9751],\n","        [0.9833, 0.0216],\n","        [0.9790, 0.0273],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3836, loss 0.3205389678478241\n","outputs:  tensor([[0.0183, 0.9752],\n","        [0.9833, 0.0216],\n","        [0.9790, 0.0272],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3837, loss 0.3205360770225525\n","outputs:  tensor([[0.0183, 0.9752],\n","        [0.9833, 0.0216],\n","        [0.9790, 0.0272],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3838, loss 0.32053321599960327\n","outputs:  tensor([[0.0183, 0.9752],\n","        [0.9833, 0.0216],\n","        [0.9790, 0.0272],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3839, loss 0.3205302953720093\n","outputs:  tensor([[0.0183, 0.9752],\n","        [0.9833, 0.0216],\n","        [0.9790, 0.0272],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3840, loss 0.3205273747444153\n","outputs:  tensor([[0.0183, 0.9752],\n","        [0.9833, 0.0216],\n","        [0.9790, 0.0272],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3841, loss 0.32052451372146606\n","outputs:  tensor([[0.0183, 0.9752],\n","        [0.9833, 0.0216],\n","        [0.9790, 0.0272],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3842, loss 0.32052168250083923\n","outputs:  tensor([[0.0183, 0.9752],\n","        [0.9834, 0.0216],\n","        [0.9790, 0.0272],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3843, loss 0.32051882147789\n","outputs:  tensor([[0.0183, 0.9752],\n","        [0.9834, 0.0216],\n","        [0.9791, 0.0272],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3844, loss 0.3205159306526184\n","outputs:  tensor([[0.0182, 0.9752],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0272],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3845, loss 0.3205130696296692\n","outputs:  tensor([[0.0182, 0.9752],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0272],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3846, loss 0.32051026821136475\n","outputs:  tensor([[0.0182, 0.9753],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0271],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3847, loss 0.32050734758377075\n","outputs:  tensor([[0.0182, 0.9753],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0271],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3848, loss 0.32050448656082153\n","outputs:  tensor([[0.0182, 0.9753],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0271],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3849, loss 0.3205016255378723\n","outputs:  tensor([[0.0182, 0.9753],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0271],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3850, loss 0.3204987645149231\n","outputs:  tensor([[0.0182, 0.9753],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0271],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3851, loss 0.3204959034919739\n","Parameter containing:\n","tensor([[-0.3152, -0.7155,  0.1955],\n","        [-1.1003, -0.9003, -0.0756],\n","        [-1.1224, -1.0767, -0.1248],\n","        [-0.4948, -0.5455, -0.0017]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5319, -0.2265,  0.2295,  0.1521], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9289,  0.8382,  1.2393,  0.1822],\n","        [-0.2903, -1.0891, -0.9636, -0.6516]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3885, -0.6337], requires_grad=True)\n","outputs:  tensor([[0.0182, 0.9753],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0271],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3852, loss 0.32049304246902466\n","outputs:  tensor([[0.0182, 0.9753],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0271],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3853, loss 0.32049018144607544\n","outputs:  tensor([[0.0182, 0.9753],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0271],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3854, loss 0.3204873502254486\n","outputs:  tensor([[0.0182, 0.9753],\n","        [0.9834, 0.0215],\n","        [0.9791, 0.0271],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3855, loss 0.320484459400177\n","outputs:  tensor([[0.0182, 0.9753],\n","        [0.9834, 0.0214],\n","        [0.9791, 0.0271],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3856, loss 0.32048165798187256\n","outputs:  tensor([[0.0182, 0.9754],\n","        [0.9834, 0.0214],\n","        [0.9791, 0.0270],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3857, loss 0.32047876715660095\n","outputs:  tensor([[0.0182, 0.9754],\n","        [0.9834, 0.0214],\n","        [0.9792, 0.0270],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3858, loss 0.3204759657382965\n","outputs:  tensor([[0.0182, 0.9754],\n","        [0.9835, 0.0214],\n","        [0.9792, 0.0270],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3859, loss 0.3204731345176697\n","outputs:  tensor([[0.0181, 0.9754],\n","        [0.9835, 0.0214],\n","        [0.9792, 0.0270],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3860, loss 0.32047027349472046\n","outputs:  tensor([[0.0181, 0.9754],\n","        [0.9835, 0.0214],\n","        [0.9792, 0.0270],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3861, loss 0.32046741247177124\n","outputs:  tensor([[0.0181, 0.9754],\n","        [0.9835, 0.0214],\n","        [0.9792, 0.0270],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3862, loss 0.3204646110534668\n","outputs:  tensor([[0.0181, 0.9754],\n","        [0.9835, 0.0214],\n","        [0.9792, 0.0270],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3863, loss 0.32046180963516235\n","outputs:  tensor([[0.0181, 0.9754],\n","        [0.9835, 0.0214],\n","        [0.9792, 0.0270],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3864, loss 0.32045894861221313\n","outputs:  tensor([[0.0181, 0.9754],\n","        [0.9835, 0.0214],\n","        [0.9792, 0.0270],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3865, loss 0.3204560875892639\n","outputs:  tensor([[0.0181, 0.9754],\n","        [0.9835, 0.0214],\n","        [0.9792, 0.0269],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3866, loss 0.3204532563686371\n","outputs:  tensor([[0.0181, 0.9755],\n","        [0.9835, 0.0214],\n","        [0.9792, 0.0269],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3205, grad_fn=<NllLossBackward>)\n","epoch 3867, loss 0.32045045495033264\n","outputs:  tensor([[0.0181, 0.9755],\n","        [0.9835, 0.0213],\n","        [0.9792, 0.0269],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3868, loss 0.3204475939273834\n","outputs:  tensor([[0.0181, 0.9755],\n","        [0.9835, 0.0213],\n","        [0.9792, 0.0269],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3869, loss 0.32044482231140137\n","outputs:  tensor([[0.0181, 0.9755],\n","        [0.9835, 0.0213],\n","        [0.9792, 0.0269],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3870, loss 0.32044196128845215\n","outputs:  tensor([[0.0181, 0.9755],\n","        [0.9835, 0.0213],\n","        [0.9792, 0.0269],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3871, loss 0.32043910026550293\n","outputs:  tensor([[0.0181, 0.9755],\n","        [0.9835, 0.0213],\n","        [0.9793, 0.0269],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3872, loss 0.3204363286495209\n","outputs:  tensor([[0.0181, 0.9755],\n","        [0.9835, 0.0213],\n","        [0.9793, 0.0269],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3873, loss 0.32043352723121643\n","outputs:  tensor([[0.0181, 0.9755],\n","        [0.9835, 0.0213],\n","        [0.9793, 0.0269],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3874, loss 0.3204307556152344\n","outputs:  tensor([[0.0180, 0.9755],\n","        [0.9836, 0.0213],\n","        [0.9793, 0.0269],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3875, loss 0.32042789459228516\n","outputs:  tensor([[0.0180, 0.9755],\n","        [0.9836, 0.0213],\n","        [0.9793, 0.0268],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3876, loss 0.3204250931739807\n","outputs:  tensor([[0.0180, 0.9756],\n","        [0.9836, 0.0213],\n","        [0.9793, 0.0268],\n","        [0.9996, 0.0007],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3877, loss 0.32042232155799866\n","outputs:  tensor([[0.0180, 0.9756],\n","        [0.9836, 0.0213],\n","        [0.9793, 0.0268],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3878, loss 0.3204194903373718\n","outputs:  tensor([[0.0180, 0.9756],\n","        [0.9836, 0.0212],\n","        [0.9793, 0.0268],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3879, loss 0.3204166889190674\n","outputs:  tensor([[0.0180, 0.9756],\n","        [0.9836, 0.0212],\n","        [0.9793, 0.0268],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3880, loss 0.3204139173030853\n","outputs:  tensor([[0.0180, 0.9756],\n","        [0.9836, 0.0212],\n","        [0.9793, 0.0268],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3881, loss 0.3204111158847809\n","outputs:  tensor([[0.0180, 0.9756],\n","        [0.9836, 0.0212],\n","        [0.9793, 0.0268],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3882, loss 0.32040834426879883\n","outputs:  tensor([[0.0180, 0.9756],\n","        [0.9836, 0.0212],\n","        [0.9793, 0.0268],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3883, loss 0.3204055428504944\n","outputs:  tensor([[0.0180, 0.9756],\n","        [0.9836, 0.0212],\n","        [0.9793, 0.0268],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3884, loss 0.32040271162986755\n","outputs:  tensor([[0.0180, 0.9756],\n","        [0.9836, 0.0212],\n","        [0.9793, 0.0268],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3885, loss 0.32039985060691833\n","outputs:  tensor([[0.0180, 0.9756],\n","        [0.9836, 0.0212],\n","        [0.9794, 0.0267],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3886, loss 0.32039713859558105\n","outputs:  tensor([[0.0180, 0.9757],\n","        [0.9836, 0.0212],\n","        [0.9794, 0.0267],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3887, loss 0.320394366979599\n","outputs:  tensor([[0.0180, 0.9757],\n","        [0.9836, 0.0212],\n","        [0.9794, 0.0267],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3888, loss 0.32039156556129456\n","outputs:  tensor([[0.0180, 0.9757],\n","        [0.9836, 0.0212],\n","        [0.9794, 0.0267],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3889, loss 0.3203887343406677\n","outputs:  tensor([[0.0179, 0.9757],\n","        [0.9836, 0.0212],\n","        [0.9794, 0.0267],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3890, loss 0.32038602232933044\n","outputs:  tensor([[0.0179, 0.9757],\n","        [0.9837, 0.0211],\n","        [0.9794, 0.0267],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3891, loss 0.3203832507133484\n","outputs:  tensor([[0.0179, 0.9757],\n","        [0.9837, 0.0211],\n","        [0.9794, 0.0267],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3892, loss 0.32038044929504395\n","outputs:  tensor([[0.0179, 0.9757],\n","        [0.9837, 0.0211],\n","        [0.9794, 0.0267],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3893, loss 0.3203776776790619\n","outputs:  tensor([[0.0179, 0.9757],\n","        [0.9837, 0.0211],\n","        [0.9794, 0.0267],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3894, loss 0.32037487626075745\n","outputs:  tensor([[0.0179, 0.9757],\n","        [0.9837, 0.0211],\n","        [0.9794, 0.0267],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3895, loss 0.320372074842453\n","outputs:  tensor([[0.0179, 0.9757],\n","        [0.9837, 0.0211],\n","        [0.9794, 0.0266],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3896, loss 0.32036930322647095\n","outputs:  tensor([[0.0179, 0.9758],\n","        [0.9837, 0.0211],\n","        [0.9794, 0.0266],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3897, loss 0.32036662101745605\n","outputs:  tensor([[0.0179, 0.9758],\n","        [0.9837, 0.0211],\n","        [0.9794, 0.0266],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3898, loss 0.3203637897968292\n","outputs:  tensor([[0.0179, 0.9758],\n","        [0.9837, 0.0211],\n","        [0.9794, 0.0266],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3899, loss 0.32036104798316956\n","outputs:  tensor([[0.0179, 0.9758],\n","        [0.9837, 0.0211],\n","        [0.9795, 0.0266],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3900, loss 0.3203582763671875\n","outputs:  tensor([[0.0179, 0.9758],\n","        [0.9837, 0.0211],\n","        [0.9795, 0.0266],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3901, loss 0.32035553455352783\n","Parameter containing:\n","tensor([[-0.3162, -0.7172,  0.1955],\n","        [-1.1020, -0.9033, -0.0756],\n","        [-1.1243, -1.0799, -0.1248],\n","        [-0.4956, -0.5468, -0.0016]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5325, -0.2254,  0.2307,  0.1526], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9304,  0.8401,  1.2416,  0.1834],\n","        [-0.2922, -1.0915, -0.9666, -0.6531]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3890, -0.6343], requires_grad=True)\n","outputs:  tensor([[0.0179, 0.9758],\n","        [0.9837, 0.0211],\n","        [0.9795, 0.0266],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3204, grad_fn=<NllLossBackward>)\n","epoch 3902, loss 0.3203527629375458\n","outputs:  tensor([[0.0179, 0.9758],\n","        [0.9837, 0.0210],\n","        [0.9795, 0.0266],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9988]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3903, loss 0.3203499913215637\n","outputs:  tensor([[0.0179, 0.9758],\n","        [0.9837, 0.0210],\n","        [0.9795, 0.0266],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3904, loss 0.32034724950790405\n","outputs:  tensor([[0.0178, 0.9758],\n","        [0.9837, 0.0210],\n","        [0.9795, 0.0266],\n","        [0.9996, 0.0006],\n","        [0.0012, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3905, loss 0.3203445076942444\n","outputs:  tensor([[0.0178, 0.9758],\n","        [0.9837, 0.0210],\n","        [0.9795, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3906, loss 0.32034173607826233\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9837, 0.0210],\n","        [0.9795, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3907, loss 0.32033902406692505\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9838, 0.0210],\n","        [0.9795, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3908, loss 0.3203362822532654\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9838, 0.0210],\n","        [0.9795, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3909, loss 0.32033345103263855\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9838, 0.0210],\n","        [0.9795, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3910, loss 0.32033079862594604\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9838, 0.0210],\n","        [0.9795, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3911, loss 0.320328027009964\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9838, 0.0210],\n","        [0.9795, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3912, loss 0.3203252851963043\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9838, 0.0210],\n","        [0.9795, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3913, loss 0.32032257318496704\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9838, 0.0210],\n","        [0.9796, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3914, loss 0.3203198313713074\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9838, 0.0209],\n","        [0.9796, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3915, loss 0.3203171193599701\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9838, 0.0209],\n","        [0.9796, 0.0265],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3916, loss 0.32031434774398804\n","outputs:  tensor([[0.0178, 0.9759],\n","        [0.9838, 0.0209],\n","        [0.9796, 0.0264],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3917, loss 0.32031160593032837\n","outputs:  tensor([[0.0178, 0.9760],\n","        [0.9838, 0.0209],\n","        [0.9796, 0.0264],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3918, loss 0.3203088641166687\n","outputs:  tensor([[0.0178, 0.9760],\n","        [0.9838, 0.0209],\n","        [0.9796, 0.0264],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3919, loss 0.32030612230300903\n","outputs:  tensor([[0.0178, 0.9760],\n","        [0.9838, 0.0209],\n","        [0.9796, 0.0264],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3920, loss 0.32030346989631653\n","outputs:  tensor([[0.0177, 0.9760],\n","        [0.9838, 0.0209],\n","        [0.9796, 0.0264],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3921, loss 0.32030072808265686\n","outputs:  tensor([[0.0177, 0.9760],\n","        [0.9838, 0.0209],\n","        [0.9796, 0.0264],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3922, loss 0.3202980160713196\n","outputs:  tensor([[0.0177, 0.9760],\n","        [0.9838, 0.0209],\n","        [0.9796, 0.0264],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3923, loss 0.3202952444553375\n","outputs:  tensor([[0.0177, 0.9760],\n","        [0.9838, 0.0209],\n","        [0.9796, 0.0264],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3924, loss 0.32029253244400024\n","outputs:  tensor([[0.0177, 0.9760],\n","        [0.9839, 0.0209],\n","        [0.9796, 0.0264],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3925, loss 0.32028982043266296\n","outputs:  tensor([[0.0177, 0.9760],\n","        [0.9839, 0.0209],\n","        [0.9796, 0.0264],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3926, loss 0.3202871084213257\n","outputs:  tensor([[0.0177, 0.9760],\n","        [0.9839, 0.0208],\n","        [0.9796, 0.0263],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3927, loss 0.3202844262123108\n","outputs:  tensor([[0.0177, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0263],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3928, loss 0.3202816843986511\n","outputs:  tensor([[0.0177, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0263],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3929, loss 0.32027897238731384\n","outputs:  tensor([[0.0177, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0263],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3930, loss 0.32027631998062134\n","outputs:  tensor([[0.0177, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0263],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3931, loss 0.3202735483646393\n","outputs:  tensor([[0.0177, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0263],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3932, loss 0.32027092576026917\n","outputs:  tensor([[0.0177, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0263],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3933, loss 0.3202681541442871\n","outputs:  tensor([[0.0177, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0263],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3934, loss 0.320265531539917\n","outputs:  tensor([[0.0177, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0263],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3935, loss 0.3202628195285797\n","outputs:  tensor([[0.0176, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0263],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3936, loss 0.32026004791259766\n","outputs:  tensor([[0.0176, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0262],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3937, loss 0.32025736570358276\n","outputs:  tensor([[0.0176, 0.9761],\n","        [0.9839, 0.0208],\n","        [0.9797, 0.0262],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3938, loss 0.32025471329689026\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9839, 0.0207],\n","        [0.9797, 0.0262],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3203, grad_fn=<NllLossBackward>)\n","epoch 3939, loss 0.320252001285553\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9839, 0.0207],\n","        [0.9797, 0.0262],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3940, loss 0.3202493190765381\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9839, 0.0207],\n","        [0.9797, 0.0262],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3941, loss 0.3202466070652008\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9840, 0.0207],\n","        [0.9797, 0.0262],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3942, loss 0.3202439844608307\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9840, 0.0207],\n","        [0.9798, 0.0262],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3943, loss 0.3202412724494934\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9840, 0.0207],\n","        [0.9798, 0.0262],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3944, loss 0.3202385902404785\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9840, 0.0207],\n","        [0.9798, 0.0262],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3945, loss 0.3202359080314636\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9840, 0.0207],\n","        [0.9798, 0.0262],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3946, loss 0.3202332556247711\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9840, 0.0207],\n","        [0.9798, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3947, loss 0.32023054361343384\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9840, 0.0207],\n","        [0.9798, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3948, loss 0.3202279210090637\n","outputs:  tensor([[0.0176, 0.9762],\n","        [0.9840, 0.0207],\n","        [0.9798, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3949, loss 0.32022517919540405\n","outputs:  tensor([[0.0176, 0.9763],\n","        [0.9840, 0.0207],\n","        [0.9798, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3950, loss 0.32022255659103394\n","outputs:  tensor([[0.0176, 0.9763],\n","        [0.9840, 0.0206],\n","        [0.9798, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3951, loss 0.32021984457969666\n","Parameter containing:\n","tensor([[-0.3171, -0.7189,  0.1955],\n","        [-1.1037, -0.9062, -0.0756],\n","        [-1.1262, -1.0832, -0.1248],\n","        [-0.4964, -0.5481, -0.0016]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5332, -0.2243,  0.2319,  0.1531], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9318,  0.8419,  1.2440,  0.1845],\n","        [-0.2940, -1.0940, -0.9697, -0.6546]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3895, -0.6349], requires_grad=True)\n","outputs:  tensor([[0.0175, 0.9763],\n","        [0.9840, 0.0206],\n","        [0.9798, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3952, loss 0.32021722197532654\n","outputs:  tensor([[0.0175, 0.9763],\n","        [0.9840, 0.0206],\n","        [0.9798, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3953, loss 0.32021456956863403\n","outputs:  tensor([[0.0175, 0.9763],\n","        [0.9840, 0.0206],\n","        [0.9798, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3954, loss 0.32021188735961914\n","outputs:  tensor([[0.0175, 0.9763],\n","        [0.9840, 0.0206],\n","        [0.9798, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3955, loss 0.32020920515060425\n","outputs:  tensor([[0.0175, 0.9763],\n","        [0.9840, 0.0206],\n","        [0.9798, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3956, loss 0.32020655274391174\n","outputs:  tensor([[0.0175, 0.9763],\n","        [0.9840, 0.0206],\n","        [0.9799, 0.0261],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3957, loss 0.32020387053489685\n","outputs:  tensor([[0.0175, 0.9763],\n","        [0.9840, 0.0206],\n","        [0.9799, 0.0260],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3958, loss 0.32020121812820435\n","outputs:  tensor([[0.0175, 0.9763],\n","        [0.9841, 0.0206],\n","        [0.9799, 0.0260],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3959, loss 0.32019859552383423\n","outputs:  tensor([[0.0175, 0.9764],\n","        [0.9841, 0.0206],\n","        [0.9799, 0.0260],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3960, loss 0.3201959729194641\n","outputs:  tensor([[0.0175, 0.9764],\n","        [0.9841, 0.0206],\n","        [0.9799, 0.0260],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3961, loss 0.320193350315094\n","outputs:  tensor([[0.0175, 0.9764],\n","        [0.9841, 0.0206],\n","        [0.9799, 0.0260],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3962, loss 0.3201906085014343\n","outputs:  tensor([[0.0175, 0.9764],\n","        [0.9841, 0.0206],\n","        [0.9799, 0.0260],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3963, loss 0.3201879858970642\n","outputs:  tensor([[0.0175, 0.9764],\n","        [0.9841, 0.0205],\n","        [0.9799, 0.0260],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3964, loss 0.3201853632926941\n","outputs:  tensor([[0.0175, 0.9764],\n","        [0.9841, 0.0205],\n","        [0.9799, 0.0260],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3965, loss 0.3201827108860016\n","outputs:  tensor([[0.0175, 0.9764],\n","        [0.9841, 0.0205],\n","        [0.9799, 0.0260],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3966, loss 0.3201800584793091\n","outputs:  tensor([[0.0175, 0.9764],\n","        [0.9841, 0.0205],\n","        [0.9799, 0.0260],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3967, loss 0.3201773762702942\n","outputs:  tensor([[0.0174, 0.9764],\n","        [0.9841, 0.0205],\n","        [0.9799, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3968, loss 0.32017478346824646\n","outputs:  tensor([[0.0174, 0.9764],\n","        [0.9841, 0.0205],\n","        [0.9799, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3969, loss 0.32017210125923157\n","outputs:  tensor([[0.0174, 0.9764],\n","        [0.9841, 0.0205],\n","        [0.9799, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3970, loss 0.32016950845718384\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9841, 0.0205],\n","        [0.9799, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3971, loss 0.32016685605049133\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9841, 0.0205],\n","        [0.9800, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3972, loss 0.3201642632484436\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9841, 0.0205],\n","        [0.9800, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3973, loss 0.3201615810394287\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9841, 0.0205],\n","        [0.9800, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3974, loss 0.3201589584350586\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9841, 0.0205],\n","        [0.9800, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3975, loss 0.32015639543533325\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9842, 0.0204],\n","        [0.9800, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3976, loss 0.32015377283096313\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9842, 0.0204],\n","        [0.9800, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3202, grad_fn=<NllLossBackward>)\n","epoch 3977, loss 0.32015112042427063\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9842, 0.0204],\n","        [0.9800, 0.0259],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3978, loss 0.3201484978199005\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9842, 0.0204],\n","        [0.9800, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3979, loss 0.3201459050178528\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9842, 0.0204],\n","        [0.9800, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3980, loss 0.3201432526111603\n","outputs:  tensor([[0.0174, 0.9765],\n","        [0.9842, 0.0204],\n","        [0.9800, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3981, loss 0.32014063000679016\n","outputs:  tensor([[0.0174, 0.9766],\n","        [0.9842, 0.0204],\n","        [0.9800, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3982, loss 0.3201380670070648\n","outputs:  tensor([[0.0174, 0.9766],\n","        [0.9842, 0.0204],\n","        [0.9800, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3983, loss 0.3201353847980499\n","outputs:  tensor([[0.0173, 0.9766],\n","        [0.9842, 0.0204],\n","        [0.9800, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3984, loss 0.3201327919960022\n","outputs:  tensor([[0.0173, 0.9766],\n","        [0.9842, 0.0204],\n","        [0.9800, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3985, loss 0.3201301693916321\n","outputs:  tensor([[0.0173, 0.9766],\n","        [0.9842, 0.0204],\n","        [0.9801, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3986, loss 0.32012757658958435\n","outputs:  tensor([[0.0173, 0.9766],\n","        [0.9842, 0.0204],\n","        [0.9801, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3987, loss 0.320125013589859\n","outputs:  tensor([[0.0173, 0.9766],\n","        [0.9842, 0.0204],\n","        [0.9801, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3988, loss 0.3201223909854889\n","outputs:  tensor([[0.0173, 0.9766],\n","        [0.9842, 0.0203],\n","        [0.9801, 0.0258],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3989, loss 0.32011979818344116\n","outputs:  tensor([[0.0173, 0.9766],\n","        [0.9842, 0.0203],\n","        [0.9801, 0.0257],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3990, loss 0.32011717557907104\n","outputs:  tensor([[0.0173, 0.9766],\n","        [0.9842, 0.0203],\n","        [0.9801, 0.0257],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3991, loss 0.3201146423816681\n","outputs:  tensor([[0.0173, 0.9766],\n","        [0.9842, 0.0203],\n","        [0.9801, 0.0257],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3992, loss 0.3201119899749756\n","outputs:  tensor([[0.0173, 0.9767],\n","        [0.9842, 0.0203],\n","        [0.9801, 0.0257],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3993, loss 0.32010942697525024\n","outputs:  tensor([[0.0173, 0.9767],\n","        [0.9843, 0.0203],\n","        [0.9801, 0.0257],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3994, loss 0.3201068341732025\n","outputs:  tensor([[0.0173, 0.9767],\n","        [0.9843, 0.0203],\n","        [0.9801, 0.0257],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3995, loss 0.32010418176651\n","outputs:  tensor([[0.0173, 0.9767],\n","        [0.9843, 0.0203],\n","        [0.9801, 0.0257],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3996, loss 0.32010161876678467\n","outputs:  tensor([[0.0173, 0.9767],\n","        [0.9843, 0.0203],\n","        [0.9801, 0.0257],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3997, loss 0.32009902596473694\n","outputs:  tensor([[0.0173, 0.9767],\n","        [0.9843, 0.0203],\n","        [0.9801, 0.0257],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3998, loss 0.3200964331626892\n","outputs:  tensor([[0.0173, 0.9767],\n","        [0.9843, 0.0203],\n","        [0.9801, 0.0257],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 3999, loss 0.3200938403606415\n","outputs:  tensor([[0.0173, 0.9767],\n","        [0.9843, 0.0203],\n","        [0.9801, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4000, loss 0.32009127736091614\n","outputs:  tensor([[0.0172, 0.9767],\n","        [0.9843, 0.0202],\n","        [0.9802, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4001, loss 0.3200886845588684\n","Parameter containing:\n","tensor([[-0.3181, -0.7206,  0.1955],\n","        [-1.1053, -0.9090, -0.0755],\n","        [-1.1280, -1.0863, -0.1247],\n","        [-0.4971, -0.5495, -0.0016]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5338, -0.2232,  0.2331,  0.1536], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9332,  0.8438,  1.2463,  0.1856],\n","        [-0.2958, -1.0963, -0.9726, -0.6561]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3900, -0.6355], requires_grad=True)\n","outputs:  tensor([[0.0172, 0.9767],\n","        [0.9843, 0.0202],\n","        [0.9802, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4002, loss 0.32008612155914307\n","outputs:  tensor([[0.0172, 0.9767],\n","        [0.9843, 0.0202],\n","        [0.9802, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4003, loss 0.3200835585594177\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9843, 0.0202],\n","        [0.9802, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4004, loss 0.32008096575737\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9843, 0.0202],\n","        [0.9802, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4005, loss 0.32007843255996704\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9843, 0.0202],\n","        [0.9802, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4006, loss 0.3200758397579193\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9843, 0.0202],\n","        [0.9802, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4007, loss 0.32007327675819397\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9843, 0.0202],\n","        [0.9802, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4008, loss 0.32007068395614624\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9843, 0.0202],\n","        [0.9802, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4009, loss 0.3200680613517761\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9843, 0.0202],\n","        [0.9802, 0.0256],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4010, loss 0.32006558775901794\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9844, 0.0202],\n","        [0.9802, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4011, loss 0.3200629651546478\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9844, 0.0202],\n","        [0.9802, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4012, loss 0.3200604319572449\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9844, 0.0202],\n","        [0.9802, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4013, loss 0.32005780935287476\n","outputs:  tensor([[0.0172, 0.9768],\n","        [0.9844, 0.0201],\n","        [0.9802, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4014, loss 0.3200553357601166\n","outputs:  tensor([[0.0172, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9802, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4015, loss 0.32005277276039124\n","outputs:  tensor([[0.0172, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3201, grad_fn=<NllLossBackward>)\n","epoch 4016, loss 0.3200501501560211\n","outputs:  tensor([[0.0171, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4017, loss 0.32004767656326294\n","outputs:  tensor([[0.0171, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4018, loss 0.3200450837612152\n","outputs:  tensor([[0.0171, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4019, loss 0.32004255056381226\n","outputs:  tensor([[0.0171, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4020, loss 0.3200399875640869\n","outputs:  tensor([[0.0171, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0255],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4021, loss 0.32003745436668396\n","outputs:  tensor([[0.0171, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4022, loss 0.3200348913669586\n","outputs:  tensor([[0.0171, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4023, loss 0.32003235816955566\n","outputs:  tensor([[0.0171, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4024, loss 0.3200297951698303\n","outputs:  tensor([[0.0171, 0.9769],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4025, loss 0.32002726197242737\n","outputs:  tensor([[0.0171, 0.9770],\n","        [0.9844, 0.0201],\n","        [0.9803, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4026, loss 0.3200247287750244\n","outputs:  tensor([[0.0171, 0.9770],\n","        [0.9844, 0.0200],\n","        [0.9803, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4027, loss 0.32002219557762146\n","outputs:  tensor([[0.0171, 0.9770],\n","        [0.9844, 0.0200],\n","        [0.9803, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4028, loss 0.3200196623802185\n","outputs:  tensor([[0.0171, 0.9770],\n","        [0.9845, 0.0200],\n","        [0.9803, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4029, loss 0.32001715898513794\n","outputs:  tensor([[0.0171, 0.9770],\n","        [0.9845, 0.0200],\n","        [0.9803, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4030, loss 0.320014625787735\n","outputs:  tensor([[0.0171, 0.9770],\n","        [0.9845, 0.0200],\n","        [0.9803, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4031, loss 0.32001209259033203\n","outputs:  tensor([[0.0171, 0.9770],\n","        [0.9845, 0.0200],\n","        [0.9804, 0.0254],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4032, loss 0.3200095295906067\n","outputs:  tensor([[0.0171, 0.9770],\n","        [0.9845, 0.0200],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4033, loss 0.32000699639320374\n","outputs:  tensor([[0.0170, 0.9770],\n","        [0.9845, 0.0200],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4034, loss 0.3200044631958008\n","outputs:  tensor([[0.0170, 0.9770],\n","        [0.9845, 0.0200],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4035, loss 0.3200019299983978\n","outputs:  tensor([[0.0170, 0.9770],\n","        [0.9845, 0.0200],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4036, loss 0.3199995160102844\n","outputs:  tensor([[0.0170, 0.9770],\n","        [0.9845, 0.0200],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4037, loss 0.3199969232082367\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9845, 0.0200],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4038, loss 0.3199944496154785\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9845, 0.0200],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4039, loss 0.3199918866157532\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9845, 0.0199],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4040, loss 0.3199893534183502\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9845, 0.0199],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4041, loss 0.31998682022094727\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9845, 0.0199],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4042, loss 0.3199843466281891\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9845, 0.0199],\n","        [0.9804, 0.0253],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4043, loss 0.31998181343078613\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9845, 0.0199],\n","        [0.9804, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4044, loss 0.31997933983802795\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9845, 0.0199],\n","        [0.9804, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4045, loss 0.319976806640625\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9845, 0.0199],\n","        [0.9804, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9989]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4046, loss 0.31997427344322205\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9846, 0.0199],\n","        [0.9805, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4047, loss 0.31997179985046387\n","outputs:  tensor([[0.0170, 0.9771],\n","        [0.9846, 0.0199],\n","        [0.9805, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4048, loss 0.3199693262577057\n","outputs:  tensor([[0.0170, 0.9772],\n","        [0.9846, 0.0199],\n","        [0.9805, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4049, loss 0.3199668228626251\n","outputs:  tensor([[0.0170, 0.9772],\n","        [0.9846, 0.0199],\n","        [0.9805, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4050, loss 0.31996434926986694\n","outputs:  tensor([[0.0169, 0.9772],\n","        [0.9846, 0.0199],\n","        [0.9805, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4051, loss 0.319961816072464\n","Parameter containing:\n","tensor([[-0.3190, -0.7222,  0.1955],\n","        [-1.1069, -0.9118, -0.0755],\n","        [-1.1297, -1.0894, -0.1247],\n","        [-0.4979, -0.5507, -0.0016]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5344, -0.2222,  0.2343,  0.1541], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9345,  0.8456,  1.2485,  0.1867],\n","        [-0.2976, -1.0987, -0.9756, -0.6575]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3904, -0.6361], requires_grad=True)\n","outputs:  tensor([[0.0169, 0.9772],\n","        [0.9846, 0.0199],\n","        [0.9805, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4052, loss 0.3199593126773834\n","outputs:  tensor([[0.0169, 0.9772],\n","        [0.9846, 0.0198],\n","        [0.9805, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4053, loss 0.31995683908462524\n","outputs:  tensor([[0.0169, 0.9772],\n","        [0.9846, 0.0198],\n","        [0.9805, 0.0252],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4054, loss 0.3199543356895447\n","outputs:  tensor([[0.0169, 0.9772],\n","        [0.9846, 0.0198],\n","        [0.9805, 0.0251],\n","        [0.9996, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3200, grad_fn=<NllLossBackward>)\n","epoch 4055, loss 0.3199518322944641\n","outputs:  tensor([[0.0169, 0.9772],\n","        [0.9846, 0.0198],\n","        [0.9805, 0.0251],\n","        [0.9997, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4056, loss 0.31994932889938354\n","outputs:  tensor([[0.0169, 0.9772],\n","        [0.9846, 0.0198],\n","        [0.9805, 0.0251],\n","        [0.9997, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4057, loss 0.319946825504303\n","outputs:  tensor([[0.0169, 0.9772],\n","        [0.9846, 0.0198],\n","        [0.9805, 0.0251],\n","        [0.9997, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4058, loss 0.3199443817138672\n","outputs:  tensor([[0.0169, 0.9772],\n","        [0.9846, 0.0198],\n","        [0.9805, 0.0251],\n","        [0.9997, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4059, loss 0.31994184851646423\n","outputs:  tensor([[0.0169, 0.9773],\n","        [0.9846, 0.0198],\n","        [0.9805, 0.0251],\n","        [0.9997, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4060, loss 0.31993940472602844\n","outputs:  tensor([[0.0169, 0.9773],\n","        [0.9846, 0.0198],\n","        [0.9805, 0.0251],\n","        [0.9997, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4061, loss 0.31993693113327026\n","outputs:  tensor([[0.0169, 0.9773],\n","        [0.9846, 0.0198],\n","        [0.9806, 0.0251],\n","        [0.9997, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4062, loss 0.3199344277381897\n","outputs:  tensor([[0.0169, 0.9773],\n","        [0.9846, 0.0198],\n","        [0.9806, 0.0251],\n","        [0.9997, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4063, loss 0.3199319839477539\n","outputs:  tensor([[0.0169, 0.9773],\n","        [0.9846, 0.0198],\n","        [0.9806, 0.0251],\n","        [0.9997, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4064, loss 0.31992948055267334\n","outputs:  tensor([[0.0169, 0.9773],\n","        [0.9847, 0.0198],\n","        [0.9806, 0.0251],\n","        [0.9997, 0.0006],\n","        [0.0011, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4065, loss 0.31992703676223755\n","outputs:  tensor([[0.0169, 0.9773],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4066, loss 0.319924533367157\n","outputs:  tensor([[0.0169, 0.9773],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4067, loss 0.3199220597743988\n","outputs:  tensor([[0.0168, 0.9773],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4068, loss 0.31991955637931824\n","outputs:  tensor([[0.0168, 0.9773],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4069, loss 0.31991714239120483\n","outputs:  tensor([[0.0168, 0.9773],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4070, loss 0.31991466879844666\n","outputs:  tensor([[0.0168, 0.9773],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4071, loss 0.31991222500801086\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4072, loss 0.3199097514152527\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4073, loss 0.3199073076248169\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4074, loss 0.31990480422973633\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4075, loss 0.31990236043930054\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0250],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4076, loss 0.31989991664886475\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0197],\n","        [0.9806, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4077, loss 0.31989744305610657\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0197],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4078, loss 0.3198949694633484\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0197],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4079, loss 0.319892555475235\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0196],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4080, loss 0.3198901116847992\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0196],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4081, loss 0.3198876678943634\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0196],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4082, loss 0.3198851943016052\n","outputs:  tensor([[0.0168, 0.9774],\n","        [0.9847, 0.0196],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4083, loss 0.3198828101158142\n","outputs:  tensor([[0.0168, 0.9775],\n","        [0.9848, 0.0196],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4084, loss 0.31988033652305603\n","outputs:  tensor([[0.0167, 0.9775],\n","        [0.9848, 0.0196],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4085, loss 0.31987786293029785\n","outputs:  tensor([[0.0167, 0.9775],\n","        [0.9848, 0.0196],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4086, loss 0.31987544894218445\n","outputs:  tensor([[0.0167, 0.9775],\n","        [0.9848, 0.0196],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4087, loss 0.31987303495407104\n","outputs:  tensor([[0.0167, 0.9775],\n","        [0.9848, 0.0196],\n","        [0.9807, 0.0249],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4088, loss 0.31987059116363525\n","outputs:  tensor([[0.0167, 0.9775],\n","        [0.9848, 0.0196],\n","        [0.9807, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4089, loss 0.31986814737319946\n","outputs:  tensor([[0.0167, 0.9775],\n","        [0.9848, 0.0196],\n","        [0.9807, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4090, loss 0.31986573338508606\n","outputs:  tensor([[0.0167, 0.9775],\n","        [0.9848, 0.0196],\n","        [0.9807, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4091, loss 0.3198632597923279\n","outputs:  tensor([[0.0167, 0.9775],\n","        [0.9848, 0.0196],\n","        [0.9807, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4092, loss 0.3198608458042145\n","outputs:  tensor([[0.0167, 0.9775],\n","        [0.9848, 0.0195],\n","        [0.9807, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4093, loss 0.3198584020137787\n","outputs:  tensor([[0.0167, 0.9775],\n","        [0.9848, 0.0195],\n","        [0.9808, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4094, loss 0.3198559880256653\n","outputs:  tensor([[0.0167, 0.9776],\n","        [0.9848, 0.0195],\n","        [0.9808, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4095, loss 0.31985360383987427\n","outputs:  tensor([[0.0167, 0.9776],\n","        [0.9848, 0.0195],\n","        [0.9808, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3199, grad_fn=<NllLossBackward>)\n","epoch 4096, loss 0.3198511600494385\n","outputs:  tensor([[0.0167, 0.9776],\n","        [0.9848, 0.0195],\n","        [0.9808, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4097, loss 0.3198487162590027\n","outputs:  tensor([[0.0167, 0.9776],\n","        [0.9848, 0.0195],\n","        [0.9808, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4098, loss 0.3198462426662445\n","outputs:  tensor([[0.0167, 0.9776],\n","        [0.9848, 0.0195],\n","        [0.9808, 0.0248],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4099, loss 0.3198438584804535\n","outputs:  tensor([[0.0167, 0.9776],\n","        [0.9848, 0.0195],\n","        [0.9808, 0.0247],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4100, loss 0.3198414742946625\n","outputs:  tensor([[0.0167, 0.9776],\n","        [0.9848, 0.0195],\n","        [0.9808, 0.0247],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4101, loss 0.3198390603065491\n","Parameter containing:\n","tensor([[-0.3199, -0.7238,  0.1955],\n","        [-1.1085, -0.9146, -0.0755],\n","        [-1.1315, -1.0925, -0.1247],\n","        [-0.4986, -0.5520, -0.0016]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5350, -0.2211,  0.2355,  0.1546], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9359,  0.8474,  1.2507,  0.1878],\n","        [-0.2994, -1.1010, -0.9784, -0.6589]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3909, -0.6367], requires_grad=True)\n","outputs:  tensor([[0.0166, 0.9776],\n","        [0.9848, 0.0195],\n","        [0.9808, 0.0247],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4102, loss 0.3198366165161133\n","outputs:  tensor([[0.0166, 0.9776],\n","        [0.9849, 0.0195],\n","        [0.9808, 0.0247],\n","        [0.9997, 0.0006],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4103, loss 0.3198341727256775\n","outputs:  tensor([[0.0166, 0.9776],\n","        [0.9849, 0.0195],\n","        [0.9808, 0.0247],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4104, loss 0.3198317587375641\n","outputs:  tensor([[0.0166, 0.9776],\n","        [0.9849, 0.0195],\n","        [0.9808, 0.0247],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4105, loss 0.31982940435409546\n","outputs:  tensor([[0.0166, 0.9776],\n","        [0.9849, 0.0195],\n","        [0.9808, 0.0247],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4106, loss 0.31982699036598206\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9808, 0.0247],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4107, loss 0.31982460618019104\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9808, 0.0247],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4108, loss 0.31982213258743286\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9808, 0.0247],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4109, loss 0.31981974840164185\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9809, 0.0247],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4110, loss 0.31981736421585083\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9809, 0.0247],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4111, loss 0.31981492042541504\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4112, loss 0.3198125958442688\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4113, loss 0.319810152053833\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4114, loss 0.319807767868042\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4115, loss 0.3198053240776062\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4116, loss 0.3198029100894928\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4117, loss 0.31980055570602417\n","outputs:  tensor([[0.0166, 0.9777],\n","        [0.9849, 0.0194],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4118, loss 0.31979817152023315\n","outputs:  tensor([[0.0166, 0.9778],\n","        [0.9849, 0.0194],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4119, loss 0.319795697927475\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9849, 0.0193],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4120, loss 0.3197934031486511\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9849, 0.0193],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4121, loss 0.3197910189628601\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9850, 0.0193],\n","        [0.9809, 0.0246],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4122, loss 0.3197886049747467\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9850, 0.0193],\n","        [0.9809, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4123, loss 0.3197862207889557\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9850, 0.0193],\n","        [0.9809, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4124, loss 0.31978386640548706\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9850, 0.0193],\n","        [0.9809, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4125, loss 0.31978148221969604\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9850, 0.0193],\n","        [0.9810, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4126, loss 0.31977909803390503\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9850, 0.0193],\n","        [0.9810, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4127, loss 0.319776713848114\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9850, 0.0193],\n","        [0.9810, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4128, loss 0.3197743892669678\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9850, 0.0193],\n","        [0.9810, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4129, loss 0.31977200508117676\n","outputs:  tensor([[0.0165, 0.9778],\n","        [0.9850, 0.0193],\n","        [0.9810, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4130, loss 0.31976962089538574\n","outputs:  tensor([[0.0165, 0.9779],\n","        [0.9850, 0.0193],\n","        [0.9810, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4131, loss 0.3197672367095947\n","outputs:  tensor([[0.0165, 0.9779],\n","        [0.9850, 0.0193],\n","        [0.9810, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4132, loss 0.31976479291915894\n","outputs:  tensor([[0.0165, 0.9779],\n","        [0.9850, 0.0193],\n","        [0.9810, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4133, loss 0.3197624683380127\n","outputs:  tensor([[0.0165, 0.9779],\n","        [0.9850, 0.0192],\n","        [0.9810, 0.0245],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4134, loss 0.3197600841522217\n","outputs:  tensor([[0.0165, 0.9779],\n","        [0.9850, 0.0192],\n","        [0.9810, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4135, loss 0.31975775957107544\n","outputs:  tensor([[0.0165, 0.9779],\n","        [0.9850, 0.0192],\n","        [0.9810, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4136, loss 0.3197554051876068\n","outputs:  tensor([[0.0165, 0.9779],\n","        [0.9850, 0.0192],\n","        [0.9810, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4137, loss 0.3197530210018158\n","outputs:  tensor([[0.0164, 0.9779],\n","        [0.9850, 0.0192],\n","        [0.9810, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3198, grad_fn=<NllLossBackward>)\n","epoch 4138, loss 0.31975069642066956\n","outputs:  tensor([[0.0164, 0.9779],\n","        [0.9850, 0.0192],\n","        [0.9810, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4139, loss 0.31974831223487854\n","outputs:  tensor([[0.0164, 0.9779],\n","        [0.9850, 0.0192],\n","        [0.9810, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4140, loss 0.3197459578514099\n","outputs:  tensor([[0.0164, 0.9779],\n","        [0.9851, 0.0192],\n","        [0.9810, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4141, loss 0.31974363327026367\n","outputs:  tensor([[0.0164, 0.9779],\n","        [0.9851, 0.0192],\n","        [0.9811, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4142, loss 0.31974127888679504\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0192],\n","        [0.9811, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4143, loss 0.31973889470100403\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0192],\n","        [0.9811, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4144, loss 0.3197365403175354\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0192],\n","        [0.9811, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4145, loss 0.3197341859340668\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0192],\n","        [0.9811, 0.0244],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4146, loss 0.31973186135292053\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0192],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4147, loss 0.3197295069694519\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0191],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4148, loss 0.3197271525859833\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0191],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4149, loss 0.31972479820251465\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0191],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4150, loss 0.3197225034236908\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0191],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4151, loss 0.31972014904022217\n","Parameter containing:\n","tensor([[-0.3208, -0.7254,  0.1955],\n","        [-1.1100, -0.9173, -0.0755],\n","        [-1.1332, -1.0955, -0.1247],\n","        [-0.4993, -0.5533, -0.0016]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5356, -0.2201,  0.2366,  0.1550], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9372,  0.8491,  1.2529,  0.1889],\n","        [-0.3011, -1.1033, -0.9813, -0.6603]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3914, -0.6373], requires_grad=True)\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0191],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4152, loss 0.3197178244590759\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0191],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4153, loss 0.3197154402732849\n","outputs:  tensor([[0.0164, 0.9780],\n","        [0.9851, 0.0191],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4154, loss 0.31971311569213867\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9851, 0.0191],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4155, loss 0.31971079111099243\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9851, 0.0191],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4156, loss 0.3197084665298462\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9851, 0.0191],\n","        [0.9811, 0.0243],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4157, loss 0.31970611214637756\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9851, 0.0191],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4158, loss 0.3197037875652313\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9851, 0.0191],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4159, loss 0.3197014629840851\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9852, 0.0191],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4160, loss 0.31969916820526123\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9852, 0.0191],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4161, loss 0.319696843624115\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4162, loss 0.319694459438324\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4163, loss 0.3196921646595001\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4164, loss 0.3196898400783539\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4165, loss 0.31968751549720764\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4166, loss 0.3196851909160614\n","outputs:  tensor([[0.0163, 0.9781],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4167, loss 0.31968289613723755\n","outputs:  tensor([[0.0163, 0.9782],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4168, loss 0.3196805417537689\n","outputs:  tensor([[0.0163, 0.9782],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0242],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4169, loss 0.31967824697494507\n","outputs:  tensor([[0.0163, 0.9782],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4170, loss 0.3196759819984436\n","outputs:  tensor([[0.0163, 0.9782],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4171, loss 0.31967365741729736\n","outputs:  tensor([[0.0163, 0.9782],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4172, loss 0.3196713328361511\n","outputs:  tensor([[0.0163, 0.9782],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4173, loss 0.3196689784526825\n","outputs:  tensor([[0.0162, 0.9782],\n","        [0.9852, 0.0190],\n","        [0.9812, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4174, loss 0.31966671347618103\n","outputs:  tensor([[0.0162, 0.9782],\n","        [0.9852, 0.0190],\n","        [0.9813, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4175, loss 0.3196644186973572\n","outputs:  tensor([[0.0162, 0.9782],\n","        [0.9852, 0.0189],\n","        [0.9813, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4176, loss 0.31966206431388855\n","outputs:  tensor([[0.0162, 0.9782],\n","        [0.9852, 0.0189],\n","        [0.9813, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4177, loss 0.3196598291397095\n","outputs:  tensor([[0.0162, 0.9782],\n","        [0.9852, 0.0189],\n","        [0.9813, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4178, loss 0.31965750455856323\n","outputs:  tensor([[0.0162, 0.9782],\n","        [0.9852, 0.0189],\n","        [0.9813, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4179, loss 0.3196552097797394\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0189],\n","        [0.9813, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4180, loss 0.31965285539627075\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0189],\n","        [0.9813, 0.0241],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3197, grad_fn=<NllLossBackward>)\n","epoch 4181, loss 0.3196505904197693\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0189],\n","        [0.9813, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4182, loss 0.3196483254432678\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0189],\n","        [0.9813, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4183, loss 0.31964603066444397\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0189],\n","        [0.9813, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4184, loss 0.3196437358856201\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0189],\n","        [0.9813, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4185, loss 0.3196414113044739\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0189],\n","        [0.9813, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4186, loss 0.3196391463279724\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0189],\n","        [0.9813, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4187, loss 0.31963682174682617\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0189],\n","        [0.9813, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4188, loss 0.3196345865726471\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0189],\n","        [0.9813, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4189, loss 0.31963226199150085\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0188],\n","        [0.9813, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4190, loss 0.3196299970149994\n","outputs:  tensor([[0.0162, 0.9783],\n","        [0.9853, 0.0188],\n","        [0.9814, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4191, loss 0.31962770223617554\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9853, 0.0188],\n","        [0.9814, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4192, loss 0.31962546706199646\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9853, 0.0188],\n","        [0.9814, 0.0240],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4193, loss 0.3196231424808502\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9853, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4194, loss 0.31962093710899353\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9853, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4195, loss 0.3196186125278473\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9853, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4196, loss 0.3196163773536682\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9853, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4197, loss 0.31961408257484436\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9853, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4198, loss 0.3196118474006653\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9853, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4199, loss 0.31960955262184143\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9854, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4200, loss 0.3196072578430176\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9854, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4201, loss 0.3196049630641937\n","Parameter containing:\n","tensor([[-0.3217, -0.7269,  0.1955],\n","        [-1.1115, -0.9200, -0.0755],\n","        [-1.1349, -1.0985, -0.1247],\n","        [-0.5000, -0.5545, -0.0016]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5362, -0.2191,  0.2377,  0.1555], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9385,  0.8508,  1.2551,  0.1899],\n","        [-0.3028, -1.1055, -0.9840, -0.6617]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3918, -0.6378], requires_grad=True)\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9854, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4202, loss 0.3196027874946594\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9854, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4203, loss 0.3196004331111908\n","outputs:  tensor([[0.0161, 0.9784],\n","        [0.9854, 0.0188],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4204, loss 0.3195982575416565\n","outputs:  tensor([[0.0161, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4205, loss 0.31959590315818787\n","outputs:  tensor([[0.0161, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9814, 0.0239],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4206, loss 0.3195936679840088\n","outputs:  tensor([[0.0161, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9814, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4207, loss 0.31959137320518494\n","outputs:  tensor([[0.0161, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4208, loss 0.3195890784263611\n","outputs:  tensor([[0.0161, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4209, loss 0.3195869028568268\n","outputs:  tensor([[0.0161, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9990]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4210, loss 0.3195846676826477\n","outputs:  tensor([[0.0160, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4211, loss 0.31958240270614624\n","outputs:  tensor([[0.0160, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4212, loss 0.3195801377296448\n","outputs:  tensor([[0.0160, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4213, loss 0.3195778727531433\n","outputs:  tensor([[0.0160, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4214, loss 0.31957560777664185\n","outputs:  tensor([[0.0160, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4215, loss 0.31957340240478516\n","outputs:  tensor([[0.0160, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4216, loss 0.3195711672306061\n","outputs:  tensor([[0.0160, 0.9785],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4217, loss 0.319568932056427\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9854, 0.0187],\n","        [0.9815, 0.0238],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4218, loss 0.31956666707992554\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9854, 0.0186],\n","        [0.9815, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4219, loss 0.31956443190574646\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9855, 0.0186],\n","        [0.9815, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4220, loss 0.3195621371269226\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9855, 0.0186],\n","        [0.9815, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4221, loss 0.31955990195274353\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9855, 0.0186],\n","        [0.9815, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4222, loss 0.31955772638320923\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9855, 0.0186],\n","        [0.9815, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4223, loss 0.3195554316043854\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9855, 0.0186],\n","        [0.9815, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4224, loss 0.3195532262325287\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9855, 0.0186],\n","        [0.9816, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3196, grad_fn=<NllLossBackward>)\n","epoch 4225, loss 0.3195509910583496\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9855, 0.0186],\n","        [0.9816, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4226, loss 0.31954875588417053\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9855, 0.0186],\n","        [0.9816, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4227, loss 0.31954652070999146\n","outputs:  tensor([[0.0160, 0.9786],\n","        [0.9855, 0.0186],\n","        [0.9816, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4228, loss 0.31954431533813477\n","outputs:  tensor([[0.0159, 0.9786],\n","        [0.9855, 0.0186],\n","        [0.9816, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4229, loss 0.3195421099662781\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9855, 0.0186],\n","        [0.9816, 0.0237],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4230, loss 0.3195398449897766\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9855, 0.0186],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4231, loss 0.3195376396179199\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9855, 0.0186],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4232, loss 0.31953534483909607\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9855, 0.0186],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4233, loss 0.31953316926956177\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9855, 0.0185],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4234, loss 0.3195309042930603\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9855, 0.0185],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4235, loss 0.319528728723526\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9855, 0.0185],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4236, loss 0.3195264935493469\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9855, 0.0185],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4237, loss 0.31952428817749023\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9855, 0.0185],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4238, loss 0.31952205300331116\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9855, 0.0185],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4239, loss 0.31951990723609924\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9856, 0.0185],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4240, loss 0.3195176124572754\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9856, 0.0185],\n","        [0.9816, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4241, loss 0.3195154070854187\n","outputs:  tensor([[0.0159, 0.9787],\n","        [0.9856, 0.0185],\n","        [0.9817, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4242, loss 0.3195132315158844\n","outputs:  tensor([[0.0159, 0.9788],\n","        [0.9856, 0.0185],\n","        [0.9817, 0.0236],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4243, loss 0.3195110261440277\n","outputs:  tensor([[0.0159, 0.9788],\n","        [0.9856, 0.0185],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4244, loss 0.3195088505744934\n","outputs:  tensor([[0.0159, 0.9788],\n","        [0.9856, 0.0185],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4245, loss 0.31950658559799194\n","outputs:  tensor([[0.0159, 0.9788],\n","        [0.9856, 0.0185],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4246, loss 0.31950435042381287\n","outputs:  tensor([[0.0159, 0.9788],\n","        [0.9856, 0.0185],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4247, loss 0.31950220465660095\n","outputs:  tensor([[0.0158, 0.9788],\n","        [0.9856, 0.0185],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4248, loss 0.31950002908706665\n","outputs:  tensor([[0.0158, 0.9788],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0010, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4249, loss 0.3194977939128876\n","outputs:  tensor([[0.0158, 0.9788],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4250, loss 0.3194955885410309\n","outputs:  tensor([[0.0158, 0.9788],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4251, loss 0.3194933831691742\n","Parameter containing:\n","tensor([[-0.3226, -0.7285,  0.1955],\n","        [-1.1130, -0.9226, -0.0755],\n","        [-1.1366, -1.1014, -0.1247],\n","        [-0.5007, -0.5557, -0.0015]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5368, -0.2181,  0.2388,  0.1559], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9398,  0.8525,  1.2572,  0.1910],\n","        [-0.3044, -1.1077, -0.9868, -0.6630]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3923, -0.6384], requires_grad=True)\n","outputs:  tensor([[0.0158, 0.9788],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4252, loss 0.3194911479949951\n","outputs:  tensor([[0.0158, 0.9788],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4253, loss 0.3194890320301056\n","outputs:  tensor([[0.0158, 0.9788],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4254, loss 0.3194867968559265\n","outputs:  tensor([[0.0158, 0.9788],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0235],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4255, loss 0.3194845914840698\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4256, loss 0.3194824457168579\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4257, loss 0.3194802403450012\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4258, loss 0.31947803497314453\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9856, 0.0184],\n","        [0.9817, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4259, loss 0.31947582960128784\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9856, 0.0184],\n","        [0.9818, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4260, loss 0.3194736838340759\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9857, 0.0184],\n","        [0.9818, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4261, loss 0.3194715082645416\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9857, 0.0184],\n","        [0.9818, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4262, loss 0.31946930289268494\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9857, 0.0184],\n","        [0.9818, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4263, loss 0.31946712732315063\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4264, loss 0.31946492195129395\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4265, loss 0.31946274638175964\n","outputs:  tensor([[0.0158, 0.9789],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4266, loss 0.31946060061454773\n","outputs:  tensor([[0.0157, 0.9789],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4267, loss 0.31945839524269104\n","outputs:  tensor([[0.0157, 0.9789],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0234],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4268, loss 0.3194562494754791\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4269, loss 0.31945401430130005\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3195, grad_fn=<NllLossBackward>)\n","epoch 4270, loss 0.31945186853408813\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4271, loss 0.3194497227668762\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4272, loss 0.3194475471973419\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4273, loss 0.31944540143013\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4274, loss 0.3194431960582733\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4275, loss 0.3194410502910614\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0183],\n","        [0.9818, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4276, loss 0.3194389045238495\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0183],\n","        [0.9819, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4277, loss 0.3194367289543152\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0183],\n","        [0.9819, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4278, loss 0.31943458318710327\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0182],\n","        [0.9819, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4279, loss 0.31943240761756897\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0182],\n","        [0.9819, 0.0233],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4280, loss 0.31943023204803467\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9857, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4281, loss 0.31942808628082275\n","outputs:  tensor([[0.0157, 0.9790],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4282, loss 0.31942594051361084\n","outputs:  tensor([[0.0157, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4283, loss 0.31942376494407654\n","outputs:  tensor([[0.0157, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4284, loss 0.31942158937454224\n","outputs:  tensor([[0.0157, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4285, loss 0.3194195330142975\n","outputs:  tensor([[0.0157, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4286, loss 0.3194173574447632\n","outputs:  tensor([[0.0156, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4287, loss 0.31941521167755127\n","outputs:  tensor([[0.0156, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4288, loss 0.31941306591033936\n","outputs:  tensor([[0.0156, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4289, loss 0.31941092014312744\n","outputs:  tensor([[0.0156, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4290, loss 0.31940874457359314\n","outputs:  tensor([[0.0156, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4291, loss 0.3194065988063812\n","outputs:  tensor([[0.0156, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4292, loss 0.3194044828414917\n","outputs:  tensor([[0.0156, 0.9791],\n","        [0.9858, 0.0182],\n","        [0.9819, 0.0232],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4293, loss 0.3194023370742798\n","outputs:  tensor([[0.0156, 0.9791],\n","        [0.9858, 0.0181],\n","        [0.9819, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4294, loss 0.3194001317024231\n","outputs:  tensor([[0.0156, 0.9791],\n","        [0.9858, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4295, loss 0.31939801573753357\n","outputs:  tensor([[0.0156, 0.9792],\n","        [0.9858, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4296, loss 0.31939589977264404\n","outputs:  tensor([[0.0156, 0.9792],\n","        [0.9858, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4297, loss 0.3193937838077545\n","outputs:  tensor([[0.0156, 0.9792],\n","        [0.9858, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4298, loss 0.3193915784358978\n","outputs:  tensor([[0.0156, 0.9792],\n","        [0.9858, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4299, loss 0.3193894922733307\n","outputs:  tensor([[0.0156, 0.9792],\n","        [0.9858, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4300, loss 0.3193873167037964\n","outputs:  tensor([[0.0156, 0.9792],\n","        [0.9858, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4301, loss 0.31938523054122925\n","Parameter containing:\n","tensor([[-0.3235, -0.7300,  0.1955],\n","        [-1.1145, -0.9252, -0.0754],\n","        [-1.1382, -1.1043, -0.1247],\n","        [-0.5013, -0.5569, -0.0015]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5374, -0.2171,  0.2399,  0.1564], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9411,  0.8542,  1.2593,  0.1920],\n","        [-0.3061, -1.1098, -0.9895, -0.6643]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3927, -0.6389], requires_grad=True)\n","outputs:  tensor([[0.0156, 0.9792],\n","        [0.9858, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4302, loss 0.31938308477401733\n","outputs:  tensor([[0.0156, 0.9792],\n","        [0.9859, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4303, loss 0.3193809390068054\n","outputs:  tensor([[0.0156, 0.9792],\n","        [0.9859, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4304, loss 0.3193788230419159\n","outputs:  tensor([[0.0156, 0.9792],\n","        [0.9859, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4305, loss 0.31937670707702637\n","outputs:  tensor([[0.0155, 0.9792],\n","        [0.9859, 0.0181],\n","        [0.9820, 0.0231],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4306, loss 0.31937462091445923\n","outputs:  tensor([[0.0155, 0.9792],\n","        [0.9859, 0.0181],\n","        [0.9820, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4307, loss 0.3193724751472473\n","outputs:  tensor([[0.0155, 0.9792],\n","        [0.9859, 0.0181],\n","        [0.9820, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4308, loss 0.3193703889846802\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0181],\n","        [0.9820, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4309, loss 0.3193682134151459\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9820, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4310, loss 0.31936612725257874\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9820, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4311, loss 0.3193639814853668\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9820, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4312, loss 0.3193618655204773\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4313, loss 0.3193597197532654\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4314, loss 0.319357693195343\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4315, loss 0.3193555474281311\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4316, loss 0.3193534016609192\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3194, grad_fn=<NllLossBackward>)\n","epoch 4317, loss 0.31935128569602966\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4318, loss 0.3193491995334625\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0230],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4319, loss 0.3193471431732178\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4320, loss 0.31934499740600586\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4321, loss 0.31934285163879395\n","outputs:  tensor([[0.0155, 0.9793],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4322, loss 0.3193407654762268\n","outputs:  tensor([[0.0155, 0.9794],\n","        [0.9859, 0.0180],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4323, loss 0.31933870911598206\n","outputs:  tensor([[0.0155, 0.9794],\n","        [0.9860, 0.0180],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4324, loss 0.31933659315109253\n","outputs:  tensor([[0.0155, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4325, loss 0.3193344473838806\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4326, loss 0.3193323612213135\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4327, loss 0.3193303644657135\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4328, loss 0.3193281590938568\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4329, loss 0.3193260729312897\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9821, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4330, loss 0.31932395696640015\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9822, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4331, loss 0.3193219304084778\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9822, 0.0229],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4332, loss 0.31931981444358826\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4333, loss 0.3193177282810211\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4334, loss 0.3193156123161316\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4335, loss 0.31931358575820923\n","outputs:  tensor([[0.0154, 0.9794],\n","        [0.9860, 0.0179],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4336, loss 0.3193114399909973\n","outputs:  tensor([[0.0154, 0.9795],\n","        [0.9860, 0.0179],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4337, loss 0.31930938363075256\n","outputs:  tensor([[0.0154, 0.9795],\n","        [0.9860, 0.0179],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4338, loss 0.3193073272705078\n","outputs:  tensor([[0.0154, 0.9795],\n","        [0.9860, 0.0179],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4339, loss 0.3193052411079407\n","outputs:  tensor([[0.0154, 0.9795],\n","        [0.9860, 0.0179],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4340, loss 0.31930312514305115\n","outputs:  tensor([[0.0154, 0.9795],\n","        [0.9860, 0.0178],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4341, loss 0.3193010687828064\n","outputs:  tensor([[0.0154, 0.9795],\n","        [0.9860, 0.0178],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4342, loss 0.31929898262023926\n","outputs:  tensor([[0.0154, 0.9795],\n","        [0.9860, 0.0178],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4343, loss 0.3192969262599945\n","outputs:  tensor([[0.0154, 0.9795],\n","        [0.9860, 0.0178],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4344, loss 0.31929484009742737\n","outputs:  tensor([[0.0154, 0.9795],\n","        [0.9860, 0.0178],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4345, loss 0.31929272413253784\n","outputs:  tensor([[0.0153, 0.9795],\n","        [0.9861, 0.0178],\n","        [0.9822, 0.0228],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4346, loss 0.3192906975746155\n","outputs:  tensor([[0.0153, 0.9795],\n","        [0.9861, 0.0178],\n","        [0.9822, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4347, loss 0.31928858160972595\n","outputs:  tensor([[0.0153, 0.9795],\n","        [0.9861, 0.0178],\n","        [0.9822, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4348, loss 0.3192865252494812\n","outputs:  tensor([[0.0153, 0.9795],\n","        [0.9861, 0.0178],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4349, loss 0.31928449869155884\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0178],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4350, loss 0.3192823529243469\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0178],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4351, loss 0.31928038597106934\n","Parameter containing:\n","tensor([[-0.3243, -0.7315,  0.1955],\n","        [-1.1160, -0.9278, -0.0754],\n","        [-1.1398, -1.1071, -0.1247],\n","        [-0.5020, -0.5581, -0.0015]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5380, -0.2162,  0.2410,  0.1568], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9423,  0.8559,  1.2614,  0.1930],\n","        [-0.3077, -1.1120, -0.9921, -0.6656]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3931, -0.6395], requires_grad=True)\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0178],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4352, loss 0.3192782402038574\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0178],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4353, loss 0.31927624344825745\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0178],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4354, loss 0.31927409768104553\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0178],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4355, loss 0.3192720413208008\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0178],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4356, loss 0.3192700445652008\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0177],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4357, loss 0.31926798820495605\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0177],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4358, loss 0.3192659020423889\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0177],\n","        [0.9823, 0.0227],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4359, loss 0.31926384568214417\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0177],\n","        [0.9823, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4360, loss 0.3192617893218994\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0177],\n","        [0.9823, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4361, loss 0.31925973296165466\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0177],\n","        [0.9823, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4362, loss 0.3192576467990875\n","outputs:  tensor([[0.0153, 0.9796],\n","        [0.9861, 0.0177],\n","        [0.9823, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4363, loss 0.31925565004348755\n","outputs:  tensor([[0.0153, 0.9797],\n","        [0.9861, 0.0177],\n","        [0.9823, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4364, loss 0.319253534078598\n","outputs:  tensor([[0.0153, 0.9797],\n","        [0.9861, 0.0177],\n","        [0.9823, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3193, grad_fn=<NllLossBackward>)\n","epoch 4365, loss 0.3192515969276428\n","outputs:  tensor([[0.0153, 0.9797],\n","        [0.9861, 0.0177],\n","        [0.9823, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4366, loss 0.3192494511604309\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9861, 0.0177],\n","        [0.9824, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4367, loss 0.31924742460250854\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9862, 0.0177],\n","        [0.9824, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4368, loss 0.3192453980445862\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9862, 0.0177],\n","        [0.9824, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4369, loss 0.31924334168434143\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9862, 0.0177],\n","        [0.9824, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4370, loss 0.3192412853240967\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9862, 0.0177],\n","        [0.9824, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4371, loss 0.31923922896385193\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9862, 0.0177],\n","        [0.9824, 0.0226],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4372, loss 0.31923723220825195\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4373, loss 0.3192351758480072\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4374, loss 0.31923311948776245\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4375, loss 0.3192310929298401\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4376, loss 0.3192290663719177\n","outputs:  tensor([[0.0152, 0.9797],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4377, loss 0.31922703981399536\n","outputs:  tensor([[0.0152, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4378, loss 0.319225013256073\n","outputs:  tensor([[0.0152, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4379, loss 0.31922298669815063\n","outputs:  tensor([[0.0152, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4380, loss 0.3192209303379059\n","outputs:  tensor([[0.0152, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4381, loss 0.3192189037799835\n","outputs:  tensor([[0.0152, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4382, loss 0.31921687722206116\n","outputs:  tensor([[0.0152, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4383, loss 0.3192148208618164\n","outputs:  tensor([[0.0152, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4384, loss 0.3192128539085388\n","outputs:  tensor([[0.0152, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9824, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4385, loss 0.31921079754829407\n","outputs:  tensor([[0.0152, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9825, 0.0225],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4386, loss 0.3192087709903717\n","outputs:  tensor([[0.0151, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4387, loss 0.31920674443244934\n","outputs:  tensor([[0.0151, 0.9798],\n","        [0.9862, 0.0176],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4388, loss 0.31920474767684937\n","outputs:  tensor([[0.0151, 0.9798],\n","        [0.9862, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4389, loss 0.3192026913166046\n","outputs:  tensor([[0.0151, 0.9798],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4390, loss 0.31920066475868225\n","outputs:  tensor([[0.0151, 0.9798],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4391, loss 0.3191986680030823\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4392, loss 0.3191966414451599\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4393, loss 0.31919461488723755\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4394, loss 0.31919264793395996\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0005],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4395, loss 0.3191905617713928\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4396, loss 0.31918859481811523\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4397, loss 0.3191865384578705\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4398, loss 0.3191845715045929\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0224],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4399, loss 0.3191825747489929\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4400, loss 0.31918051838874817\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4401, loss 0.31917861104011536\n","Parameter containing:\n","tensor([[-0.3251, -0.7329,  0.1955],\n","        [-1.1174, -0.9303, -0.0754],\n","        [-1.1414, -1.1099, -0.1247],\n","        [-0.5027, -0.5592, -0.0015]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5385, -0.2152,  0.2420,  0.1573], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9435,  0.8575,  1.2634,  0.1940],\n","        [-0.3093, -1.1141, -0.9947, -0.6669]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3935, -0.6400], requires_grad=True)\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9991]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4402, loss 0.3191765546798706\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4403, loss 0.31917452812194824\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0175],\n","        [0.9825, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4404, loss 0.31917253136634827\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0174],\n","        [0.9826, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4405, loss 0.3191705346107483\n","outputs:  tensor([[0.0151, 0.9799],\n","        [0.9863, 0.0174],\n","        [0.9826, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4406, loss 0.3191685378551483\n","outputs:  tensor([[0.0151, 0.9800],\n","        [0.9863, 0.0174],\n","        [0.9826, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4407, loss 0.31916651129722595\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9863, 0.0174],\n","        [0.9826, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4408, loss 0.31916454434394836\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9863, 0.0174],\n","        [0.9826, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4409, loss 0.3191625475883484\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9863, 0.0174],\n","        [0.9826, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4410, loss 0.3191605508327484\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9863, 0.0174],\n","        [0.9826, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4411, loss 0.31915855407714844\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9864, 0.0174],\n","        [0.9826, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4412, loss 0.31915658712387085\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9864, 0.0174],\n","        [0.9826, 0.0223],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4413, loss 0.3191545903682709\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9864, 0.0174],\n","        [0.9826, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4414, loss 0.3191525936126709\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9864, 0.0174],\n","        [0.9826, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3192, grad_fn=<NllLossBackward>)\n","epoch 4415, loss 0.3191505968570709\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9864, 0.0174],\n","        [0.9826, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4416, loss 0.31914862990379333\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9864, 0.0174],\n","        [0.9826, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4417, loss 0.31914663314819336\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9864, 0.0174],\n","        [0.9826, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4418, loss 0.31914466619491577\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9864, 0.0174],\n","        [0.9826, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4419, loss 0.3191426396369934\n","outputs:  tensor([[0.0150, 0.9800],\n","        [0.9864, 0.0174],\n","        [0.9826, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4420, loss 0.3191406726837158\n","outputs:  tensor([[0.0150, 0.9801],\n","        [0.9864, 0.0174],\n","        [0.9826, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4421, loss 0.31913867592811584\n","outputs:  tensor([[0.0150, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9826, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4422, loss 0.31913670897483826\n","outputs:  tensor([[0.0150, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9826, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4423, loss 0.31913480162620544\n","outputs:  tensor([[0.0150, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4424, loss 0.3191327452659607\n","outputs:  tensor([[0.0150, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4425, loss 0.3191307783126831\n","outputs:  tensor([[0.0150, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4426, loss 0.31912875175476074\n","outputs:  tensor([[0.0150, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0222],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4427, loss 0.31912684440612793\n","outputs:  tensor([[0.0150, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4428, loss 0.3191247880458832\n","outputs:  tensor([[0.0149, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4429, loss 0.319122850894928\n","outputs:  tensor([[0.0149, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4430, loss 0.31912094354629517\n","outputs:  tensor([[0.0149, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4431, loss 0.3191189467906952\n","outputs:  tensor([[0.0149, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4432, loss 0.31911700963974\n","outputs:  tensor([[0.0149, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4433, loss 0.3191149830818176\n","outputs:  tensor([[0.0149, 0.9801],\n","        [0.9864, 0.0173],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4434, loss 0.3191130459308624\n","outputs:  tensor([[0.0149, 0.9801],\n","        [0.9865, 0.0173],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4435, loss 0.31911107897758484\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0173],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4436, loss 0.31910914182662964\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0173],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4437, loss 0.3191071152687073\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4438, loss 0.3191051781177521\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4439, loss 0.3191032111644745\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4440, loss 0.3191012740135193\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9827, 0.0221],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4441, loss 0.3190992772579193\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9827, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4442, loss 0.3190973401069641\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4443, loss 0.3190954327583313\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4444, loss 0.31909340620040894\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4445, loss 0.3190914988517761\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4446, loss 0.31908953189849854\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4447, loss 0.31908756494522095\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4448, loss 0.31908559799194336\n","outputs:  tensor([[0.0149, 0.9802],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4449, loss 0.31908369064331055\n","outputs:  tensor([[0.0149, 0.9803],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4450, loss 0.31908172369003296\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4451, loss 0.31907978653907776\n","Parameter containing:\n","tensor([[-0.3260, -0.7344,  0.1955],\n","        [-1.1188, -0.9328, -0.0754],\n","        [-1.1429, -1.1126, -0.1247],\n","        [-0.5033, -0.5604, -0.0015]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5391, -0.2143,  0.2431,  0.1577], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9448,  0.8591,  1.2654,  0.1950],\n","        [-0.3108, -1.1161, -0.9973, -0.6681]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3940, -0.6405], requires_grad=True)\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4452, loss 0.31907781958580017\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4453, loss 0.31907588243484497\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9865, 0.0172],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4454, loss 0.3190739154815674\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9865, 0.0171],\n","        [0.9828, 0.0220],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4455, loss 0.31907200813293457\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9865, 0.0171],\n","        [0.9828, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4456, loss 0.319070041179657\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9865, 0.0171],\n","        [0.9828, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4457, loss 0.3190681040287018\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9866, 0.0171],\n","        [0.9828, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4458, loss 0.31906619668006897\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9866, 0.0171],\n","        [0.9828, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4459, loss 0.31906428933143616\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9866, 0.0171],\n","        [0.9828, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4460, loss 0.3190622925758362\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9866, 0.0171],\n","        [0.9828, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4461, loss 0.3190603256225586\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9866, 0.0171],\n","        [0.9829, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4462, loss 0.3190584182739258\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9866, 0.0171],\n","        [0.9829, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4463, loss 0.3190564513206482\n","outputs:  tensor([[0.0148, 0.9803],\n","        [0.9866, 0.0171],\n","        [0.9829, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4464, loss 0.31905460357666016\n","outputs:  tensor([[0.0148, 0.9804],\n","        [0.9866, 0.0171],\n","        [0.9829, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4465, loss 0.31905263662338257\n","outputs:  tensor([[0.0148, 0.9804],\n","        [0.9866, 0.0171],\n","        [0.9829, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0009, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3191, grad_fn=<NllLossBackward>)\n","epoch 4466, loss 0.31905069947242737\n","outputs:  tensor([[0.0148, 0.9804],\n","        [0.9866, 0.0171],\n","        [0.9829, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4467, loss 0.31904882192611694\n","outputs:  tensor([[0.0148, 0.9804],\n","        [0.9866, 0.0171],\n","        [0.9829, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4468, loss 0.31904688477516174\n","outputs:  tensor([[0.0148, 0.9804],\n","        [0.9866, 0.0171],\n","        [0.9829, 0.0219],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4469, loss 0.31904491782188416\n","outputs:  tensor([[0.0148, 0.9804],\n","        [0.9866, 0.0171],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4470, loss 0.31904301047325134\n","outputs:  tensor([[0.0148, 0.9804],\n","        [0.9866, 0.0171],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4471, loss 0.31904107332229614\n","outputs:  tensor([[0.0147, 0.9804],\n","        [0.9866, 0.0170],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4472, loss 0.31903916597366333\n","outputs:  tensor([[0.0147, 0.9804],\n","        [0.9866, 0.0170],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4473, loss 0.31903719902038574\n","outputs:  tensor([[0.0147, 0.9804],\n","        [0.9866, 0.0170],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4474, loss 0.31903529167175293\n","outputs:  tensor([[0.0147, 0.9804],\n","        [0.9866, 0.0170],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4475, loss 0.3190334439277649\n","outputs:  tensor([[0.0147, 0.9804],\n","        [0.9866, 0.0170],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4476, loss 0.3190315365791321\n","outputs:  tensor([[0.0147, 0.9804],\n","        [0.9866, 0.0170],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4477, loss 0.3190295696258545\n","outputs:  tensor([[0.0147, 0.9804],\n","        [0.9866, 0.0170],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4478, loss 0.3190276622772217\n","outputs:  tensor([[0.0147, 0.9804],\n","        [0.9866, 0.0170],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4479, loss 0.31902575492858887\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9866, 0.0170],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4480, loss 0.3190237879753113\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0170],\n","        [0.9829, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4481, loss 0.31902194023132324\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0170],\n","        [0.9830, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4482, loss 0.31901997327804565\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0170],\n","        [0.9830, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4483, loss 0.31901806592941284\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0170],\n","        [0.9830, 0.0218],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4484, loss 0.31901615858078003\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0170],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4485, loss 0.3190142512321472\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0170],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4486, loss 0.3190123438835144\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0170],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4487, loss 0.31901049613952637\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0170],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4488, loss 0.3190084993839264\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4489, loss 0.31900662183761597\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4490, loss 0.31900477409362793\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4491, loss 0.31900277733802795\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4492, loss 0.31900089979171753\n","outputs:  tensor([[0.0147, 0.9805],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4493, loss 0.3189990520477295\n","outputs:  tensor([[0.0146, 0.9805],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4494, loss 0.3189971446990967\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4495, loss 0.31899523735046387\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4496, loss 0.31899333000183105\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4497, loss 0.31899142265319824\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0217],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4498, loss 0.3189895749092102\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4499, loss 0.3189876973628998\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4500, loss 0.3189857602119446\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9867, 0.0169],\n","        [0.9830, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4501, loss 0.31898388266563416\n","Parameter containing:\n","tensor([[-0.3268, -0.7358,  0.1955],\n","        [-1.1202, -0.9352, -0.0754],\n","        [-1.1445, -1.1153, -0.1247],\n","        [-0.5039, -0.5615, -0.0015]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5396, -0.2134,  0.2441,  0.1581], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9459,  0.8607,  1.2674,  0.1959],\n","        [-0.3124, -1.1182, -0.9998, -0.6694]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3944, -0.6410], requires_grad=True)\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9867, 0.0169],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4502, loss 0.31898197531700134\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9867, 0.0169],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4503, loss 0.31898006796836853\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9867, 0.0169],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4504, loss 0.3189782202243805\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9868, 0.0169],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4505, loss 0.3189763128757477\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9868, 0.0169],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4506, loss 0.31897443532943726\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4507, loss 0.3189725875854492\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4508, loss 0.31897062063217163\n","outputs:  tensor([[0.0146, 0.9806],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4509, loss 0.3189687728881836\n","outputs:  tensor([[0.0146, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4510, loss 0.31896692514419556\n","outputs:  tensor([[0.0146, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4511, loss 0.31896501779556274\n","outputs:  tensor([[0.0146, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4512, loss 0.3189631402492523\n","outputs:  tensor([[0.0146, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0216],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4513, loss 0.3189612925052643\n","outputs:  tensor([[0.0146, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4514, loss 0.31895941495895386\n","outputs:  tensor([[0.0146, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4515, loss 0.31895750761032104\n","outputs:  tensor([[0.0145, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4516, loss 0.318955659866333\n","outputs:  tensor([[0.0145, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4517, loss 0.31895381212234497\n","outputs:  tensor([[0.0145, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4518, loss 0.31895193457603455\n","outputs:  tensor([[0.0145, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3190, grad_fn=<NllLossBackward>)\n","epoch 4519, loss 0.31895002722740173\n","outputs:  tensor([[0.0145, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4520, loss 0.3189481198787689\n","outputs:  tensor([[0.0145, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9831, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4521, loss 0.31894630193710327\n","outputs:  tensor([[0.0145, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9832, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4522, loss 0.31894445419311523\n","outputs:  tensor([[0.0145, 0.9807],\n","        [0.9868, 0.0168],\n","        [0.9832, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4523, loss 0.3189425468444824\n","outputs:  tensor([[0.0145, 0.9807],\n","        [0.9868, 0.0167],\n","        [0.9832, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4524, loss 0.3189406991004944\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9868, 0.0167],\n","        [0.9832, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4525, loss 0.31893882155418396\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9868, 0.0167],\n","        [0.9832, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4526, loss 0.31893691420555115\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9868, 0.0167],\n","        [0.9832, 0.0215],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4527, loss 0.3189350962638855\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9868, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4528, loss 0.31893324851989746\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4529, loss 0.3189314007759094\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4530, loss 0.318929523229599\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4531, loss 0.31892767548561096\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4532, loss 0.31892579793930054\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4533, loss 0.3189239799976349\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4534, loss 0.31892210245132446\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4535, loss 0.3189202547073364\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4536, loss 0.3189184069633484\n","outputs:  tensor([[0.0145, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4537, loss 0.3189164996147156\n","outputs:  tensor([[0.0144, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4538, loss 0.3189147114753723\n","outputs:  tensor([[0.0144, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4539, loss 0.3189128339290619\n","outputs:  tensor([[0.0144, 0.9808],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4540, loss 0.31891101598739624\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0167],\n","        [0.9832, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4541, loss 0.3189091086387634\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0214],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4542, loss 0.31890735030174255\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4543, loss 0.31890544295310974\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4544, loss 0.3189035952091217\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4545, loss 0.31890180706977844\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4546, loss 0.318899929523468\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4547, loss 0.31889811158180237\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4548, loss 0.31889623403549194\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4549, loss 0.3188944160938263\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4550, loss 0.31889256834983826\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4551, loss 0.3188907504081726\n","Parameter containing:\n","tensor([[-0.3276, -0.7372,  0.1955],\n","        [-1.1216, -0.9376, -0.0753],\n","        [-1.1460, -1.1180, -0.1246],\n","        [-0.5046, -0.5626, -0.0015]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5402, -0.2124,  0.2451,  0.1585], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9471,  0.8622,  1.2693,  0.1969],\n","        [-0.3139, -1.1202, -1.0023, -0.6706]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3948, -0.6415], requires_grad=True)\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9869, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4552, loss 0.31888893246650696\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9870, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4553, loss 0.3188870847225189\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9870, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4554, loss 0.3188852369785309\n","outputs:  tensor([[0.0144, 0.9809],\n","        [0.9870, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4555, loss 0.31888335943222046\n","outputs:  tensor([[0.0144, 0.9810],\n","        [0.9870, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4556, loss 0.3188815712928772\n","outputs:  tensor([[0.0144, 0.9810],\n","        [0.9870, 0.0166],\n","        [0.9833, 0.0213],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4557, loss 0.31887978315353394\n","outputs:  tensor([[0.0144, 0.9810],\n","        [0.9870, 0.0166],\n","        [0.9833, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4558, loss 0.3188779354095459\n","outputs:  tensor([[0.0144, 0.9810],\n","        [0.9870, 0.0166],\n","        [0.9833, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4559, loss 0.31887608766555786\n","outputs:  tensor([[0.0144, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9833, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4560, loss 0.3188742697238922\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9833, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4561, loss 0.3188724219799042\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4562, loss 0.3188706040382385\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4563, loss 0.31886881589889526\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4564, loss 0.3188669681549072\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4565, loss 0.3188651204109192\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4566, loss 0.3188633322715759\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4567, loss 0.3188614845275879\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4568, loss 0.31885963678359985\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4569, loss 0.3188578486442566\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4570, loss 0.3188560903072357\n","outputs:  tensor([[0.0143, 0.9810],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4571, loss 0.31885427236557007\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0212],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4572, loss 0.31885239481925964\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3189, grad_fn=<NllLossBackward>)\n","epoch 4573, loss 0.318850576877594\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4574, loss 0.31884875893592834\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4575, loss 0.3188469707965851\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4576, loss 0.3188451826572418\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9870, 0.0165],\n","        [0.9834, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4577, loss 0.31884336471557617\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9871, 0.0164],\n","        [0.9834, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4578, loss 0.3188416063785553\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9871, 0.0164],\n","        [0.9834, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4579, loss 0.3188397288322449\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9871, 0.0164],\n","        [0.9834, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4580, loss 0.3188379406929016\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9871, 0.0164],\n","        [0.9834, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4581, loss 0.31883612275123596\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9871, 0.0164],\n","        [0.9834, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4582, loss 0.3188343346118927\n","outputs:  tensor([[0.0143, 0.9811],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4583, loss 0.31883251667022705\n","outputs:  tensor([[0.0142, 0.9811],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4584, loss 0.3188307583332062\n","outputs:  tensor([[0.0142, 0.9811],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4585, loss 0.3188289403915405\n","outputs:  tensor([[0.0142, 0.9811],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4586, loss 0.3188271224498749\n","outputs:  tensor([[0.0142, 0.9811],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0211],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4587, loss 0.31882530450820923\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4588, loss 0.31882351636886597\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4589, loss 0.3188217282295227\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4590, loss 0.31881994009017944\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4591, loss 0.3188180923461914\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4592, loss 0.31881633400917053\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4593, loss 0.31881454586982727\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4594, loss 0.3188127875328064\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0164],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4595, loss 0.31881099939346313\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0163],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4596, loss 0.3188091516494751\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0163],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4597, loss 0.3188073933124542\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0163],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4598, loss 0.31880560517311096\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0163],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4599, loss 0.3188038468360901\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0163],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4600, loss 0.31880196928977966\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0163],\n","        [0.9835, 0.0210],\n","        [0.9997, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4601, loss 0.31880027055740356\n","Parameter containing:\n","tensor([[-0.3284, -0.7386,  0.1955],\n","        [-1.1229, -0.9400, -0.0753],\n","        [-1.1475, -1.1206, -0.1246],\n","        [-0.5052, -0.5637, -0.0014]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5407, -0.2115,  0.2461,  0.1589], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9483,  0.8638,  1.2712,  0.1978],\n","        [-0.3154, -1.1221, -1.0048, -0.6718]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3952, -0.6420], requires_grad=True)\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9871, 0.0163],\n","        [0.9835, 0.0210],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4602, loss 0.3187984824180603\n","outputs:  tensor([[0.0142, 0.9812],\n","        [0.9872, 0.0163],\n","        [0.9835, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4603, loss 0.31879669427871704\n","outputs:  tensor([[0.0142, 0.9813],\n","        [0.9872, 0.0163],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4604, loss 0.31879493594169617\n","outputs:  tensor([[0.0142, 0.9813],\n","        [0.9872, 0.0163],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4605, loss 0.3187931180000305\n","outputs:  tensor([[0.0142, 0.9813],\n","        [0.9872, 0.0163],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4606, loss 0.31879132986068726\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0163],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4607, loss 0.31878960132598877\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0163],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4608, loss 0.31878775358200073\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0163],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4609, loss 0.31878599524497986\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0163],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4610, loss 0.3187841773033142\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0163],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4611, loss 0.3187824487686157\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0163],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4612, loss 0.31878066062927246\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0163],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4613, loss 0.318778932094574\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4614, loss 0.3187771439552307\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4615, loss 0.31877535581588745\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4616, loss 0.3187735676765442\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4617, loss 0.3187718391418457\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0209],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4618, loss 0.31876999139785767\n","outputs:  tensor([[0.0141, 0.9813],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4619, loss 0.31876832246780396\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4620, loss 0.3187665343284607\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4621, loss 0.31876474618911743\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4622, loss 0.31876298785209656\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4623, loss 0.31876125931739807\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9872, 0.0162],\n","        [0.9836, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4624, loss 0.3187594711780548\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9872, 0.0162],\n","        [0.9837, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4625, loss 0.31875771284103394\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9872, 0.0162],\n","        [0.9837, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4626, loss 0.31875595450401306\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9872, 0.0162],\n","        [0.9837, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4627, loss 0.3187541961669922\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9873, 0.0162],\n","        [0.9837, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4628, loss 0.3187524378299713\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9873, 0.0162],\n","        [0.9837, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3188, grad_fn=<NllLossBackward>)\n","epoch 4629, loss 0.31875067949295044\n","outputs:  tensor([[0.0141, 0.9814],\n","        [0.9873, 0.0162],\n","        [0.9837, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4630, loss 0.31874895095825195\n","outputs:  tensor([[0.0140, 0.9814],\n","        [0.9873, 0.0162],\n","        [0.9837, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9992]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4631, loss 0.3187471926212311\n","outputs:  tensor([[0.0140, 0.9814],\n","        [0.9873, 0.0162],\n","        [0.9837, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4632, loss 0.3187454342842102\n","outputs:  tensor([[0.0140, 0.9814],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0208],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4633, loss 0.31874364614486694\n","outputs:  tensor([[0.0140, 0.9814],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4634, loss 0.31874188780784607\n","outputs:  tensor([[0.0140, 0.9814],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4635, loss 0.31874018907546997\n","outputs:  tensor([[0.0140, 0.9814],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4636, loss 0.3187384605407715\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4637, loss 0.31873664259910583\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4638, loss 0.31873494386672974\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4639, loss 0.3187331557273865\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4640, loss 0.3187314569950104\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4641, loss 0.3187296986579895\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4642, loss 0.31872791051864624\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4643, loss 0.31872621178627014\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4644, loss 0.31872445344924927\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9837, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4645, loss 0.3187227249145508\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9838, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4646, loss 0.3187209963798523\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9838, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4647, loss 0.3187192380428314\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9838, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4648, loss 0.3187175393104553\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9838, 0.0207],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4649, loss 0.31871581077575684\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4650, loss 0.31871405243873596\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0161],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4651, loss 0.3187122344970703\n","Parameter containing:\n","tensor([[-0.3291, -0.7400,  0.1955],\n","        [-1.1242, -0.9423, -0.0753],\n","        [-1.1490, -1.1232, -0.1246],\n","        [-0.5058, -0.5647, -0.0014]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5412, -0.2107,  0.2471,  0.1593], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9494,  0.8653,  1.2731,  0.1988],\n","        [-0.3168, -1.1241, -1.0072, -0.6730]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3956, -0.6425], requires_grad=True)\n","outputs:  tensor([[0.0140, 0.9815],\n","        [0.9873, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4652, loss 0.3187105655670166\n","outputs:  tensor([[0.0140, 0.9816],\n","        [0.9873, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4653, loss 0.3187088370323181\n","outputs:  tensor([[0.0140, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4654, loss 0.31870707869529724\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4655, loss 0.31870537996292114\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4656, loss 0.31870365142822266\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4657, loss 0.3187018930912018\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4658, loss 0.3187001645565033\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4659, loss 0.3186984062194824\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4660, loss 0.3186967372894287\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4661, loss 0.31869497895240784\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4662, loss 0.31869325041770935\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4663, loss 0.31869155168533325\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4664, loss 0.31868988275527954\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0206],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4665, loss 0.3186880946159363\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4666, loss 0.3186863958835602\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9838, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4667, loss 0.3186846673488617\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4668, loss 0.3186829686164856\n","outputs:  tensor([[0.0139, 0.9816],\n","        [0.9874, 0.0160],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4669, loss 0.3186812400817871\n","outputs:  tensor([[0.0139, 0.9817],\n","        [0.9874, 0.0160],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4670, loss 0.3186795115470886\n","outputs:  tensor([[0.0139, 0.9817],\n","        [0.9874, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4671, loss 0.3186778128147125\n","outputs:  tensor([[0.0139, 0.9817],\n","        [0.9874, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4672, loss 0.31867608428001404\n","outputs:  tensor([[0.0139, 0.9817],\n","        [0.9874, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4673, loss 0.31867432594299316\n","outputs:  tensor([[0.0139, 0.9817],\n","        [0.9874, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4674, loss 0.31867265701293945\n","outputs:  tensor([[0.0139, 0.9817],\n","        [0.9874, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4675, loss 0.31867092847824097\n","outputs:  tensor([[0.0139, 0.9817],\n","        [0.9874, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4676, loss 0.31866922974586487\n","outputs:  tensor([[0.0139, 0.9817],\n","        [0.9874, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4677, loss 0.31866756081581116\n","outputs:  tensor([[0.0139, 0.9817],\n","        [0.9874, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4678, loss 0.31866583228111267\n","outputs:  tensor([[0.0138, 0.9817],\n","        [0.9874, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4679, loss 0.3186641335487366\n","outputs:  tensor([[0.0138, 0.9817],\n","        [0.9875, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4680, loss 0.3186624050140381\n","outputs:  tensor([[0.0138, 0.9817],\n","        [0.9875, 0.0159],\n","        [0.9839, 0.0205],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4681, loss 0.3186606764793396\n","outputs:  tensor([[0.0138, 0.9817],\n","        [0.9875, 0.0159],\n","        [0.9839, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4682, loss 0.3186589777469635\n","outputs:  tensor([[0.0138, 0.9817],\n","        [0.9875, 0.0159],\n","        [0.9839, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4683, loss 0.3186573088169098\n","outputs:  tensor([[0.0138, 0.9817],\n","        [0.9875, 0.0159],\n","        [0.9839, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4684, loss 0.3186555802822113\n","outputs:  tensor([[0.0138, 0.9817],\n","        [0.9875, 0.0159],\n","        [0.9839, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4685, loss 0.31865397095680237\n","outputs:  tensor([[0.0138, 0.9817],\n","        [0.9875, 0.0159],\n","        [0.9839, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4686, loss 0.3186521530151367\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0159],\n","        [0.9839, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3187, grad_fn=<NllLossBackward>)\n","epoch 4687, loss 0.3186505436897278\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0159],\n","        [0.9839, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4688, loss 0.3186487555503845\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0159],\n","        [0.9839, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4689, loss 0.3186470568180084\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4690, loss 0.3186453878879547\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4691, loss 0.3186436593532562\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4692, loss 0.3186419904232025\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4693, loss 0.3186402916908264\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4694, loss 0.3186386227607727\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4695, loss 0.3186368942260742\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4696, loss 0.3186352252960205\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0204],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4697, loss 0.318633496761322\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4698, loss 0.3186318278312683\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4699, loss 0.3186301589012146\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4700, loss 0.3186284601688385\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4701, loss 0.31862673163414\n","Parameter containing:\n","tensor([[-0.3299, -0.7413,  0.1955],\n","        [-1.1255, -0.9446, -0.0753],\n","        [-1.1504, -1.1258, -0.1246],\n","        [-0.5064, -0.5658, -0.0014]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5417, -0.2098,  0.2481,  0.1597], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9506,  0.8668,  1.2750,  0.1997],\n","        [-0.3183, -1.1260, -1.0096, -0.6741]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3960, -0.6430], requires_grad=True)\n","outputs:  tensor([[0.0138, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4702, loss 0.3186251223087311\n","outputs:  tensor([[0.0137, 0.9818],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4703, loss 0.31862345337867737\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4704, loss 0.31862178444862366\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9875, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4705, loss 0.31862005591392517\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4706, loss 0.31861838698387146\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4707, loss 0.31861671805381775\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0158],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4708, loss 0.3186149597167969\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4709, loss 0.31861329078674316\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4710, loss 0.31861168146133423\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9840, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4711, loss 0.31860995292663574\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4712, loss 0.3186083436012268\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0203],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4713, loss 0.3186066150665283\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4714, loss 0.31860488653182983\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4715, loss 0.3186032176017761\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4716, loss 0.3186015486717224\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4717, loss 0.3185999393463135\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4718, loss 0.31859827041625977\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4719, loss 0.3185965418815613\n","outputs:  tensor([[0.0137, 0.9819],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4720, loss 0.31859493255615234\n","outputs:  tensor([[0.0137, 0.9820],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4721, loss 0.31859326362609863\n","outputs:  tensor([[0.0137, 0.9820],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4722, loss 0.3185915946960449\n","outputs:  tensor([[0.0137, 0.9820],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4723, loss 0.31858986616134644\n","outputs:  tensor([[0.0137, 0.9820],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4724, loss 0.3185882568359375\n","outputs:  tensor([[0.0137, 0.9820],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0008, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4725, loss 0.318586528301239\n","outputs:  tensor([[0.0137, 0.9820],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4726, loss 0.3185849189758301\n","outputs:  tensor([[0.0137, 0.9820],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4727, loss 0.31858325004577637\n","outputs:  tensor([[0.0136, 0.9820],\n","        [0.9876, 0.0157],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4728, loss 0.31858164072036743\n","outputs:  tensor([[0.0136, 0.9820],\n","        [0.9876, 0.0156],\n","        [0.9841, 0.0202],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4729, loss 0.31857991218566895\n","outputs:  tensor([[0.0136, 0.9820],\n","        [0.9876, 0.0156],\n","        [0.9841, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4730, loss 0.3185783326625824\n","outputs:  tensor([[0.0136, 0.9820],\n","        [0.9876, 0.0156],\n","        [0.9841, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4731, loss 0.3185765743255615\n","outputs:  tensor([[0.0136, 0.9820],\n","        [0.9876, 0.0156],\n","        [0.9841, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4732, loss 0.3185749650001526\n","outputs:  tensor([[0.0136, 0.9820],\n","        [0.9877, 0.0156],\n","        [0.9841, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4733, loss 0.3185732364654541\n","outputs:  tensor([[0.0136, 0.9820],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4734, loss 0.31857162714004517\n","outputs:  tensor([[0.0136, 0.9820],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4735, loss 0.31856998801231384\n","outputs:  tensor([[0.0136, 0.9820],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4736, loss 0.3185683488845825\n","outputs:  tensor([[0.0136, 0.9820],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4737, loss 0.3185666501522064\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4738, loss 0.3185650408267975\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4739, loss 0.3185633718967438\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4740, loss 0.31856170296669006\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4741, loss 0.31856009364128113\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4742, loss 0.31855839490890503\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4743, loss 0.3185567855834961\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4744, loss 0.3185551166534424\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4745, loss 0.31855344772338867\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0201],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4746, loss 0.31855183839797974\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3186, grad_fn=<NllLossBackward>)\n","epoch 4747, loss 0.318550169467926\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0156],\n","        [0.9842, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4748, loss 0.3185485303401947\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0155],\n","        [0.9842, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4749, loss 0.31854695081710815\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0155],\n","        [0.9842, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4750, loss 0.31854525208473206\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0155],\n","        [0.9842, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4751, loss 0.31854361295700073\n","Parameter containing:\n","tensor([[-0.3307, -0.7427,  0.1955],\n","        [-1.1268, -0.9469, -0.0753],\n","        [-1.1519, -1.1283, -0.1246],\n","        [-0.5070, -0.5668, -0.0014]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5423, -0.2089,  0.2491,  0.1601], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9517,  0.8683,  1.2769,  0.2006],\n","        [-0.3197, -1.1279, -1.0119, -0.6753]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3963, -0.6435], requires_grad=True)\n","outputs:  tensor([[0.0136, 0.9821],\n","        [0.9877, 0.0155],\n","        [0.9842, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4752, loss 0.3185420036315918\n","outputs:  tensor([[0.0135, 0.9821],\n","        [0.9877, 0.0155],\n","        [0.9842, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4753, loss 0.3185403048992157\n","outputs:  tensor([[0.0135, 0.9821],\n","        [0.9877, 0.0155],\n","        [0.9842, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4754, loss 0.31853872537612915\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9877, 0.0155],\n","        [0.9842, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4755, loss 0.31853705644607544\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9877, 0.0155],\n","        [0.9842, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4756, loss 0.3185354769229889\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9877, 0.0155],\n","        [0.9843, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4757, loss 0.3185337781906128\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9877, 0.0155],\n","        [0.9843, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4758, loss 0.31853216886520386\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9877, 0.0155],\n","        [0.9843, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4759, loss 0.3185305595397949\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0155],\n","        [0.9843, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4760, loss 0.3185288608074188\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0155],\n","        [0.9843, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4761, loss 0.3185272812843323\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0155],\n","        [0.9843, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4762, loss 0.31852561235427856\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0155],\n","        [0.9843, 0.0200],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4763, loss 0.31852400302886963\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0155],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4764, loss 0.3185223639011383\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0155],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4765, loss 0.31852075457572937\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0155],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4766, loss 0.31851908564567566\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0155],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4767, loss 0.3185174763202667\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0155],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4768, loss 0.3185158669948578\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4769, loss 0.3185141980648041\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4770, loss 0.31851261854171753\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4771, loss 0.3185110092163086\n","outputs:  tensor([[0.0135, 0.9822],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4772, loss 0.31850939989089966\n","outputs:  tensor([[0.0135, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4773, loss 0.31850773096084595\n","outputs:  tensor([[0.0135, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4774, loss 0.3185061812400818\n","outputs:  tensor([[0.0135, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4775, loss 0.3185045123100281\n","outputs:  tensor([[0.0135, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4776, loss 0.31850287318229675\n","outputs:  tensor([[0.0135, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4777, loss 0.3185012638568878\n","outputs:  tensor([[0.0135, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4778, loss 0.3184996545314789\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9843, 0.0199],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4779, loss 0.31849804520606995\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4780, loss 0.318496435880661\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4781, loss 0.3184948265552521\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4782, loss 0.31849321722984314\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4783, loss 0.3184915781021118\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4784, loss 0.31848999857902527\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4785, loss 0.31848832964897156\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4786, loss 0.3184867799282074\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9878, 0.0154],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4787, loss 0.31848523020744324\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9879, 0.0154],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4788, loss 0.31848353147506714\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4789, loss 0.3184819519519806\n","outputs:  tensor([[0.0134, 0.9823],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4790, loss 0.31848031282424927\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4791, loss 0.3184787333011627\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4792, loss 0.3184770941734314\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4793, loss 0.31847551465034485\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0004],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4794, loss 0.3184738755226135\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4795, loss 0.3184722661972046\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0198],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4796, loss 0.31847071647644043\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4797, loss 0.3184690773487091\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4798, loss 0.31846755743026733\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4799, loss 0.3184658885002136\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4800, loss 0.31846433877944946\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4801, loss 0.31846269965171814\n","Parameter containing:\n","tensor([[-0.3314, -0.7440,  0.1955],\n","        [-1.1281, -0.9491, -0.0753],\n","        [-1.1533, -1.1308, -0.1246],\n","        [-0.5076, -0.5679, -0.0014]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5428, -0.2081,  0.2500,  0.1605], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9528,  0.8697,  1.2787,  0.2015],\n","        [-0.3211, -1.1297, -1.0142, -0.6764]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3967, -0.6439], requires_grad=True)\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9844, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4802, loss 0.318461149930954\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4803, loss 0.31845951080322266\n","outputs:  tensor([[0.0134, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4804, loss 0.3184579312801361\n","outputs:  tensor([[0.0133, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4805, loss 0.31845635175704956\n","outputs:  tensor([[0.0133, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4806, loss 0.318454772233963\n","outputs:  tensor([[0.0133, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4807, loss 0.3184531331062317\n","outputs:  tensor([[0.0133, 0.9824],\n","        [0.9879, 0.0153],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3185, grad_fn=<NllLossBackward>)\n","epoch 4808, loss 0.31845152378082275\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9879, 0.0153],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4809, loss 0.3184499740600586\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9879, 0.0152],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4810, loss 0.31844839453697205\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9879, 0.0152],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4811, loss 0.3184467852115631\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9879, 0.0152],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4812, loss 0.3184451758861542\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9879, 0.0152],\n","        [0.9845, 0.0197],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4813, loss 0.3184435963630676\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9879, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4814, loss 0.31844204664230347\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9879, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4815, loss 0.3184404969215393\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4816, loss 0.318438857793808\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4817, loss 0.31843727827072144\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4818, loss 0.3184356689453125\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4819, loss 0.31843411922454834\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4820, loss 0.3184325397014618\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4821, loss 0.31843096017837524\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4822, loss 0.3184294104576111\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4823, loss 0.31842783093452454\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4824, loss 0.3184262216091156\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9845, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4825, loss 0.31842464208602905\n","outputs:  tensor([[0.0133, 0.9825],\n","        [0.9880, 0.0152],\n","        [0.9846, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4826, loss 0.3184230923652649\n","outputs:  tensor([[0.0133, 0.9826],\n","        [0.9880, 0.0152],\n","        [0.9846, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4827, loss 0.31842148303985596\n","outputs:  tensor([[0.0133, 0.9826],\n","        [0.9880, 0.0152],\n","        [0.9846, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4828, loss 0.3184199631214142\n","outputs:  tensor([[0.0133, 0.9826],\n","        [0.9880, 0.0152],\n","        [0.9846, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4829, loss 0.31841835379600525\n","outputs:  tensor([[0.0133, 0.9826],\n","        [0.9880, 0.0152],\n","        [0.9846, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4830, loss 0.3184167742729187\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0196],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4831, loss 0.31841522455215454\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4832, loss 0.318413645029068\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4833, loss 0.31841206550598145\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4834, loss 0.3184105157852173\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4835, loss 0.3184089958667755\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4836, loss 0.3184073865413666\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4837, loss 0.31840580701828003\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4838, loss 0.31840425729751587\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4839, loss 0.3184026777744293\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4840, loss 0.31840115785598755\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4841, loss 0.3183995187282562\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4842, loss 0.31839799880981445\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9880, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4843, loss 0.3183964192867279\n","outputs:  tensor([[0.0132, 0.9826],\n","        [0.9881, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4844, loss 0.31839486956596375\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4845, loss 0.3183932900428772\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4846, loss 0.31839174032211304\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4847, loss 0.3183901906013489\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0151],\n","        [0.9846, 0.0195],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4848, loss 0.3183886408805847\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0151],\n","        [0.9846, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4849, loss 0.31838706135749817\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0151],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4850, loss 0.3183855414390564\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0151],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4851, loss 0.31838396191596985\n","Parameter containing:\n","tensor([[-0.3322, -0.7453,  0.1955],\n","        [-1.1293, -0.9513, -0.0752],\n","        [-1.1547, -1.1333, -0.1246],\n","        [-0.5081, -0.5689, -0.0014]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5433, -0.2072,  0.2510,  0.1609], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9539,  0.8712,  1.2805,  0.2023],\n","        [-0.3225, -1.1316, -1.0165, -0.6775]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3971, -0.6444], requires_grad=True)\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4852, loss 0.3183824419975281\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4853, loss 0.3183808922767639\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4854, loss 0.31837934255599976\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4855, loss 0.31837767362594604\n","outputs:  tensor([[0.0132, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4856, loss 0.31837624311447144\n","outputs:  tensor([[0.0131, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4857, loss 0.3183746933937073\n","outputs:  tensor([[0.0131, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4858, loss 0.3183731436729431\n","outputs:  tensor([[0.0131, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4859, loss 0.3183715343475342\n","outputs:  tensor([[0.0131, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4860, loss 0.3183700144290924\n","outputs:  tensor([[0.0131, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4861, loss 0.31836849451065063\n","outputs:  tensor([[0.0131, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4862, loss 0.3183669447898865\n","outputs:  tensor([[0.0131, 0.9827],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4863, loss 0.3183653950691223\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4864, loss 0.31836384534835815\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4865, loss 0.3183623254299164\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0194],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4866, loss 0.31836074590682983\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4867, loss 0.31835922598838806\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4868, loss 0.3183576464653015\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4869, loss 0.31835612654685974\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4870, loss 0.31835460662841797\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4871, loss 0.3183530271053314\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9881, 0.0150],\n","        [0.9847, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3184, grad_fn=<NllLossBackward>)\n","epoch 4872, loss 0.3183515667915344\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9882, 0.0149],\n","        [0.9847, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4873, loss 0.3183499872684479\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4874, loss 0.3183484971523285\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4875, loss 0.31834691762924194\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4876, loss 0.31834539771080017\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4877, loss 0.3183438777923584\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4878, loss 0.31834229826927185\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4879, loss 0.3183407783508301\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4880, loss 0.3183392584323883\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4881, loss 0.31833773851394653\n","outputs:  tensor([[0.0131, 0.9828],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4882, loss 0.31833624839782715\n","outputs:  tensor([[0.0131, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0193],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4883, loss 0.3183346688747406\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4884, loss 0.31833314895629883\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4885, loss 0.31833162903785706\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4886, loss 0.3183301091194153\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4887, loss 0.3183285593986511\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4888, loss 0.31832703948020935\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4889, loss 0.3183255195617676\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4890, loss 0.3183240294456482\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4891, loss 0.3183225095272064\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4892, loss 0.3183209300041199\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4893, loss 0.3183194696903229\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0149],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4894, loss 0.31831789016723633\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0148],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4895, loss 0.3183164596557617\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0148],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4896, loss 0.31831493973731995\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0148],\n","        [0.9848, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4897, loss 0.3183133602142334\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0148],\n","        [0.9849, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4898, loss 0.3183118402957916\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0148],\n","        [0.9849, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4899, loss 0.31831032037734985\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0148],\n","        [0.9849, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4900, loss 0.31830883026123047\n","outputs:  tensor([[0.0130, 0.9829],\n","        [0.9882, 0.0148],\n","        [0.9849, 0.0192],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4901, loss 0.3183073401451111\n","Parameter containing:\n","tensor([[-0.3329, -0.7466,  0.1955],\n","        [-1.1306, -0.9535, -0.0752],\n","        [-1.1560, -1.1357, -0.1246],\n","        [-0.5087, -0.5699, -0.0014]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5438, -0.2064,  0.2519,  0.1613], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9550,  0.8726,  1.2823,  0.2032],\n","        [-0.3239, -1.1334, -1.0188, -0.6786]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3975, -0.6448], requires_grad=True)\n","outputs:  tensor([[0.0130, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4902, loss 0.3183058202266693\n","outputs:  tensor([[0.0130, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4903, loss 0.31830430030822754\n","outputs:  tensor([[0.0130, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4904, loss 0.31830278038978577\n","outputs:  tensor([[0.0130, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4905, loss 0.3183012902736664\n","outputs:  tensor([[0.0130, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4906, loss 0.31829971075057983\n","outputs:  tensor([[0.0130, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4907, loss 0.3182982802391052\n","outputs:  tensor([[0.0130, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4908, loss 0.3182968199253082\n","outputs:  tensor([[0.0130, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9993]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4909, loss 0.3182952404022217\n","outputs:  tensor([[0.0130, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4910, loss 0.3182937204837799\n","outputs:  tensor([[0.0129, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4911, loss 0.3182922303676605\n","outputs:  tensor([[0.0129, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4912, loss 0.3182907700538635\n","outputs:  tensor([[0.0129, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4913, loss 0.31828922033309937\n","outputs:  tensor([[0.0129, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4914, loss 0.31828776001930237\n","outputs:  tensor([[0.0129, 0.9830],\n","        [0.9883, 0.0148],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4915, loss 0.3182862401008606\n","outputs:  tensor([[0.0129, 0.9830],\n","        [0.9883, 0.0147],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4916, loss 0.31828469038009644\n","outputs:  tensor([[0.0129, 0.9830],\n","        [0.9883, 0.0147],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4917, loss 0.3182832598686218\n","outputs:  tensor([[0.0129, 0.9830],\n","        [0.9883, 0.0147],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4918, loss 0.31828171014785767\n","outputs:  tensor([[0.0129, 0.9830],\n","        [0.9883, 0.0147],\n","        [0.9849, 0.0191],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4919, loss 0.3182802200317383\n","outputs:  tensor([[0.0129, 0.9830],\n","        [0.9883, 0.0147],\n","        [0.9849, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4920, loss 0.3182787001132965\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9849, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4921, loss 0.3182772696018219\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9849, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4922, loss 0.31827569007873535\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4923, loss 0.31827425956726074\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4924, loss 0.31827276945114136\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4925, loss 0.3182712495326996\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4926, loss 0.3182697892189026\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4927, loss 0.3182682991027832\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4928, loss 0.31826677918434143\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4929, loss 0.31826528906822205\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4930, loss 0.31826382875442505\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9883, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4931, loss 0.3182622492313385\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9884, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4932, loss 0.3182608187198639\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9884, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4933, loss 0.3182592988014221\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9884, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4934, loss 0.31825780868530273\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9884, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4935, loss 0.31825631856918335\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9884, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4936, loss 0.31825485825538635\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9884, 0.0147],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4937, loss 0.31825342774391174\n","outputs:  tensor([[0.0129, 0.9831],\n","        [0.9884, 0.0146],\n","        [0.9850, 0.0190],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4938, loss 0.31825190782546997\n","outputs:  tensor([[0.0128, 0.9831],\n","        [0.9884, 0.0146],\n","        [0.9850, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3183, grad_fn=<NllLossBackward>)\n","epoch 4939, loss 0.3182504177093506\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9850, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4940, loss 0.3182489275932312\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9850, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4941, loss 0.3182474672794342\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9850, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4942, loss 0.3182459771633148\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9850, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4943, loss 0.3182445168495178\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9850, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4944, loss 0.31824302673339844\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9850, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4945, loss 0.31824153661727905\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9850, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4946, loss 0.31824007630348206\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9850, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4947, loss 0.31823858618736267\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4948, loss 0.3182371258735657\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4949, loss 0.3182356357574463\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4950, loss 0.3182341456413269\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4951, loss 0.3182326853275299\n","Parameter containing:\n","tensor([[-0.3336, -0.7478,  0.1955],\n","        [-1.1318, -0.9556, -0.0752],\n","        [-1.1574, -1.1381, -0.1246],\n","        [-0.5093, -0.5709, -0.0014]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5443, -0.2056,  0.2528,  0.1617], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.9560,  0.8740,  1.2840,  0.2041],\n","        [-0.3252, -1.1352, -1.0210, -0.6797]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3978, -0.6453], requires_grad=True)\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4952, loss 0.3182311952114105\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4953, loss 0.3182297348976135\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4954, loss 0.3182283043861389\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4955, loss 0.31822675466537476\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0189],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4956, loss 0.3182253837585449\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4957, loss 0.31822386384010315\n","outputs:  tensor([[0.0128, 0.9832],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4958, loss 0.31822237372398376\n","outputs:  tensor([[0.0128, 0.9833],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4959, loss 0.31822091341018677\n","outputs:  tensor([[0.0128, 0.9833],\n","        [0.9884, 0.0146],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4960, loss 0.31821948289871216\n","outputs:  tensor([[0.0128, 0.9833],\n","        [0.9884, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4961, loss 0.31821805238723755\n","outputs:  tensor([[0.0128, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4962, loss 0.3182165026664734\n","outputs:  tensor([[0.0128, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4963, loss 0.3182150721549988\n","outputs:  tensor([[0.0128, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4964, loss 0.318213552236557\n","outputs:  tensor([[0.0128, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4965, loss 0.3182121217250824\n","outputs:  tensor([[0.0128, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4966, loss 0.3182106912136078\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4967, loss 0.3182092308998108\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4968, loss 0.3182078003883362\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4969, loss 0.3182063102722168\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4970, loss 0.318204790353775\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4971, loss 0.3182033896446228\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9851, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4972, loss 0.3182019293308258\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9852, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4973, loss 0.3182004392147064\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9852, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4974, loss 0.3181990087032318\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9852, 0.0188],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4975, loss 0.3181975483894348\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4976, loss 0.31819605827331543\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4977, loss 0.3181946277618408\n","outputs:  tensor([[0.0127, 0.9833],\n","        [0.9885, 0.0145],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4978, loss 0.3181931972503662\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0145],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4979, loss 0.3181917071342468\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0145],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4980, loss 0.3181902766227722\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0145],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4981, loss 0.3181888163089752\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0145],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4982, loss 0.318187415599823\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4983, loss 0.318185955286026\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4984, loss 0.3181845247745514\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4985, loss 0.318183034658432\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4986, loss 0.318181574344635\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4987, loss 0.3181801736354828\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4988, loss 0.3181787133216858\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4989, loss 0.3181772828102112\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4990, loss 0.3181758522987366\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4991, loss 0.31817442178726196\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9885, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4992, loss 0.3181729316711426\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9886, 0.0144],\n","        [0.9852, 0.0187],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4993, loss 0.31817150115966797\n","outputs:  tensor([[0.0127, 0.9834],\n","        [0.9886, 0.0144],\n","        [0.9852, 0.0186],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4994, loss 0.31817007064819336\n","outputs:  tensor([[0.0126, 0.9834],\n","        [0.9886, 0.0144],\n","        [0.9852, 0.0186],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4995, loss 0.31816864013671875\n","outputs:  tensor([[0.0126, 0.9834],\n","        [0.9886, 0.0144],\n","        [0.9852, 0.0186],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4996, loss 0.31816715002059937\n","outputs:  tensor([[0.0126, 0.9834],\n","        [0.9886, 0.0144],\n","        [0.9852, 0.0186],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4997, loss 0.31816568970680237\n","outputs:  tensor([[0.0126, 0.9834],\n","        [0.9886, 0.0144],\n","        [0.9853, 0.0186],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4998, loss 0.31816425919532776\n","outputs:  tensor([[0.0126, 0.9835],\n","        [0.9886, 0.0144],\n","        [0.9853, 0.0186],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 4999, loss 0.31816285848617554\n","outputs:  tensor([[0.0126, 0.9835],\n","        [0.9886, 0.0144],\n","        [0.9853, 0.0186],\n","        [0.9998, 0.0003],\n","        [0.0007, 0.9994]], grad_fn=<SigmoidBackward>)\n","labels:  tensor([1, 0, 0, 0, 1])\n","outputs size:  torch.Size([5, 2])\n","labels size:  torch.Size([5])\n","loss: tensor(0.3182, grad_fn=<NllLossBackward>)\n","epoch 5000, loss 0.3181614577770233\n"],"name":"stdout"}]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-15T15:21:26.445260Z","start_time":"2018-10-15T15:21:26.282006Z"},"colab_type":"code","id":"hu6RrNJsmQE6","outputId":"fd54f608-bb76-4ec2-dc2f-1309b952a350","colab":{"base_uri":"https://localhost:8080/","height":376}},"cell_type":"code","source":["#Plotting Loss vs Epochs \n","fig,ax = plt.subplots(1)\n","plt.title('Loss vs Epochs')\n","ax.plot(losses)\n","#ax.set_xticklabels([])\n","#ax.set_yticklabels([])\n","ax.set_ylabel('Loss')\n","ax.set_xlabel('Epoch')\n","plt.savefig('Loss_vs_Epoch.png')"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH34MGmEOwEGcAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7fcd8ad61e10>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"rO0ayHs0ZIBC","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:"]},{"metadata":{"id":"2O14hJP1ZIem","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Too Simple, I am wasting time\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f-pGUF9rZIi8","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"test\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pKEQRPL8ZIci","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"No\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UVBYc3A8ZGwN","colab_type":"code","cellView":"form","outputId":"cbf57a08-bc05-40d5-c30a-2937d5156771","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Your submission is successful. Ref: 14870\n"],"name":"stdout"}]}]}