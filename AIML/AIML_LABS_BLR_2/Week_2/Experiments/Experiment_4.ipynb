{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment_4.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"E9fcwT9NHfDY","colab_type":"text"},"cell_type":"markdown","source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"UsS05CpxHfDa","colab_type":"text"},"cell_type":"markdown","source":["\n","#### To be done in the  Lab"]},{"metadata":{"id":"AL-29QPHHfDc","colab_type":"text"},"cell_type":"markdown","source":["The objective of this experiment is to learn Performance evaluation and metrics"]},{"metadata":{"id":"_5xg9YVCHfDd","colab_type":"text"},"cell_type":"markdown","source":["In this experiment we will use Wisconsin Breast Cancer data set.The data has been modified as below\n","\n","* The id field has been removed\n","* The diagnosis field has been moved to the end"]},{"metadata":{"id":"Z-DjwEjGHfDe","colab_type":"text"},"cell_type":"markdown","source":["#### Data Set Information\n","\n","Number of instances: 569 \n","\n","Number of attributes: 31 (diagnosis, 30 real-valued input features)\n","\n","Ten real-valued features are computed for each cell nucleus:\n","\n","\ta) radius (mean of distances from center to points on the perimeter)\n","\tb) texture (standard deviation of gray-scale values)\n","\tc) perimeter\n","\td) area\n","\te) smoothness (local variation in radius lengths)\n","\tf) compactness (perimeter^2 / area - 1.0)\n","\tg) concavity (severity of concave portions of the contour)\n","\th) concave points (number of concave portions of the contour)\n","\ti) symmetry \n","\tj) fractal dimension (\"coastline approximation\" - 1)\n","\n","The mean, standard error, and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features.  For instance, field 1 is Mean Radius, field 11 is Radius SE, field 21 is Worst Radius. All feature values are recoded with four significant digits.\n","\n","The last field is diagnosis: M for Malignant and B for Benign\n","\n","Class distribution: 357 benign, 212 malignant"]},{"metadata":{"id":"Ifv-CFLXHfDg","colab_type":"text"},"cell_type":"markdown","source":["#### Data Source\n","\n","https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"]},{"metadata":{"id":"Z-1taCDqH6Pd","colab_type":"text"},"cell_type":"markdown","source":["### Setup Steps"]},{"metadata":{"id":"BspvBnq1H8KP","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P19A06E_test\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hibVs9dhH_bu","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"981234567\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ef15ddF0IBhS","colab_type":"code","cellView":"form","outputId":"7edaac23-a8ae-455a-f75b-1dcc052236b2","executionInfo":{"status":"ok","timestamp":1542457966683,"user_tz":-330,"elapsed":7416,"user":{"displayName":"Amulya Mamindla","photoUrl":"","userId":"12783715330151357368"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M1W2_SAT_EXP_4\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/AIML_DS_WDBC_NOIDFIELD.data.zip?dl=1\")\n","    ipython.magic(\"sx unzip AIML_DS_WDBC_NOIDFIELD.data.zip?dl=1\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful. Ref:\", submission_id)\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"metadata":{"id":"AhpTpfqsHfDh","colab_type":"code","colab":{}},"cell_type":"code","source":["### Importing Required Packages\n","import pandas  as pd"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9HdZ7GTSHfDm","colab_type":"code","colab":{}},"cell_type":"code","source":["## Setting up the files\n","CANCERDATA = \"AIML_DS_WDBC_NOIDFIELD.data\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Oda0ozAvHfDq","colab_type":"code","outputId":"a4087ea0-2be5-4205-cc58-a79d46fc122b","executionInfo":{"status":"ok","timestamp":1542457970495,"user_tz":-330,"elapsed":688,"user":{"displayName":"Amulya Mamindla","photoUrl":"","userId":"12783715330151357368"}},"colab":{"base_uri":"https://localhost:8080/","height":408}},"cell_type":"code","source":["# Function to convert Categorical variables into numeric variables\n","def labelConvert(s):\n","    s = s.strip().lower()\n","    if s == \"m\":\n","        return 0\n","    if s == \"b\":\n","        return 1\n","    return -1\n","\n","data = pd.read_csv(CANCERDATA, header = None, converters={30:labelConvert})\n","data[:10]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.30010</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>...</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.1622</td>\n","      <td>0.6656</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.08690</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>...</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.19740</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>...</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.24140</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>...</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.19800</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>...</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>12.45</td>\n","      <td>15.70</td>\n","      <td>82.57</td>\n","      <td>477.1</td>\n","      <td>0.12780</td>\n","      <td>0.17000</td>\n","      <td>0.15780</td>\n","      <td>0.08089</td>\n","      <td>0.2087</td>\n","      <td>0.07613</td>\n","      <td>...</td>\n","      <td>23.75</td>\n","      <td>103.40</td>\n","      <td>741.6</td>\n","      <td>0.1791</td>\n","      <td>0.5249</td>\n","      <td>0.5355</td>\n","      <td>0.1741</td>\n","      <td>0.3985</td>\n","      <td>0.12440</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>18.25</td>\n","      <td>19.98</td>\n","      <td>119.60</td>\n","      <td>1040.0</td>\n","      <td>0.09463</td>\n","      <td>0.10900</td>\n","      <td>0.11270</td>\n","      <td>0.07400</td>\n","      <td>0.1794</td>\n","      <td>0.05742</td>\n","      <td>...</td>\n","      <td>27.66</td>\n","      <td>153.20</td>\n","      <td>1606.0</td>\n","      <td>0.1442</td>\n","      <td>0.2576</td>\n","      <td>0.3784</td>\n","      <td>0.1932</td>\n","      <td>0.3063</td>\n","      <td>0.08368</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>13.71</td>\n","      <td>20.83</td>\n","      <td>90.20</td>\n","      <td>577.9</td>\n","      <td>0.11890</td>\n","      <td>0.16450</td>\n","      <td>0.09366</td>\n","      <td>0.05985</td>\n","      <td>0.2196</td>\n","      <td>0.07451</td>\n","      <td>...</td>\n","      <td>28.14</td>\n","      <td>110.60</td>\n","      <td>897.0</td>\n","      <td>0.1654</td>\n","      <td>0.3682</td>\n","      <td>0.2678</td>\n","      <td>0.1556</td>\n","      <td>0.3196</td>\n","      <td>0.11510</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>13.00</td>\n","      <td>21.82</td>\n","      <td>87.50</td>\n","      <td>519.8</td>\n","      <td>0.12730</td>\n","      <td>0.19320</td>\n","      <td>0.18590</td>\n","      <td>0.09353</td>\n","      <td>0.2350</td>\n","      <td>0.07389</td>\n","      <td>...</td>\n","      <td>30.73</td>\n","      <td>106.20</td>\n","      <td>739.3</td>\n","      <td>0.1703</td>\n","      <td>0.5401</td>\n","      <td>0.5390</td>\n","      <td>0.2060</td>\n","      <td>0.4378</td>\n","      <td>0.10720</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>12.46</td>\n","      <td>24.04</td>\n","      <td>83.97</td>\n","      <td>475.9</td>\n","      <td>0.11860</td>\n","      <td>0.23960</td>\n","      <td>0.22730</td>\n","      <td>0.08543</td>\n","      <td>0.2030</td>\n","      <td>0.08243</td>\n","      <td>...</td>\n","      <td>40.68</td>\n","      <td>97.65</td>\n","      <td>711.4</td>\n","      <td>0.1853</td>\n","      <td>1.0580</td>\n","      <td>1.1050</td>\n","      <td>0.2210</td>\n","      <td>0.4366</td>\n","      <td>0.20750</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 31 columns</p>\n","</div>"],"text/plain":["      0      1       2       3        4        5        6        7       8   \\\n","0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n","1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n","2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n","3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n","4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n","5  12.45  15.70   82.57   477.1  0.12780  0.17000  0.15780  0.08089  0.2087   \n","6  18.25  19.98  119.60  1040.0  0.09463  0.10900  0.11270  0.07400  0.1794   \n","7  13.71  20.83   90.20   577.9  0.11890  0.16450  0.09366  0.05985  0.2196   \n","8  13.00  21.82   87.50   519.8  0.12730  0.19320  0.18590  0.09353  0.2350   \n","9  12.46  24.04   83.97   475.9  0.11860  0.23960  0.22730  0.08543  0.2030   \n","\n","        9  ...     21      22      23      24      25      26      27      28  \\\n","0  0.07871 ...  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601   \n","1  0.05667 ...  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860  0.2750   \n","2  0.05999 ...  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430  0.3613   \n","3  0.09744 ...  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575  0.6638   \n","4  0.05883 ...  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625  0.2364   \n","5  0.07613 ...  23.75  103.40   741.6  0.1791  0.5249  0.5355  0.1741  0.3985   \n","6  0.05742 ...  27.66  153.20  1606.0  0.1442  0.2576  0.3784  0.1932  0.3063   \n","7  0.07451 ...  28.14  110.60   897.0  0.1654  0.3682  0.2678  0.1556  0.3196   \n","8  0.07389 ...  30.73  106.20   739.3  0.1703  0.5401  0.5390  0.2060  0.4378   \n","9  0.08243 ...  40.68   97.65   711.4  0.1853  1.0580  1.1050  0.2210  0.4366   \n","\n","        29  30  \n","0  0.11890   0  \n","1  0.08902   0  \n","2  0.08758   0  \n","3  0.17300   0  \n","4  0.07678   0  \n","5  0.12440   0  \n","6  0.08368   0  \n","7  0.11510   0  \n","8  0.10720   0  \n","9  0.20750   0  \n","\n","[10 rows x 31 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"AfoF8fmMHfD0","colab_type":"text"},"cell_type":"markdown","source":["Splitting dataset into train and test sets"]},{"metadata":{"id":"0PEl2XQ-HfD1","colab_type":"code","colab":{}},"cell_type":"code","source":["def split_Train_Test(data):\n","    import random\n","    TRAIN_TEST_RATIO = 0.8\n","    train = []\n","    test = []\n","    train_labels = []\n","    test_labels = []\n","    for d in data:\n","        if random.random() < TRAIN_TEST_RATIO:\n","            train.append(d[:-1])\n","            train_labels.append(d[-1])\n","        else:\n","            test.append(d[:-1])\n","            test_labels.append(d[-1])\n","    return train, test,train_labels,test_labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K3_s_F_aHfD6","colab_type":"code","outputId":"b45253ba-7069-4bee-bd65-e9bdd0657e6b","executionInfo":{"status":"ok","timestamp":1541738225681,"user_tz":-330,"elapsed":584,"user":{"displayName":"Priyanka Gaddam","photoUrl":"","userId":"07316718693164986599"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"cell_type":"code","source":["## Do not worry about the hyperparameters of this algorithm right now.\n","train_data, test_data, train_labels, test_labels = split_Train_Test(data.values)\n","print(\"Training\", len(train_data))\n","print(\"Testing\", len(test_data))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training 444\n","Testing 125\n"],"name":"stdout"}]},{"metadata":{"id":"GUOEHpVP5PEH","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn import linear_model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cvMtGIIp5XaK","colab_type":"code","outputId":"73bab8a3-7cfa-4be6-9cfc-8a7c1b9ea851","executionInfo":{"status":"ok","timestamp":1541738269297,"user_tz":-330,"elapsed":906,"user":{"displayName":"Priyanka Gaddam","photoUrl":"","userId":"07316718693164986599"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"cell_type":"code","source":["clf = linear_model.SGDClassifier(max_iter=1000)\n","clf.fit(train_data,train_labels)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n","       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n","       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n","       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n","       shuffle=True, tol=None, verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"vPZVJBIuHfEA","colab_type":"text"},"cell_type":"markdown","source":["### Exercise 1\n","\n","Use the predict function to calculate the accuracy on the test set."]},{"metadata":{"id":"d3wouqhtHfEC","colab_type":"code","colab":{}},"cell_type":"code","source":["### You have preds and actuals now :)\n","### Your Code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m70nfODdHfEF","colab_type":"text"},"cell_type":"markdown","source":["Now let us calculate a different metric to analyze our results, called confusion matrix."]},{"metadata":{"id":"4fBVHr0KHfEI","colab_type":"text"},"cell_type":"markdown","source":["A confusion matrix is a table that is often used to \n","describe the performance of a classification model\n","on a set of test data for which the true values are known.\n","\n","The entries in the confusion matrix have the following meaning in the context of our study:\n","\n","* a (True Positive) is the number of correct predictions that an instance is positive,\n","* b (False Positive) is the number of incorrect predictions that an instance is positive,\n","* c (False Negative) is the number of incorrect of predictions that an instance is negative, and\n","* d (True Negative) is the number of correct predictions that an instance is negative.  \n","\n","\n","![alt](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRozZ7IpyD6mTSUREZZ09SbaC-w8_Gae6syq2rKOBl8Az4gKzCU)"]},{"metadata":{"id":"z1chbxFOHfEJ","colab_type":"text"},"cell_type":"markdown","source":["Here M is positive and B is negative; that is we are looking for cancerous cells. So M means it is cancerous that is positive."]},{"metadata":{"id":"oVYB9xvNHfEK","colab_type":"code","colab":{}},"cell_type":"code","source":["def confusionmatrix(actuals, prediction):\n","    TruePositive = sum([int(a == 1 and p == 1) for a, p in zip(actuals, prediction)])\n","    TrueNegative = sum([int(a == 0 and p == 0) for a, p in zip(actuals, prediction)])\n","    FalsePositive = sum([int(a == 0 and p == 1) for a, p in zip(actuals, prediction)])\n","    FalseNegative = sum([int(a == 1 and p == 0) for a, p in zip(actuals, prediction)])\n","    return TruePositive, TrueNegative, FalsePositive, FalseNegative\n","tp,tn,fp,fn = confusionmatrix(test_labels, pred)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qoI1D4dpHfEO","colab_type":"text"},"cell_type":"markdown","source":["** Precision ** -  ratio of correctly predicted positive observations to the total predicted positive observations. \n","\n","** Recall ** - ratio of correctly predicted positive observations to the all observations in actual class"]},{"metadata":{"id":"pSSTssIXHfEP","colab_type":"text"},"cell_type":"markdown","source":["### Exercise 2\n","\n","Calculate precision\n","\n","$ p $ = $ tp $ $ / $ ($ tp $ + $ fp $)"]},{"metadata":{"id":"eO2gTiS-2Bfb","colab_type":"code","colab":{}},"cell_type":"code","source":["### Your Code"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ouIIY6CpHfEV","colab_type":"text"},"cell_type":"markdown","source":["### Exercise 3 \n","\n","Calculate recall \n","\n","$ r $ = $ tp $ $ /$ ( $ tp $ + $fn $ ) "]},{"metadata":{"id":"TfKczg8_2Duq","colab_type":"code","colab":{}},"cell_type":"code","source":["## Your code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2iqdtm0gHfEa","colab_type":"text"},"cell_type":"markdown","source":["### Exercise 4 \n","\n","Calculate miss rate\n","\n","$ m $ = $ 1 $ $ - $ $ r $"]},{"metadata":{"id":"8fD3G3vb2FvL","colab_type":"code","colab":{}},"cell_type":"code","source":["### Your code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dPnsLG9xHfEf","colab_type":"text"},"cell_type":"markdown","source":["### Exercise 5 \n","\n","Calculate accuracy and check with earlier accuracy that we computed.\n","\n","$ a $ = ($ tp $ + $ tn $) / ($ tp $ + $ tn $ + $ fp $ + $ fn $ )"]},{"metadata":{"id":"ly7md4FK2HxV","colab_type":"code","colab":{}},"cell_type":"code","source":["### Your code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RFdTxRPMHfEm","colab_type":"text"},"cell_type":"markdown","source":["### Summary"]},{"metadata":{"id":"csF79mTPHfEn","colab_type":"text"},"cell_type":"markdown","source":["From above experiment we can say that an algorithm that has a high value for both is very good, an algorithm that is good at one or the other can be useful but it’s important to understand when to use it."]},{"metadata":{"id":"4_TDbZBpIvtq","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:"]},{"metadata":{"id":"GbZufiEjIzjb","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v0tgsd_GI3Sk","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"test\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G_43KsIpI5zJ","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t1tQA5wNI-RP","colab_type":"code","cellView":"form","outputId":"ac685afa-c043-433b-86be-570a56fc8e2e","executionInfo":{"status":"ok","timestamp":1541738330827,"user_tz":-330,"elapsed":1809,"user":{"displayName":"Priyanka Gaddam","photoUrl":"","userId":"07316718693164986599"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Your submission is successful. Ref: 11682\n"],"name":"stdout"}]},{"metadata":{"id":"k6MjS_xwJPD7","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}