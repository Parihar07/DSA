{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML_GL_LAB_JN01_EX.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"QbZjZ1i5KMsv","colab_type":"text"},"cell_type":"markdown","source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"LrIlNFZeKMsx","colab_type":"text"},"cell_type":"markdown","source":["The objective of this lab is to learn how to perform Data preprocessing. "]},{"metadata":{"id":"fqJ1h77-KMsy","colab_type":"text"},"cell_type":"markdown","source":["We will be using district wise demographics, enrollments, school and teacher indicator data to predict whether the literacy rate is high / medium / low in each district."]},{"metadata":{"id":"3B5ztQVbKMsz","colab_type":"text"},"cell_type":"markdown","source":["Data preprocessing is an important step of solving every machine learning problem. Most of\n","the datasets used with Machine Learning problems need to be processed / cleaned / transformed\n","so that a Machine Learning algorithm can be trained on it."]},{"metadata":{"id":"QsxaJLZAKMs0","colab_type":"text"},"cell_type":"markdown","source":["There are different steps involved for Data Preprocessing. These steps are as follows:"]},{"metadata":{"id":"QF3Eg-5pKMs1","colab_type":"text"},"cell_type":"markdown","source":["    1. Data Cleaning → In this step the primary focus is on\n","        -Handling missing data\n","        -Handling nosiy data\n","        -Detection and removal of outliers\n","    \n","    2. Data Integration → This process is used when data is gathered from various data sources\n","    and data are combined to form consistent data. This data after performing cleaning is used\n","    for analysis.\n","    \n","    3. Data Transformation → In this step we will convert the raw data into a specified for-\n","    mat according to the need of the model we are building. There are many options used for\n","    transforming the data as below:\n","        -Normalization\n","        -Aggregation\n","        -Generalization\n","        \n","    4. Data Reduction → After data transformation and scaling the redundancy within the data\n","    is removed and efficiently organizing the data is performed.\n","\n"]},{"metadata":{"id":"Qk0G-I3iKMs2","colab_type":"text"},"cell_type":"markdown","source":["### Total Marks  = 20"]},{"metadata":{"id":"mXKT6V2zKb_v","colab_type":"text"},"cell_type":"markdown","source":["#### Setup Steps"]},{"metadata":{"id":"bIVdqocyr3Tk","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P18_test\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tmrHzW02sDB_","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"912345678\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4rs_IPdUsFcP","colab_type":"code","cellView":"form","outputId":"a9e44395-d765-48ca-e5c4-21625332e8dd","executionInfo":{"status":"ok","timestamp":1541848433711,"user_tz":-330,"elapsed":9432,"user":{"displayName":"Vidyadhar Rao","photoUrl":"https://lh5.googleusercontent.com/-um6SAcmQKBA/AAAAAAAAAAI/AAAAAAAAC7o/q07oNDn7ftg/s64/photo.jpg","userId":"01257137440126415573"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M1W2_SUN_GL_1\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx wget https://www.dropbox.com/s/454v4h3xh2xkbpd/data.zip?dl=1\")\n","    ipython.magic(\"sx unzip data.zip?dl=1\")\n","    ipython.magic(\"sx wget https://www.dropbox.com/s/zwn92k5wx313j1v/normal_dist.png?dl=1\")\n","    ipython.magic(\"sx mv normal_dist.png?dl=1 normal_dist.png\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful. Ref:\", submission_id)\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"metadata":{"id":"hZSlj_nWKMs4","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 1 - (2 Marks)\n","We have four different files\n","\n","* Districtwise_Basicdata.csv\n","* Districtwise_Enrollment_details_indicator.csv\n","* Districtwise_SchoolData.csv\n","* Districtwise_Teacher_indicator.csv\n","These files contain the neccesary data to solve the problem.\n","Load all the files correctly, after observing the header level details, data records etc\n","\n","Hint : Use read_csv from pandas"]},{"metadata":{"id":"YhT63mvifGSH","colab_type":"code","colab":{}},"cell_type":"code","source":["# Your code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K2A3OKraKMs9","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 2  - (3 Marks)\n","\n","* Remove the unwanted columns, which are unlikely to contribute for the prediction of overall literacy grade\n","* As the required data is present in different files, we need to integrate all the four to make single dataframe/dataset. For that purpose, create a unique identifier for each row in all the dataframes so that it can be used to map the data in different files correctly\n","* Join/integrate this data \n","\n","Example : data of the district ananthapur in Andrapradesh, which present in different files should form a single row \n","\n","Hint : \n","* Use the combination of year, statecode, district code as unique identifier \n"]},{"metadata":{"id":"le5wGzUuKMs_","colab_type":"code","colab":{}},"cell_type":"code","source":["# Your Code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k3wf8dFrKMtC","colab_type":"text"},"cell_type":"markdown","source":["Follow this steps in order to clean the data:"]},{"metadata":{"id":"_jcX4aRsKMtE","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 3 - (2 Marks)\n","\n","* Overall_lit is our target variable, which we need to predict. Delete the row with missing overall_lit column\n","* Take a call to replace the missing values in any other column appropriately with mean/median/mode\n","* Convert categorical values to numerical values\n","Example : If a feature contains categorical values such as dog, cat, mouse etc then replace them with 1, 2, 3 etc or using one hot encoding (your judgement)\n","\n","*Hint* :\n","* Use pandas fillna function to replace the missing values"]},{"metadata":{"id":"REcYtu79KMtF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Your Code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SzsY-knQKMtI","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 4 - (3 Marks)\n","\n","Use the functions below to adjust the outliers\n","\n","smooth_out function takes pandas dataframe as input and caculates mean, standard deviation of every column to check whether all the values in that lies within the range of mean +/- 2*standard_deviation of that column or not.\n","If any of the values are not present in that boundary, then that values is brought on to the boundary\n","\n","<img src=\"normal_dist.png\">"]},{"metadata":{"id":"uhdy63OSKMtK","colab_type":"code","colab":{}},"cell_type":"code","source":["# Function to clip and clam the data\n","def clip_clamp(x, mean, sd):\n","    # Checking whether the value is less than a differenced value between mean and standard deviation.\n","    if x < mean - 2*sd :\n","        return mean - 2*sd\n","    #Checking whether the value is greater than a differenced value between mean and standard deviation.\n","    elif x > mean + 2*sd :\n","        return mean + 2*sd\n","    # If above two conditions are not statisfied we will return the original value\n","    else :\n","        return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YXWSJ2wCKMtP","colab_type":"code","colab":{}},"cell_type":"code","source":["# Function to smooth the data\n","def smooth_out(Total_data):\n","    for i in Total_data.columns:\n","        # Calculating the mean value\n","        mean = np.mean(Total_data[i].values, axis=0)\n","        # Calculating the standard deviation value\n","        sd = np.std(Total_data[i].values, axis=0)\n","        # Calculating the corrected value using clip and clamp function\n","        corrected = np.array([clip_clamp(x, mean, sd) for x in Total_data[i].values])\n","        # Storing the data in form of series\n","        Total_data[i] = pd.Series(corrected, index=Total_data[i].index)\n","    return Total_data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-hU2poUeKMtT","colab_type":"code","colab":{}},"cell_type":"code","source":["# Your Code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-dMbvU-KKMtY","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 5 - (2 Marks)\n","\n","Use the function below (corr_features) to identify uncorrelated features and remove the remaining features\n","* corr_features takes pandas dataframe, columns in the dataframe and bar (corelation co-efficient)"]},{"metadata":{"id":"kgJeGouOKMtZ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Function to find uncorrelated features\n","def corr_features(df,cols,bar=0.9):\n","    for c,i in enumerate(cols[:-1]):\n","        col_set = set(cols)\n","        for j in cols[c+1:]:\n","            if i==j:\n","                continue\n","           \n","            score = df[i].corr(df[j])\n","            \n","            if score>bar:\n","                cols = list(col_set-set([j]))\n","            if score<-bar:\n","                cols = list(col_set-set([j]))\n","    return cols"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5njOPWIXKMtd","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 6 - (3 Marks)\n","\n","Perform Mean Correction and Standard Scaling on the data feature/column wise"]},{"metadata":{"id":"988wdlpDKMtd","colab_type":"code","colab":{}},"cell_type":"code","source":["# Your Code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PWdpfBCfKMtg","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 7 - (2 Marks)\n","\n","Split the data into train and test"]},{"metadata":{"id":"eI8xH_D8KMti","colab_type":"code","colab":{}},"cell_type":"code","source":["# Your Code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QugqX021KMtl","colab_type":"text"},"cell_type":"markdown","source":["#### Exercise 8 - (3 Marks)\n","\n","Apply different classifiers on the preprocessed data and figure out which classifier gives the best result."]},{"metadata":{"id":"ZuY1XkSAKMtn","colab_type":"code","colab":{}},"cell_type":"code","source":["# Your Code Here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3Kj2TR53KMtq","colab_type":"text"},"cell_type":"markdown","source":["### Replace any of the above given functions and get correct results to get excellence"]}]}