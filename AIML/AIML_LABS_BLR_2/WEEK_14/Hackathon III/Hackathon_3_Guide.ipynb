{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hackathon_3_Guide.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"SZIubkln0AI2","colab_type":"text"},"cell_type":"markdown","source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"4LNbxek40AI4","colab_type":"text"},"cell_type":"markdown","source":["# Hackathon 3: Anti Face Spoofing"]},{"metadata":{"id":"3e0e3sFh0JZJ","colab_type":"text"},"cell_type":"markdown","source":["### Setup Steps"]},{"metadata":{"id":"xWQwfHmR0MDu","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P18_test\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RBdFVMDi0Ou0","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"912345678\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Kv0xxq_d0Qb_","colab_type":"code","cellView":"form","outputId":"89369f11-f44b-495c-e7d1-ec3314b5bc07","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"M2_Hackathon\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx wget wget https://cdn.talentsprint.com/aiml/Experiment_related_data/IMFDB_final.zip\")\n","    ipython.magic(\"sx wget wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Expression_data.zip\")\n","    ipython.magic(\"sx unzip IMFDB_final.zip\")\n","    ipython.magic(\"sx unzip Expression_data.zip\")\n","    ipython.magic(\"sx pip install torch torchvision\")\n","    ipython.magic(\"sx pip install opencv-python\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful. Ref:\", submission_id)\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"metadata":{"id":"DqNBNvC25WNV","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","from torch.autograd import Variable\n","import numpy as np\n","import librosa\n","import os\n","import warnings\n","from time import sleep\n","import sys\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wqMmxLR38vJ3","colab_type":"text"},"cell_type":"markdown","source":["##Data Collection\n","\n","* Using the Mobile Application, please collect the Faces and Expression data of your team. \n","* These will be stored in the Server to which login is provided to you.\n","* Download the data into your colab server using the downloadable link provided to you\n","* This data will be usefull training the networks\n"]},{"metadata":{"id":"NhLFY4n6BwIj","colab_type":"text"},"cell_type":"markdown","source":["##Data used: Indian Movie Face database (IMFDB)\n","It is a large unconstrained face database of images of 100 Indian actors collected from more than 100 videos. All the images are manually selected and cropped from the video frames resulting in a high degree of variability interms of scale, pose, expression, illumination, age, resolution, occlusion, and makeup\n","\n","During the setup you have downloaded this data:\n","\n","* **IMFDB_final**: This folder contains the face images segregrated by the actor in each folder\n","\n","\n","> * Each class is organised as one folder\n","\n","\n","* **Expression_data**: In this folder, the same images are segregrated in terms of Expression\n","> * Expressions available: ANGER, DISGUST, FEAR, HAPPINESS, NEUTRAL, SADNESS, SURPRISE\n","> * Each class is organised as one folder\n","\n"]},{"metadata":{"id":"B4-clpEl-1RF","colab_type":"code","outputId":"7d632c7a-a75a-4cdf-c8e1-ceb879c4dd50","colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["%ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mExpression_data\u001b[0m/     \u001b[01;34mIMFDB_final\u001b[0m/     M2_Hackathon.ipynb  \u001b[01;34msample_data\u001b[0m/\n","Expression_data.zip  IMFDB_final.zip  \u001b[01;34m__MACOSX\u001b[0m/\n"],"name":"stdout"}]},{"metadata":{"id":"bHpqJDuFHVmL","colab_type":"text"},"cell_type":"markdown","source":["###Download your data using the links provided to you"]},{"metadata":{"id":"g6AlHmHNIdw3","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget -nH --recursive --no-parent --reject 'index.*' https://aiml-sandbox.talentsprint.com/expression_detection/username/captured_face_images/ --cut-dirs=3  -P ./captured_face_images\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I8U0F_CDIhmh","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget -nH --recursive --no-parent --reject 'index.*' https://aiml-sandbox.talentsprint.com/expression_detection/username/captured_images_with_Expression/ --cut-dirs=3  -P ./captured_images_with_Expression"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sneRrCAeImPg","colab_type":"text"},"cell_type":"markdown","source":["Once downloaded using 'mv', please add the data into the respective folders IMFDB_final"]},{"metadata":{"id":"SB-LowDuCMUL","colab_type":"text"},"cell_type":"markdown","source":["##Stage 1 (Face Recognition): (15 marks) (Hint: We have an experiment on it)\n","\n","* From the provided IMFDB data, select any ten celebrity face images (100 classes is too big) and add one of your team member’s data (11th celebrity :p ) using the mobile app\n","\n","* Define and train a Siamese network\n","\n","* Save the state dictionary of the Siamese network (use pytorch only), It will be useful in\n","integrating to the mobile app\n","\n","* Define and train a classifier which takes output from the above trained Siamese network\n","(feature extraction network) as input to classify the above 11 classes\n","\n","* Save the state dictionary of the classifier (use pytorch only), It will be useful in\n","integrating to the mobile app\n","\n","* “face_recognition.py” routine in the server contains the necessary skeleton, integrate your model in\n","this to predict the face and to get similarity measure.(Note: To define the architecture of your trained model, you'll need to define it in the file \"face_recognition_model.py\")\n","\n","* .Upload your files to the given ftp server and test your model on the mobile app\n","\n","* . **Grading Scheme:**\n","\n","\n","> * Face Similarity (5M): The face similarity should close similar faces and should be\n","distant for dissimilar faces using the mobile app’s “Face Similarity” functionality\n","\n","\n","> * Face Recognition (10M): Recognize the person correctly using the mobile app’s “Face Recognition” functionality"]},{"metadata":{"id":"qDzCa-532EUj","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"XuojnAB7VTx4","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"u5CjrlPVPjNs","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"CE__iTELMolD","colab_type":"text"},"cell_type":"markdown","source":["####Save your model\n","\n","* Save the state dictionary of the classifier (use pytorch only), It will be useful in\n","integrating model to the mobile app"]},{"metadata":{"colab_type":"text","id":"V2zKlpz_MzY1"},"cell_type":"markdown","source":["#### Download your trained model using the code below\n","* given the path of model file the following code downloads it through the browser"]},{"metadata":{"colab_type":"code","id":"R7LaIqCDMzY5","colab":{}},"cell_type":"code","source":["from google.colab import files\n","files.download('<model_file_path>')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BGq6XpvhFynP","colab_type":"text"},"cell_type":"markdown","source":["##Stage 2 (Expression Recognition): (15 marks)\n","* Define and train a CNN for expression recognition with the given IMFDB data segregated\n","on expression basis.\n","* Collect your data using mobiledata and fine-tune the CNN for expression data on your team\n","* “exp_recognition.py” routine contains the necessary skeleton, integrate your model to predict the expression on the face (Note: To define the architecture of your trained model, you'll need to define it in the file \"exp_recognition_model.py\")\n","* Upload your files to the given ftp server and test your model on the mobile app\n","* Grading Scheme:\n","> * Expression Recognition (10M): If the functionality of giving back an expression\n","class for the face using the mobile app’s “Expression Recognition” functionality\n","> * Sequence Expression (5M): Get three consecutive correct Expressions using the\n","mobile app’s “Sequence Expressions” functionality"]},{"metadata":{"id":"VU5hdERsFw5o","colab_type":"code","colab":{}},"cell_type":"code","source":["##YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MOs7aj03Lo1M","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"L2p9KZobLo9C","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ut8aQN5_G7bx","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"OGixO_z6Gf-Y","colab_type":"text"},"cell_type":"markdown","source":["####Save your model\n","\n","* Save the state dictionary of the classifier (use pytorch only), It will be useful in\n","integrating model to the mobile app"]},{"metadata":{"id":"jsCHKXubHAJB","colab_type":"text"},"cell_type":"markdown","source":["#### Download your trained model using the code below\n","* given the path of model file the following code downloads it through the browser"]},{"metadata":{"id":"BDmWXfPaHJZG","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import files\n","files.download('<model_file_path>')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R7ccsM_ZISWj","colab_type":"text"},"cell_type":"markdown","source":["\n","***Stage 3 (Anti Face Spoofing): (10 marks)***\n","The objective of anti-spoofing, is to be able to unlock (say) a screen not just by your image\n","(which can be easily be spoofed with a photograph of yours) but by a switch in the expression\n","demanded by the Mobile App (which is much less probable to mimic)\n","* **Grading scheme**:\n","> * **Anti Face Spoofing**: (10M Only if both the cases mentioned below are achieved)\n",">>* **Unlock**: Correct face + Correct Demanded Expression\n",">>* **Stay Locked**: Correct face + Incorrect Demanded Expression (as you might imagine there are multiple other such possibilities, which you are free to explore)"]},{"metadata":{"id":"zQhiuXMaMRp2","colab_type":"text"},"cell_type":"markdown","source":["### Deployment instruction are given the Hackathon documentation"]},{"metadata":{"id":"jx6Y0Roy19a0","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:"]},{"metadata":{"id":"-O68_f5E2Az_","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good and Challenging me\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4YpxQ61Q2CjX","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"test\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QZWB9A6M2Fuv","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"03H962QV2Haz","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[]}]}